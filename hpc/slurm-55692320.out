SLURM_JOB_ID: 55692320
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: interpolate_cifar10_sgl
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_v100
SLURM_NNODES: 1
SLURM_NODELIST: r24g09
SLURM_JOB_CPUS_PER_NODE: 8
SLURM_JOB_GPUS: 0,1
Date: Wed Feb 21 20:49:43 CET 2024
Walltime: 00-00:15:00
========================================================================
This is before main
2024-02-21 20:49:47,883 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-21 20:49:47,884 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-21 20:49:47,884 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x150f10e9a200>' in 2 processes
This is before idist.Parallel
This is before parallel.run
2024-02-21 20:49:55,993 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-21 20:49:56,847 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 128, 'num_workers': 1, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1481ec2d49e0>, 'pin_memory': True}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
2024-02-21 20:49:57,174 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 1, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1481d773eed0>, 'pin_memory': True}
[2024-02-21 20:49:57,177][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-21 20:49:57,177][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-21 20:49:57,178][PyLogger][INFO]: GPU device: Tesla V100-SXM2-32GB
[2024-02-21 20:49:57,178][PyLogger][INFO]: CUDA version: 12.1
[2024-02-21 20:49:57,179][PyLogger][INFO]: CUDNN version: 8902
[2024-02-21 20:49:57,179][PyLogger][INFO]: Distributed setting:
[2024-02-21 20:49:57,179][PyLogger][INFO]: Backend: nccl
[2024-02-21 20:49:57,179][PyLogger][INFO]: World size: 2
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
This is start of training
This is after idist.auto_model
Files already downloaded and verified
This is after hydra.utils.instantiate
This is before checkpoint
This is before pylogger
This is before tensorboard
[2024-02-21 20:49:57,184][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-21 20:49:57,184][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-21 20:49:57,184][PyLogger][INFO]: GPU device: Tesla V100-SXM2-32GB
[2024-02-21 20:49:57,184][PyLogger][INFO]: CUDA version: 12.1
[2024-02-21 20:49:57,185][PyLogger][INFO]: CUDNN version: 8902
[2024-02-21 20:49:57,185][PyLogger][INFO]: Distributed setting:
[2024-02-21 20:49:57,185][PyLogger][INFO]: Backend: nccl
[2024-02-21 20:49:57,185][PyLogger][INFO]: World size: 2
This is start of training
This is after idist.auto_model
Files already downloaded and verified
This is after hydra.utils.instantiate
This is before checkpoint
This is before pylogger
This is before tensorboard
This is before trainer.run
Error executing job with overrides: ['dist.backend=nccl', 'dist.nproc_per_node=2', 'dist.nnodes=1', 'task_name=train_interpolate_cifar10_org', 'data=cifar10', 'metric=cifar10', 'model=interpolate_model_cifar', 'model.num_classes=10', 'model.new_size=32']
Traceback (most recent call last):
  File "/vsc-hard-mounts/leuven-data/336/vsc33647/projects/lsvd/src/train.py", line 135, in main
    parallel.run(training, cfg)
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/ignite/distributed/launcher.py", line 312, in run
    idist.spawn(self.backend, func, args=args, kwargs_dict=kwargs, **self._spawn_params)
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/ignite/distributed/utils.py", line 322, in spawn
    comp_model_cls.spawn(
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/ignite/distributed/comp_models/native.py", line 392, in spawn
    start_processes(
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
              ^^^^^^^^^^^^^^
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 158, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
    fn(i, *args)
  File "/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/ignite/distributed/comp_models/native.py", line 341, in _dist_worker_task_fn
    fn(local_rank, *args, **kw_dict)
  File "/vsc-hard-mounts/leuven-data/336/vsc33647/projects/lsvd/src/train.py", line 115, in training
    handlers[key] = hydra.utils.instantiate(value)(objects=objects)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vsc-hard-mounts/leuven-data/336/vsc33647/projects/lsvd/src/utils/tensorboard.py", line 25, in tensorboard
    return tb_logger
           ^^^^^^^^^
UnboundLocalError: cannot access local variable 'tb_logger' where it is not associated with a value


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
cat: ../.temp/interpolate_cifar10_org.txt: No such file or directory
