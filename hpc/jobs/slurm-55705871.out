SLURM_JOB_ID: 55705871
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: interpolate_cifar10_dec
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r22g39
SLURM_JOB_CPUS_PER_NODE: 18
SLURM_JOB_GPUS: 2,3
Date: Mon Feb 26 23:56:32 CET 2024
Walltime: 00-12:00:00
========================================================================
2024-02-26 23:56:37,480 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:56:37,480 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:56:37,480 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x14cc52df93a0>' in 2 processes
2024-02-26 23:56:45,588 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:56:46,423 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1530d532a240>}
2024-02-26 23:56:46,769 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1530d5339a90>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-26 23:56:46,775][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:56:46,775][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:56:46,775][PyLogger][INFO]: World size: 2
[2024-02-26 23:56:46,780][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:56:46,780][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:56:46,780][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:56:46,780][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:56:46,781][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:56:46,781][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:56:46,781][PyLogger][INFO]: World size: 2
[2024-02-26 23:57:14,994][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 2.34753
[2024-02-26 23:57:14,994][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 2.34525
[2024-02-26 23:57:42,620][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.30253
[2024-02-26 23:57:42,620][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.30638
[2024-02-26 23:58:08,932][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.25624
[2024-02-26 23:58:08,932][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.28966
[2024-02-26 23:58:35,754][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.14113
[2024-02-26 23:58:35,754][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.06777
[2024-02-26 23:59:02,094][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 2.08102
[2024-02-26 23:59:02,094][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.15668
[2024-02-26 23:59:28,759][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.04273
[2024-02-26 23:59:28,759][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 1.99807
[2024-02-26 23:59:54,980][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 1.94261
[2024-02-26 23:59:54,980][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 2.00598
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-27 00:00:21,713][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 1.88511
[2024-02-27 00:00:21,713][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 1.90953
[2024-02-27 00:00:47,878][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 1.98949
[2024-02-27 00:00:47,878][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 2.15990
[2024-02-27 00:01:42,023][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.84858
[2024-02-27 00:01:42,023][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.92896
[2024-02-27 00:02:08,299][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.87364
[2024-02-27 00:02:08,299][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.78548
[2024-02-27 00:02:34,871][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.76594
[2024-02-27 00:02:34,871][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.84046
[2024-02-27 00:03:01,070][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.88189
[2024-02-27 00:03:01,070][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.72010
[2024-02-27 00:03:27,744][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.75646
[2024-02-27 00:03:27,744][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.99396
[2024-02-27 00:03:54,126][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.66837
[2024-02-27 00:03:54,126][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.64122
[2024-02-27 00:04:20,900][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.65199
[2024-02-27 00:04:20,900][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.68265
[2024-02-27 00:04:47,271][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 2.22825
[2024-02-27 00:04:47,271][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.55789
[2024-02-27 00:05:14,066][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.59346
[2024-02-27 00:05:14,066][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.58773
[2024-02-27 00:05:40,276][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.65096
[2024-02-27 00:05:40,276][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.31814 - val_accuracy: 0.32920 - train_loss: 1.92966 - val_loss: 1.92565 - loss: 1.62020
[2024-02-27 00:06:34,444][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.57161
[2024-02-27 00:06:34,444][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.70431
[2024-02-27 00:07:00,624][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.63073
[2024-02-27 00:07:00,624][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.48614
[2024-02-27 00:07:27,405][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.42167
[2024-02-27 00:07:27,405][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.45542
[2024-02-27 00:07:53,659][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.41499
[2024-02-27 00:07:53,660][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.45128
[2024-02-27 00:08:20,458][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.46355
[2024-02-27 00:08:20,458][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.43715
[2024-02-27 00:08:46,850][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.50344
[2024-02-27 00:08:46,850][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.49667
[2024-02-27 00:09:13,609][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.37074
[2024-02-27 00:09:13,609][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.45289
[2024-02-27 00:09:39,816][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.30586
[2024-02-27 00:09:39,816][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.36910
[2024-02-27 00:10:06,622][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.40778
[2024-02-27 00:10:06,622][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.40419
[2024-02-27 00:10:32,943][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.30398
[2024-02-27 00:10:32,943][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.45409 - val_accuracy: 0.45370 - train_loss: 1.69345 - val_loss: 1.75388 - loss: 1.51520
[2024-02-27 00:11:26,877][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.26810
[2024-02-27 00:11:26,877][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.23910
[2024-02-27 00:11:53,083][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 2.24712
[2024-02-27 00:11:53,083][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.34260
[2024-02-27 00:12:19,737][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.33605
[2024-02-27 00:12:19,737][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.36168
[2024-02-27 00:12:46,884][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.35468
[2024-02-27 00:12:46,885][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.26282
[2024-02-27 00:13:13,282][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.33866
[2024-02-27 00:13:13,282][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.41231
[2024-02-27 00:13:39,999][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.40427
[2024-02-27 00:13:39,999][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.18520
[2024-02-27 00:14:06,229][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.23998
[2024-02-27 00:14:06,230][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.95240
[2024-02-27 00:14:33,394][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.17137
[2024-02-27 00:14:33,394][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.21605
[2024-02-27 00:14:59,664][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.22177
[2024-02-27 00:14:59,664][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.53157 - val_accuracy: 0.56480 - train_loss: 1.58654 - val_loss: 1.51098 - loss: 1.20644
[2024-02-27 00:15:53,677][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.11759
[2024-02-27 00:15:53,677][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.13867
[2024-02-27 00:16:19,930][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.14318
[2024-02-27 00:16:19,929][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.22439
[2024-02-27 00:16:46,800][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.17463
[2024-02-27 00:16:46,800][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.63481
[2024-02-27 00:17:12,996][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.16793
[2024-02-27 00:17:12,996][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.12934
[2024-02-27 00:17:39,964][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.15270
[2024-02-27 00:17:39,964][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.08192
[2024-02-27 00:18:06,219][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.10157
[2024-02-27 00:18:06,219][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.51703
[2024-02-27 00:18:32,945][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.71199
[2024-02-27 00:18:32,945][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.01356
[2024-02-27 00:18:59,233][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.09891
[2024-02-27 00:18:59,233][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.31019
[2024-02-27 00:19:25,932][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.24048
[2024-02-27 00:19:25,932][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.12665
[2024-02-27 00:19:52,061][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.05469
[2024-02-27 00:19:52,061][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.57059 - val_accuracy: 0.55510 - train_loss: 1.47000 - val_loss: 1.50897 - loss: 1.24569
[2024-02-27 00:20:46,271][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.01318
[2024-02-27 00:20:46,271][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.14271
[2024-02-27 00:21:12,481][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.05873
[2024-02-27 00:21:12,481][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.02224
[2024-02-27 00:21:39,152][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.64359
[2024-02-27 00:21:39,152][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.21512
[2024-02-27 00:22:05,318][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.04097
[2024-02-27 00:22:05,318][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.91254
[2024-02-27 00:22:32,057][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 0.99651
[2024-02-27 00:22:32,057][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.15593
[2024-02-27 00:22:58,395][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.31743
[2024-02-27 00:22:58,395][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.02797
[2024-02-27 00:23:25,022][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.04521
[2024-02-27 00:23:25,022][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.87517
[2024-02-27 00:23:51,321][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.01040
[2024-02-27 00:23:51,321][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.11888
[2024-02-27 00:24:17,937][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.08840
[2024-02-27 00:24:17,937][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.88100
[2024-02-27 00:24:44,070][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 0.96173
[2024-02-27 00:24:44,071][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.66358 - val_accuracy: 0.65320 - train_loss: 1.25971 - val_loss: 1.30077 - loss: 1.11402
[2024-02-27 00:25:37,961][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.00637
[2024-02-27 00:25:37,961][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.09099
[2024-02-27 00:26:04,157][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.96548
[2024-02-27 00:26:04,157][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.32461
[2024-02-27 00:26:30,775][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.90915
[2024-02-27 00:26:30,775][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.10128
[2024-02-27 00:26:56,870][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.97807
[2024-02-27 00:26:56,870][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.25574
[2024-02-27 00:27:23,739][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.00896
[2024-02-27 00:27:23,739][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.94535
[2024-02-27 00:27:50,147][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 1.81121
[2024-02-27 00:27:50,147][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.93811
[2024-02-27 00:28:16,938][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.92633
[2024-02-27 00:28:16,938][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.94820
[2024-02-27 00:28:44,284][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.89152
[2024-02-27 00:28:44,284][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.99305
[2024-02-27 00:29:10,570][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.85151
[2024-02-27 00:29:10,571][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.65311 - val_accuracy: 0.64530 - train_loss: 1.31576 - val_loss: 1.34948 - loss: 0.95580
[2024-02-27 00:30:05,971][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.89583
[2024-02-27 00:30:05,971][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.85537
[2024-02-27 00:30:32,332][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.20904
[2024-02-27 00:30:32,332][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.71670
[2024-02-27 00:30:59,142][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.91586
[2024-02-27 00:30:59,142][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.90504
[2024-02-27 00:31:25,347][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.02490
[2024-02-27 00:31:25,347][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.55051
[2024-02-27 00:31:52,200][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.85433
[2024-02-27 00:31:52,201][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.00418
[2024-02-27 00:32:18,422][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.89152
[2024-02-27 00:32:18,422][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.83527
[2024-02-27 00:32:45,307][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.83080
[2024-02-27 00:32:45,307][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.60835
[2024-02-27 00:33:11,535][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.88629
[2024-02-27 00:33:11,535][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.73451
[2024-02-27 00:33:38,254][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.97298
[2024-02-27 00:33:38,255][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.01470
[2024-02-27 00:34:04,475][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 1.85993
[2024-02-27 00:34:04,475][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.66267 - val_accuracy: 0.68810 - train_loss: 1.28226 - val_loss: 1.24511 - loss: 0.94668
[2024-02-27 00:34:58,922][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.81709
[2024-02-27 00:34:58,922][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.93500
[2024-02-27 00:35:25,208][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.49218
[2024-02-27 00:35:25,208][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.02539
[2024-02-27 00:35:51,834][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.63266
[2024-02-27 00:35:51,834][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.86248
[2024-02-27 00:36:18,098][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.77791
[2024-02-27 00:36:18,098][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.07771
[2024-02-27 00:36:44,794][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.85129
[2024-02-27 00:36:44,795][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.02677
[2024-02-27 00:37:10,973][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.79213
[2024-02-27 00:37:10,973][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.87304
[2024-02-27 00:37:37,705][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.81704
[2024-02-27 00:37:37,705][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.84668
[2024-02-27 00:38:03,939][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.78308
[2024-02-27 00:38:03,939][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.73713
[2024-02-27 00:38:30,500][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.85772
[2024-02-27 00:38:30,500][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 1.72742
[2024-02-27 00:38:56,685][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.70897
[2024-02-27 00:38:56,685][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.73121 - val_accuracy: 0.65480 - train_loss: 1.12623 - val_loss: 1.33908 - loss: 0.76048
[2024-02-27 00:39:50,737][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.72812
[2024-02-27 00:39:50,737][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.72200
[2024-02-27 00:40:17,006][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.78522
[2024-02-27 00:40:17,006][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.45859
[2024-02-27 00:40:43,633][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.27052
[2024-02-27 00:40:43,633][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.80631
[2024-02-27 00:41:09,811][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.89046
[2024-02-27 00:41:09,811][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.75215
[2024-02-27 00:41:36,479][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.24900
[2024-02-27 00:41:36,479][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.83946
[2024-02-27 00:42:02,606][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.11844
[2024-02-27 00:42:02,606][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.88369
[2024-02-27 00:42:29,354][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.73486
[2024-02-27 00:42:29,354][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.84037
[2024-02-27 00:42:55,661][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.59429
[2024-02-27 00:42:55,661][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.82444
[2024-02-27 00:43:22,373][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.05328
[2024-02-27 00:43:22,373][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 1.53953
[2024-02-27 00:43:48,705][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.88413
[2024-02-27 00:43:48,705][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.70838 - val_accuracy: 0.68540 - train_loss: 1.16731 - val_loss: 1.23788 - loss: 0.74194
[2024-02-27 00:44:43,206][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.72122
[2024-02-27 00:44:43,206][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.69412
[2024-02-27 00:45:09,780][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.73080
[2024-02-27 00:45:09,780][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.75358
[2024-02-27 00:45:36,148][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.72729
[2024-02-27 00:45:36,148][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.83829
[2024-02-27 00:46:02,952][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.86414
[2024-02-27 00:46:02,952][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.69721
[2024-02-27 00:46:29,265][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.73538
[2024-02-27 00:46:29,266][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.73275
[2024-02-27 00:46:55,970][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.73072
[2024-02-27 00:46:55,970][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 1.07841
[2024-02-27 00:47:22,037][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.95134
[2024-02-27 00:47:22,037][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.78608
[2024-02-27 00:47:48,812][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.72481
[2024-02-27 00:47:48,812][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.74955
[2024-02-27 00:48:15,044][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 1.93550
[2024-02-27 00:48:15,044][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.72435 - val_accuracy: 0.71140 - train_loss: 1.15004 - val_loss: 1.19474 - loss: 0.81944
[2024-02-27 00:49:10,449][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.71975
[2024-02-27 00:49:10,449][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.75645
[2024-02-27 00:49:36,456][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.98715
[2024-02-27 00:49:36,456][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.77585
[2024-02-27 00:50:02,971][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.75089
[2024-02-27 00:50:02,971][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.77125
[2024-02-27 00:50:29,249][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.91471
[2024-02-27 00:50:29,249][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.69610
[2024-02-27 00:50:55,895][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.74145
[2024-02-27 00:50:55,895][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.74984
[2024-02-27 00:51:21,993][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 1.32130
[2024-02-27 00:51:21,993][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.93212
[2024-02-27 00:51:48,492][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 1.12432
[2024-02-27 00:51:48,492][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.93396
[2024-02-27 00:52:14,795][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 1.13281
[2024-02-27 00:52:14,795][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.93092
[2024-02-27 00:52:41,501][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.76290
[2024-02-27 00:52:41,501][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 0.66118
[2024-02-27 00:53:07,603][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 1.12653
[2024-02-27 00:53:07,603][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.75157 - val_accuracy: 0.67170 - train_loss: 1.09433 - val_loss: 1.34359 - loss: 1.34824
[2024-02-27 00:54:02,846][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.69497
[2024-02-27 00:54:02,846][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.73616
[2024-02-27 00:54:28,885][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.80368
[2024-02-27 00:54:28,885][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.79832
[2024-02-27 00:54:55,576][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.83743
[2024-02-27 00:54:55,576][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.77711
[2024-02-27 00:55:21,607][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.04957
[2024-02-27 00:55:21,607][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.64012
[2024-02-27 00:55:48,213][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.20035
[2024-02-27 00:55:48,213][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.40643
[2024-02-27 00:56:14,464][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.30528
[2024-02-27 00:56:14,464][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.67924
[2024-02-27 00:56:41,095][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 2.00514
[2024-02-27 00:56:41,095][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.68943
[2024-02-27 00:57:07,161][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.73602
[2024-02-27 00:57:07,161][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 1.39801
[2024-02-27 00:57:33,750][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.96284
[2024-02-27 00:57:33,750][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.74401
[2024-02-27 00:57:59,964][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.70392
[2024-02-27 00:57:59,964][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.75648 - val_accuracy: 0.79080 - train_loss: 1.10756 - val_loss: 1.00852 - loss: 0.69700
[2024-02-27 00:58:53,624][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.77577
[2024-02-27 00:58:53,624][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.92441
[2024-02-27 00:59:19,799][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.69251
[2024-02-27 00:59:19,799][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.76126
[2024-02-27 00:59:46,304][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 1.00758
[2024-02-27 00:59:46,304][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.76776
[2024-02-27 01:00:13,018][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.65638
[2024-02-27 01:00:13,018][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.66249
[2024-02-27 01:00:39,218][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.76105
[2024-02-27 01:00:39,218][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 1.07802
[2024-02-27 01:01:05,732][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.71354
[2024-02-27 01:01:05,732][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.70038
[2024-02-27 01:01:31,913][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.86409
[2024-02-27 01:01:31,913][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 1.19108
[2024-02-27 01:01:58,448][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.65745
[2024-02-27 01:01:58,448][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.70964
[2024-02-27 01:02:24,672][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 0.71058
[2024-02-27 01:02:24,672][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.74789 - val_accuracy: 0.75430 - train_loss: 1.07254 - val_loss: 1.07384 - loss: 1.79681
[2024-02-27 01:03:18,273][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.62900
[2024-02-27 01:03:18,273][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.97710
[2024-02-27 01:03:44,333][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 1.55991
[2024-02-27 01:03:44,333][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.96940
[2024-02-27 01:04:11,002][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.83752
[2024-02-27 01:04:11,002][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.70999
[2024-02-27 01:04:37,164][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.63788
[2024-02-27 01:04:37,164][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.73343
[2024-02-27 01:05:03,759][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.72909
[2024-02-27 01:05:03,759][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.65570
[2024-02-27 01:05:29,785][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.66011
[2024-02-27 01:05:29,786][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.68079
[2024-02-27 01:05:56,348][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 1.75677
[2024-02-27 01:05:56,348][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.70312
[2024-02-27 01:06:22,456][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 1.00104
[2024-02-27 01:06:22,456][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 1.39352
[2024-02-27 01:06:49,011][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 1.07623
[2024-02-27 01:06:49,011][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.73052
[2024-02-27 01:07:15,141][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.66660
[2024-02-27 01:07:15,141][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.77104 - val_accuracy: 0.70800 - train_loss: 1.05591 - val_loss: 1.25091 - loss: 0.66183
[2024-02-27 01:08:08,899][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.65148
[2024-02-27 01:08:08,899][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.66799
[2024-02-27 01:08:35,120][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.61245
[2024-02-27 01:08:35,120][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.91242
[2024-02-27 01:09:01,727][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.67687
[2024-02-27 01:09:01,727][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.61778
[2024-02-27 01:09:27,824][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 1.13811
[2024-02-27 01:09:27,824][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.74342
[2024-02-27 01:09:54,333][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 1.28658
[2024-02-27 01:09:54,333][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.71314
[2024-02-27 01:10:20,406][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.63635
[2024-02-27 01:10:20,406][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.73635
[2024-02-27 01:10:47,111][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.71749
[2024-02-27 01:10:47,111][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.71448
[2024-02-27 01:11:13,248][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.65549
[2024-02-27 01:11:13,248][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.67346
[2024-02-27 01:11:39,845][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.65751
[2024-02-27 01:11:39,845][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 1.15526
[2024-02-27 01:12:05,994][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 0.61505
[2024-02-27 01:12:05,994][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.74289 - val_accuracy: 0.74350 - train_loss: 1.08397 - val_loss: 1.08180 - loss: 1.94681
[2024-02-27 01:12:59,623][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 1.64370
[2024-02-27 01:12:59,623][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.81954
[2024-02-27 01:13:25,781][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.66275
[2024-02-27 01:13:25,781][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 1.00897
[2024-02-27 01:13:52,347][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.64288
[2024-02-27 01:13:52,347][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.61291
[2024-02-27 01:14:18,417][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.63462
[2024-02-27 01:14:18,417][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.79714
[2024-02-27 01:14:44,917][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 2.00730
[2024-02-27 01:14:44,917][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.64602
[2024-02-27 01:15:11,003][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.68953
[2024-02-27 01:15:11,003][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.63583
[2024-02-27 01:15:37,684][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 1.39695
[2024-02-27 01:15:37,684][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 1.92926
[2024-02-27 01:16:04,372][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.62678
[2024-02-27 01:16:04,372][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 0.64668
[2024-02-27 01:16:30,482][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 1.00002
[2024-02-27 01:16:30,482][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.79528 - val_accuracy: 0.74200 - train_loss: 1.00978 - val_loss: 1.17569 - loss: 2.05413
[2024-02-27 01:17:24,152][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.67477
[2024-02-27 01:17:24,152][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.65785
[2024-02-27 01:17:50,218][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.66699
[2024-02-27 01:17:50,218][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.64243
[2024-02-27 01:18:16,830][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.67345
[2024-02-27 01:18:16,830][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.69930
[2024-02-27 01:18:42,999][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.68929
[2024-02-27 01:18:42,999][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.61795
[2024-02-27 01:19:09,545][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.63541
[2024-02-27 01:19:09,545][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 1.84771
[2024-02-27 01:19:35,588][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.64245
[2024-02-27 01:19:35,588][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.65701
[2024-02-27 01:20:02,053][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.66643
[2024-02-27 01:20:02,053][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.73939
[2024-02-27 01:20:28,174][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.80273
[2024-02-27 01:20:28,174][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.69443
[2024-02-27 01:20:54,696][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.69511
[2024-02-27 01:20:54,696][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.72303
[2024-02-27 01:21:20,929][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 2.06761
[2024-02-27 01:21:20,929][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.80034 - val_accuracy: 0.78820 - train_loss: 0.97623 - val_loss: 1.01844 - loss: 0.62063
[2024-02-27 01:22:14,462][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.63919
[2024-02-27 01:22:14,462][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.59619
[2024-02-27 01:22:40,534][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.83660
[2024-02-27 01:22:40,535][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.01388
[2024-02-27 01:23:07,183][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.64825
[2024-02-27 01:23:07,183][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.27517
[2024-02-27 01:23:33,263][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.36425
[2024-02-27 01:23:33,263][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.65124
[2024-02-27 01:23:59,636][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.66593
[2024-02-27 01:23:59,636][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.60812
[2024-02-27 01:24:25,641][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.64548
[2024-02-27 01:24:25,641][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.61941
[2024-02-27 01:24:52,163][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.68016
[2024-02-27 01:24:52,163][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.60930
[2024-02-27 01:25:18,197][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.68416
[2024-02-27 01:25:18,197][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.69214
[2024-02-27 01:25:44,689][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.60449
[2024-02-27 01:25:44,689][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 0.64430
[2024-02-27 01:26:10,683][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.16929
[2024-02-27 01:26:10,682][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.75763 - val_accuracy: 0.69190 - train_loss: 1.07609 - val_loss: 1.27565 - loss: 1.99997
[2024-02-27 01:27:04,091][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.58131
[2024-02-27 01:27:04,091][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.59659
[2024-02-27 01:27:30,169][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 1.79629
[2024-02-27 01:27:30,169][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 1.18813
[2024-02-27 01:27:56,581][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.71537
[2024-02-27 01:27:56,582][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.71073
[2024-02-27 01:28:22,533][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.63293
[2024-02-27 01:28:22,533][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.66522
[2024-02-27 01:28:48,934][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.67846
[2024-02-27 01:28:48,934][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 1.99345
[2024-02-27 01:29:14,979][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.98306
[2024-02-27 01:29:14,979][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.72692
[2024-02-27 01:29:41,471][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.60126
[2024-02-27 01:29:41,471][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 1.06324
[2024-02-27 01:30:07,616][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.59654
[2024-02-27 01:30:07,616][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.59451
[2024-02-27 01:30:34,206][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 1.17415
[2024-02-27 01:30:34,206][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.57545
[2024-02-27 01:31:00,268][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.65582
[2024-02-27 01:31:00,269][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.80394 - val_accuracy: 0.76400 - train_loss: 0.98001 - val_loss: 1.08326 - loss: 0.64731
[2024-02-27 01:31:53,813][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 1.61208
[2024-02-27 01:31:53,813][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.90245
[2024-02-27 01:32:20,354][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.67576
[2024-02-27 01:32:20,354][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.65393
[2024-02-27 01:32:46,345][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.66314
[2024-02-27 01:32:46,345][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.61753
[2024-02-27 01:33:12,827][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.63251
[2024-02-27 01:33:12,827][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.64019
[2024-02-27 01:33:38,828][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.69831
[2024-02-27 01:33:38,828][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.90813
[2024-02-27 01:34:05,313][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.64906
[2024-02-27 01:34:05,314][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.64488
[2024-02-27 01:34:31,361][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.66279
[2024-02-27 01:34:31,361][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.69472
[2024-02-27 01:34:57,795][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.62731
[2024-02-27 01:34:57,795][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.61603
[2024-02-27 01:35:23,790][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.66412
[2024-02-27 01:35:23,790][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.73524 - val_accuracy: 0.73930 - train_loss: 1.15317 - val_loss: 1.14375 - loss: 0.62341
[2024-02-27 01:36:17,294][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.55614
[2024-02-27 01:36:17,294][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.61598
[2024-02-27 01:36:43,477][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.86804
[2024-02-27 01:36:43,477][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.66362
[2024-02-27 01:37:09,976][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.63047
[2024-02-27 01:37:09,976][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 1.77608
[2024-02-27 01:37:36,076][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 1.26742
[2024-02-27 01:37:36,076][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.59298
[2024-02-27 01:38:02,494][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.75192
[2024-02-27 01:38:02,494][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.89070
[2024-02-27 01:38:28,558][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.63860
[2024-02-27 01:38:28,558][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.68354
[2024-02-27 01:38:55,140][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.77171
[2024-02-27 01:38:55,140][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.90255
[2024-02-27 01:39:21,297][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.77835
[2024-02-27 01:39:21,297][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.62908
[2024-02-27 01:39:47,874][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.60920
[2024-02-27 01:39:47,874][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 0.60964
[2024-02-27 01:40:14,001][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 1.60436
[2024-02-27 01:40:14,001][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.79446 - val_accuracy: 0.76280 - train_loss: 0.98066 - val_loss: 1.07297 - loss: 1.48722
[2024-02-27 01:41:07,826][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.75762
[2024-02-27 01:41:07,826][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 1.98222
[2024-02-27 01:41:33,957][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.64147
[2024-02-27 01:41:33,957][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.57704
[2024-02-27 01:42:00,420][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.80070
[2024-02-27 01:42:00,420][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.63601
[2024-02-27 01:42:26,564][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.93126
[2024-02-27 01:42:26,564][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.62224
[2024-02-27 01:42:53,129][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.60804
[2024-02-27 01:42:53,129][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.82451
[2024-02-27 01:43:19,231][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.61529
[2024-02-27 01:43:19,231][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.64167
[2024-02-27 01:43:45,789][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.61593
[2024-02-27 01:43:45,789][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.69674
[2024-02-27 01:44:11,806][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.62304
[2024-02-27 01:44:11,806][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.63093
[2024-02-27 01:44:38,298][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.62617
[2024-02-27 01:44:38,299][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.61959
[2024-02-27 01:45:04,410][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 1.18438
[2024-02-27 01:45:04,410][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.78747 - val_accuracy: 0.71160 - train_loss: 1.04550 - val_loss: 1.26785 - loss: 0.60821
[2024-02-27 01:45:57,777][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 1.18803
[2024-02-27 01:45:57,777][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.59629
[2024-02-27 01:46:23,899][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.74530
[2024-02-27 01:46:23,899][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.78535
[2024-02-27 01:46:50,601][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.69340
[2024-02-27 01:46:50,601][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.73786
[2024-02-27 01:47:17,117][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 1.12282
[2024-02-27 01:47:17,117][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.60288
[2024-02-27 01:47:43,147][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.62135
[2024-02-27 01:47:43,147][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.63864
[2024-02-27 01:48:09,522][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.60803
[2024-02-27 01:48:09,522][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.54835
[2024-02-27 01:48:35,514][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.58693
[2024-02-27 01:48:35,514][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.59710
[2024-02-27 01:49:02,036][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.55929
[2024-02-27 01:49:02,036][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.92692
[2024-02-27 01:49:28,057][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.79909
[2024-02-27 01:49:28,057][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.79504 - val_accuracy: 0.80420 - train_loss: 1.00423 - val_loss: 0.96350 - loss: 0.63208
[2024-02-27 01:50:21,501][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.59791
[2024-02-27 01:50:21,501][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 1.83680
[2024-02-27 01:50:47,522][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.57509
[2024-02-27 01:50:47,522][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.97317
[2024-02-27 01:51:14,133][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.62415
[2024-02-27 01:51:14,133][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.58514
[2024-02-27 01:51:40,237][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.71244
[2024-02-27 01:51:40,237][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.58494
[2024-02-27 01:52:06,858][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.84079
[2024-02-27 01:52:06,857][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 1.76353
[2024-02-27 01:52:32,947][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.59751
[2024-02-27 01:52:32,947][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.60103
[2024-02-27 01:52:59,394][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.58836
[2024-02-27 01:52:59,394][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.70538
[2024-02-27 01:53:25,356][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.58549
[2024-02-27 01:53:25,356][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.56466
[2024-02-27 01:53:51,821][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.58316
[2024-02-27 01:53:51,821][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.59983
[2024-02-27 01:54:17,755][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.68353
[2024-02-27 01:54:17,755][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.78830 - val_accuracy: 0.66600 - train_loss: 1.03549 - val_loss: 1.39244 - loss: 0.56973
[2024-02-27 01:55:11,207][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.59940
[2024-02-27 01:55:11,207][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 1.94296
[2024-02-27 01:55:37,289][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.54905
[2024-02-27 01:55:37,289][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.60614
[2024-02-27 01:56:03,782][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.55550
[2024-02-27 01:56:03,782][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.63621
[2024-02-27 01:56:29,905][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.60384
[2024-02-27 01:56:29,905][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.62414
[2024-02-27 01:56:56,670][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.60511
[2024-02-27 01:56:56,670][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 1.90080
[2024-02-27 01:57:22,881][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.63403
[2024-02-27 01:57:22,881][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.56925
[2024-02-27 01:57:49,503][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.57344
[2024-02-27 01:57:49,503][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.56739
[2024-02-27 01:58:15,510][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.66619
[2024-02-27 01:58:15,510][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 1.22292
[2024-02-27 01:58:42,160][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.59338
[2024-02-27 01:58:42,160][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.59022
[2024-02-27 01:59:08,198][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.57026
[2024-02-27 01:59:08,198][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.79536 - val_accuracy: 0.68470 - train_loss: 1.01445 - val_loss: 1.37349 - loss: 0.54386
[2024-02-27 02:00:03,274][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.58152
[2024-02-27 02:00:03,274][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.53896
[2024-02-27 02:00:29,274][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.70745
[2024-02-27 02:00:29,274][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.71013
[2024-02-27 02:00:55,904][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.63270
[2024-02-27 02:00:55,904][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.95502
[2024-02-27 02:01:21,863][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.76176
[2024-02-27 02:01:21,863][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.67328
[2024-02-27 02:01:48,274][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.60482
[2024-02-27 02:01:48,274][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.56729
[2024-02-27 02:02:14,171][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.59317
[2024-02-27 02:02:14,171][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 1.19133
[2024-02-27 02:02:40,556][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.55178
[2024-02-27 02:02:40,556][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.55970
[2024-02-27 02:03:07,133][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.55560
[2024-02-27 02:03:07,133][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.57265
[2024-02-27 02:03:33,203][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 1.28948
[2024-02-27 02:03:33,203][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.79446 - val_accuracy: 0.76430 - train_loss: 1.04606 - val_loss: 1.14182 - loss: 0.57648
[2024-02-27 02:04:27,691][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.58847
[2024-02-27 02:04:27,691][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.90165
[2024-02-27 02:04:53,662][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.64131
[2024-02-27 02:04:53,662][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 1.13882
[2024-02-27 02:05:20,111][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.79122
[2024-02-27 02:05:20,111][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.75157
[2024-02-27 02:05:46,183][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.54224
[2024-02-27 02:05:46,183][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 1.00051
[2024-02-27 02:06:12,923][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.59480
[2024-02-27 02:06:12,923][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 1.04572
[2024-02-27 02:06:38,937][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.55694
[2024-02-27 02:06:38,937][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.64863
[2024-02-27 02:07:05,486][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.55806
[2024-02-27 02:07:05,486][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.56412
[2024-02-27 02:07:31,500][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.56085
[2024-02-27 02:07:31,500][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.59000
[2024-02-27 02:07:57,894][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 1.05284
[2024-02-27 02:07:57,894][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.56786
[2024-02-27 02:08:23,797][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.62443
[2024-02-27 02:08:23,797][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.81596 - val_accuracy: 0.79750 - train_loss: 0.95315 - val_loss: 1.02511 - loss: 0.56870
[2024-02-27 02:09:17,189][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.55146
[2024-02-27 02:09:17,189][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.53773
[2024-02-27 02:09:43,260][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.58883
[2024-02-27 02:09:43,260][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 1.21610
[2024-02-27 02:10:09,743][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.56585
[2024-02-27 02:10:09,743][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.72819
[2024-02-27 02:10:35,894][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 1.24075
[2024-02-27 02:10:35,894][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.62620
[2024-02-27 02:11:02,586][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.55455
[2024-02-27 02:11:02,586][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.58603
[2024-02-27 02:11:28,515][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 1.17076
[2024-02-27 02:11:28,515][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.72604
[2024-02-27 02:11:54,950][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.63117
[2024-02-27 02:11:54,950][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.53618
[2024-02-27 02:12:20,956][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.92477
[2024-02-27 02:12:20,956][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.58590
[2024-02-27 02:12:47,432][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.58233
[2024-02-27 02:12:47,432][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.69435
[2024-02-27 02:13:13,391][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.58232
[2024-02-27 02:13:13,391][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.77318 - val_accuracy: 0.73850 - train_loss: 1.02257 - val_loss: 1.12668 - loss: 0.54947
[2024-02-27 02:14:06,915][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 1.19891
[2024-02-27 02:14:06,915][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 2.01193
[2024-02-27 02:14:32,942][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.72486
[2024-02-27 02:14:32,942][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.62169
[2024-02-27 02:14:59,441][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.98693
[2024-02-27 02:14:59,441][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.55464
[2024-02-27 02:15:25,437][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.57433
[2024-02-27 02:15:25,437][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.54732
[2024-02-27 02:15:51,926][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.62816
[2024-02-27 02:15:51,926][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.56778
[2024-02-27 02:16:18,077][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.60134
[2024-02-27 02:16:18,077][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.54955
[2024-02-27 02:16:44,611][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.56748
[2024-02-27 02:16:44,611][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.54856
[2024-02-27 02:17:10,677][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.57098
[2024-02-27 02:17:10,677][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 1.17967
[2024-02-27 02:17:37,119][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.54253
[2024-02-27 02:17:37,119][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.60202
[2024-02-27 02:18:03,122][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.93460
[2024-02-27 02:18:03,122][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.80958 - val_accuracy: 0.76180 - train_loss: 0.96818 - val_loss: 1.08516 - loss: 0.59868
[2024-02-27 02:18:57,541][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 1.04011
[2024-02-27 02:18:57,541][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.55323
[2024-02-27 02:19:23,967][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.53794
[2024-02-27 02:19:23,967][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.54869
[2024-02-27 02:19:49,921][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.54122
[2024-02-27 02:19:49,921][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 1.24845
[2024-02-27 02:20:16,482][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 1.13985
[2024-02-27 02:20:16,482][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.60928
[2024-02-27 02:20:42,528][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.55167
[2024-02-27 02:20:42,528][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.57478
[2024-02-27 02:21:08,908][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.56741
[2024-02-27 02:21:08,908][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.58567
[2024-02-27 02:21:34,937][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.60905
[2024-02-27 02:21:34,937][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 1.36935
[2024-02-27 02:22:01,807][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.56990
[2024-02-27 02:22:01,807][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 1.25677
[2024-02-27 02:22:27,914][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.62650
[2024-02-27 02:22:27,914][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.82621 - val_accuracy: 0.79480 - train_loss: 0.94886 - val_loss: 1.02117 - loss: 0.64775
[2024-02-27 02:23:21,345][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.56242
[2024-02-27 02:23:21,345][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.89947
[2024-02-27 02:23:47,357][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.55559
[2024-02-27 02:23:47,357][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 1.01243
[2024-02-27 02:24:14,132][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.71022
[2024-02-27 02:24:14,132][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 1.01233
[2024-02-27 02:24:40,162][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.55576
[2024-02-27 02:24:40,162][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.68750
[2024-02-27 02:25:06,613][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.58414
[2024-02-27 02:25:06,613][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 1.80450
[2024-02-27 02:25:32,609][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.59956
[2024-02-27 02:25:32,609][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.57891
[2024-02-27 02:25:58,956][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.71399
[2024-02-27 02:25:58,956][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.52267
[2024-02-27 02:26:25,078][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 1.19047
[2024-02-27 02:26:25,078][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.56697
[2024-02-27 02:26:51,506][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.58143
[2024-02-27 02:26:51,506][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.52152
[2024-02-27 02:27:17,519][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.56127
[2024-02-27 02:27:17,519][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.81912 - val_accuracy: 0.63070 - train_loss: 0.97416 - val_loss: 1.51703 - loss: 0.57449
[2024-02-27 02:28:10,543][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.31829
[2024-02-27 02:28:10,543][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.84339
[2024-02-27 02:28:36,676][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.59983
[2024-02-27 02:28:36,676][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.55419
[2024-02-27 02:29:03,101][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.21959
[2024-02-27 02:29:03,101][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.66378
[2024-02-27 02:29:29,130][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.59154
[2024-02-27 02:29:29,130][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.55453
[2024-02-27 02:29:55,740][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.52914
[2024-02-27 02:29:55,740][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.53676
[2024-02-27 02:30:21,624][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.95457
[2024-02-27 02:30:21,624][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.59691
[2024-02-27 02:30:48,086][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.56443
[2024-02-27 02:30:48,086][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.55263
[2024-02-27 02:31:14,097][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.54684
[2024-02-27 02:31:14,097][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.58183
[2024-02-27 02:31:40,625][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.41294
[2024-02-27 02:31:40,625][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.79317
[2024-02-27 02:32:06,787][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 0.58065
[2024-02-27 02:32:06,787][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.84607 - val_accuracy: 0.74330 - train_loss: 0.88394 - val_loss: 1.15818 - loss: 1.74449
[2024-02-27 02:33:00,138][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 1.77354
[2024-02-27 02:33:00,138][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.69011
[2024-02-27 02:33:26,187][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.56881
[2024-02-27 02:33:26,187][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.57362
[2024-02-27 02:33:52,723][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.57434
[2024-02-27 02:33:52,723][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.61718
[2024-02-27 02:34:19,196][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 1.57047
[2024-02-27 02:34:19,196][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.56001
[2024-02-27 02:34:45,224][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.53460
[2024-02-27 02:34:45,224][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.69416
[2024-02-27 02:35:11,681][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.58432
[2024-02-27 02:35:11,681][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.54726
[2024-02-27 02:35:37,765][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.63756
[2024-02-27 02:35:37,765][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 1.00044
[2024-02-27 02:36:04,375][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 1.12915
[2024-02-27 02:36:04,375][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.56038
[2024-02-27 02:36:30,419][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.56935
[2024-02-27 02:36:30,420][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.82289 - val_accuracy: 0.81400 - train_loss: 0.93830 - val_loss: 0.95800 - loss: 0.80104
[2024-02-27 02:37:24,272][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.52171
[2024-02-27 02:37:24,272][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.89843
[2024-02-27 02:37:50,362][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.52899
[2024-02-27 02:37:50,362][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.59265
[2024-02-27 02:38:16,941][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.54593
[2024-02-27 02:38:16,941][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 1.46850
[2024-02-27 02:38:42,940][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.81902
[2024-02-27 02:38:42,940][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.63334
[2024-02-27 02:39:09,377][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.67764
[2024-02-27 02:39:09,377][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.59368
[2024-02-27 02:39:35,492][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 1.42270
[2024-02-27 02:39:35,492][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.53996
[2024-02-27 02:40:02,254][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.59026
[2024-02-27 02:40:02,254][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.53207
[2024-02-27 02:40:28,471][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.54767
[2024-02-27 02:40:28,471][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.54275
[2024-02-27 02:40:55,342][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 1.95808
[2024-02-27 02:40:55,342][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.56303
[2024-02-27 02:41:21,449][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.58629
[2024-02-27 02:41:21,449][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.84766 - val_accuracy: 0.78450 - train_loss: 0.91299 - val_loss: 1.13041 - loss: 0.59186
[2024-02-27 02:42:16,424][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.52112
[2024-02-27 02:42:16,424][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.55559
[2024-02-27 02:42:42,399][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.60597
[2024-02-27 02:42:42,399][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.55415
[2024-02-27 02:43:09,052][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.58096
[2024-02-27 02:43:09,052][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.56292
[2024-02-27 02:43:35,114][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.55975
[2024-02-27 02:43:35,114][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.82445
[2024-02-27 02:44:01,639][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.55108
[2024-02-27 02:44:01,639][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.78937
[2024-02-27 02:44:27,597][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.56949
[2024-02-27 02:44:27,597][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.58429
[2024-02-27 02:44:54,009][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.53822
[2024-02-27 02:44:54,009][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.54090
[2024-02-27 02:45:20,030][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.54497
[2024-02-27 02:45:20,030][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 1.27679
[2024-02-27 02:45:46,421][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.56000
[2024-02-27 02:45:46,421][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 1.09534
[2024-02-27 02:46:12,383][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.55233
[2024-02-27 02:46:12,383][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.82935 - val_accuracy: 0.80040 - train_loss: 0.93617 - val_loss: 1.01438 - loss: 0.53523
[2024-02-27 02:47:06,186][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.54215
[2024-02-27 02:47:06,186][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.55037
[2024-02-27 02:47:32,165][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.53980
[2024-02-27 02:47:32,165][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.54235
[2024-02-27 02:47:58,690][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.51709
[2024-02-27 02:47:58,690][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.75826
[2024-02-27 02:48:24,865][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.57703
[2024-02-27 02:48:24,865][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.61133
[2024-02-27 02:48:51,377][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 1.51803
[2024-02-27 02:48:51,377][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.53063
[2024-02-27 02:49:17,518][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 1.16696
[2024-02-27 02:49:17,518][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.53202
[2024-02-27 02:49:44,209][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.61552
[2024-02-27 02:49:44,209][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.59450
[2024-02-27 02:50:10,913][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.65358
[2024-02-27 02:50:10,913][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.54274
[2024-02-27 02:50:36,977][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.63748
[2024-02-27 02:50:36,977][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.83719 - val_accuracy: 0.84420 - train_loss: 0.95384 - val_loss: 0.87125 - loss: 0.52037
[2024-02-27 02:51:30,225][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.56819
[2024-02-27 02:51:30,226][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.83317
[2024-02-27 02:51:56,137][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.61167
[2024-02-27 02:51:56,137][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.57627
[2024-02-27 02:52:22,527][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.75905
[2024-02-27 02:52:22,527][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.55518
[2024-02-27 02:52:48,549][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.03821
[2024-02-27 02:52:48,549][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.57358
[2024-02-27 02:53:15,225][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.04380
[2024-02-27 02:53:15,225][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.52208
[2024-02-27 02:53:41,178][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.15514
[2024-02-27 02:53:41,178][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.45706
[2024-02-27 02:54:07,525][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.62430
[2024-02-27 02:54:07,526][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.53685
[2024-02-27 02:54:33,634][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.56170
[2024-02-27 02:54:33,635][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.50634
[2024-02-27 02:55:00,165][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.58251
[2024-02-27 02:55:00,165][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.61727
[2024-02-27 02:55:26,339][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 0.53514
[2024-02-27 02:55:26,339][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.82637 - val_accuracy: 0.73430 - train_loss: 0.94554 - val_loss: 1.21539 - loss: 1.01596
[2024-02-27 02:56:19,762][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.54022
[2024-02-27 02:56:19,763][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.65975
[2024-02-27 02:56:45,832][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.55004
[2024-02-27 02:56:45,832][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.53658
[2024-02-27 02:57:12,351][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.53848
[2024-02-27 02:57:12,351][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.89792
[2024-02-27 02:57:38,337][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.55717
[2024-02-27 02:57:38,337][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.72514
[2024-02-27 02:58:04,883][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.68799
[2024-02-27 02:58:04,883][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.58722
[2024-02-27 02:58:30,996][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.61547
[2024-02-27 02:58:30,996][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.64485
[2024-02-27 02:58:57,554][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.54725
[2024-02-27 02:58:57,554][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.57092
[2024-02-27 02:59:23,695][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.53202
[2024-02-27 02:59:23,695][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 1.55613
[2024-02-27 02:59:50,459][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.64339
[2024-02-27 02:59:50,459][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.92394
[2024-02-27 03:00:16,440][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.81092
[2024-02-27 03:00:16,440][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.82633 - val_accuracy: 0.79100 - train_loss: 0.93171 - val_loss: 1.01701 - loss: 0.54588
[2024-02-27 03:01:09,962][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.54539
[2024-02-27 03:01:09,962][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.52261
[2024-02-27 03:01:36,031][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.63737
[2024-02-27 03:01:36,031][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 1.49352
[2024-02-27 03:02:02,543][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.77074
[2024-02-27 03:02:02,543][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.66759
[2024-02-27 03:02:28,511][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.52519
[2024-02-27 03:02:28,511][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.99331
[2024-02-27 03:02:54,902][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 1.57585
[2024-02-27 03:02:54,902][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.55238
[2024-02-27 03:03:21,052][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.53272
[2024-02-27 03:03:21,052][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.58282
[2024-02-27 03:03:47,607][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 1.33370
[2024-02-27 03:03:47,607][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.52859
[2024-02-27 03:04:13,824][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.56632
[2024-02-27 03:04:13,824][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.98404
[2024-02-27 03:04:40,324][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.89622
[2024-02-27 03:04:40,324][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.58800
[2024-02-27 03:05:06,232][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.56103
[2024-02-27 03:05:06,232][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.83612 - val_accuracy: 0.80310 - train_loss: 0.93503 - val_loss: 1.00368 - loss: 0.51990
[2024-02-27 03:05:59,471][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.56245
[2024-02-27 03:05:59,471][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.52153
[2024-02-27 03:06:25,948][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 1.97578
[2024-02-27 03:06:25,948][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.51736
[2024-02-27 03:06:51,909][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.60366
[2024-02-27 03:06:51,909][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.54852
[2024-02-27 03:07:18,500][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 1.98274
[2024-02-27 03:07:18,500][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.53704
[2024-02-27 03:07:44,541][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 1.32873
[2024-02-27 03:07:44,541][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.84774
[2024-02-27 03:08:10,921][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.57523
[2024-02-27 03:08:10,921][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.56106
[2024-02-27 03:08:36,926][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.52341
[2024-02-27 03:08:36,926][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.72732
[2024-02-27 03:09:03,446][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.54620
[2024-02-27 03:09:03,446][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.53608
[2024-02-27 03:09:29,350][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 0.96065
[2024-02-27 03:09:29,350][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.83390 - val_accuracy: 0.64910 - train_loss: 0.92369 - val_loss: 1.48462 - loss: 1.30885
[2024-02-27 03:10:22,774][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.54085
[2024-02-27 03:10:22,774][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.53596
[2024-02-27 03:10:48,723][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 2.07188
[2024-02-27 03:10:48,723][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.54726
[2024-02-27 03:11:15,408][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.64069
[2024-02-27 03:11:15,408][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.52012
[2024-02-27 03:11:41,507][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.53000
[2024-02-27 03:11:41,508][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 1.65113
[2024-02-27 03:12:08,012][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.52539
[2024-02-27 03:12:08,012][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.57768
[2024-02-27 03:12:34,146][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.53665
[2024-02-27 03:12:34,146][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.58825
[2024-02-27 03:13:00,617][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 1.09284
[2024-02-27 03:13:00,617][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.86249
[2024-02-27 03:13:26,546][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.52688
[2024-02-27 03:13:26,546][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.85252
[2024-02-27 03:13:53,037][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.60516
[2024-02-27 03:13:53,037][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.57800
[2024-02-27 03:14:19,177][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.99368
[2024-02-27 03:14:19,177][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.86010 - val_accuracy: 0.79010 - train_loss: 0.83548 - val_loss: 0.99491 - loss: 0.56008
[2024-02-27 03:15:12,756][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.55069
[2024-02-27 03:15:12,756][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.95894
[2024-02-27 03:15:38,780][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.52952
[2024-02-27 03:15:38,780][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.98168
[2024-02-27 03:16:05,400][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.62210
[2024-02-27 03:16:05,400][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.54109
[2024-02-27 03:16:31,394][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.24506
[2024-02-27 03:16:31,395][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.79697
[2024-02-27 03:16:57,917][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.53290
[2024-02-27 03:16:57,917][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.75492
[2024-02-27 03:17:23,948][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.49305
[2024-02-27 03:17:23,948][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.57835
[2024-02-27 03:17:50,307][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.54895
[2024-02-27 03:17:50,307][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.53765
[2024-02-27 03:18:16,303][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.53807
[2024-02-27 03:18:16,303][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.53944
[2024-02-27 03:18:42,737][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 1.95144
[2024-02-27 03:18:42,737][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.54779
[2024-02-27 03:19:08,768][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.67016
[2024-02-27 03:19:08,768][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.83306 - val_accuracy: 0.71200 - train_loss: 0.97096 - val_loss: 1.34728 - loss: 0.55605
[2024-02-27 03:20:02,015][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.51929
[2024-02-27 03:20:02,016][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.60646
[2024-02-27 03:20:28,047][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.51312
[2024-02-27 03:20:28,047][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.54094
[2024-02-27 03:20:54,574][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.56204
[2024-02-27 03:20:54,574][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.77066
[2024-02-27 03:21:21,034][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.95755
[2024-02-27 03:21:21,034][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.57212
[2024-02-27 03:21:47,113][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.54838
[2024-02-27 03:21:47,114][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.52271
[2024-02-27 03:22:13,515][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.55974
[2024-02-27 03:22:13,515][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.51733
[2024-02-27 03:22:39,517][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.52682
[2024-02-27 03:22:39,517][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.70952
[2024-02-27 03:23:05,957][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.44348
[2024-02-27 03:23:05,957][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.55543
[2024-02-27 03:23:32,083][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 0.60533
[2024-02-27 03:23:32,083][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.80920 - val_accuracy: 0.71800 - train_loss: 0.97440 - val_loss: 1.22208 - loss: 1.36475
[2024-02-27 03:24:25,441][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 1.21357
[2024-02-27 03:24:25,441][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.52987
[2024-02-27 03:24:51,484][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.57504
[2024-02-27 03:24:51,484][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.51325
[2024-02-27 03:25:18,103][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.51431
[2024-02-27 03:25:18,103][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 1.48491
[2024-02-27 03:25:44,185][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.58122
[2024-02-27 03:25:44,185][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.56785
[2024-02-27 03:26:10,724][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.54956
[2024-02-27 03:26:10,725][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.53225
[2024-02-27 03:26:36,771][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 1.49923
[2024-02-27 03:26:36,771][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.56288
[2024-02-27 03:27:03,429][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.73496
[2024-02-27 03:27:03,429][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.51922
[2024-02-27 03:27:29,444][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.53648
[2024-02-27 03:27:29,444][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.51726
[2024-02-27 03:27:56,056][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.53878
[2024-02-27 03:27:56,056][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 1.84159
[2024-02-27 03:28:22,309][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.60644
[2024-02-27 03:28:22,309][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.84212 - val_accuracy: 0.82980 - train_loss: 0.92305 - val_loss: 0.90353 - loss: 0.51917
[2024-02-27 03:29:15,730][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.53462
[2024-02-27 03:29:15,730][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.80727
[2024-02-27 03:29:41,741][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.55892
[2024-02-27 03:29:41,741][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.57821
[2024-02-27 03:30:08,240][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.52347
[2024-02-27 03:30:08,240][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.55275
[2024-02-27 03:30:34,178][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.63686
[2024-02-27 03:30:34,178][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.52448
[2024-02-27 03:31:00,680][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.55402
[2024-02-27 03:31:00,680][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.53199
[2024-02-27 03:31:26,755][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.54213
[2024-02-27 03:31:26,755][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.52407
[2024-02-27 03:31:53,261][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.54406
[2024-02-27 03:31:53,261][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.50820
[2024-02-27 03:32:19,314][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.68210
[2024-02-27 03:32:19,314][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.54077
[2024-02-27 03:32:46,250][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.51667
[2024-02-27 03:32:46,250][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.58395
[2024-02-27 03:33:12,226][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.53075
[2024-02-27 03:33:12,226][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.82748 - val_accuracy: 0.81470 - train_loss: 0.96569 - val_loss: 0.94582 - loss: 0.52528
[2024-02-27 03:34:05,524][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.52649
[2024-02-27 03:34:05,524][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.57793
[2024-02-27 03:34:31,593][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.53493
[2024-02-27 03:34:31,593][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.52581
[2024-02-27 03:34:58,058][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.54586
[2024-02-27 03:34:58,058][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.96708
[2024-02-27 03:35:24,004][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.52832
[2024-02-27 03:35:24,004][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.60428
[2024-02-27 03:35:50,544][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.55790
[2024-02-27 03:35:50,544][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.53596
[2024-02-27 03:36:16,606][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.53920
[2024-02-27 03:36:16,606][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.54528
[2024-02-27 03:36:43,118][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.52071
[2024-02-27 03:36:43,118][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.74603
[2024-02-27 03:37:09,688][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 2.00835
[2024-02-27 03:37:09,688][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.52833
[2024-02-27 03:37:35,674][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.51481
[2024-02-27 03:37:35,674][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.85364 - val_accuracy: 0.75380 - train_loss: 0.95392 - val_loss: 1.21354 - loss: 0.53044
[2024-02-27 03:38:28,948][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.51302
[2024-02-27 03:38:28,948][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.79548
[2024-02-27 03:38:54,996][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.51185
[2024-02-27 03:38:54,996][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 1.47023
[2024-02-27 03:39:21,341][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.54115
[2024-02-27 03:39:21,341][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.51659
[2024-02-27 03:39:47,389][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 1.34348
[2024-02-27 03:39:47,389][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.63577
[2024-02-27 03:40:13,772][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.52379
[2024-02-27 03:40:13,772][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.54195
[2024-02-27 03:40:39,818][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.52032
[2024-02-27 03:40:39,818][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 1.35032
[2024-02-27 03:41:06,234][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 1.51952
[2024-02-27 03:41:06,234][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.53444
[2024-02-27 03:41:32,267][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.54085
[2024-02-27 03:41:32,267][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.53577
[2024-02-27 03:41:58,727][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.53018
[2024-02-27 03:41:58,727][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.51338
[2024-02-27 03:42:24,850][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.51441
[2024-02-27 03:42:24,850][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.81840 - val_accuracy: 0.76110 - train_loss: 0.98596 - val_loss: 1.12168 - loss: 0.76711
[2024-02-27 03:43:19,515][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.61668
[2024-02-27 03:43:19,515][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.51468
[2024-02-27 03:43:45,563][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.55719
[2024-02-27 03:43:45,563][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 1.09154
[2024-02-27 03:44:11,900][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.50892
[2024-02-27 03:44:11,900][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.55143
[2024-02-27 03:44:37,756][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.51675
[2024-02-27 03:44:37,756][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.52924
[2024-02-27 03:45:04,160][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 1.10947
[2024-02-27 03:45:04,160][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.57832
[2024-02-27 03:45:30,062][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.52671
[2024-02-27 03:45:30,062][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.54625
[2024-02-27 03:45:56,684][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.52061
[2024-02-27 03:45:56,684][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.53142
[2024-02-27 03:46:22,730][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.52912
[2024-02-27 03:46:22,730][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.67522
[2024-02-27 03:46:49,290][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.70415
[2024-02-27 03:46:49,290][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.50701
[2024-02-27 03:47:15,507][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 0.52138
[2024-02-27 03:47:15,507][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.83042 - val_accuracy: 0.73410 - train_loss: 0.94512 - val_loss: 1.21788 - loss: 1.71527
[2024-02-27 03:48:10,102][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.66839
[2024-02-27 03:48:10,102][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.94610
[2024-02-27 03:48:36,081][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 1.13942
[2024-02-27 03:48:36,081][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.55120
[2024-02-27 03:49:02,553][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 1.44210
[2024-02-27 03:49:02,553][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.54562
[2024-02-27 03:49:28,494][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.51296
[2024-02-27 03:49:28,494][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.53415
[2024-02-27 03:49:55,127][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.53648
[2024-02-27 03:49:55,127][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.52383
[2024-02-27 03:50:21,136][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.65304
[2024-02-27 03:50:21,136][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.53816
[2024-02-27 03:50:47,654][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 1.23710
[2024-02-27 03:50:47,654][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.51850
[2024-02-27 03:51:13,723][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 1.02250
[2024-02-27 03:51:13,723][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.52228
[2024-02-27 03:51:40,281][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.53513
[2024-02-27 03:51:40,281][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.55125
[2024-02-27 03:52:06,358][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 1.97859
[2024-02-27 03:52:06,358][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.84989 - val_accuracy: 0.75200 - train_loss: 0.92112 - val_loss: 1.21339 - loss: 0.53054
[2024-02-27 03:52:59,829][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.57261
[2024-02-27 03:52:59,830][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.56970
[2024-02-27 03:53:26,297][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.69487
[2024-02-27 03:53:26,297][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.41057
[2024-02-27 03:53:52,275][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.77664
[2024-02-27 03:53:52,275][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.52467
[2024-02-27 03:54:18,780][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.65820
[2024-02-27 03:54:18,780][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.14347
[2024-02-27 03:54:44,849][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.53515
[2024-02-27 03:54:44,849][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.11461
[2024-02-27 03:55:11,402][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.50861
[2024-02-27 03:55:11,402][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.69079
[2024-02-27 03:55:37,361][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.25706
[2024-02-27 03:55:37,361][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 1.23927
[2024-02-27 03:56:03,969][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.52098
[2024-02-27 03:56:03,970][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.52055
[2024-02-27 03:56:29,932][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.50527
[2024-02-27 03:56:29,932][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.84172 - val_accuracy: 0.75520 - train_loss: 0.90993 - val_loss: 1.13008 - loss: 0.53621
[2024-02-27 03:57:24,808][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.50509
[2024-02-27 03:57:24,808][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.53204
[2024-02-27 03:57:50,876][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.52256
[2024-02-27 03:57:50,876][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.51054
[2024-02-27 03:58:17,239][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 1.20539
[2024-02-27 03:58:17,239][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 1.44067
[2024-02-27 03:58:43,374][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.51766
[2024-02-27 03:58:43,374][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.51340
[2024-02-27 03:59:09,880][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.56122
[2024-02-27 03:59:09,880][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.52939
[2024-02-27 03:59:35,921][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.66874
[2024-02-27 03:59:35,921][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.51870
[2024-02-27 04:00:02,434][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 1.05199
[2024-02-27 04:00:02,434][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.52527
[2024-02-27 04:00:28,544][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.95556
[2024-02-27 04:00:28,544][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.50901
[2024-02-27 04:00:55,535][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.81830
[2024-02-27 04:00:55,535][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.54562
[2024-02-27 04:01:21,544][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 1.14556
[2024-02-27 04:01:21,544][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.87377 - val_accuracy: 0.65950 - train_loss: 0.83416 - val_loss: 1.47383 - loss: 0.53887
[2024-02-27 04:02:15,877][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.66125
[2024-02-27 04:02:15,877][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51575
[2024-02-27 04:02:41,830][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 1.23774
[2024-02-27 04:02:41,830][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51599
[2024-02-27 04:03:08,269][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.52473
[2024-02-27 04:03:08,269][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.52404
[2024-02-27 04:03:34,266][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 1.46005
[2024-02-27 04:03:34,266][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.73065
[2024-02-27 04:04:00,580][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51908
[2024-02-27 04:04:00,580][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.52327
[2024-02-27 04:04:26,606][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51006
[2024-02-27 04:04:26,606][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.52525
[2024-02-27 04:04:52,999][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51856
[2024-02-27 04:04:52,999][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.95518
[2024-02-27 04:05:19,190][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.75021
[2024-02-27 04:05:19,190][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.55338
[2024-02-27 04:05:45,673][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.57182
[2024-02-27 04:05:45,673][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.50598
[2024-02-27 04:06:11,740][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.51884
[2024-02-27 04:06:11,740][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.83630 - val_accuracy: 0.70490 - train_loss: 0.92151 - val_loss: 1.27027 - loss: 0.56594
[2024-02-27 04:07:05,179][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.29200
[2024-02-27 04:07:05,179][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.66086
[2024-02-27 04:07:31,091][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.53231
[2024-02-27 04:07:31,091][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.61084
[2024-02-27 04:07:57,640][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.02596
[2024-02-27 04:07:57,640][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.52804
[2024-02-27 04:08:24,127][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.54042
[2024-02-27 04:08:24,127][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.51528
[2024-02-27 04:08:50,150][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.54948
[2024-02-27 04:08:50,150][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.80632
[2024-02-27 04:09:16,615][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.06133
[2024-02-27 04:09:16,615][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.70275
[2024-02-27 04:09:42,699][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.51219
[2024-02-27 04:09:42,699][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.20088
[2024-02-27 04:10:09,167][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.53077
[2024-02-27 04:10:09,167][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.52737
[2024-02-27 04:10:35,248][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 0.52055
[2024-02-27 04:10:35,248][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.86902 - val_accuracy: 0.75110 - train_loss: 0.86826 - val_loss: 1.20414 - loss: 1.95692
[2024-02-27 04:11:28,771][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 1.86655
[2024-02-27 04:11:28,771][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.50663
[2024-02-27 04:11:54,907][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 1.05738
[2024-02-27 04:11:54,907][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.55680
[2024-02-27 04:12:21,399][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51908
[2024-02-27 04:12:21,399][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 2.03172
[2024-02-27 04:12:47,344][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51671
[2024-02-27 04:12:47,344][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.53011
[2024-02-27 04:13:13,775][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.50748
[2024-02-27 04:13:13,775][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.52277
[2024-02-27 04:13:39,869][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 1.02788
[2024-02-27 04:13:39,869][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51716
[2024-02-27 04:14:06,499][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.53660
[2024-02-27 04:14:06,499][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51489
[2024-02-27 04:14:32,543][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51673
[2024-02-27 04:14:32,543][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 1.02522
[2024-02-27 04:14:59,057][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.51922
[2024-02-27 04:14:59,057][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.50698
[2024-02-27 04:15:25,212][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.50696
[2024-02-27 04:15:25,212][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.85376 - val_accuracy: 0.71520 - train_loss: 0.93903 - val_loss: 1.37580 - loss: 0.52212
[2024-02-27 04:16:18,678][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.66218
[2024-02-27 04:16:18,678][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 1.28806
[2024-02-27 04:16:44,624][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.50443
[2024-02-27 04:16:44,624][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.50753
[2024-02-27 04:17:11,239][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.51297
[2024-02-27 04:17:11,239][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.51133
[2024-02-27 04:17:37,248][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.51778
[2024-02-27 04:17:37,248][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.63833
[2024-02-27 04:18:03,793][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.51823
[2024-02-27 04:18:03,793][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.53318
[2024-02-27 04:18:29,883][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.54767
[2024-02-27 04:18:29,884][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.55636
[2024-02-27 04:18:56,385][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.62561
[2024-02-27 04:18:56,385][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.51261
[2024-02-27 04:19:22,515][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.50457
[2024-02-27 04:19:22,515][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 1.97889
[2024-02-27 04:19:48,973][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.52203
[2024-02-27 04:19:48,973][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.58540
[2024-02-27 04:20:14,933][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.52297
[2024-02-27 04:20:14,933][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.86332 - val_accuracy: 0.78230 - train_loss: 0.85700 - val_loss: 1.06069 - loss: 0.50855
[2024-02-27 04:21:10,002][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 1.04995
[2024-02-27 04:21:10,002][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.52366
[2024-02-27 04:21:36,017][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.52399
[2024-02-27 04:21:36,017][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51906
[2024-02-27 04:22:02,434][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.50677
[2024-02-27 04:22:02,434][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.66820
[2024-02-27 04:22:28,550][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51431
[2024-02-27 04:22:28,550][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.52527
[2024-02-27 04:22:55,087][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 1.68288
[2024-02-27 04:22:55,087][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.54326
[2024-02-27 04:23:21,141][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51756
[2024-02-27 04:23:21,141][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51028
[2024-02-27 04:23:47,531][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51583
[2024-02-27 04:23:47,531][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.53571
[2024-02-27 04:24:13,989][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.50677
[2024-02-27 04:24:13,989][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 1.92850
[2024-02-27 04:24:39,947][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 1.94565
[2024-02-27 04:24:39,947][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.86658 - val_accuracy: 0.81130 - train_loss: 0.86459 - val_loss: 0.97957 - loss: 0.51037
[2024-02-27 04:25:33,396][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.51422
[2024-02-27 04:25:33,397][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.50431
[2024-02-27 04:25:59,403][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 1.06147
[2024-02-27 04:25:59,403][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.51698
[2024-02-27 04:26:25,791][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.52245
[2024-02-27 04:26:25,791][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.57858
[2024-02-27 04:26:51,821][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 1.11394
[2024-02-27 04:26:51,821][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 1.95365
[2024-02-27 04:27:18,305][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.51393
[2024-02-27 04:27:18,305][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.57393
[2024-02-27 04:27:44,419][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.50906
[2024-02-27 04:27:44,419][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.58517
[2024-02-27 04:28:10,847][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.52909
[2024-02-27 04:28:10,847][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.55203
[2024-02-27 04:28:36,975][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.51824
[2024-02-27 04:28:36,976][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.50528
[2024-02-27 04:29:03,527][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.78784
[2024-02-27 04:29:03,528][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.65840
[2024-02-27 04:29:29,482][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 1.11899
[2024-02-27 04:29:29,482][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.88599 - val_accuracy: 0.84750 - train_loss: 0.79773 - val_loss: 0.88966 - loss: 0.53155
[2024-02-27 04:30:22,759][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.52963
[2024-02-27 04:30:22,759][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.70898
[2024-02-27 04:30:48,799][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.52844
[2024-02-27 04:30:48,799][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.57517
[2024-02-27 04:31:15,220][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.51612
[2024-02-27 04:31:15,220][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.89445
[2024-02-27 04:31:41,324][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.53637
[2024-02-27 04:31:41,324][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.62615
[2024-02-27 04:32:07,795][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.51299
[2024-02-27 04:32:07,795][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.51258
[2024-02-27 04:32:33,785][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.50809
[2024-02-27 04:32:33,785][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.57691
[2024-02-27 04:33:00,584][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.51195
[2024-02-27 04:33:00,584][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.52533
[2024-02-27 04:33:26,680][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.52037
[2024-02-27 04:33:26,680][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.50489
[2024-02-27 04:33:53,123][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 1.23806
[2024-02-27 04:33:53,124][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.50773
[2024-02-27 04:34:19,096][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.51400
[2024-02-27 04:34:19,096][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.87617 - val_accuracy: 0.71310 - train_loss: 0.83703 - val_loss: 1.32230 - loss: 0.50689
[2024-02-27 04:35:13,395][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.51039
[2024-02-27 04:35:13,395][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.63644
[2024-02-27 04:35:39,438][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 2.02094
[2024-02-27 04:35:39,438][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.50684
[2024-02-27 04:36:06,048][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 1.76888
[2024-02-27 04:36:06,048][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.51868
[2024-02-27 04:36:32,175][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.52249
[2024-02-27 04:36:32,175][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.55673
[2024-02-27 04:36:58,655][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.60827
[2024-02-27 04:36:58,655][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 1.14069
[2024-02-27 04:37:24,723][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.50418
[2024-02-27 04:37:24,723][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.99669
[2024-02-27 04:37:51,254][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.73294
[2024-02-27 04:37:51,254][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.74825
[2024-02-27 04:38:17,294][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.86164
[2024-02-27 04:38:17,294][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.56454
[2024-02-27 04:38:43,772][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.51044
[2024-02-27 04:38:43,772][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 1.30026
[2024-02-27 04:39:09,696][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.52657
[2024-02-27 04:39:09,696][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.85283 - val_accuracy: 0.72570 - train_loss: 0.90230 - val_loss: 1.28199 - loss: 0.51452
[2024-02-27 04:40:03,151][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 1.28302
[2024-02-27 04:40:03,151][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.51220
[2024-02-27 04:40:29,564][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 1.63089
[2024-02-27 04:40:29,564][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.75939
[2024-02-27 04:40:55,545][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.50488
[2024-02-27 04:40:55,546][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.82150
[2024-02-27 04:41:22,250][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.55337
[2024-02-27 04:41:22,250][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.50833
[2024-02-27 04:41:48,218][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 1.77845
[2024-02-27 04:41:48,218][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 1.41613
[2024-02-27 04:42:14,677][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.84907
[2024-02-27 04:42:14,677][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.50505
[2024-02-27 04:42:40,735][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.89191
[2024-02-27 04:42:40,735][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.51431
[2024-02-27 04:43:07,150][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.56749
[2024-02-27 04:43:07,150][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.73510
[2024-02-27 04:43:33,103][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.51442
[2024-02-27 04:43:33,103][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.85950 - val_accuracy: 0.82240 - train_loss: 0.85465 - val_loss: 0.92942 - loss: 0.51424
[2024-02-27 04:44:27,525][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.60804
[2024-02-27 04:44:27,526][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51456
[2024-02-27 04:44:53,500][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 1.18077
[2024-02-27 04:44:53,500][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.57447
[2024-02-27 04:45:19,982][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51853
[2024-02-27 04:45:19,982][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.54275
[2024-02-27 04:45:46,054][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 1.01215
[2024-02-27 04:45:46,054][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.50335
[2024-02-27 04:46:12,565][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 1.31962
[2024-02-27 04:46:12,565][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.50824
[2024-02-27 04:46:38,527][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.82478
[2024-02-27 04:46:38,527][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51112
[2024-02-27 04:47:04,968][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.50443
[2024-02-27 04:47:04,968][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 1.31298
[2024-02-27 04:47:30,955][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51800
[2024-02-27 04:47:30,955][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.50609
[2024-02-27 04:47:57,452][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51490
[2024-02-27 04:47:57,452][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 1.72534
[2024-02-27 04:48:23,403][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.69328
[2024-02-27 04:48:23,403][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.87311 - val_accuracy: 0.67510 - train_loss: 0.83601 - val_loss: 1.39668 - loss: 0.51885
[2024-02-27 04:49:16,723][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.54737
[2024-02-27 04:49:16,723][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 1.70644
[2024-02-27 04:49:42,772][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.51410
[2024-02-27 04:49:42,772][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.60643
[2024-02-27 04:50:09,194][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50726
[2024-02-27 04:50:09,194][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50724
[2024-02-27 04:50:35,131][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50850
[2024-02-27 04:50:35,131][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.53582
[2024-02-27 04:51:01,694][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.54775
[2024-02-27 04:51:01,694][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.51294
[2024-02-27 04:51:27,740][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50248
[2024-02-27 04:51:27,740][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 1.09990
[2024-02-27 04:51:54,201][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50616
[2024-02-27 04:51:54,201][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.50888
[2024-02-27 04:52:20,311][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 1.22798
[2024-02-27 04:52:20,311][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.62916
[2024-02-27 04:52:46,781][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.56224
[2024-02-27 04:52:46,781][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.51638
[2024-02-27 04:53:12,888][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.51124
[2024-02-27 04:53:12,888][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.87446 - val_accuracy: 0.80140 - train_loss: 0.84915 - val_loss: 1.04441 - loss: 0.70177
[2024-02-27 04:54:06,377][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.51657
[2024-02-27 04:54:06,377][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50786
[2024-02-27 04:54:32,499][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.58564
[2024-02-27 04:54:32,500][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.99825
[2024-02-27 04:54:59,007][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50619
[2024-02-27 04:54:59,007][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.51463
[2024-02-27 04:55:25,441][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.78673
[2024-02-27 04:55:25,441][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.59002
[2024-02-27 04:55:51,420][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50837
[2024-02-27 04:55:51,420][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 1.94159
[2024-02-27 04:56:17,921][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.51006
[2024-02-27 04:56:17,921][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50292
[2024-02-27 04:56:44,024][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50840
[2024-02-27 04:56:44,024][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.51330
[2024-02-27 04:57:10,513][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50453
[2024-02-27 04:57:10,513][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 1.97730
[2024-02-27 04:57:36,582][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50318
[2024-02-27 04:57:36,582][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.80424 - val_accuracy: 0.74770 - train_loss: 0.98433 - val_loss: 1.12323 - loss: 0.50229
[2024-02-27 04:58:30,042][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50208
[2024-02-27 04:58:30,042][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.51273
[2024-02-27 04:58:56,158][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.51486
[2024-02-27 04:58:56,159][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.52123
[2024-02-27 04:59:22,650][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.58455
[2024-02-27 04:59:22,650][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 1.70015
[2024-02-27 04:59:48,821][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 1.96381
[2024-02-27 04:59:48,822][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 1.47331
[2024-02-27 05:00:15,398][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.54113
[2024-02-27 05:00:15,398][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50773
[2024-02-27 05:00:41,565][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.53463
[2024-02-27 05:00:41,565][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 1.32289
[2024-02-27 05:01:07,890][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50539
[2024-02-27 05:01:07,890][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.52407
[2024-02-27 05:01:33,844][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50856
[2024-02-27 05:01:33,844][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50364
[2024-02-27 05:02:00,651][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.58541
[2024-02-27 05:02:00,651][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.86498
[2024-02-27 05:02:26,755][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.50937
[2024-02-27 05:02:26,755][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.81540 - val_accuracy: 0.81800 - train_loss: 1.02834 - val_loss: 1.00169 - loss: 0.51567
[2024-02-27 05:03:20,285][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.54066
[2024-02-27 05:03:20,285][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.52246
[2024-02-27 05:03:46,300][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50246
[2024-02-27 05:03:46,300][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50235
[2024-02-27 05:04:12,977][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50906
[2024-02-27 05:04:12,977][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.51334
[2024-02-27 05:04:39,021][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50511
[2024-02-27 05:04:39,021][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50261
[2024-02-27 05:05:05,455][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.51815
[2024-02-27 05:05:05,455][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.51699
[2024-02-27 05:05:31,461][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.53301
[2024-02-27 05:05:31,461][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 1.88827
[2024-02-27 05:05:58,124][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.84057
[2024-02-27 05:05:58,124][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50211
[2024-02-27 05:06:24,246][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.51392
[2024-02-27 05:06:24,246][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 1.48333
[2024-02-27 05:06:50,684][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50581
[2024-02-27 05:06:50,684][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 1.67629
[2024-02-27 05:07:16,771][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.50282
[2024-02-27 05:07:16,771][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.83745 - val_accuracy: 0.84020 - train_loss: 0.93848 - val_loss: 0.89121 - loss: 0.51676
[2024-02-27 05:08:10,241][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.56070
[2024-02-27 05:08:10,241][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50695
[2024-02-27 05:08:36,373][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 1.03927
[2024-02-27 05:08:36,373][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.71822
[2024-02-27 05:09:02,949][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.51397
[2024-02-27 05:09:02,949][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.58225
[2024-02-27 05:09:28,898][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50289
[2024-02-27 05:09:28,898][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.51428
[2024-02-27 05:09:55,356][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50821
[2024-02-27 05:09:55,356][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50700
[2024-02-27 05:10:21,512][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50806
[2024-02-27 05:10:21,512][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.54550
[2024-02-27 05:10:48,061][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50943
[2024-02-27 05:10:48,061][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.53383
[2024-02-27 05:11:14,376][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50318
[2024-02-27 05:11:14,376][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.50879
[2024-02-27 05:11:40,472][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.61028
[2024-02-27 05:11:40,472][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.88466 - val_accuracy: 0.82850 - train_loss: 0.82472 - val_loss: 0.95987 - loss: 0.51106
[2024-02-27 05:12:33,880][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50231
[2024-02-27 05:12:33,880][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.51950
[2024-02-27 05:12:59,752][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.51788
[2024-02-27 05:12:59,752][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.58617
[2024-02-27 05:13:26,271][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50308
[2024-02-27 05:13:26,271][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50322
[2024-02-27 05:13:52,352][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50483
[2024-02-27 05:13:52,352][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.64860
[2024-02-27 05:14:18,884][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50710
[2024-02-27 05:14:18,885][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.62218
[2024-02-27 05:14:44,851][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.51120
[2024-02-27 05:14:44,851][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.77972
[2024-02-27 05:15:11,419][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.62383
[2024-02-27 05:15:11,419][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50180
[2024-02-27 05:15:37,567][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.52490
[2024-02-27 05:15:37,567][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.60524
[2024-02-27 05:16:04,093][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50852
[2024-02-27 05:16:04,093][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50453
[2024-02-27 05:16:29,919][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.50419
[2024-02-27 05:16:29,919][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.88835 - val_accuracy: 0.79620 - train_loss: 0.78602 - val_loss: 0.99591 - loss: 0.61291
[2024-02-27 05:17:23,630][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50478
[2024-02-27 05:17:23,630][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.52023
[2024-02-27 05:17:49,579][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50228
[2024-02-27 05:17:49,579][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.54691
[2024-02-27 05:18:16,111][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50281
[2024-02-27 05:18:16,111][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.78397
[2024-02-27 05:18:42,157][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.59410
[2024-02-27 05:18:42,157][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.56585
[2024-02-27 05:19:08,873][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 1.04270
[2024-02-27 05:19:08,873][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.83276
[2024-02-27 05:19:34,884][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.56697
[2024-02-27 05:19:34,884][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.52649
[2024-02-27 05:20:01,367][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.97054
[2024-02-27 05:20:01,367][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.52345
[2024-02-27 05:20:27,490][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50673
[2024-02-27 05:20:27,490][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50278
[2024-02-27 05:20:54,069][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.51445
[2024-02-27 05:20:54,069][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.50285
[2024-02-27 05:21:20,262][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 0.53201
[2024-02-27 05:21:20,262][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.88501 - val_accuracy: 0.73480 - train_loss: 0.79464 - val_loss: 1.20480 - loss: 2.02229
[2024-02-27 05:22:13,734][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 1.39143
[2024-02-27 05:22:13,734][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50199
[2024-02-27 05:22:39,802][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50337
[2024-02-27 05:22:39,802][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 1.20436
[2024-02-27 05:23:06,236][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50256
[2024-02-27 05:23:06,236][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50281
[2024-02-27 05:23:32,247][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.51915
[2024-02-27 05:23:32,247][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50225
[2024-02-27 05:23:58,766][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.99295
[2024-02-27 05:23:58,766][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50115
[2024-02-27 05:24:24,807][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50667
[2024-02-27 05:24:24,807][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 1.15988
[2024-02-27 05:24:51,284][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.51606
[2024-02-27 05:24:51,284][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 1.99182
[2024-02-27 05:25:17,538][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.59337
[2024-02-27 05:25:17,538][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50196
[2024-02-27 05:25:44,016][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 1.65288
[2024-02-27 05:25:44,016][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.52239
[2024-02-27 05:26:10,010][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50443
[2024-02-27 05:26:10,010][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 0.87299 - val_accuracy: 0.70970 - train_loss: 0.82418 - val_loss: 1.26783 - loss: 0.50313
[2024-02-27 05:27:04,628][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50962
[2024-02-27 05:27:04,628][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.80558
[2024-02-27 05:27:30,953][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.51995
[2024-02-27 05:27:30,953][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.65838
[2024-02-27 05:27:57,027][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.51280
[2024-02-27 05:27:57,027][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 1.23021
[2024-02-27 05:28:23,634][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50179
[2024-02-27 05:28:23,634][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.54072
[2024-02-27 05:28:49,576][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50615
[2024-02-27 05:28:49,576][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.51300
[2024-02-27 05:29:16,051][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50343
[2024-02-27 05:29:16,051][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50312
[2024-02-27 05:29:42,022][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50181
[2024-02-27 05:29:42,022][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.66137
[2024-02-27 05:30:08,724][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50188
[2024-02-27 05:30:08,724][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50323
[2024-02-27 05:30:34,709][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.50175
[2024-02-27 05:30:34,709][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.85654 - val_accuracy: 0.75870 - train_loss: 0.88097 - val_loss: 1.14984 - loss: 0.64391
[2024-02-27 05:31:28,120][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.53484
[2024-02-27 05:31:28,120][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 1.14361
[2024-02-27 05:31:54,043][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 1.93675
[2024-02-27 05:31:54,043][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50381
[2024-02-27 05:32:20,687][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.53158
[2024-02-27 05:32:20,687][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 1.25551
[2024-02-27 05:32:46,702][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34600] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.58053
[2024-02-27 05:32:46,702][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34600] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.51462
[2024-02-27 05:33:13,123][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34650] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.51833
[2024-02-27 05:33:13,123][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34650] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.51899
[2024-02-27 05:33:39,234][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34700] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.55093
[2024-02-27 05:33:39,234][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34700] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.51732
[2024-02-27 05:34:05,749][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34750] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 1.35906
[2024-02-27 05:34:05,749][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34750] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50808
[2024-02-27 05:34:31,823][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34800] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50800
[2024-02-27 05:34:31,823][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34800] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.64643
[2024-02-27 05:34:58,295][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34850] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50306
[2024-02-27 05:34:58,295][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34850] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50741
[2024-02-27 05:35:24,381][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34900] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50567
[2024-02-27 05:35:24,381][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34900] - train_accuracy: 0.86197 - val_accuracy: 0.72050 - train_loss: 0.93645 - val_loss: 1.38625 - loss: 0.50527
[2024-02-27 05:36:17,715][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[34950] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.56942
[2024-02-27 05:36:17,715][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[34950] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 1.14312
[2024-02-27 05:36:43,858][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[35000] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.68038
[2024-02-27 05:36:43,858][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[35000] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.95420
[2024-02-27 05:37:10,296][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35050] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50236
[2024-02-27 05:37:10,296][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35050] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50911
[2024-02-27 05:37:36,248][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35100] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50116
[2024-02-27 05:37:36,248][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35100] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50362
[2024-02-27 05:38:02,656][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35150] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50155
[2024-02-27 05:38:02,656][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35150] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.51847
[2024-02-27 05:38:28,775][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35200] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.51462
[2024-02-27 05:38:28,775][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35200] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 1.47082
[2024-02-27 05:38:55,245][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35250] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.51368
[2024-02-27 05:38:55,245][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35250] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50237
[2024-02-27 05:39:21,143][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35300] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.98771
[2024-02-27 05:39:21,143][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35300] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50505
[2024-02-27 05:39:47,595][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35350] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50192
[2024-02-27 05:39:47,596][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35350] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.51287
[2024-02-27 05:40:13,591][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35400] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.50147
[2024-02-27 05:40:13,591][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35400] - train_accuracy: 0.86852 - val_accuracy: 0.80100 - train_loss: 0.85688 - val_loss: 1.01870 - loss: 0.54841
[2024-02-27 05:41:06,879][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35450] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.51978
[2024-02-27 05:41:06,879][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35450] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.57784
[2024-02-27 05:41:32,816][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35500] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 1.99157
[2024-02-27 05:41:32,816][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35500] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50375
[2024-02-27 05:41:59,478][PyLogger][INFO]: Rank[1]: Epoch[367/500], iter[35550] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.94984
[2024-02-27 05:41:59,478][PyLogger][INFO]: Rank[0]: Epoch[367/500], iter[35550] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50277
[2024-02-27 05:42:25,946][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35600] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50140
[2024-02-27 05:42:25,947][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35600] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50124
[2024-02-27 05:42:51,973][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35650] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50226
[2024-02-27 05:42:51,973][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35650] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50426
[2024-02-27 05:43:18,535][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35700] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.52055
[2024-02-27 05:43:18,535][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35700] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.51157
[2024-02-27 05:43:44,658][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35750] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.52655
[2024-02-27 05:43:44,658][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35750] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50305
[2024-02-27 05:44:11,151][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35800] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50157
[2024-02-27 05:44:11,151][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35800] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 1.45560
[2024-02-27 05:44:37,166][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35850] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 1.10811
[2024-02-27 05:44:37,166][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35850] - train_accuracy: 0.87095 - val_accuracy: 0.74200 - train_loss: 0.85774 - val_loss: 1.20950 - loss: 0.50626
[2024-02-27 05:45:32,067][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35900] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50437
[2024-02-27 05:45:32,067][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35900] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50155
[2024-02-27 05:45:58,209][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35950] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50190
[2024-02-27 05:45:58,209][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35950] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50228
[2024-02-27 05:46:24,738][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36000] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.95960
[2024-02-27 05:46:24,738][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36000] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 1.18904
[2024-02-27 05:46:50,972][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36050] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50310
[2024-02-27 05:46:50,972][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36050] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50160
[2024-02-27 05:47:17,574][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36100] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.51584
[2024-02-27 05:47:17,574][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36100] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.92926
[2024-02-27 05:47:43,448][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36150] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50123
[2024-02-27 05:47:43,448][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36150] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50851
[2024-02-27 05:48:09,923][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36200] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.52021
[2024-02-27 05:48:09,923][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36200] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50340
[2024-02-27 05:48:36,032][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36250] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 1.95318
[2024-02-27 05:48:36,032][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36250] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50103
[2024-02-27 05:49:02,491][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36300] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.50273
[2024-02-27 05:49:02,491][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36300] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.71073
[2024-02-27 05:49:28,619][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36350] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.51871
[2024-02-27 05:49:28,619][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36350] - train_accuracy: 0.86832 - val_accuracy: 0.82600 - train_loss: 0.88190 - val_loss: 0.99515 - loss: 0.94043
[2024-02-27 05:50:22,654][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36400] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50108
[2024-02-27 05:50:22,654][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36400] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 1.24293
[2024-02-27 05:50:48,550][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36450] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50134
[2024-02-27 05:50:48,550][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36450] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.67017
[2024-02-27 05:51:15,013][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36500] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50898
[2024-02-27 05:51:15,013][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36500] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.77096
[2024-02-27 05:51:41,062][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36550] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 1.38974
[2024-02-27 05:51:41,062][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36550] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50276
[2024-02-27 05:52:07,551][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36600] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.87243
[2024-02-27 05:52:07,551][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36600] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.56880
[2024-02-27 05:52:33,447][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36650] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.60766
[2024-02-27 05:52:33,447][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36650] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50113
[2024-02-27 05:52:59,808][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36700] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.96521
[2024-02-27 05:52:59,808][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36700] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50433
[2024-02-27 05:53:25,995][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36750] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.51639
[2024-02-27 05:53:25,995][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36750] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.53723
[2024-02-27 05:53:52,601][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36800] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.50322
[2024-02-27 05:53:52,601][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36800] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.51339
[2024-02-27 05:54:18,647][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36850] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 0.51826
[2024-02-27 05:54:18,647][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36850] - train_accuracy: 0.90224 - val_accuracy: 0.75990 - train_loss: 0.76071 - val_loss: 1.12711 - loss: 1.11283
[2024-02-27 05:55:13,436][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36900] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50155
[2024-02-27 05:55:13,436][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36900] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 2.00743
[2024-02-27 05:55:39,397][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36950] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50091
[2024-02-27 05:55:39,397][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36950] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.51202
[2024-02-27 05:56:06,187][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37000] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50133
[2024-02-27 05:56:06,187][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37000] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50195
[2024-02-27 05:56:32,265][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37050] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50384
[2024-02-27 05:56:32,265][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37050] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50118
[2024-02-27 05:56:58,625][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37100] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50124
[2024-02-27 05:56:58,625][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37100] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 1.42067
[2024-02-27 05:57:24,579][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37150] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50201
[2024-02-27 05:57:24,579][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37150] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50111
[2024-02-27 05:57:50,984][PyLogger][INFO]: Rank[1]: Epoch[384/500], iter[37200] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50627
[2024-02-27 05:57:50,984][PyLogger][INFO]: Rank[0]: Epoch[384/500], iter[37200] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50765
[2024-02-27 05:58:17,557][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37250] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 1.35748
[2024-02-27 05:58:17,557][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37250] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.62664
[2024-02-27 05:58:43,662][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37300] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.50112
[2024-02-27 05:58:43,662][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37300] - train_accuracy: 0.91920 - val_accuracy: 0.82920 - train_loss: 0.72253 - val_loss: 0.94486 - loss: 0.53376
[2024-02-27 05:59:36,926][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37350] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.84287
[2024-02-27 05:59:36,926][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37350] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50140
[2024-02-27 06:00:03,093][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37400] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50111
[2024-02-27 06:00:03,093][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37400] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.51396
[2024-02-27 06:00:29,952][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37450] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 1.34042
[2024-02-27 06:00:29,952][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37450] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.51492
[2024-02-27 06:00:55,983][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37500] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50351
[2024-02-27 06:00:55,983][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37500] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 1.39398
[2024-02-27 06:01:22,559][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37550] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.53933
[2024-02-27 06:01:22,559][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37550] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50133
[2024-02-27 06:01:48,479][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37600] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50363
[2024-02-27 06:01:48,479][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37600] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 1.39695
[2024-02-27 06:02:15,001][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37650] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50121
[2024-02-27 06:02:15,001][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37650] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50086
[2024-02-27 06:02:41,106][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37700] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.58775
[2024-02-27 06:02:41,106][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37700] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50091
[2024-02-27 06:03:07,495][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37750] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50099
[2024-02-27 06:03:07,495][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37750] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50130
[2024-02-27 06:03:33,504][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37800] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 0.50123
[2024-02-27 06:03:33,504][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37800] - train_accuracy: 0.87935 - val_accuracy: 0.77930 - train_loss: 0.84485 - val_loss: 1.14770 - loss: 1.21286
[2024-02-27 06:04:26,973][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37850] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50219
[2024-02-27 06:04:26,973][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37850] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50115
[2024-02-27 06:04:53,059][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37900] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.87593
[2024-02-27 06:04:53,059][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37900] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 1.98862
[2024-02-27 06:05:19,515][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[37950] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.52590
[2024-02-27 06:05:19,515][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[37950] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.55660
[2024-02-27 06:05:45,615][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[38000] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50124
[2024-02-27 06:05:45,615][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[38000] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.51504
[2024-02-27 06:06:12,018][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38050] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50093
[2024-02-27 06:06:12,018][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38050] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50091
[2024-02-27 06:06:38,020][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38100] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50474
[2024-02-27 06:06:38,020][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38100] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50099
[2024-02-27 06:07:04,515][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38150] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50249
[2024-02-27 06:07:04,515][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38150] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50142
[2024-02-27 06:07:30,722][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38200] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50395
[2024-02-27 06:07:30,722][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38200] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.51553
[2024-02-27 06:07:57,252][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38250] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50107
[2024-02-27 06:07:57,252][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38250] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.72156
[2024-02-27 06:08:23,223][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38300] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.50134
[2024-02-27 06:08:23,224][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38300] - train_accuracy: 0.88336 - val_accuracy: 0.82440 - train_loss: 0.85903 - val_loss: 1.02583 - loss: 0.66039
[2024-02-27 06:09:17,562][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38350] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50121
[2024-02-27 06:09:17,563][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38350] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50161
[2024-02-27 06:09:43,683][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38400] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 1.17129
[2024-02-27 06:09:43,683][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38400] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50112
[2024-02-27 06:10:10,194][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38450] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50117
[2024-02-27 06:10:10,194][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38450] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 1.72086
[2024-02-27 06:10:36,258][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38500] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50415
[2024-02-27 06:10:36,258][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38500] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50365
[2024-02-27 06:11:02,781][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38550] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.86600
[2024-02-27 06:11:02,781][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38550] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.79327
[2024-02-27 06:11:28,829][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38600] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50094
[2024-02-27 06:11:28,829][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38600] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50077
[2024-02-27 06:11:55,431][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38650] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50092
[2024-02-27 06:11:55,432][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38650] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50083
[2024-02-27 06:12:21,495][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38700] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50074
[2024-02-27 06:12:21,495][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38700] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50071
[2024-02-27 06:12:47,851][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38750] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50136
[2024-02-27 06:12:47,851][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38750] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.50686
[2024-02-27 06:13:13,777][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38800] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 1.33168
[2024-02-27 06:13:13,777][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38800] - train_accuracy: 0.91360 - val_accuracy: 0.75380 - train_loss: 0.74732 - val_loss: 1.22298 - loss: 0.61054
[2024-02-27 06:14:07,382][PyLogger][INFO]: Rank[0]: Epoch[401/500], iter[38850] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50073
[2024-02-27 06:14:07,382][PyLogger][INFO]: Rank[1]: Epoch[401/500], iter[38850] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.54220
[2024-02-27 06:14:33,926][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38900] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50081
[2024-02-27 06:14:33,926][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38900] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.51174
[2024-02-27 06:15:00,069][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38950] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 1.35676
[2024-02-27 06:15:00,069][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38950] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.52457
[2024-02-27 06:15:26,618][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39000] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50111
[2024-02-27 06:15:26,618][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39000] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50441
[2024-02-27 06:15:52,547][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39050] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50078
[2024-02-27 06:15:52,547][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39050] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.67538
[2024-02-27 06:16:18,976][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39100] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 1.88695
[2024-02-27 06:16:18,976][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39100] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50084
[2024-02-27 06:16:44,967][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39150] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50152
[2024-02-27 06:16:44,967][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39150] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.50098
[2024-02-27 06:17:11,498][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39200] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.60957
[2024-02-27 06:17:11,498][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39200] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.51612
[2024-02-27 06:17:37,492][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39250] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 1.32810
[2024-02-27 06:17:37,492][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39250] - train_accuracy: 0.88247 - val_accuracy: 0.76500 - train_loss: 0.82098 - val_loss: 1.10800 - loss: 0.51325
[2024-02-27 06:18:31,008][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39300] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50086
[2024-02-27 06:18:31,009][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39300] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50919
[2024-02-27 06:18:56,966][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39350] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50316
[2024-02-27 06:18:56,966][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39350] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50110
[2024-02-27 06:19:23,656][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39400] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.55018
[2024-02-27 06:19:23,656][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39400] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 1.18773
[2024-02-27 06:19:49,681][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39450] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50279
[2024-02-27 06:19:49,681][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39450] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50137
[2024-02-27 06:20:16,111][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39500] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50313
[2024-02-27 06:20:16,111][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39500] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50081
[2024-02-27 06:20:42,131][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39550] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.51075
[2024-02-27 06:20:42,131][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39550] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50076
[2024-02-27 06:21:08,532][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39600] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.58751
[2024-02-27 06:21:08,532][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39600] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50101
[2024-02-27 06:21:34,467][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39650] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50611
[2024-02-27 06:21:34,467][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39650] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 1.68560
[2024-02-27 06:22:00,913][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39700] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.51186
[2024-02-27 06:22:00,913][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39700] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50065
[2024-02-27 06:22:26,826][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39750] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50806
[2024-02-27 06:22:26,826][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39750] - train_accuracy: 0.90877 - val_accuracy: 0.82780 - train_loss: 0.74885 - val_loss: 0.93843 - loss: 0.50075
[2024-02-27 06:23:21,003][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39800] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50508
[2024-02-27 06:23:21,003][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39800] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50188
[2024-02-27 06:23:47,258][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39850] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.53355
[2024-02-27 06:23:47,258][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39850] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.51897
[2024-02-27 06:24:13,641][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39900] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50398
[2024-02-27 06:24:13,641][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39900] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50109
[2024-02-27 06:24:39,650][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39950] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.52093
[2024-02-27 06:24:39,650][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39950] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 1.95662
[2024-02-27 06:25:06,110][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40000] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.54935
[2024-02-27 06:25:06,110][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40000] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50113
[2024-02-27 06:25:32,205][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40050] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.55964
[2024-02-27 06:25:32,205][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40050] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.56540
[2024-02-27 06:25:58,523][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40100] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50137
[2024-02-27 06:25:58,523][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40100] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.75446
[2024-02-27 06:26:24,643][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40150] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50872
[2024-02-27 06:26:24,643][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40150] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 1.28532
[2024-02-27 06:26:51,121][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40200] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 2.08286
[2024-02-27 06:26:51,121][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40200] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50091
[2024-02-27 06:27:17,111][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40250] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50082
[2024-02-27 06:27:17,111][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40250] - train_accuracy: 0.89016 - val_accuracy: 0.72920 - train_loss: 0.81275 - val_loss: 1.30556 - loss: 0.50088
[2024-02-27 06:28:10,649][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40300] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.87620
[2024-02-27 06:28:10,649][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40300] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50079
[2024-02-27 06:28:36,642][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40350] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50157
[2024-02-27 06:28:36,642][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40350] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.51095
[2024-02-27 06:29:02,954][PyLogger][INFO]: Rank[0]: Epoch[417/500], iter[40400] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.57572
[2024-02-27 06:29:02,954][PyLogger][INFO]: Rank[1]: Epoch[417/500], iter[40400] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50406
[2024-02-27 06:29:29,373][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40450] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50071
[2024-02-27 06:29:29,374][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40450] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50077
[2024-02-27 06:29:55,381][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40500] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50076
[2024-02-27 06:29:55,381][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40500] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50083
[2024-02-27 06:30:22,054][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40550] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50072
[2024-02-27 06:30:22,054][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40550] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50116
[2024-02-27 06:30:48,027][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40600] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50076
[2024-02-27 06:30:48,027][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40600] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50086
[2024-02-27 06:31:14,593][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40650] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50071
[2024-02-27 06:31:14,593][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40650] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50094
[2024-02-27 06:31:40,604][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40700] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.52823
[2024-02-27 06:31:40,604][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40700] - train_accuracy: 0.85478 - val_accuracy: 0.72920 - train_loss: 0.93091 - val_loss: 1.34361 - loss: 0.50201
[2024-02-27 06:32:33,862][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40750] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50132
[2024-02-27 06:32:33,862][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40750] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50082
[2024-02-27 06:32:59,869][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40800] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.73526
[2024-02-27 06:32:59,869][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40800] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50079
[2024-02-27 06:33:26,654][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40850] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50094
[2024-02-27 06:33:26,653][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40850] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50068
[2024-02-27 06:33:52,647][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40900] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 1.92281
[2024-02-27 06:33:52,647][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40900] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50105
[2024-02-27 06:34:19,082][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[40950] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.51768
[2024-02-27 06:34:19,082][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[40950] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.51410
[2024-02-27 06:34:45,133][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[41000] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.61781
[2024-02-27 06:34:45,133][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[41000] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50198
[2024-02-27 06:35:11,762][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41050] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50102
[2024-02-27 06:35:11,762][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41050] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50072
[2024-02-27 06:35:37,867][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41100] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 1.10481
[2024-02-27 06:35:37,867][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41100] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.55983
[2024-02-27 06:36:04,397][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41150] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50067
[2024-02-27 06:36:04,397][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41150] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.50095
[2024-02-27 06:36:30,553][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41200] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 1.35812
[2024-02-27 06:36:30,553][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41200] - train_accuracy: 0.92192 - val_accuracy: 0.79030 - train_loss: 0.70958 - val_loss: 1.06730 - loss: 0.89586
[2024-02-27 06:37:25,654][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41250] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50078
[2024-02-27 06:37:25,654][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41250] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50070
[2024-02-27 06:37:51,628][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41300] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.51428
[2024-02-27 06:37:51,628][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41300] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.53327
[2024-02-27 06:38:18,268][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41350] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50101
[2024-02-27 06:38:18,268][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41350] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50072
[2024-02-27 06:38:44,332][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41400] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 1.11946
[2024-02-27 06:38:44,332][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41400] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50083
[2024-02-27 06:39:10,683][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41450] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50067
[2024-02-27 06:39:10,683][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41450] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.77571
[2024-02-27 06:39:36,643][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41500] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50074
[2024-02-27 06:39:36,643][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41500] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50128
[2024-02-27 06:40:03,449][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41550] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50071
[2024-02-27 06:40:03,450][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41550] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 1.36120
[2024-02-27 06:40:29,373][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41600] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 1.66030
[2024-02-27 06:40:29,373][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41600] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.51014
[2024-02-27 06:40:55,919][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41650] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50071
[2024-02-27 06:40:55,919][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41650] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50074
[2024-02-27 06:41:21,959][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41700] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.55090
[2024-02-27 06:41:21,959][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41700] - train_accuracy: 0.92099 - val_accuracy: 0.73570 - train_loss: 0.73173 - val_loss: 1.30035 - loss: 0.50086
[2024-02-27 06:42:15,541][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41750] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50112
[2024-02-27 06:42:15,542][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41750] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50063
[2024-02-27 06:42:41,641][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41800] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50100
[2024-02-27 06:42:41,641][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41800] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50458
[2024-02-27 06:43:08,148][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41850] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50132
[2024-02-27 06:43:08,148][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41850] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.52635
[2024-02-27 06:43:34,173][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41900] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50066
[2024-02-27 06:43:34,173][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41900] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50073
[2024-02-27 06:44:00,678][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[41950] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50626
[2024-02-27 06:44:00,678][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[41950] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.51468
[2024-02-27 06:44:26,880][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[42000] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50079
[2024-02-27 06:44:26,880][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[42000] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50074
[2024-02-27 06:44:53,454][PyLogger][INFO]: Rank[0]: Epoch[434/500], iter[42050] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 1.94740
[2024-02-27 06:44:53,454][PyLogger][INFO]: Rank[1]: Epoch[434/500], iter[42050] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.58767
[2024-02-27 06:45:19,839][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42100] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 1.13677
[2024-02-27 06:45:19,839][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42100] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50080
[2024-02-27 06:45:45,920][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42150] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.50063
[2024-02-27 06:45:45,920][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42150] - train_accuracy: 0.92641 - val_accuracy: 0.78370 - train_loss: 0.70109 - val_loss: 1.04841 - loss: 0.72192
[2024-02-27 06:46:39,484][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42200] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50098
[2024-02-27 06:46:39,484][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42200] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50079
[2024-02-27 06:47:05,499][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42250] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 1.33857
[2024-02-27 06:47:05,499][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42250] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50080
[2024-02-27 06:47:32,086][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42300] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50116
[2024-02-27 06:47:32,086][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42300] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50072
[2024-02-27 06:47:58,148][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42350] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50062
[2024-02-27 06:47:58,148][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42350] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50077
[2024-02-27 06:48:24,582][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42400] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50063
[2024-02-27 06:48:24,582][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42400] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50151
[2024-02-27 06:48:50,554][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42450] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.52733
[2024-02-27 06:48:50,554][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42450] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50066
[2024-02-27 06:49:17,045][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42500] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50072
[2024-02-27 06:49:17,045][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42500] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50058
[2024-02-27 06:49:43,114][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42550] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50073
[2024-02-27 06:49:43,114][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42550] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50073
[2024-02-27 06:50:09,679][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42600] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 1.06287
[2024-02-27 06:50:09,679][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42600] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50062
[2024-02-27 06:50:35,580][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42650] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.50073
[2024-02-27 06:50:35,580][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42650] - train_accuracy: 0.88760 - val_accuracy: 0.80030 - train_loss: 0.83723 - val_loss: 1.09063 - loss: 0.57949
[2024-02-27 06:51:28,828][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42700] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50227
[2024-02-27 06:51:28,828][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42700] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50280
[2024-02-27 06:51:54,984][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42750] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50209
[2024-02-27 06:51:54,985][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42750] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50075
[2024-02-27 06:52:21,688][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42800] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.66280
[2024-02-27 06:52:21,689][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42800] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 1.31397
[2024-02-27 06:52:47,765][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42850] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50092
[2024-02-27 06:52:47,765][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42850] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.68645
[2024-02-27 06:53:14,347][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42900] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.89835
[2024-02-27 06:53:14,347][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42900] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50100
[2024-02-27 06:53:40,386][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42950] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50066
[2024-02-27 06:53:40,386][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42950] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 1.26425
[2024-02-27 06:54:06,853][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43000] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50061
[2024-02-27 06:54:06,853][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43000] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50067
[2024-02-27 06:54:33,001][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43050] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 1.14174
[2024-02-27 06:54:33,001][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43050] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 1.14025
[2024-02-27 06:54:59,589][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43100] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.57907
[2024-02-27 06:54:59,589][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43100] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50067
[2024-02-27 06:55:25,522][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43150] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50070
[2024-02-27 06:55:25,522][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43150] - train_accuracy: 0.90281 - val_accuracy: 0.85700 - train_loss: 0.79417 - val_loss: 0.89461 - loss: 0.50089
[2024-02-27 06:56:18,794][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43200] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50075
[2024-02-27 06:56:18,794][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43200] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.84818
[2024-02-27 06:56:44,737][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43250] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50748
[2024-02-27 06:56:44,737][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43250] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50062
[2024-02-27 06:57:11,453][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43300] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50077
[2024-02-27 06:57:11,453][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43300] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.53558
[2024-02-27 06:57:37,509][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43350] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50497
[2024-02-27 06:57:37,509][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43350] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 1.88376
[2024-02-27 06:58:04,000][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43400] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50065
[2024-02-27 06:58:04,000][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43400] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50074
[2024-02-27 06:58:29,929][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43450] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50061
[2024-02-27 06:58:29,929][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43450] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50074
[2024-02-27 06:58:56,310][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43500] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 1.40289
[2024-02-27 06:58:56,310][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43500] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50064
[2024-02-27 06:59:22,402][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43550] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.51264
[2024-02-27 06:59:22,402][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43550] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50094
[2024-02-27 06:59:49,016][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43600] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50066
[2024-02-27 06:59:49,016][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43600] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50059
[2024-02-27 07:00:15,201][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43650] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50062
[2024-02-27 07:00:15,201][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43650] - train_accuracy: 0.90949 - val_accuracy: 0.84280 - train_loss: 0.75597 - val_loss: 0.90821 - loss: 0.50125
[2024-02-27 07:01:09,283][PyLogger][INFO]: Rank[1]: Epoch[451/500], iter[43700] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50089
[2024-02-27 07:01:09,283][PyLogger][INFO]: Rank[0]: Epoch[451/500], iter[43700] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50081
[2024-02-27 07:01:35,934][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43750] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50067
[2024-02-27 07:01:35,934][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43750] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50063
[2024-02-27 07:02:02,001][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43800] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50385
[2024-02-27 07:02:02,001][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43800] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50074
[2024-02-27 07:02:28,847][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43850] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50082
[2024-02-27 07:02:28,847][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43850] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.52039
[2024-02-27 07:02:54,824][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43900] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.51617
[2024-02-27 07:02:54,824][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43900] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50218
[2024-02-27 07:03:21,186][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[43950] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50082
[2024-02-27 07:03:21,186][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[43950] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50073
[2024-02-27 07:03:47,271][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[44000] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50063
[2024-02-27 07:03:47,271][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[44000] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.57600
[2024-02-27 07:04:13,790][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44050] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 1.88702
[2024-02-27 07:04:13,790][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44050] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 1.54248
[2024-02-27 07:04:39,740][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44100] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.50061
[2024-02-27 07:04:39,741][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44100] - train_accuracy: 0.84645 - val_accuracy: 0.82990 - train_loss: 0.96298 - val_loss: 1.02776 - loss: 0.66642
[2024-02-27 07:05:33,622][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44150] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.51451
[2024-02-27 07:05:33,622][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44150] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50078
[2024-02-27 07:05:59,466][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44200] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.51916
[2024-02-27 07:05:59,466][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44200] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50056
[2024-02-27 07:06:25,803][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44250] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50060
[2024-02-27 07:06:25,803][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44250] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.60208
[2024-02-27 07:06:51,853][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44300] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50359
[2024-02-27 07:06:51,853][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44300] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 1.89798
[2024-02-27 07:07:18,373][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44350] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.81263
[2024-02-27 07:07:18,373][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44350] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50060
[2024-02-27 07:07:44,323][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44400] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50060
[2024-02-27 07:07:44,323][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44400] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50067
[2024-02-27 07:08:10,909][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44450] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 1.97548
[2024-02-27 07:08:10,909][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44450] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50060
[2024-02-27 07:08:36,950][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44500] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 1.89600
[2024-02-27 07:08:36,950][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44500] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50067
[2024-02-27 07:09:03,624][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44550] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50633
[2024-02-27 07:09:03,624][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44550] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 1.95627
[2024-02-27 07:09:29,689][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44600] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50079
[2024-02-27 07:09:29,689][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44600] - train_accuracy: 0.90057 - val_accuracy: 0.83860 - train_loss: 0.79706 - val_loss: 0.95723 - loss: 0.50069
[2024-02-27 07:10:24,797][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44650] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50065
[2024-02-27 07:10:24,797][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44650] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50065
[2024-02-27 07:10:50,800][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44700] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50064
[2024-02-27 07:10:50,800][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44700] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.57328
[2024-02-27 07:11:17,129][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44750] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.57171
[2024-02-27 07:11:17,129][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44750] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50065
[2024-02-27 07:11:42,971][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44800] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50182
[2024-02-27 07:11:42,971][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44800] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.57718
[2024-02-27 07:12:09,469][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44850] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50057
[2024-02-27 07:12:09,469][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44850] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50073
[2024-02-27 07:12:35,462][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44900] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50066
[2024-02-27 07:12:35,462][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44900] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50731
[2024-02-27 07:13:01,836][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[44950] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50056
[2024-02-27 07:13:01,836][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[44950] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50075
[2024-02-27 07:13:27,834][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[45000] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50059
[2024-02-27 07:13:27,834][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[45000] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 1.59517
[2024-02-27 07:13:54,400][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45050] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50076
[2024-02-27 07:13:54,400][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45050] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50056
[2024-02-27 07:14:20,414][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45100] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 0.50056
[2024-02-27 07:14:20,414][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45100] - train_accuracy: 0.88060 - val_accuracy: 0.80260 - train_loss: 0.83847 - val_loss: 1.07830 - loss: 1.36026
[2024-02-27 07:15:14,025][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45150] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50218
[2024-02-27 07:15:14,025][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45150] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.57853
[2024-02-27 07:15:40,134][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45200] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50069
[2024-02-27 07:15:40,134][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45200] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50060
[2024-02-27 07:16:06,531][PyLogger][INFO]: Rank[0]: Epoch[467/500], iter[45250] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.82582
[2024-02-27 07:16:06,531][PyLogger][INFO]: Rank[1]: Epoch[467/500], iter[45250] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50057
[2024-02-27 07:16:33,140][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45300] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.56742
[2024-02-27 07:16:33,140][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45300] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50065
[2024-02-27 07:16:59,200][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45350] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50084
[2024-02-27 07:16:59,200][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45350] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 1.95822
[2024-02-27 07:17:25,730][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45400] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50057
[2024-02-27 07:17:25,730][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45400] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50070
[2024-02-27 07:17:51,761][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45450] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.86891
[2024-02-27 07:17:51,761][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45450] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50055
[2024-02-27 07:18:19,292][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45500] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50064
[2024-02-27 07:18:19,292][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45500] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.78966
[2024-02-27 07:18:45,261][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45550] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50583
[2024-02-27 07:18:45,262][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45550] - train_accuracy: 0.94833 - val_accuracy: 0.78360 - train_loss: 0.64050 - val_loss: 1.09730 - loss: 0.50057
[2024-02-27 07:19:38,620][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45600] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50562
[2024-02-27 07:19:38,620][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45600] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50063
[2024-02-27 07:20:04,684][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45650] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50067
[2024-02-27 07:20:04,685][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45650] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50059
[2024-02-27 07:20:31,179][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45700] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 1.92049
[2024-02-27 07:20:31,179][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45700] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.52530
[2024-02-27 07:20:57,257][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45750] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 1.38043
[2024-02-27 07:20:57,257][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45750] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50482
[2024-02-27 07:21:23,821][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45800] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50064
[2024-02-27 07:21:23,821][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45800] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 1.30159
[2024-02-27 07:21:49,761][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45850] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.51906
[2024-02-27 07:21:49,761][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45850] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50128
[2024-02-27 07:22:16,232][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45900] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50092
[2024-02-27 07:22:16,232][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45900] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 1.04242
[2024-02-27 07:22:42,151][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45950] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.81967
[2024-02-27 07:22:42,151][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45950] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 2.03837
[2024-02-27 07:23:08,601][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46000] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50064
[2024-02-27 07:23:08,601][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46000] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50667
[2024-02-27 07:23:34,578][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46050] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50086
[2024-02-27 07:23:34,578][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46050] - train_accuracy: 0.89578 - val_accuracy: 0.78620 - train_loss: 0.77845 - val_loss: 1.02200 - loss: 0.50066
[2024-02-27 07:24:28,857][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46100] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50068
[2024-02-27 07:24:28,857][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46100] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50050
[2024-02-27 07:24:54,806][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46150] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.58125
[2024-02-27 07:24:54,806][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46150] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50070
[2024-02-27 07:25:21,289][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46200] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.67509
[2024-02-27 07:25:21,289][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46200] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50698
[2024-02-27 07:25:47,310][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46250] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 1.06465
[2024-02-27 07:25:47,310][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46250] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50067
[2024-02-27 07:26:13,762][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46300] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 1.01320
[2024-02-27 07:26:13,762][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46300] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50053
[2024-02-27 07:26:39,936][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46350] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50064
[2024-02-27 07:26:39,936][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46350] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50065
[2024-02-27 07:27:06,373][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46400] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50069
[2024-02-27 07:27:06,374][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46400] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.97501
[2024-02-27 07:27:32,499][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46450] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 1.43605
[2024-02-27 07:27:32,499][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46450] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.51322
[2024-02-27 07:27:59,181][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46500] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50066
[2024-02-27 07:27:59,181][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46500] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50108
[2024-02-27 07:28:25,229][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46550] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 1.97808
[2024-02-27 07:28:25,229][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46550] - train_accuracy: 0.92864 - val_accuracy: 0.82190 - train_loss: 0.69235 - val_loss: 0.91766 - loss: 0.50059
[2024-02-27 07:29:18,543][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46600] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50062
[2024-02-27 07:29:18,543][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46600] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50268
[2024-02-27 07:29:44,484][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46650] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.57421
[2024-02-27 07:29:44,484][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46650] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 1.62127
[2024-02-27 07:30:11,018][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46700] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.68719
[2024-02-27 07:30:11,018][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46700] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50064
[2024-02-27 07:30:37,137][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46750] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50069
[2024-02-27 07:30:37,137][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46750] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50100
[2024-02-27 07:31:03,779][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46800] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50056
[2024-02-27 07:31:03,778][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46800] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.52936
[2024-02-27 07:31:29,671][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46850] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.54051
[2024-02-27 07:31:29,671][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46850] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50071
[2024-02-27 07:31:56,297][PyLogger][INFO]: Rank[0]: Epoch[484/500], iter[46900] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50064
[2024-02-27 07:31:56,297][PyLogger][INFO]: Rank[1]: Epoch[484/500], iter[46900] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 1.29951
[2024-02-27 07:32:22,878][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[46950] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50058
[2024-02-27 07:32:22,878][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[46950] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 1.01776
[2024-02-27 07:32:48,934][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[47000] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 0.50116
[2024-02-27 07:32:48,934][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[47000] - train_accuracy: 0.92433 - val_accuracy: 0.79610 - train_loss: 0.70361 - val_loss: 1.02701 - loss: 1.96666
[2024-02-27 07:33:42,458][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47050] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 1.02521
[2024-02-27 07:33:42,458][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47050] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50066
[2024-02-27 07:34:08,530][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47100] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50057
[2024-02-27 07:34:08,530][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47100] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50065
[2024-02-27 07:34:35,359][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47150] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 1.64608
[2024-02-27 07:34:35,359][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47150] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.51206
[2024-02-27 07:35:01,383][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47200] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50061
[2024-02-27 07:35:01,383][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47200] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50057
[2024-02-27 07:35:27,949][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47250] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50058
[2024-02-27 07:35:27,949][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47250] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.53791
[2024-02-27 07:35:53,979][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47300] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50073
[2024-02-27 07:35:53,979][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47300] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50904
[2024-02-27 07:36:20,588][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47350] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50061
[2024-02-27 07:36:20,588][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47350] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50067
[2024-02-27 07:36:46,663][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47400] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50052
[2024-02-27 07:36:46,663][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47400] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 2.02332
[2024-02-27 07:37:13,016][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47450] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50060
[2024-02-27 07:37:13,016][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47450] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50065
[2024-02-27 07:37:38,989][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47500] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.57951
[2024-02-27 07:37:38,989][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47500] - train_accuracy: 0.91936 - val_accuracy: 0.79390 - train_loss: 0.73003 - val_loss: 1.11890 - loss: 0.50062
[2024-02-27 07:38:32,295][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47550] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50072
[2024-02-27 07:38:32,295][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47550] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50057
[2024-02-27 07:38:58,469][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47600] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50063
[2024-02-27 07:38:58,469][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47600] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50062
[2024-02-27 07:39:25,097][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47650] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50073
[2024-02-27 07:39:25,097][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47650] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.63063
[2024-02-27 07:39:51,180][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47700] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50075
[2024-02-27 07:39:51,180][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47700] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 1.33601
[2024-02-27 07:40:17,863][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47750] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.75358
[2024-02-27 07:40:17,863][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47750] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50386
[2024-02-27 07:40:43,909][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47800] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50291
[2024-02-27 07:40:43,909][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47800] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50104
[2024-02-27 07:41:10,352][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47850] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50068
[2024-02-27 07:41:10,352][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47850] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.51913
[2024-02-27 07:41:36,489][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47900] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50066
[2024-02-27 07:41:36,489][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47900] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50057
[2024-02-27 07:42:02,919][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[47950] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50059
[2024-02-27 07:42:02,919][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[47950] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50054
[2024-02-27 07:42:29,000][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[48000] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.53595
[2024-02-27 07:42:29,001][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[48000] - train_accuracy: 0.91060 - val_accuracy: 0.65760 - train_loss: 0.74425 - val_loss: 1.46243 - loss: 0.50056
[2024-02-27 07:43:22,732][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48050] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50053
[2024-02-27 07:43:22,732][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48050] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50106
[2024-02-27 07:43:48,792][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48100] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50064
[2024-02-27 07:43:48,792][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48100] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.51351
[2024-02-27 07:44:15,313][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48150] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.15072
[2024-02-27 07:44:15,313][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48150] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.52483
[2024-02-27 07:44:41,333][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48200] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50063
[2024-02-27 07:44:41,333][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48200] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50067
[2024-02-27 07:45:07,919][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48250] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50056
[2024-02-27 07:45:07,919][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48250] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50058
[2024-02-27 07:45:34,094][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48300] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50063
[2024-02-27 07:45:34,094][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48300] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.04316
[2024-02-27 07:46:00,653][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48350] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50063
[2024-02-27 07:46:00,653][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48350] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50141
[2024-02-27 07:46:26,743][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48400] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.24406
[2024-02-27 07:46:26,743][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48400] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.61172
[2024-02-27 07:46:53,192][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48450] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.57463
[2024-02-27 07:46:53,192][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48450] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.50063
[2024-02-27 07:47:19,287][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48500] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 1.03681
[2024-02-27 07:47:19,287][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48500] - train_accuracy: 0.90224 - val_accuracy: 0.79850 - train_loss: 0.77807 - val_loss: 1.08261 - loss: 0.99408
Files already downloaded and verified
Files already downloaded and verified
2024-02-27 07:47:47,760 ignite.distributed.launcher.Parallel INFO: End of run
2024-02-27 07:47:51,839 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:47:51,839 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:47:51,840 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c492afa3e0>' in 2 processes
2024-02-27 07:47:59,434 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:47:59,840 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a6fe4415e0>}
[2024-02-27 07:48:00,609][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:48:00,609][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:48:00,609][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:00,610][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:48:00,611][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:48:00,611][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:00,611][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:00,611][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:00,611][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:00,611][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:05,685][PyLogger][INFO]: Rank[1]: val_accuracy: 0.19920
[2024-02-27 07:48:05,685][PyLogger][INFO]: Rank[0]: val_accuracy: 0.19920
2024-02-27 07:48:07,199 ignite.distributed.launcher.Parallel INFO: End of run
new_size=2 done.
2024-02-27 07:48:10,609 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:48:10,609 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:48:10,609 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154853fee3e0>' in 2 processes
2024-02-27 07:48:18,191 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:48:18,578 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15278a08f260>}
[2024-02-27 07:48:18,692][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:18,692][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:18,692][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:18,697][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:48:18,697][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:48:18,697][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:18,697][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:48:18,698][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:48:18,698][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:18,698][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:23,958][PyLogger][INFO]: Rank[0]: val_accuracy: 0.28210
[2024-02-27 07:48:23,958][PyLogger][INFO]: Rank[1]: val_accuracy: 0.28210
2024-02-27 07:48:25,485 ignite.distributed.launcher.Parallel INFO: End of run
new_size=3 done.
2024-02-27 07:48:28,903 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:48:28,903 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:48:28,903 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1499dd32a3e0>' in 2 processes
2024-02-27 07:48:36,483 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:48:36,875 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b5a6c40e00>}
[2024-02-27 07:48:36,989][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:48:36,989][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:48:36,989][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:36,989][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:48:36,990][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:48:36,991][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:36,991][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:36,993][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:36,993][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:36,994][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:42,183][PyLogger][INFO]: Rank[0]: val_accuracy: 0.42450
[2024-02-27 07:48:42,183][PyLogger][INFO]: Rank[1]: val_accuracy: 0.42450
2024-02-27 07:48:43,708 ignite.distributed.launcher.Parallel INFO: End of run
new_size=4 done.
2024-02-27 07:48:47,342 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:48:47,342 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:48:47,342 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x151d16a4a3e0>' in 2 processes
2024-02-27 07:48:53,902 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:48:54,299 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145e74304440>}
[2024-02-27 07:48:54,411][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:54,412][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:54,412][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:54,418][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:48:54,418][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:48:54,418][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:48:54,418][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:48:54,419][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:48:54,419][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:48:54,419][PyLogger][INFO]: World size: 2
[2024-02-27 07:48:59,597][PyLogger][INFO]: Rank[1]: val_accuracy: 0.55250
[2024-02-27 07:48:59,597][PyLogger][INFO]: Rank[0]: val_accuracy: 0.55250
2024-02-27 07:49:00,664 ignite.distributed.launcher.Parallel INFO: End of run
new_size=5 done.
2024-02-27 07:49:04,298 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:49:04,298 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:49:04,298 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x145cc899a3e0>' in 2 processes
2024-02-27 07:49:10,862 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:49:11,271 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145434eee000>}
[2024-02-27 07:49:11,388][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:11,388][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:11,388][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:11,390][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:49:11,390][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:49:11,390][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:11,390][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:49:11,391][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:49:11,391][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:11,391][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:16,487][PyLogger][INFO]: Rank[0]: val_accuracy: 0.67560
[2024-02-27 07:49:16,487][PyLogger][INFO]: Rank[1]: val_accuracy: 0.67560
2024-02-27 07:49:17,953 ignite.distributed.launcher.Parallel INFO: End of run
new_size=6 done.
2024-02-27 07:49:21,338 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:49:21,338 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:49:21,338 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14787f75a3e0>' in 2 processes
2024-02-27 07:49:27,838 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:49:28,231 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1495a3780860>}
[2024-02-27 07:49:28,344][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:49:28,344][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:49:28,344][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:28,344][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:49:28,345][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:49:28,345][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:28,345][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:28,348][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:28,348][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:28,348][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:33,658][PyLogger][INFO]: Rank[1]: val_accuracy: 0.74240
[2024-02-27 07:49:33,658][PyLogger][INFO]: Rank[0]: val_accuracy: 0.74240
2024-02-27 07:49:35,163 ignite.distributed.launcher.Parallel INFO: End of run
new_size=7 done.
2024-02-27 07:49:38,634 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:49:38,634 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:49:38,634 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x153596d3e3e0>' in 2 processes
2024-02-27 07:49:45,128 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:49:45,555 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15299f540740>}
[2024-02-27 07:49:45,667][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:49:45,667][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:49:45,667][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:45,667][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:49:45,668][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:49:45,668][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:45,669][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:45,678][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:49:45,678][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:49:45,678][PyLogger][INFO]: World size: 2
[2024-02-27 07:49:50,824][PyLogger][INFO]: Rank[1]: val_accuracy: 0.78620
[2024-02-27 07:49:50,824][PyLogger][INFO]: Rank[0]: val_accuracy: 0.78620
2024-02-27 07:49:52,327 ignite.distributed.launcher.Parallel INFO: End of run
new_size=8 done.
2024-02-27 07:49:55,838 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:49:55,838 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:49:55,838 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14dcda3063e0>' in 2 processes
2024-02-27 07:50:02,345 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:50:02,747 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b208ba80e0>}
[2024-02-27 07:50:02,864][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:50:02,864][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:50:02,864][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:02,864][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:50:02,865][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:50:02,865][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:02,865][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:02,866][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:02,866][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:02,866][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:07,978][PyLogger][INFO]: Rank[0]: val_accuracy: 0.80370
[2024-02-27 07:50:07,978][PyLogger][INFO]: Rank[1]: val_accuracy: 0.80370
2024-02-27 07:50:09,457 ignite.distributed.launcher.Parallel INFO: End of run
new_size=9 done.
2024-02-27 07:50:13,169 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:50:13,169 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:50:13,169 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15364e69a3e0>' in 2 processes
2024-02-27 07:50:19,858 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:50:20,271 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1496d8de2000>}
[2024-02-27 07:50:20,389][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:20,389][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:20,389][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:50:20,389][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:20,389][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:50:20,389][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:20,389][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:50:20,390][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:50:20,390][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:20,390][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:25,534][PyLogger][INFO]: Rank[1]: val_accuracy: 0.82120
[2024-02-27 07:50:25,534][PyLogger][INFO]: Rank[0]: val_accuracy: 0.82120
2024-02-27 07:50:27,048 ignite.distributed.launcher.Parallel INFO: End of run
new_size=10 done.
2024-02-27 07:50:30,394 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:50:30,395 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:50:30,395 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150a992a23e0>' in 2 processes
2024-02-27 07:50:38,052 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:50:38,450 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15002dad8380>}
[2024-02-27 07:50:38,564][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:50:38,564][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:50:38,565][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:38,565][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:50:38,565][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:38,565][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:38,566][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:38,566][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:50:38,566][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:38,566][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:43,804][PyLogger][INFO]: Rank[1]: val_accuracy: 0.83380
[2024-02-27 07:50:43,804][PyLogger][INFO]: Rank[0]: val_accuracy: 0.83380
2024-02-27 07:50:45,344 ignite.distributed.launcher.Parallel INFO: End of run
new_size=11 done.
2024-02-27 07:50:48,735 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:50:48,735 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:50:48,735 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1535664263e0>' in 2 processes
2024-02-27 07:50:56,365 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:50:56,760 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1501c5228a10>}
[2024-02-27 07:50:56,877][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:50:56,877][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:50:56,877][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:56,877][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:50:56,878][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:50:56,878][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:56,878][PyLogger][INFO]: World size: 2
[2024-02-27 07:50:56,880][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:50:56,880][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:50:56,880][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:02,016][PyLogger][INFO]: Rank[1]: val_accuracy: 0.83840
[2024-02-27 07:51:02,016][PyLogger][INFO]: Rank[0]: val_accuracy: 0.83840
2024-02-27 07:51:03,604 ignite.distributed.launcher.Parallel INFO: End of run
new_size=12 done.
2024-02-27 07:51:07,169 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:51:07,169 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:51:07,169 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1542bc3663e0>' in 2 processes
2024-02-27 07:51:14,588 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:51:15,003 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14e967cd8800>}
[2024-02-27 07:51:15,123][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:51:15,123][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:51:15,123][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:15,123][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:51:15,124][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:51:15,124][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:15,124][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:15,127][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:15,127][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:15,127][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:20,289][PyLogger][INFO]: Rank[1]: val_accuracy: 0.83910
[2024-02-27 07:51:20,289][PyLogger][INFO]: Rank[0]: val_accuracy: 0.83910
2024-02-27 07:51:21,791 ignite.distributed.launcher.Parallel INFO: End of run
new_size=13 done.
2024-02-27 07:51:25,492 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:51:25,492 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:51:25,492 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154b0db063e0>' in 2 processes
2024-02-27 07:51:32,065 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:51:32,482 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1476439dd370>}
[2024-02-27 07:51:32,594][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:51:32,594][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:51:32,595][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:32,595][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:51:32,595][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:51:32,596][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:32,596][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:32,597][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:32,598][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:32,598][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:37,819][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85080
[2024-02-27 07:51:37,819][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85080
2024-02-27 07:51:39,317 ignite.distributed.launcher.Parallel INFO: End of run
new_size=14 done.
2024-02-27 07:51:43,158 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:51:43,158 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:51:43,158 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1554d93f23e0>' in 2 processes
2024-02-27 07:51:49,808 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:51:50,215 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f22bfd4260>}
[2024-02-27 07:51:50,330][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:51:50,330][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:51:50,330][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:50,330][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:51:50,331][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:51:50,331][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:50,331][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:50,332][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:51:50,332][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:51:50,332][PyLogger][INFO]: World size: 2
[2024-02-27 07:51:55,515][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85580
[2024-02-27 07:51:55,515][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85580
2024-02-27 07:51:57,014 ignite.distributed.launcher.Parallel INFO: End of run
new_size=15 done.
2024-02-27 07:52:00,593 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:52:00,593 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:52:00,593 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1507ce5463e0>' in 2 processes
2024-02-27 07:52:08,098 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:52:08,499 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1503dd890860>}
[2024-02-27 07:52:08,616][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:52:08,616][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:52:08,616][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:08,616][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:52:08,617][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:52:08,617][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:08,617][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:08,617][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:08,617][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:08,617][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:13,830][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85990
[2024-02-27 07:52:13,830][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85990
2024-02-27 07:52:15,358 ignite.distributed.launcher.Parallel INFO: End of run
new_size=16 done.
2024-02-27 07:52:18,820 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:52:18,820 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:52:18,820 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14783d0663e0>' in 2 processes
2024-02-27 07:52:25,393 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:52:25,807 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1529f8906d20>}
[2024-02-27 07:52:25,919][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:25,919][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:25,919][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:25,926][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:52:25,926][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:52:25,926][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:25,926][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:52:25,927][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:52:25,927][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:25,927][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:31,040][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85860
[2024-02-27 07:52:31,041][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85860
2024-02-27 07:52:32,119 ignite.distributed.launcher.Parallel INFO: End of run
new_size=17 done.
2024-02-27 07:52:35,944 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:52:35,944 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:52:35,944 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14888e1b23e0>' in 2 processes
2024-02-27 07:52:42,739 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:52:43,150 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15015f15c200>}
[2024-02-27 07:52:43,270][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:52:43,270][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:52:43,270][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:43,270][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:52:43,271][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:52:43,271][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:43,271][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:43,271][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:52:43,271][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:52:43,272][PyLogger][INFO]: World size: 2
[2024-02-27 07:52:48,470][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85530
[2024-02-27 07:52:48,470][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85530
2024-02-27 07:52:49,969 ignite.distributed.launcher.Parallel INFO: End of run
new_size=18 done.
2024-02-27 07:52:53,421 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:52:53,421 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:52:53,421 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1512463663e0>' in 2 processes
2024-02-27 07:52:59,999 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:53:00,408 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14dd702b1640>}
[2024-02-27 07:53:00,522][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:53:00,522][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:53:00,522][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:00,522][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:53:00,523][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:53:00,523][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:00,524][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:00,524][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:00,524][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:00,524][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:05,641][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85790
[2024-02-27 07:53:05,641][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85790
2024-02-27 07:53:07,141 ignite.distributed.launcher.Parallel INFO: End of run
new_size=19 done.
2024-02-27 07:53:10,607 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:53:10,607 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:53:10,608 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15396fce23e0>' in 2 processes
2024-02-27 07:53:18,103 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:53:18,505 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15003e560c80>}
[2024-02-27 07:53:18,619][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:53:18,619][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:53:18,619][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:18,619][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:53:18,620][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:53:18,620][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:18,620][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:18,622][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:18,622][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:18,622][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:23,836][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85570
[2024-02-27 07:53:23,836][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85570
2024-02-27 07:53:25,418 ignite.distributed.launcher.Parallel INFO: End of run
new_size=20 done.
2024-02-27 07:53:28,943 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:53:28,943 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:53:28,943 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15216119a3e0>' in 2 processes
2024-02-27 07:53:36,464 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:53:36,862 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14afa9ac6d20>}
[2024-02-27 07:53:36,978][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:36,978][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:36,978][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:36,982][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:53:36,982][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:53:36,982][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:36,982][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:53:36,983][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:53:36,983][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:36,983][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:42,164][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86030
[2024-02-27 07:53:42,165][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86030
2024-02-27 07:53:43,674 ignite.distributed.launcher.Parallel INFO: End of run
new_size=21 done.
2024-02-27 07:53:47,385 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:53:47,385 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:53:47,385 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x147d934063e0>' in 2 processes
2024-02-27 07:53:54,982 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:53:55,392 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1518540e5640>}
[2024-02-27 07:53:55,502][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:53:55,502][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:53:55,502][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:55,502][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:53:55,503][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:53:55,503][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:55,503][PyLogger][INFO]: World size: 2
[2024-02-27 07:53:55,507][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:53:55,507][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:53:55,507][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:00,654][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85790
[2024-02-27 07:54:00,654][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85790
2024-02-27 07:54:02,185 ignite.distributed.launcher.Parallel INFO: End of run
new_size=22 done.
2024-02-27 07:54:05,544 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:54:05,545 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:54:05,545 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14efd03223e0>' in 2 processes
2024-02-27 07:54:13,008 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:54:13,396 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x152b4edb9b80>}
[2024-02-27 07:54:13,512][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:54:13,512][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:54:13,512][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:13,512][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:54:13,513][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:54:13,513][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:13,513][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:13,526][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:13,526][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:13,526][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:18,640][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86020
[2024-02-27 07:54:18,640][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86020
2024-02-27 07:54:20,169 ignite.distributed.launcher.Parallel INFO: End of run
new_size=23 done.
2024-02-27 07:54:23,739 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:54:23,739 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:54:23,739 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1501b649a3e0>' in 2 processes
2024-02-27 07:54:30,237 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:54:30,634 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d7e59d4440>}
[2024-02-27 07:54:30,750][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:54:30,750][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:54:30,750][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:30,750][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:54:30,751][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:54:30,751][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:30,752][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:30,753][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:30,753][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:30,753][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:35,955][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86430
[2024-02-27 07:54:35,955][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86430
2024-02-27 07:54:37,446 ignite.distributed.launcher.Parallel INFO: End of run
new_size=24 done.
2024-02-27 07:54:41,088 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:54:41,088 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:54:41,088 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x149b6d58a3e0>' in 2 processes
2024-02-27 07:54:47,965 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:54:48,359 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14895ea80c80>}
[2024-02-27 07:54:48,473][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:54:48,473][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:54:48,474][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:48,474][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:54:48,475][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:54:48,475][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:48,475][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:48,479][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:54:48,479][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:54:48,479][PyLogger][INFO]: World size: 2
[2024-02-27 07:54:53,740][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86050
[2024-02-27 07:54:53,740][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86050
2024-02-27 07:54:55,242 ignite.distributed.launcher.Parallel INFO: End of run
new_size=25 done.
2024-02-27 07:54:58,968 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:54:58,968 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:54:58,968 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e8066623e0>' in 2 processes
2024-02-27 07:55:06,656 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:55:07,057 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15442ada8680>}
[2024-02-27 07:55:07,175][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:07,175][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:07,175][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:07,176][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:55:07,176][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:55:07,177][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:07,177][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:55:07,177][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:55:07,178][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:07,178][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:12,322][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86050
[2024-02-27 07:55:12,322][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86050
2024-02-27 07:55:13,913 ignite.distributed.launcher.Parallel INFO: End of run
new_size=26 done.
2024-02-27 07:55:17,393 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:55:17,394 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:55:17,394 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146fc40223e0>' in 2 processes
2024-02-27 07:55:24,920 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:55:25,318 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151752590440>}
[2024-02-27 07:55:25,432][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:55:25,432][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:55:25,432][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:25,432][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:55:25,433][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:55:25,433][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:25,433][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:25,434][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:25,434][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:25,434][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:30,526][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86210
[2024-02-27 07:55:30,526][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86210
2024-02-27 07:55:32,051 ignite.distributed.launcher.Parallel INFO: End of run
new_size=27 done.
2024-02-27 07:55:35,708 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:55:35,708 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:55:35,709 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15388ee063e0>' in 2 processes
2024-02-27 07:55:42,226 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:55:42,630 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148cb0638c80>}
[2024-02-27 07:55:42,745][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:55:42,746][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:55:42,746][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:42,746][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:55:42,747][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:55:42,747][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:42,747][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:42,747][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:42,747][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:42,747][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:47,919][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86350
[2024-02-27 07:55:47,919][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86350
2024-02-27 07:55:49,415 ignite.distributed.launcher.Parallel INFO: End of run
new_size=28 done.
2024-02-27 07:55:52,986 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:55:52,986 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:55:52,986 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d6213063e0>' in 2 processes
2024-02-27 07:55:59,379 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:55:59,771 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14cdc9b560f0>}
[2024-02-27 07:55:59,887][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:55:59,887][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:55:59,888][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:59,888][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:55:59,888][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:55:59,889][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:59,889][PyLogger][INFO]: World size: 2
[2024-02-27 07:55:59,891][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:55:59,891][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:55:59,891][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:05,107][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86370
[2024-02-27 07:56:05,107][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86370
2024-02-27 07:56:06,689 ignite.distributed.launcher.Parallel INFO: End of run
new_size=29 done.
2024-02-27 07:56:10,781 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:56:10,781 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:56:10,781 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150595db23e0>' in 2 processes
2024-02-27 07:56:18,529 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:56:18,939 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1513f14d0440>}
[2024-02-27 07:56:19,058][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:56:19,058][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:56:19,058][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:19,058][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:56:19,059][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:56:19,059][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:19,059][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:19,060][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:19,060][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:19,060][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:24,192][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86370
[2024-02-27 07:56:24,192][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86370
2024-02-27 07:56:25,710 ignite.distributed.launcher.Parallel INFO: End of run
new_size=30 done.
2024-02-27 07:56:29,211 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:56:29,211 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:56:29,211 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d2efd223e0>' in 2 processes
2024-02-27 07:56:35,763 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:56:36,161 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a83b248740>}
[2024-02-27 07:56:36,276][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:36,276][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:36,276][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:36,279][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:56:36,279][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:56:36,279][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:36,279][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:56:36,280][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:56:36,280][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:36,280][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:41,526][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86590
[2024-02-27 07:56:41,526][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86590
2024-02-27 07:56:43,063 ignite.distributed.launcher.Parallel INFO: End of run
new_size=31 done.
2024-02-27 07:56:46,527 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:56:46,527 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:56:46,527 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14607cc863e0>' in 2 processes
2024-02-27 07:56:53,904 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:56:54,299 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b87b1082c0>}
[2024-02-27 07:56:54,413][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:54,413][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:54,413][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:54,417][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:56:54,417][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:56:54,417][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:56:54,417][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:56:54,418][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:56:54,418][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:56:54,418][PyLogger][INFO]: World size: 2
[2024-02-27 07:56:59,571][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86680
[2024-02-27 07:56:59,571][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86680
2024-02-27 07:57:01,101 ignite.distributed.launcher.Parallel INFO: End of run
new_size=32 done.
2024-02-27 07:57:04,559 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:57:04,559 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:57:04,559 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1473101263e0>' in 2 processes
2024-02-27 07:57:12,137 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:57:12,535 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14617002c530>}
[2024-02-27 07:57:12,653][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:57:12,653][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:57:12,653][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:12,653][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:57:12,654][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:57:12,654][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:12,654][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:12,654][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:12,655][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:12,655][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:17,874][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86590
[2024-02-27 07:57:17,874][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86590
2024-02-27 07:57:19,395 ignite.distributed.launcher.Parallel INFO: End of run
new_size=33 done.
2024-02-27 07:57:23,229 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:57:23,229 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:57:23,229 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14aa1ffd63e0>' in 2 processes
2024-02-27 07:57:30,126 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:57:30,535 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14e5b3794680>}
[2024-02-27 07:57:30,647][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:57:30,647][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:57:30,647][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:30,647][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:57:30,648][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:57:30,648][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:30,648][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:30,650][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:30,650][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:30,650][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:35,861][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86370
[2024-02-27 07:57:35,861][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86370
2024-02-27 07:57:37,372 ignite.distributed.launcher.Parallel INFO: End of run
new_size=34 done.
2024-02-27 07:57:41,031 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:57:41,031 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:57:41,031 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154fc61ce3e0>' in 2 processes
2024-02-27 07:57:47,923 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:57:48,319 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1553496d7440>}
[2024-02-27 07:57:48,435][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:57:48,435][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:57:48,435][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:48,435][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:57:48,436][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:57:48,436][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:48,436][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:48,436][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:57:48,436][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:57:48,436][PyLogger][INFO]: World size: 2
[2024-02-27 07:57:53,585][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86590
[2024-02-27 07:57:53,585][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86590
2024-02-27 07:57:55,094 ignite.distributed.launcher.Parallel INFO: End of run
new_size=35 done.
2024-02-27 07:57:58,519 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:57:58,519 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:57:58,519 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d77c9e23e0>' in 2 processes
2024-02-27 07:58:05,078 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:58:05,486 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149cdb9a1550>}
[2024-02-27 07:58:05,600][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:58:05,600][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:58:05,600][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:58:05,600][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:58:05,601][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:58:05,601][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:58:05,601][PyLogger][INFO]: World size: 2
[2024-02-27 07:58:05,605][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:58:05,605][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:58:05,605][PyLogger][INFO]: World size: 2
[2024-02-27 07:58:10,770][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86350
[2024-02-27 07:58:10,771][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86350
2024-02-27 07:58:12,260 ignite.distributed.launcher.Parallel INFO: End of run
new_size=36 done.
