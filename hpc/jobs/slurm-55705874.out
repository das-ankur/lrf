SLURM_JOB_ID: 55705874
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: dct_cifar10_dec
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r22g39
SLURM_JOB_CPUS_PER_NODE: 18
SLURM_JOB_GPUS: 2,3
Date: Tue Feb 27 07:58:16 CET 2024
Walltime: 00-12:00:00
========================================================================
2024-02-27 07:58:19,840 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 07:58:19,840 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 07:58:19,840 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x146c2a8d13a0>' in 2 processes
2024-02-27 07:58:26,956 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 07:58:27,784 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149764e13500>}
2024-02-27 07:58:28,129 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149764901eb0>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-27 07:58:28,138][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 07:58:28,138][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:58:28,139][PyLogger][INFO]: World size: 2
[2024-02-27 07:58:28,140][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 07:58:28,140][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 07:58:28,140][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 07:58:28,140][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 07:58:28,154][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 07:58:28,154][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 07:58:28,154][PyLogger][INFO]: World size: 2
[2024-02-27 07:58:50,749][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 8.51670
[2024-02-27 07:58:50,750][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 2.55413
[2024-02-27 07:59:11,943][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.80011
[2024-02-27 07:59:11,943][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.54542
[2024-02-27 07:59:33,060][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.41677
[2024-02-27 07:59:33,060][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.54772
[2024-02-27 07:59:54,500][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.33533
[2024-02-27 07:59:54,500][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.33320
[2024-02-27 08:00:16,303][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.35623
[2024-02-27 08:00:16,303][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 2.34254
[2024-02-27 08:00:36,564][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 2.27169
[2024-02-27 08:00:36,565][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.29263
[2024-02-27 08:00:57,433][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 2.20377
[2024-02-27 08:00:57,433][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 2.12151
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-27 08:01:17,443][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 1.99550
[2024-02-27 08:01:17,443][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 2.08145
[2024-02-27 08:01:38,043][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 2.18375
[2024-02-27 08:01:38,043][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 2.19660
[2024-02-27 08:02:19,661][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.05334
[2024-02-27 08:02:19,661][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.01904
[2024-02-27 08:02:41,094][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.00446
[2024-02-27 08:02:41,094][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.01203
[2024-02-27 08:03:01,849][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.96049
[2024-02-27 08:03:01,849][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.08743
[2024-02-27 08:03:23,413][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.92704
[2024-02-27 08:03:23,413][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.05321
[2024-02-27 08:03:44,616][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.11990
[2024-02-27 08:03:44,616][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.87910
[2024-02-27 08:04:05,420][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.76842
[2024-02-27 08:04:05,420][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.76616
[2024-02-27 08:04:26,718][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.85363
[2024-02-27 08:04:26,718][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.76188
[2024-02-27 08:04:47,151][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 2.17988
[2024-02-27 08:04:47,151][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.70944
[2024-02-27 08:05:08,639][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.77787
[2024-02-27 08:05:08,639][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.78958
[2024-02-27 08:05:29,006][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.77962
[2024-02-27 08:05:29,006][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.11608 - val_accuracy: 0.11670 - train_loss: 4.07949 - val_loss: 3.94530 - loss: 1.82537
[2024-02-27 08:06:10,581][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.80758
[2024-02-27 08:06:10,581][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.63839
[2024-02-27 08:06:30,810][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.91606
[2024-02-27 08:06:30,810][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.57955
[2024-02-27 08:06:51,660][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.53269
[2024-02-27 08:06:51,660][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.57434
[2024-02-27 08:07:12,346][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.55326
[2024-02-27 08:07:12,346][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.60287
[2024-02-27 08:07:33,730][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.59180
[2024-02-27 08:07:33,730][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.54959
[2024-02-27 08:07:54,579][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.65679
[2024-02-27 08:07:54,580][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.58755
[2024-02-27 08:08:14,935][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.49761
[2024-02-27 08:08:14,935][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.53707
[2024-02-27 08:08:35,585][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.48754
[2024-02-27 08:08:35,585][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.49574
[2024-02-27 08:08:56,647][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.57571
[2024-02-27 08:08:56,647][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.61344
[2024-02-27 08:09:17,748][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.63512
[2024-02-27 08:09:17,748][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.13013 - val_accuracy: 0.14910 - train_loss: 3.75946 - val_loss: 3.59768 - loss: 1.43835
[2024-02-27 08:10:00,119][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.38626
[2024-02-27 08:10:00,119][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.43496
[2024-02-27 08:10:21,637][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 2.14506
[2024-02-27 08:10:21,637][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.55192
[2024-02-27 08:10:43,752][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.47482
[2024-02-27 08:10:43,752][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.52184
[2024-02-27 08:11:05,247][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.43162
[2024-02-27 08:11:05,247][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.38510
[2024-02-27 08:11:25,387][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.62264
[2024-02-27 08:11:25,387][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.51628
[2024-02-27 08:11:46,317][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.60178
[2024-02-27 08:11:46,317][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.32394
[2024-02-27 08:12:06,940][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 2.06009
[2024-02-27 08:12:06,940][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.58396
[2024-02-27 08:12:28,172][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.38587
[2024-02-27 08:12:28,172][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.34513
[2024-02-27 08:12:48,806][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.34934
[2024-02-27 08:12:48,806][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.12724 - val_accuracy: 0.17170 - train_loss: 3.18328 - val_loss: 2.54867 - loss: 1.27503
[2024-02-27 08:13:29,902][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.31686
[2024-02-27 08:13:29,902][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.22156
[2024-02-27 08:13:50,356][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.26817
[2024-02-27 08:13:50,356][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.35262
[2024-02-27 08:14:11,430][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.83466
[2024-02-27 08:14:11,430][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.29578
[2024-02-27 08:14:33,290][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.24471
[2024-02-27 08:14:33,290][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.29906
[2024-02-27 08:14:54,867][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.24869
[2024-02-27 08:14:54,867][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.20685
[2024-02-27 08:15:16,647][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.70096
[2024-02-27 08:15:16,647][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.22148
[2024-02-27 08:15:38,447][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.86189
[2024-02-27 08:15:38,447][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.15042
[2024-02-27 08:15:58,541][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.19055
[2024-02-27 08:15:58,541][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.45333
[2024-02-27 08:16:19,538][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.36177
[2024-02-27 08:16:19,538][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.22890
[2024-02-27 08:16:39,872][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.18939
[2024-02-27 08:16:39,872][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.15228 - val_accuracy: 0.23810 - train_loss: 2.82779 - val_loss: 2.38108 - loss: 1.44547
[2024-02-27 08:17:23,699][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.25481
[2024-02-27 08:17:23,699][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.17186
[2024-02-27 08:17:44,696][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.18398
[2024-02-27 08:17:44,696][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.14482
[2024-02-27 08:18:05,566][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.50923
[2024-02-27 08:18:05,566][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.85491
[2024-02-27 08:18:26,880][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.91892
[2024-02-27 08:18:26,880][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.12963
[2024-02-27 08:18:47,109][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.19320
[2024-02-27 08:18:47,108][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.24564
[2024-02-27 08:19:08,328][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.40952
[2024-02-27 08:19:08,329][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.06799
[2024-02-27 08:19:28,475][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.97163
[2024-02-27 08:19:28,475][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.12378
[2024-02-27 08:19:49,302][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.30507
[2024-02-27 08:19:49,302][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.15072
[2024-02-27 08:20:10,640][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.89260
[2024-02-27 08:20:10,640][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.23540
[2024-02-27 08:20:31,323][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.25065
[2024-02-27 08:20:31,323][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.17675 - val_accuracy: 0.21250 - train_loss: 4.18894 - val_loss: 3.27235 - loss: 1.12097
[2024-02-27 08:21:14,202][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.15730
[2024-02-27 08:21:14,202][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.32021
[2024-02-27 08:21:34,125][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.10662
[2024-02-27 08:21:34,125][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.53401
[2024-02-27 08:21:56,239][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.32661
[2024-02-27 08:21:56,239][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.02457
[2024-02-27 08:22:16,331][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.48056
[2024-02-27 08:22:16,332][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.13083
[2024-02-27 08:22:37,158][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.04870
[2024-02-27 08:22:37,158][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.09370
[2024-02-27 08:22:57,793][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.91121
[2024-02-27 08:22:57,793][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.20664
[2024-02-27 08:23:19,777][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.02292
[2024-02-27 08:23:19,777][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.06371
[2024-02-27 08:23:40,566][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.03709
[2024-02-27 08:23:40,566][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 0.95976
[2024-02-27 08:24:01,534][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 0.96511
[2024-02-27 08:24:01,534][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.21523 - val_accuracy: 0.18500 - train_loss: 8.31343 - val_loss: 5.99362 - loss: 1.08114
[2024-02-27 08:24:43,612][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.06681
[2024-02-27 08:24:43,612][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.07320
[2024-02-27 08:25:04,472][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.82579
[2024-02-27 08:25:04,472][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.25680
[2024-02-27 08:25:26,071][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.04276
[2024-02-27 08:25:26,071][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.08141
[2024-02-27 08:25:46,257][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.68152
[2024-02-27 08:25:46,257][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.15004
[2024-02-27 08:26:07,012][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.00442
[2024-02-27 08:26:07,012][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.29362
[2024-02-27 08:26:27,469][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 0.93882
[2024-02-27 08:26:27,469][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 0.88709
[2024-02-27 08:26:48,978][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.74899
[2024-02-27 08:26:48,978][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.01029
[2024-02-27 08:27:09,756][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.01365
[2024-02-27 08:27:09,756][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.87540
[2024-02-27 08:27:31,049][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.06059
[2024-02-27 08:27:31,049][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.22133
[2024-02-27 08:27:51,186][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.93574
[2024-02-27 08:27:51,186][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.16938 - val_accuracy: 0.19260 - train_loss: 2.98271 - val_loss: 2.46076 - loss: 1.08849
[2024-02-27 08:28:32,440][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.11785
[2024-02-27 08:28:32,440][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.92202
[2024-02-27 08:28:52,631][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.66092
[2024-02-27 08:28:52,631][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.24629
[2024-02-27 08:29:13,820][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.80230
[2024-02-27 08:29:13,820][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.98877
[2024-02-27 08:29:35,207][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.19225
[2024-02-27 08:29:35,207][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.92551
[2024-02-27 08:29:55,856][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.14332
[2024-02-27 08:29:55,856][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.05265
[2024-02-27 08:30:16,134][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.90428
[2024-02-27 08:30:16,134][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.92876
[2024-02-27 08:30:37,537][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.93050
[2024-02-27 08:30:37,537][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.89288
[2024-02-27 08:30:59,161][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.90037
[2024-02-27 08:30:59,161][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.84104
[2024-02-27 08:31:20,151][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 1.81469
[2024-02-27 08:31:20,151][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.97839
[2024-02-27 08:31:40,321][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.81291
[2024-02-27 08:31:40,321][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.16962 - val_accuracy: 0.24510 - train_loss: 3.06071 - val_loss: 2.60269 - loss: 0.86507
[2024-02-27 08:32:23,109][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.86726
[2024-02-27 08:32:23,109][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.88605
[2024-02-27 08:32:43,777][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.66398
[2024-02-27 08:32:43,777][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.98021
[2024-02-27 08:33:04,717][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.49706
[2024-02-27 08:33:04,717][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.97966
[2024-02-27 08:33:25,628][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.91841
[2024-02-27 08:33:25,628][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.94696
[2024-02-27 08:33:46,328][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.40698
[2024-02-27 08:33:46,328][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.98492
[2024-02-27 08:34:07,597][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.00503
[2024-02-27 08:34:07,597][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.25560
[2024-02-27 08:34:28,959][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.88066
[2024-02-27 08:34:28,959][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.95980
[2024-02-27 08:34:49,900][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.72835
[2024-02-27 08:34:49,900][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.88329
[2024-02-27 08:35:10,970][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.65286
[2024-02-27 08:35:10,970][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 1.21804
[2024-02-27 08:35:31,834][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.82752
[2024-02-27 08:35:31,834][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.14125 - val_accuracy: 0.15720 - train_loss: 2.69977 - val_loss: 2.62197 - loss: 0.95857
[2024-02-27 08:36:13,504][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.86151
[2024-02-27 08:36:13,504][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.84799
[2024-02-27 08:36:34,369][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.97608
[2024-02-27 08:36:34,369][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.93770
[2024-02-27 08:36:55,059][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.93701
[2024-02-27 08:36:55,059][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.83296
[2024-02-27 08:37:16,947][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 1.04385
[2024-02-27 08:37:16,947][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.78882
[2024-02-27 08:37:37,733][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.88570
[2024-02-27 08:37:37,733][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.89745
[2024-02-27 08:37:58,795][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 1.26513
[2024-02-27 08:37:58,795][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.83188
[2024-02-27 08:38:19,251][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.89565
[2024-02-27 08:38:19,251][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 1.21492
[2024-02-27 08:38:41,467][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.93321
[2024-02-27 08:38:41,467][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.81716
[2024-02-27 08:39:02,437][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 0.96346
[2024-02-27 08:39:02,437][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.21947 - val_accuracy: 0.29030 - train_loss: 2.49420 - val_loss: 2.35356 - loss: 1.81485
[2024-02-27 08:39:46,079][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.90884
[2024-02-27 08:39:46,079][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.80176
[2024-02-27 08:40:05,725][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.19714
[2024-02-27 08:40:05,725][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.91334
[2024-02-27 08:40:26,740][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.86187
[2024-02-27 08:40:26,740][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.90417
[2024-02-27 08:40:48,261][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.85067
[2024-02-27 08:40:48,261][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.07597
[2024-02-27 08:41:09,633][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.84018
[2024-02-27 08:41:09,633][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.82450
[2024-02-27 08:41:30,545][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.50415
[2024-02-27 08:41:30,545][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.06548
[2024-02-27 08:41:51,305][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.27640
[2024-02-27 08:41:51,305][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.03576
[2024-02-27 08:42:11,277][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.35769
[2024-02-27 08:42:11,277][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.04249
[2024-02-27 08:42:33,536][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.91409
[2024-02-27 08:42:33,536][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 0.78702
[2024-02-27 08:42:54,792][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.42618
[2024-02-27 08:42:54,792][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.21412 - val_accuracy: 0.27380 - train_loss: 2.44463 - val_loss: 2.24582 - loss: 1.39856
[2024-02-27 08:43:36,608][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.75121
[2024-02-27 08:43:36,608][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.82069
[2024-02-27 08:43:57,148][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.82703
[2024-02-27 08:43:57,148][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.87626
[2024-02-27 08:44:18,221][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.86077
[2024-02-27 08:44:18,221][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.00636
[2024-02-27 08:44:38,885][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.67072
[2024-02-27 08:44:38,885][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.19646
[2024-02-27 08:45:00,017][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.75075
[2024-02-27 08:45:00,017][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.57189
[2024-02-27 08:45:21,421][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.80622
[2024-02-27 08:45:21,421][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.50731
[2024-02-27 08:45:42,242][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.95975
[2024-02-27 08:45:42,242][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.84763
[2024-02-27 08:46:02,786][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.49567
[2024-02-27 08:46:02,786][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.79252
[2024-02-27 08:46:24,414][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.95713
[2024-02-27 08:46:24,414][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 1.09454
[2024-02-27 08:46:45,214][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.84980
[2024-02-27 08:46:45,213][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.26722 - val_accuracy: 0.29200 - train_loss: 2.36459 - val_loss: 2.25815 - loss: 0.84167
[2024-02-27 08:47:26,150][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.07964
[2024-02-27 08:47:26,151][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.91280
[2024-02-27 08:47:47,209][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.82121
[2024-02-27 08:47:47,209][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.82112
[2024-02-27 08:48:08,101][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.30342
[2024-02-27 08:48:08,101][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.86437
[2024-02-27 08:48:29,079][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.77603
[2024-02-27 08:48:29,079][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.81280
[2024-02-27 08:48:49,904][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.80668
[2024-02-27 08:48:49,904][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.29709
[2024-02-27 08:49:11,139][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.86779
[2024-02-27 08:49:11,139][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.83775
[2024-02-27 08:49:31,017][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.00675
[2024-02-27 08:49:31,017][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.41073
[2024-02-27 08:49:51,619][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.82190
[2024-02-27 08:49:51,619][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 0.77284
[2024-02-27 08:50:12,894][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.97277
[2024-02-27 08:50:12,894][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.18603 - val_accuracy: 0.12640 - train_loss: 2.39728 - val_loss: 2.48790 - loss: 1.03418
[2024-02-27 08:50:54,392][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.35232
[2024-02-27 08:50:54,392][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.83742
[2024-02-27 08:51:15,239][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.76862
[2024-02-27 08:51:15,239][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.13845
[2024-02-27 08:51:36,200][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.06637
[2024-02-27 08:51:36,200][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.79409
[2024-02-27 08:51:57,126][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.81676
[2024-02-27 08:51:57,126][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.97441
[2024-02-27 08:52:18,119][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.89487
[2024-02-27 08:52:18,119][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.78754
[2024-02-27 08:52:37,534][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.76821
[2024-02-27 08:52:37,534][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.82767
[2024-02-27 08:52:58,113][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.79659
[2024-02-27 08:52:58,113][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.83686
[2024-02-27 08:53:19,132][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.83443
[2024-02-27 08:53:19,132][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.52907
[2024-02-27 08:53:40,631][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.60967
[2024-02-27 08:53:40,631][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 1.10153
[2024-02-27 08:54:00,848][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.87935
[2024-02-27 08:54:00,848][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.17538 - val_accuracy: 0.19150 - train_loss: 2.77259 - val_loss: 2.71260 - loss: 0.88139
[2024-02-27 08:54:44,434][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.89090
[2024-02-27 08:54:44,434][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.88122
[2024-02-27 08:55:05,281][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 1.20693
[2024-02-27 08:55:05,282][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.79411
[2024-02-27 08:55:26,489][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.79188
[2024-02-27 08:55:26,490][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.83321
[2024-02-27 08:55:46,528][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 1.47221
[2024-02-27 08:55:46,528][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.96698
[2024-02-27 08:56:07,318][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 1.49520
[2024-02-27 08:56:07,318][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.78881
[2024-02-27 08:56:27,659][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.92949
[2024-02-27 08:56:27,660][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.75689
[2024-02-27 08:56:49,158][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.83067
[2024-02-27 08:56:49,158][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.82092
[2024-02-27 08:57:10,434][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.80641
[2024-02-27 08:57:10,434][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.75046
[2024-02-27 08:57:31,771][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 1.38489
[2024-02-27 08:57:31,771][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.77626
[2024-02-27 08:57:52,844][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 0.82700
[2024-02-27 08:57:52,844][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.15915 - val_accuracy: 0.13980 - train_loss: 2.56645 - val_loss: 2.63025 - loss: 2.00552
[2024-02-27 08:58:34,119][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.78792
[2024-02-27 08:58:34,119][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.00292
[2024-02-27 08:58:55,403][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.28097
[2024-02-27 08:58:55,403][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.84820
[2024-02-27 08:59:15,819][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.70993
[2024-02-27 08:59:15,819][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.71483
[2024-02-27 08:59:36,683][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.01153
[2024-02-27 08:59:36,683][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.80745
[2024-02-27 08:59:57,296][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.97131
[2024-02-27 08:59:57,296][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.80079
[2024-02-27 09:00:17,436][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.77692
[2024-02-27 09:00:17,436][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.78225
[2024-02-27 09:00:38,476][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 2.00142
[2024-02-27 09:00:38,476][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.52745
[2024-02-27 09:00:59,849][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.77941
[2024-02-27 09:00:59,849][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 0.74188
[2024-02-27 09:01:20,651][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 2.03877
[2024-02-27 09:01:20,651][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.14723 - val_accuracy: 0.16330 - train_loss: 2.72616 - val_loss: 2.69752 - loss: 1.18004
[2024-02-27 09:02:01,890][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.87391
[2024-02-27 09:02:01,890][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.70569
[2024-02-27 09:02:21,496][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.76007
[2024-02-27 09:02:21,496][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.81738
[2024-02-27 09:02:43,601][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.85266
[2024-02-27 09:02:43,602][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.74225
[2024-02-27 09:03:04,263][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.77488
[2024-02-27 09:03:04,263][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.74266
[2024-02-27 09:03:25,564][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.79860
[2024-02-27 09:03:25,564][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 1.79318
[2024-02-27 09:03:47,238][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.75593
[2024-02-27 09:03:47,238][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.74704
[2024-02-27 09:04:09,395][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.81062
[2024-02-27 09:04:09,395][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.85730
[2024-02-27 09:04:29,274][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.81587
[2024-02-27 09:04:29,274][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 1.09985
[2024-02-27 09:04:50,469][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.99119
[2024-02-27 09:04:50,469][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.92388
[2024-02-27 09:05:11,376][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 0.74273
[2024-02-27 09:05:11,376][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.20794 - val_accuracy: 0.17780 - train_loss: 2.52085 - val_loss: 2.66555 - loss: 1.97420
[2024-02-27 09:05:52,679][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.84019
[2024-02-27 09:05:52,679][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.74964
[2024-02-27 09:06:13,671][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.43568
[2024-02-27 09:06:13,671][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.16767
[2024-02-27 09:06:34,582][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.54436
[2024-02-27 09:06:34,582][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.80083
[2024-02-27 09:06:55,662][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.81086
[2024-02-27 09:06:55,662][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.48204
[2024-02-27 09:07:16,688][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.90205
[2024-02-27 09:07:16,688][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.70495
[2024-02-27 09:07:36,585][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.74365
[2024-02-27 09:07:36,585][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.70611
[2024-02-27 09:07:57,995][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.91557
[2024-02-27 09:07:57,995][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.81423
[2024-02-27 09:08:17,712][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.82844
[2024-02-27 09:08:17,712][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.90145
[2024-02-27 09:08:38,361][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.76048
[2024-02-27 09:08:38,361][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 0.81542
[2024-02-27 09:08:58,043][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 2.05183
[2024-02-27 09:08:58,043][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.20039 - val_accuracy: 0.21180 - train_loss: 2.33605 - val_loss: 2.30461 - loss: 1.34594
[2024-02-27 09:09:40,944][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.83946
[2024-02-27 09:09:40,944][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.71210
[2024-02-27 09:10:01,255][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 1.37766
[2024-02-27 09:10:01,255][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 1.80483
[2024-02-27 09:10:22,130][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.89326
[2024-02-27 09:10:22,130][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.88869
[2024-02-27 09:10:43,143][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.80382
[2024-02-27 09:10:43,143][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.76997
[2024-02-27 09:11:04,570][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 2.12053
[2024-02-27 09:11:04,570][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.91310
[2024-02-27 09:11:25,090][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 1.19729
[2024-02-27 09:11:25,090][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.94852
[2024-02-27 09:11:45,977][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 1.26955
[2024-02-27 09:11:45,977][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.75873
[2024-02-27 09:12:06,592][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.72249
[2024-02-27 09:12:06,592][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.75776
[2024-02-27 09:12:28,105][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 1.38138
[2024-02-27 09:12:28,105][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.64816
[2024-02-27 09:12:48,967][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.77076
[2024-02-27 09:12:48,967][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.17020 - val_accuracy: 0.18370 - train_loss: 2.46152 - val_loss: 2.43495 - loss: 0.78357
[2024-02-27 09:13:29,639][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 1.12279
[2024-02-27 09:13:29,639][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 1.75492
[2024-02-27 09:13:50,321][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.78557
[2024-02-27 09:13:50,321][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.81145
[2024-02-27 09:14:10,735][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.82650
[2024-02-27 09:14:10,735][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.73404
[2024-02-27 09:14:30,883][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.74102
[2024-02-27 09:14:30,883][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.74160
[2024-02-27 09:14:51,499][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 1.15560
[2024-02-27 09:14:51,499][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.88744
[2024-02-27 09:15:11,870][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.75018
[2024-02-27 09:15:11,870][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.74954
[2024-02-27 09:15:31,793][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.92754
[2024-02-27 09:15:31,793][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.83478
[2024-02-27 09:15:52,860][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.72562
[2024-02-27 09:15:52,860][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.79350
[2024-02-27 09:16:12,953][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.83731
[2024-02-27 09:16:12,953][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.17290 - val_accuracy: 0.16170 - train_loss: 2.53528 - val_loss: 2.61405 - loss: 0.78816
[2024-02-27 09:16:55,385][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.71430
[2024-02-27 09:16:55,385][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.70359
[2024-02-27 09:17:17,593][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.07069
[2024-02-27 09:17:17,593][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.77292
[2024-02-27 09:17:38,597][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.78720
[2024-02-27 09:17:38,597][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.87189
[2024-02-27 09:17:59,745][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.71757
[2024-02-27 09:17:59,745][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.33758
[2024-02-27 09:18:21,091][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.88087
[2024-02-27 09:18:21,091][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.10832
[2024-02-27 09:18:41,153][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.87814
[2024-02-27 09:18:41,153][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.73890
[2024-02-27 09:19:01,836][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.95309
[2024-02-27 09:19:01,836][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.06977
[2024-02-27 09:19:22,715][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.89112
[2024-02-27 09:19:22,716][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.75156
[2024-02-27 09:19:43,384][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.73105
[2024-02-27 09:19:43,384][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 0.68400
[2024-02-27 09:20:04,370][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.74084
[2024-02-27 09:20:04,370][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.16680 - val_accuracy: 0.17840 - train_loss: 2.74162 - val_loss: 2.76091 - loss: 1.56956
[2024-02-27 09:20:44,193][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.96855
[2024-02-27 09:20:44,193][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 1.94585
[2024-02-27 09:21:04,850][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.71672
[2024-02-27 09:21:04,850][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.71263
[2024-02-27 09:21:26,207][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.96928
[2024-02-27 09:21:26,207][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.66245
[2024-02-27 09:21:46,552][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 1.03153
[2024-02-27 09:21:46,552][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.78851
[2024-02-27 09:22:08,171][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.68842
[2024-02-27 09:22:08,171][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.92916
[2024-02-27 09:22:28,974][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.67097
[2024-02-27 09:22:28,974][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.69441
[2024-02-27 09:22:49,783][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.68182
[2024-02-27 09:22:49,783][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.87524
[2024-02-27 09:23:10,361][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.68592
[2024-02-27 09:23:10,361][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.72707
[2024-02-27 09:23:32,416][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.75349
[2024-02-27 09:23:32,416][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.67509
[2024-02-27 09:23:52,768][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 0.72810
[2024-02-27 09:23:52,768][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.23051 - val_accuracy: 0.26320 - train_loss: 2.53835 - val_loss: 2.48713 - loss: 1.41684
[2024-02-27 09:24:34,197][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.72274
[2024-02-27 09:24:34,197][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 1.41164
[2024-02-27 09:24:55,313][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.88187
[2024-02-27 09:24:55,313][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 1.04924
[2024-02-27 09:25:17,002][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.95572
[2024-02-27 09:25:17,003][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.83307
[2024-02-27 09:25:37,854][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 1.28623
[2024-02-27 09:25:37,854][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.69780
[2024-02-27 09:25:57,562][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.73125
[2024-02-27 09:25:57,562][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.70855
[2024-02-27 09:26:18,412][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.81971
[2024-02-27 09:26:18,412][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.63411
[2024-02-27 09:26:39,132][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.75066
[2024-02-27 09:26:39,132][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.70411
[2024-02-27 09:27:00,536][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 1.15342
[2024-02-27 09:27:00,536][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.71087
[2024-02-27 09:27:20,806][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.93436
[2024-02-27 09:27:20,806][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.17562 - val_accuracy: 0.16520 - train_loss: 2.70495 - val_loss: 2.73167 - loss: 0.73766
[2024-02-27 09:28:02,367][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.71567
[2024-02-27 09:28:02,367][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 1.75870
[2024-02-27 09:28:23,206][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 1.03982
[2024-02-27 09:28:23,206][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.70821
[2024-02-27 09:28:44,130][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.63671
[2024-02-27 09:28:44,130][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.77648
[2024-02-27 09:29:04,707][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.85129
[2024-02-27 09:29:04,707][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.63498
[2024-02-27 09:29:25,413][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.98669
[2024-02-27 09:29:25,413][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 1.74861
[2024-02-27 09:29:45,485][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.63191
[2024-02-27 09:29:45,486][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.65306
[2024-02-27 09:30:06,608][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.84916
[2024-02-27 09:30:06,608][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.66799
[2024-02-27 09:30:27,171][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.64554
[2024-02-27 09:30:27,171][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.74835
[2024-02-27 09:30:47,356][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.61109
[2024-02-27 09:30:47,356][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.68037
[2024-02-27 09:31:07,868][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.66843
[2024-02-27 09:31:07,868][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.23673 - val_accuracy: 0.29740 - train_loss: 2.38091 - val_loss: 2.20480 - loss: 0.84945
[2024-02-27 09:31:49,244][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.68346
[2024-02-27 09:31:49,244][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 1.89512
[2024-02-27 09:32:10,347][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.63836
[2024-02-27 09:32:10,347][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.63784
[2024-02-27 09:32:31,764][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.65420
[2024-02-27 09:32:31,764][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.63539
[2024-02-27 09:32:51,465][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.74776
[2024-02-27 09:32:51,465][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.67911
[2024-02-27 09:33:11,693][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 1.89845
[2024-02-27 09:33:11,693][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.73787
[2024-02-27 09:33:32,194][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.76636
[2024-02-27 09:33:32,194][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.70583
[2024-02-27 09:33:52,138][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.68122
[2024-02-27 09:33:52,138][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.70114
[2024-02-27 09:34:12,527][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 1.40170
[2024-02-27 09:34:12,527][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.78848
[2024-02-27 09:34:34,060][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.67836
[2024-02-27 09:34:34,060][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.65058
[2024-02-27 09:34:53,846][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.60708
[2024-02-27 09:34:53,846][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.23214 - val_accuracy: 0.28290 - train_loss: 2.54845 - val_loss: 2.35431 - loss: 0.67275
[2024-02-27 09:35:35,253][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.66667
[2024-02-27 09:35:35,253][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.63195
[2024-02-27 09:35:55,299][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.88560
[2024-02-27 09:35:55,299][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 1.03120
[2024-02-27 09:36:15,354][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 1.22409
[2024-02-27 09:36:15,354][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.73592
[2024-02-27 09:36:35,370][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.72339
[2024-02-27 09:36:35,370][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.85940
[2024-02-27 09:36:56,667][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.68774
[2024-02-27 09:36:56,667][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.67912
[2024-02-27 09:37:17,956][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 1.36908
[2024-02-27 09:37:17,956][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.70253
[2024-02-27 09:37:39,855][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.56460
[2024-02-27 09:37:39,855][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.61660
[2024-02-27 09:38:00,325][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.64604
[2024-02-27 09:38:00,325][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.62573
[2024-02-27 09:38:21,205][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 1.37813
[2024-02-27 09:38:21,205][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.27646 - val_accuracy: 0.32370 - train_loss: 2.30581 - val_loss: 2.20005 - loss: 0.66702
[2024-02-27 09:39:03,923][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.99008
[2024-02-27 09:39:03,923][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.68565
[2024-02-27 09:39:24,101][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 1.36966
[2024-02-27 09:39:24,101][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.69292
[2024-02-27 09:39:44,154][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.92309
[2024-02-27 09:39:44,154][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.96596
[2024-02-27 09:40:05,381][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.62194
[2024-02-27 09:40:05,381][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 1.16816
[2024-02-27 09:40:26,015][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.73178
[2024-02-27 09:40:26,015][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 1.10546
[2024-02-27 09:40:46,430][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.81540
[2024-02-27 09:40:46,430][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.62802
[2024-02-27 09:41:07,785][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.63012
[2024-02-27 09:41:07,785][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.62445
[2024-02-27 09:41:28,576][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.71699
[2024-02-27 09:41:28,576][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.64996
[2024-02-27 09:41:51,144][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 1.22387
[2024-02-27 09:41:51,144][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.67644
[2024-02-27 09:42:11,569][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.60439
[2024-02-27 09:42:11,569][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.17711 - val_accuracy: 0.12720 - train_loss: 2.76829 - val_loss: 3.04907 - loss: 0.63985
[2024-02-27 09:42:51,659][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.58714
[2024-02-27 09:42:51,659][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.65169
[2024-02-27 09:43:12,196][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 1.26005
[2024-02-27 09:43:12,196][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.69975
[2024-02-27 09:43:33,124][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.61175
[2024-02-27 09:43:33,124][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.79939
[2024-02-27 09:43:53,234][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.71303
[2024-02-27 09:43:53,234][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 1.40357
[2024-02-27 09:44:15,788][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.65207
[2024-02-27 09:44:15,788][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.60465
[2024-02-27 09:44:36,227][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 1.27946
[2024-02-27 09:44:36,227][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.83703
[2024-02-27 09:44:57,475][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.63985
[2024-02-27 09:44:57,475][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.65189
[2024-02-27 09:45:18,509][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 1.11757
[2024-02-27 09:45:18,509][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.62924
[2024-02-27 09:45:39,504][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.79742
[2024-02-27 09:45:39,504][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.59729
[2024-02-27 09:46:00,286][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.66633
[2024-02-27 09:46:00,287][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.18122 - val_accuracy: 0.15950 - train_loss: 2.42369 - val_loss: 2.47902 - loss: 0.62876
[2024-02-27 09:46:42,996][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 2.01979
[2024-02-27 09:46:42,996][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 1.26790
[2024-02-27 09:47:03,608][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.92491
[2024-02-27 09:47:03,608][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.65443
[2024-02-27 09:47:24,280][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 1.55692
[2024-02-27 09:47:24,281][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 1.01296
[2024-02-27 09:47:45,033][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.75413
[2024-02-27 09:47:45,034][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.79378
[2024-02-27 09:48:05,889][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.84763
[2024-02-27 09:48:05,889][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.72251
[2024-02-27 09:48:26,965][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.67088
[2024-02-27 09:48:26,965][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.65330
[2024-02-27 09:48:47,896][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.65738
[2024-02-27 09:48:47,896][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.66975
[2024-02-27 09:49:08,165][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 1.27917
[2024-02-27 09:49:08,165][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.69063
[2024-02-27 09:49:29,582][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.65147
[2024-02-27 09:49:29,582][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.64459
[2024-02-27 09:49:50,571][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 1.16326
[2024-02-27 09:49:50,571][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.19489 - val_accuracy: 0.19900 - train_loss: 2.37498 - val_loss: 2.38420 - loss: 0.79895
[2024-02-27 09:50:33,238][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 1.10884
[2024-02-27 09:50:33,238][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.65701
[2024-02-27 09:50:54,904][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.58414
[2024-02-27 09:50:54,904][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.66282
[2024-02-27 09:51:16,432][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 1.41274
[2024-02-27 09:51:16,432][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.65617
[2024-02-27 09:51:38,248][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.69906
[2024-02-27 09:51:38,248][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 1.35587
[2024-02-27 09:51:58,192][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.61030
[2024-02-27 09:51:58,192][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.63982
[2024-02-27 09:52:18,956][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.68841
[2024-02-27 09:52:18,956][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.65906
[2024-02-27 09:52:39,400][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.77389
[2024-02-27 09:52:39,400][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 1.43374
[2024-02-27 09:53:01,062][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 1.38413
[2024-02-27 09:53:01,062][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.62877
[2024-02-27 09:53:22,141][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.94305
[2024-02-27 09:53:22,141][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.21092 - val_accuracy: 0.17450 - train_loss: 2.52971 - val_loss: 2.67672 - loss: 0.72375
[2024-02-27 09:54:02,662][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 1.07945
[2024-02-27 09:54:02,662][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.65174
[2024-02-27 09:54:23,458][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 1.13881
[2024-02-27 09:54:23,459][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.62985
[2024-02-27 09:54:44,220][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.86054
[2024-02-27 09:54:44,220][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 1.15513
[2024-02-27 09:55:04,524][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.63955
[2024-02-27 09:55:04,524][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.83494
[2024-02-27 09:55:25,206][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.70733
[2024-02-27 09:55:25,206][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 1.86441
[2024-02-27 09:55:46,130][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.68538
[2024-02-27 09:55:46,130][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.62744
[2024-02-27 09:56:06,964][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.95977
[2024-02-27 09:56:06,965][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.63017
[2024-02-27 09:56:27,610][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 1.24762
[2024-02-27 09:56:27,610][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.64064
[2024-02-27 09:56:49,357][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.66165
[2024-02-27 09:56:49,357][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.72684
[2024-02-27 09:57:09,281][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.69107
[2024-02-27 09:57:09,281][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.17314 - val_accuracy: 0.27070 - train_loss: 2.50680 - val_loss: 2.20165 - loss: 0.59927
[2024-02-27 09:57:50,820][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.75673
[2024-02-27 09:57:50,820][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.41546
[2024-02-27 09:58:10,686][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.63920
[2024-02-27 09:58:10,686][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.70226
[2024-02-27 09:58:31,631][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.73003
[2024-02-27 09:58:31,631][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.34627
[2024-02-27 09:58:51,864][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.66277
[2024-02-27 09:58:51,864][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.60756
[2024-02-27 09:59:13,495][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.57572
[2024-02-27 09:59:13,495][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.59080
[2024-02-27 09:59:33,773][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.11501
[2024-02-27 09:59:33,773][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.69059
[2024-02-27 09:59:55,269][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.61402
[2024-02-27 09:59:55,269][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.60095
[2024-02-27 10:00:16,063][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.62176
[2024-02-27 10:00:16,063][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.55694
[2024-02-27 10:00:37,302][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.76556
[2024-02-27 10:00:37,302][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.50855
[2024-02-27 10:00:58,698][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 1.70544
[2024-02-27 10:00:58,698][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.20701 - val_accuracy: 0.20770 - train_loss: 2.64429 - val_loss: 2.78601 - loss: 0.59316
[2024-02-27 10:01:41,816][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 1.70635
[2024-02-27 10:01:41,816][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.78772
[2024-02-27 10:02:02,773][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.68878
[2024-02-27 10:02:02,773][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.62898
[2024-02-27 10:02:24,493][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.76994
[2024-02-27 10:02:24,493][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.62056
[2024-02-27 10:02:45,149][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 1.56982
[2024-02-27 10:02:45,149][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.62195
[2024-02-27 10:03:05,629][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.90114
[2024-02-27 10:03:05,629][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.66292
[2024-02-27 10:03:26,035][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.66024
[2024-02-27 10:03:26,035][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.62279
[2024-02-27 10:03:46,799][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 1.22519
[2024-02-27 10:03:46,799][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.81158
[2024-02-27 10:04:08,533][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 1.28212
[2024-02-27 10:04:08,533][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.73200
[2024-02-27 10:04:28,597][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.94682
[2024-02-27 10:04:28,597][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.16839 - val_accuracy: 0.13790 - train_loss: 2.75265 - val_loss: 2.82392 - loss: 0.63754
[2024-02-27 10:05:11,641][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.60608
[2024-02-27 10:05:11,641][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 1.12528
[2024-02-27 10:05:32,860][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.63808
[2024-02-27 10:05:32,860][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.57718
[2024-02-27 10:05:55,102][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 1.52063
[2024-02-27 10:05:55,102][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.59907
[2024-02-27 10:06:16,108][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 1.00887
[2024-02-27 10:06:16,108][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.77059
[2024-02-27 10:06:37,269][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.92262
[2024-02-27 10:06:37,269][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.73415
[2024-02-27 10:06:57,853][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 1.52527
[2024-02-27 10:06:57,853][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.62179
[2024-02-27 10:07:18,307][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.65801
[2024-02-27 10:07:18,307][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.65570
[2024-02-27 10:07:39,232][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.59830
[2024-02-27 10:07:39,232][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.60044
[2024-02-27 10:07:59,788][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 1.93806
[2024-02-27 10:07:59,788][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.58998
[2024-02-27 10:08:20,684][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.66935
[2024-02-27 10:08:20,684][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.28157 - val_accuracy: 0.22340 - train_loss: 2.38565 - val_loss: 2.54336 - loss: 0.66659
[2024-02-27 10:09:03,057][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.63343
[2024-02-27 10:09:03,057][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.59481
[2024-02-27 10:09:23,919][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.65342
[2024-02-27 10:09:23,919][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.59306
[2024-02-27 10:09:44,214][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.72197
[2024-02-27 10:09:44,214][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.63709
[2024-02-27 10:10:04,769][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.93031
[2024-02-27 10:10:04,769][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.65574
[2024-02-27 10:10:25,678][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.62425
[2024-02-27 10:10:25,678][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.95193
[2024-02-27 10:10:46,684][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.68803
[2024-02-27 10:10:46,684][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.57247
[2024-02-27 10:11:07,665][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.57525
[2024-02-27 10:11:07,665][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.57724
[2024-02-27 10:11:27,989][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 1.29580
[2024-02-27 10:11:27,989][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.64588
[2024-02-27 10:11:48,651][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.60385
[2024-02-27 10:11:48,651][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 1.10597
[2024-02-27 10:12:08,602][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.68313
[2024-02-27 10:12:08,602][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.22912 - val_accuracy: 0.19430 - train_loss: 2.46065 - val_loss: 2.58498 - loss: 0.60312
[2024-02-27 10:12:51,386][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.66975
[2024-02-27 10:12:51,386][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.59906
[2024-02-27 10:13:12,660][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.63585
[2024-02-27 10:13:12,660][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.62210
[2024-02-27 10:13:33,675][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.85964
[2024-02-27 10:13:33,675][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.60722
[2024-02-27 10:13:52,962][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.61037
[2024-02-27 10:13:52,962][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.71052
[2024-02-27 10:14:14,803][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 1.58213
[2024-02-27 10:14:14,803][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.60495
[2024-02-27 10:14:35,752][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.57838
[2024-02-27 10:14:35,752][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 1.33473
[2024-02-27 10:14:56,282][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.72362
[2024-02-27 10:14:56,282][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.73984
[2024-02-27 10:15:17,088][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.79790
[2024-02-27 10:15:17,088][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.59923
[2024-02-27 10:15:38,398][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.59738
[2024-02-27 10:15:38,398][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.24432 - val_accuracy: 0.24590 - train_loss: 2.36285 - val_loss: 2.40111 - loss: 0.75963
[2024-02-27 10:16:21,635][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.75708
[2024-02-27 10:16:21,635][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.57340
[2024-02-27 10:16:41,697][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.57602
[2024-02-27 10:16:41,697][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.60968
[2024-02-27 10:17:02,562][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.91530
[2024-02-27 10:17:02,562][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.57259
[2024-02-27 10:17:23,448][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.60197
[2024-02-27 10:17:23,448][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.20724
[2024-02-27 10:17:45,107][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.58093
[2024-02-27 10:17:45,107][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.16770
[2024-02-27 10:18:05,745][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.46738
[2024-02-27 10:18:05,745][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.23961
[2024-02-27 10:18:27,326][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.80722
[2024-02-27 10:18:27,327][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.55458
[2024-02-27 10:18:47,725][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.58757
[2024-02-27 10:18:47,725][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.57808
[2024-02-27 10:19:08,730][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.79539
[2024-02-27 10:19:08,730][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.61923
[2024-02-27 10:19:27,974][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 1.23087
[2024-02-27 10:19:27,974][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.18657 - val_accuracy: 0.14500 - train_loss: 2.59592 - val_loss: 2.62701 - loss: 0.58967
[2024-02-27 10:20:09,698][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.58032
[2024-02-27 10:20:09,698][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.70377
[2024-02-27 10:20:30,788][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.59582
[2024-02-27 10:20:30,788][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.56643
[2024-02-27 10:20:51,554][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 1.13154
[2024-02-27 10:20:51,554][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.67564
[2024-02-27 10:21:12,270][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.77701
[2024-02-27 10:21:12,270][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.57623
[2024-02-27 10:21:33,783][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.87230
[2024-02-27 10:21:33,783][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.67561
[2024-02-27 10:21:54,457][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.89088
[2024-02-27 10:21:54,457][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.74642
[2024-02-27 10:22:15,335][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.66599
[2024-02-27 10:22:15,335][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.59751
[2024-02-27 10:22:36,425][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.57633
[2024-02-27 10:22:36,425][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 1.57644
[2024-02-27 10:22:56,606][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.77981
[2024-02-27 10:22:56,606][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 1.10271
[2024-02-27 10:23:17,115][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.97726
[2024-02-27 10:23:17,115][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.19668 - val_accuracy: 0.23330 - train_loss: 2.62062 - val_loss: 2.56122 - loss: 0.66373
[2024-02-27 10:23:59,293][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.63747
[2024-02-27 10:23:59,293][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.55384
[2024-02-27 10:24:19,770][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 1.54876
[2024-02-27 10:24:19,770][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.72480
[2024-02-27 10:24:41,354][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.82706
[2024-02-27 10:24:41,354][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.88711
[2024-02-27 10:25:02,522][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 1.12181
[2024-02-27 10:25:02,522][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.58460
[2024-02-27 10:25:23,989][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 1.56045
[2024-02-27 10:25:23,989][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.55346
[2024-02-27 10:25:44,662][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.73903
[2024-02-27 10:25:44,662][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.58857
[2024-02-27 10:26:05,973][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.60165
[2024-02-27 10:26:05,973][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 1.34964
[2024-02-27 10:26:26,308][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 1.16454
[2024-02-27 10:26:26,308][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.65992
[2024-02-27 10:26:47,756][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.98549
[2024-02-27 10:26:47,756][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.74232
[2024-02-27 10:27:07,957][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.68669
[2024-02-27 10:27:07,957][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.25683 - val_accuracy: 0.29410 - train_loss: 2.34755 - val_loss: 2.24114 - loss: 0.55440
[2024-02-27 10:27:49,326][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.59365
[2024-02-27 10:27:49,326][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.60671
[2024-02-27 10:28:11,434][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.96405
[2024-02-27 10:28:11,434][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.62384
[2024-02-27 10:28:32,280][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.79580
[2024-02-27 10:28:32,280][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.63884
[2024-02-27 10:28:53,038][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.97822
[2024-02-27 10:28:53,039][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.60327
[2024-02-27 10:29:13,220][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.37014
[2024-02-27 10:29:13,220][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.04105
[2024-02-27 10:29:35,572][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.67372
[2024-02-27 10:29:35,572][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.56825
[2024-02-27 10:29:56,038][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.89622
[2024-02-27 10:29:56,038][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.54813
[2024-02-27 10:30:16,644][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.65893
[2024-02-27 10:30:16,644][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 0.56776
[2024-02-27 10:30:36,506][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.11252
[2024-02-27 10:30:36,506][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.25846 - val_accuracy: 0.26260 - train_loss: 2.29630 - val_loss: 2.26650 - loss: 1.25568
[2024-02-27 10:31:19,126][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.60770
[2024-02-27 10:31:19,126][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.58410
[2024-02-27 10:31:40,414][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 1.96183
[2024-02-27 10:31:40,414][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.61970
[2024-02-27 10:32:01,881][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.81433
[2024-02-27 10:32:01,881][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.60330
[2024-02-27 10:32:22,660][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 1.66505
[2024-02-27 10:32:22,660][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.55243
[2024-02-27 10:32:43,862][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.53936
[2024-02-27 10:32:43,862][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.72563
[2024-02-27 10:33:03,087][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.55694
[2024-02-27 10:33:03,087][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.56227
[2024-02-27 10:33:23,947][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.96535
[2024-02-27 10:33:23,947][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 1.19413
[2024-02-27 10:33:44,427][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 1.04115
[2024-02-27 10:33:44,427][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.57162
[2024-02-27 10:34:04,778][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.75024
[2024-02-27 10:34:04,778][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.59285
[2024-02-27 10:34:25,431][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 1.10750
[2024-02-27 10:34:25,431][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.17580 - val_accuracy: 0.16520 - train_loss: 2.60785 - val_loss: 2.67507 - loss: 0.58298
[2024-02-27 10:35:07,922][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.57697
[2024-02-27 10:35:07,922][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.13788
[2024-02-27 10:35:29,227][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.89910
[2024-02-27 10:35:29,227][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.56310
[2024-02-27 10:35:50,376][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.65388
[2024-02-27 10:35:50,376][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.73953
[2024-02-27 10:36:11,267][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.31398
[2024-02-27 10:36:11,267][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.92691
[2024-02-27 10:36:31,833][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.58668
[2024-02-27 10:36:31,833][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.72488
[2024-02-27 10:36:52,192][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.56963
[2024-02-27 10:36:52,192][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.57833
[2024-02-27 10:37:12,573][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.64911
[2024-02-27 10:37:12,573][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.59827
[2024-02-27 10:37:32,767][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.56681
[2024-02-27 10:37:32,767][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.59892
[2024-02-27 10:37:54,114][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 1.93488
[2024-02-27 10:37:54,114][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.69166
[2024-02-27 10:38:15,281][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.77076
[2024-02-27 10:38:15,281][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.26927 - val_accuracy: 0.29100 - train_loss: 2.45050 - val_loss: 2.37692 - loss: 0.59040
[2024-02-27 10:38:56,508][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.71326
[2024-02-27 10:38:56,508][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.56505
[2024-02-27 10:39:17,911][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.56856
[2024-02-27 10:39:17,911][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.58464
[2024-02-27 10:39:38,306][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.68231
[2024-02-27 10:39:38,306][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.58998
[2024-02-27 10:39:59,462][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.60752
[2024-02-27 10:39:59,462][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.90230
[2024-02-27 10:40:20,113][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.51954
[2024-02-27 10:40:20,113][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.69383
[2024-02-27 10:40:40,503][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.59410
[2024-02-27 10:40:40,504][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.54048
[2024-02-27 10:41:00,916][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.61997
[2024-02-27 10:41:00,916][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.58228
[2024-02-27 10:41:21,572][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.55656
[2024-02-27 10:41:21,572][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.53955
[2024-02-27 10:41:41,812][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 0.74060
[2024-02-27 10:41:41,812][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.18231 - val_accuracy: 0.17530 - train_loss: 2.46378 - val_loss: 2.47304 - loss: 1.37554
[2024-02-27 10:42:24,238][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 1.33158
[2024-02-27 10:42:24,238][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.56405
[2024-02-27 10:42:44,623][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.71651
[2024-02-27 10:42:44,624][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.55862
[2024-02-27 10:43:05,351][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.55627
[2024-02-27 10:43:05,351][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 1.46453
[2024-02-27 10:43:25,465][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.56854
[2024-02-27 10:43:25,465][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.58515
[2024-02-27 10:43:45,554][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.61768
[2024-02-27 10:43:45,555][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.58131
[2024-02-27 10:44:05,069][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.66042
[2024-02-27 10:44:05,069][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 1.55136
[2024-02-27 10:44:26,227][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.87807
[2024-02-27 10:44:26,227][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.55812
[2024-02-27 10:44:47,231][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.55100
[2024-02-27 10:44:47,231][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.54482
[2024-02-27 10:45:07,949][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 1.65595
[2024-02-27 10:45:07,949][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.57756
[2024-02-27 10:45:28,096][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.61157
[2024-02-27 10:45:28,096][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.22801 - val_accuracy: 0.21710 - train_loss: 2.37433 - val_loss: 2.39799 - loss: 0.57310
[2024-02-27 10:46:09,088][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.78782
[2024-02-27 10:46:09,088][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.61017
[2024-02-27 10:46:29,085][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.69079
[2024-02-27 10:46:29,085][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.60620
[2024-02-27 10:46:49,746][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.61124
[2024-02-27 10:46:49,746][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.56870
[2024-02-27 10:47:11,461][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.72784
[2024-02-27 10:47:11,461][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.55806
[2024-02-27 10:47:32,267][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.66959
[2024-02-27 10:47:32,267][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.57763
[2024-02-27 10:47:53,740][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.64791
[2024-02-27 10:47:53,740][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.55870
[2024-02-27 10:48:14,583][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.55374
[2024-02-27 10:48:14,583][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.60487
[2024-02-27 10:48:34,604][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.80567
[2024-02-27 10:48:34,604][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.51817
[2024-02-27 10:48:55,724][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.85436
[2024-02-27 10:48:55,724][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.52801
[2024-02-27 10:49:17,000][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.64391
[2024-02-27 10:49:17,000][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.24720 - val_accuracy: 0.24520 - train_loss: 2.39067 - val_loss: 2.48488 - loss: 0.54868
[2024-02-27 10:49:59,361][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.58938
[2024-02-27 10:49:59,361][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.68385
[2024-02-27 10:50:20,503][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.61057
[2024-02-27 10:50:20,503][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.58108
[2024-02-27 10:50:41,392][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 1.09639
[2024-02-27 10:50:41,392][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.58178
[2024-02-27 10:51:01,874][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.74756
[2024-02-27 10:51:01,874][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.53774
[2024-02-27 10:51:22,973][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.61318
[2024-02-27 10:51:22,973][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.59121
[2024-02-27 10:51:43,949][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.56723
[2024-02-27 10:51:43,949][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.58885
[2024-02-27 10:52:03,868][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.93551
[2024-02-27 10:52:03,868][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.53826
[2024-02-27 10:52:24,990][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.57335
[2024-02-27 10:52:24,990][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 1.88751
[2024-02-27 10:52:45,063][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.60180
[2024-02-27 10:52:45,063][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.30817 - val_accuracy: 0.37380 - train_loss: 2.39336 - val_loss: 2.24409 - loss: 0.54064
[2024-02-27 10:53:25,790][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.88196
[2024-02-27 10:53:25,790][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.53714
[2024-02-27 10:53:46,893][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 1.48654
[2024-02-27 10:53:46,893][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.57656
[2024-02-27 10:54:08,516][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.57397
[2024-02-27 10:54:08,516][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.57072
[2024-02-27 10:54:29,529][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 1.41264
[2024-02-27 10:54:29,529][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.80953
[2024-02-27 10:54:49,365][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.61494
[2024-02-27 10:54:49,365][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.55531
[2024-02-27 10:55:09,272][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 1.33204
[2024-02-27 10:55:09,272][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.56360
[2024-02-27 10:55:29,620][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 1.49089
[2024-02-27 10:55:29,621][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.53704
[2024-02-27 10:55:51,354][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.55166
[2024-02-27 10:55:51,354][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.55024
[2024-02-27 10:56:12,462][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.57660
[2024-02-27 10:56:12,462][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.55601
[2024-02-27 10:56:32,420][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.86341
[2024-02-27 10:56:32,420][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.22692 - val_accuracy: 0.22190 - train_loss: 2.37820 - val_loss: 2.43459 - loss: 0.53734
[2024-02-27 10:57:14,428][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.68612
[2024-02-27 10:57:14,428][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.55857
[2024-02-27 10:57:35,812][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 1.13592
[2024-02-27 10:57:35,812][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.54699
[2024-02-27 10:57:56,529][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.61857
[2024-02-27 10:57:56,529][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.57770
[2024-02-27 10:58:18,278][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.57328
[2024-02-27 10:58:18,278][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.58826
[2024-02-27 10:58:38,507][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 1.21682
[2024-02-27 10:58:38,507][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.63164
[2024-02-27 10:58:58,333][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.54560
[2024-02-27 10:58:58,333][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.55202
[2024-02-27 10:59:19,963][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.57528
[2024-02-27 10:59:19,963][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.59697
[2024-02-27 10:59:40,863][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.56557
[2024-02-27 10:59:40,863][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.87651
[2024-02-27 11:00:01,927][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.91045
[2024-02-27 11:00:01,927][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.55658
[2024-02-27 11:00:22,623][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 1.72708
[2024-02-27 11:00:22,623][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.18565 - val_accuracy: 0.18280 - train_loss: 2.45339 - val_loss: 2.42645 - loss: 0.54836
[2024-02-27 11:01:04,086][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.05172
[2024-02-27 11:01:04,086][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.83629
[2024-02-27 11:01:24,972][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.17718
[2024-02-27 11:01:24,972][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.62727
[2024-02-27 11:01:46,081][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.56227
[2024-02-27 11:01:46,082][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.54552
[2024-02-27 11:02:07,206][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.53579
[2024-02-27 11:02:07,206][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.55847
[2024-02-27 11:02:27,853][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.55587
[2024-02-27 11:02:27,853][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.59760
[2024-02-27 11:02:48,791][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.53788
[2024-02-27 11:02:48,791][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.80007
[2024-02-27 11:03:10,989][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.61101
[2024-02-27 11:03:10,989][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.28280
[2024-02-27 11:03:30,402][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.15486
[2024-02-27 11:03:30,402][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.56971
[2024-02-27 11:03:50,526][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.55738
[2024-02-27 11:03:50,526][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.56009
[2024-02-27 11:04:11,392][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 1.86542
[2024-02-27 11:04:11,392][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.30040 - val_accuracy: 0.30280 - train_loss: 2.25786 - val_loss: 2.21354 - loss: 0.55105
[2024-02-27 11:04:53,953][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.71643
[2024-02-27 11:04:53,953][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.67314
[2024-02-27 11:05:15,588][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.73238
[2024-02-27 11:05:15,588][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.51486
[2024-02-27 11:05:36,705][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.91631
[2024-02-27 11:05:36,706][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.53671
[2024-02-27 11:05:57,904][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.82454
[2024-02-27 11:05:57,904][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.14676
[2024-02-27 11:06:18,574][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.16216
[2024-02-27 11:06:18,575][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.58497
[2024-02-27 11:06:40,021][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.58257
[2024-02-27 11:06:40,021][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.52989
[2024-02-27 11:07:01,100][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.26918
[2024-02-27 11:07:01,100][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 1.27064
[2024-02-27 11:07:22,225][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.56908
[2024-02-27 11:07:22,225][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.53991
[2024-02-27 11:07:42,712][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.54990
[2024-02-27 11:07:42,711][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.17401 - val_accuracy: 0.16650 - train_loss: 2.71861 - val_loss: 2.65839 - loss: 0.55495
[2024-02-27 11:08:24,331][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.56796
[2024-02-27 11:08:24,331][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.53368
[2024-02-27 11:08:44,788][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.53182
[2024-02-27 11:08:44,788][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.54659
[2024-02-27 11:09:06,268][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 1.42038
[2024-02-27 11:09:06,268][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 1.24911
[2024-02-27 11:09:26,507][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.54657
[2024-02-27 11:09:26,507][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.52505
[2024-02-27 11:09:48,348][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.57160
[2024-02-27 11:09:48,348][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.52077
[2024-02-27 11:10:08,877][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.82958
[2024-02-27 11:10:08,877][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.58769
[2024-02-27 11:10:30,759][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 1.07736
[2024-02-27 11:10:30,759][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.57609
[2024-02-27 11:10:50,878][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 1.11201
[2024-02-27 11:10:50,878][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.55026
[2024-02-27 11:11:11,647][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.53803
[2024-02-27 11:11:11,647][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.99869
[2024-02-27 11:11:31,925][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 1.26861
[2024-02-27 11:11:31,925][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.22697 - val_accuracy: 0.25460 - train_loss: 2.67612 - val_loss: 2.47597 - loss: 0.54019
[2024-02-27 11:12:14,004][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.57962
[2024-02-27 11:12:14,004][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.87463
[2024-02-27 11:12:34,628][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 1.32503
[2024-02-27 11:12:34,628][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.54380
[2024-02-27 11:12:54,735][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.54735
[2024-02-27 11:12:54,735][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.57617
[2024-02-27 11:13:15,585][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 1.46573
[2024-02-27 11:13:15,585][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.86338
[2024-02-27 11:13:37,031][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.54581
[2024-02-27 11:13:37,031][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.52600
[2024-02-27 11:13:57,986][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.52331
[2024-02-27 11:13:57,986][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.52894
[2024-02-27 11:14:19,378][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 1.03684
[2024-02-27 11:14:19,378][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.55540
[2024-02-27 11:14:39,809][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.55699
[2024-02-27 11:14:39,808][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.91854
[2024-02-27 11:15:01,682][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.53871
[2024-02-27 11:15:01,682][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.52177
[2024-02-27 11:15:21,930][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.64725
[2024-02-27 11:15:21,930][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.18132 - val_accuracy: 0.21530 - train_loss: 2.69817 - val_loss: 2.54197 - loss: 0.57678
[2024-02-27 11:16:03,205][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.80514
[2024-02-27 11:16:03,205][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.28863
[2024-02-27 11:16:24,367][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.72521
[2024-02-27 11:16:24,367][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.59416
[2024-02-27 11:16:46,126][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.12547
[2024-02-27 11:16:46,126][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.63088
[2024-02-27 11:17:07,451][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.54650
[2024-02-27 11:17:07,451][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.53430
[2024-02-27 11:17:27,823][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.60043
[2024-02-27 11:17:27,823][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.57893
[2024-02-27 11:17:48,810][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.71146
[2024-02-27 11:17:48,810][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.16494
[2024-02-27 11:18:09,948][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.35189
[2024-02-27 11:18:09,948][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.53832
[2024-02-27 11:18:29,866][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.60230
[2024-02-27 11:18:29,866][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.54241
[2024-02-27 11:18:50,602][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 1.89980
[2024-02-27 11:18:50,602][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.30489 - val_accuracy: 0.33870 - train_loss: 2.31117 - val_loss: 2.19490 - loss: 0.54172
[2024-02-27 11:19:33,052][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 1.73890
[2024-02-27 11:19:33,052][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.53702
[2024-02-27 11:19:53,206][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 1.21470
[2024-02-27 11:19:53,207][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.65586
[2024-02-27 11:20:14,642][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 1.84296
[2024-02-27 11:20:14,642][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.57641
[2024-02-27 11:20:35,287][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.51521
[2024-02-27 11:20:35,287][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.56435
[2024-02-27 11:20:57,336][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.51857
[2024-02-27 11:20:57,336][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.55329
[2024-02-27 11:21:18,431][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 1.07262
[2024-02-27 11:21:18,431][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.56399
[2024-02-27 11:21:39,649][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.53621
[2024-02-27 11:21:39,649][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.52065
[2024-02-27 11:22:00,435][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.51425
[2024-02-27 11:22:00,435][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 1.08068
[2024-02-27 11:22:21,521][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.52275
[2024-02-27 11:22:21,522][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.55402
[2024-02-27 11:22:42,457][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.53090
[2024-02-27 11:22:42,457][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.31707 - val_accuracy: 0.29630 - train_loss: 2.44718 - val_loss: 2.53412 - loss: 0.54205
[2024-02-27 11:23:24,763][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.78597
[2024-02-27 11:23:24,763][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 1.32188
[2024-02-27 11:23:45,369][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.51752
[2024-02-27 11:23:45,369][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.52131
[2024-02-27 11:24:07,279][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.50530
[2024-02-27 11:24:07,279][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.53322
[2024-02-27 11:24:27,331][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.55469
[2024-02-27 11:24:27,331][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.82130
[2024-02-27 11:24:48,533][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.52063
[2024-02-27 11:24:48,533][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.52750
[2024-02-27 11:25:08,794][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.61319
[2024-02-27 11:25:08,794][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.55003
[2024-02-27 11:25:29,815][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.52376
[2024-02-27 11:25:29,815][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.73680
[2024-02-27 11:25:51,153][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 1.93468
[2024-02-27 11:25:51,153][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.54508
[2024-02-27 11:26:12,753][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.71281
[2024-02-27 11:26:12,753][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.53147
[2024-02-27 11:26:33,515][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.53462
[2024-02-27 11:26:33,515][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.22725 - val_accuracy: 0.26370 - train_loss: 2.53714 - val_loss: 2.42010 - loss: 0.54219
[2024-02-27 11:27:14,807][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 1.11912
[2024-02-27 11:27:14,807][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.57543
[2024-02-27 11:27:35,706][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.56796
[2024-02-27 11:27:35,706][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.59456
[2024-02-27 11:27:56,246][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.82235
[2024-02-27 11:27:56,246][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.52042
[2024-02-27 11:28:17,375][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.53201
[2024-02-27 11:28:17,375][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.52553
[2024-02-27 11:28:38,188][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 1.61192
[2024-02-27 11:28:38,188][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.62926
[2024-02-27 11:28:57,652][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.55851
[2024-02-27 11:28:57,652][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.52835
[2024-02-27 11:29:18,260][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.54685
[2024-02-27 11:29:18,260][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.52388
[2024-02-27 11:29:39,200][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 1.85102
[2024-02-27 11:29:39,200][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.53931
[2024-02-27 11:29:59,963][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 1.85601
[2024-02-27 11:29:59,963][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.22250 - val_accuracy: 0.23620 - train_loss: 2.41921 - val_loss: 2.38545 - loss: 0.57734
[2024-02-27 11:30:41,891][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.53438
[2024-02-27 11:30:41,891][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.53387
[2024-02-27 11:31:03,155][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.52894
[2024-02-27 11:31:03,155][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 1.12372
[2024-02-27 11:31:24,318][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.64995
[2024-02-27 11:31:24,318][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.56934
[2024-02-27 11:31:44,823][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 1.90163
[2024-02-27 11:31:44,823][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 1.08950
[2024-02-27 11:32:05,839][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.71734
[2024-02-27 11:32:05,839][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.51815
[2024-02-27 11:32:25,769][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.64891
[2024-02-27 11:32:25,769][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.53852
[2024-02-27 11:32:47,730][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.59635
[2024-02-27 11:32:47,730][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.58561
[2024-02-27 11:33:09,067][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.52150
[2024-02-27 11:33:09,067][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.54031
[2024-02-27 11:33:30,798][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.89630
[2024-02-27 11:33:30,798][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.85801
[2024-02-27 11:33:51,593][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 1.14118
[2024-02-27 11:33:51,593][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.28272 - val_accuracy: 0.29540 - train_loss: 2.34787 - val_loss: 2.33673 - loss: 0.52880
[2024-02-27 11:34:34,928][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.57368
[2024-02-27 11:34:34,928][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.85335
[2024-02-27 11:34:55,224][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.61585
[2024-02-27 11:34:55,224][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.53621
[2024-02-27 11:35:15,984][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.96987
[2024-02-27 11:35:15,984][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.51495
[2024-02-27 11:35:36,294][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.64014
[2024-02-27 11:35:36,294][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.54665
[2024-02-27 11:35:57,599][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.55663
[2024-02-27 11:35:57,599][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.54331
[2024-02-27 11:36:16,938][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.65160
[2024-02-27 11:36:16,938][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.53185
[2024-02-27 11:36:39,252][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.51657
[2024-02-27 11:36:39,252][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.52031
[2024-02-27 11:36:59,495][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.54073
[2024-02-27 11:36:59,495][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.52439
[2024-02-27 11:37:20,012][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 1.29645
[2024-02-27 11:37:20,012][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.52226
[2024-02-27 11:37:40,597][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.55039
[2024-02-27 11:37:40,597][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.24513 - val_accuracy: 0.24260 - train_loss: 2.54029 - val_loss: 2.53038 - loss: 0.54029
[2024-02-27 11:38:21,503][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.52157
[2024-02-27 11:38:21,503][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.80426
[2024-02-27 11:38:41,569][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 1.91317
[2024-02-27 11:38:41,569][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.54191
[2024-02-27 11:39:02,687][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 1.60066
[2024-02-27 11:39:02,687][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.61202
[2024-02-27 11:39:24,327][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.51866
[2024-02-27 11:39:24,327][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.64844
[2024-02-27 11:39:44,842][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.73051
[2024-02-27 11:39:44,842][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 1.19078
[2024-02-27 11:40:06,314][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.54691
[2024-02-27 11:40:06,314][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 1.04239
[2024-02-27 11:40:27,443][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.94747
[2024-02-27 11:40:27,443][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.92075
[2024-02-27 11:40:47,332][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.97536
[2024-02-27 11:40:47,332][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.60437
[2024-02-27 11:41:07,675][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.53864
[2024-02-27 11:41:07,675][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 1.19509
[2024-02-27 11:41:28,503][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.50894
[2024-02-27 11:41:28,503][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.27736 - val_accuracy: 0.27760 - train_loss: 2.36741 - val_loss: 2.24010 - loss: 0.51091
[2024-02-27 11:42:11,671][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 1.30725
[2024-02-27 11:42:11,671][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.52907
[2024-02-27 11:42:31,476][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.88592
[2024-02-27 11:42:31,476][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 1.58565
[2024-02-27 11:42:51,491][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 1.01488
[2024-02-27 11:42:51,491][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.53984
[2024-02-27 11:43:13,594][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.52589
[2024-02-27 11:43:13,594][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.58705
[2024-02-27 11:43:34,432][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 1.40534
[2024-02-27 11:43:34,432][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 1.59860
[2024-02-27 11:43:55,254][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.97425
[2024-02-27 11:43:55,254][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.51054
[2024-02-27 11:44:15,535][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.94194
[2024-02-27 11:44:15,535][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.51544
[2024-02-27 11:44:36,614][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.66365
[2024-02-27 11:44:36,614][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.90116
[2024-02-27 11:44:57,214][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.52085
[2024-02-27 11:44:57,214][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.19412 - val_accuracy: 0.14400 - train_loss: 2.53259 - val_loss: 2.67161 - loss: 0.51622
[2024-02-27 11:45:39,320][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.78043
[2024-02-27 11:45:39,321][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.55571
[2024-02-27 11:45:59,998][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 1.14613
[2024-02-27 11:45:59,998][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.68650
[2024-02-27 11:46:20,833][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.52817
[2024-02-27 11:46:20,833][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.51868
[2024-02-27 11:46:41,431][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 1.02874
[2024-02-27 11:46:41,431][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.54721
[2024-02-27 11:47:02,902][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 1.23546
[2024-02-27 11:47:02,902][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.51912
[2024-02-27 11:47:22,954][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.93028
[2024-02-27 11:47:22,954][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.55631
[2024-02-27 11:47:43,477][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 1.33908
[2024-02-27 11:47:43,477][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.53183
[2024-02-27 11:48:03,675][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.50963
[2024-02-27 11:48:03,675][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.52988
[2024-02-27 11:48:25,459][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 1.60908
[2024-02-27 11:48:25,459][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.52859
[2024-02-27 11:48:45,908][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.81926
[2024-02-27 11:48:45,908][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.20276 - val_accuracy: 0.25060 - train_loss: 2.53215 - val_loss: 2.39195 - loss: 0.51450
[2024-02-27 11:49:28,045][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 1.62158
[2024-02-27 11:49:28,045][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.59008
[2024-02-27 11:49:48,115][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.68789
[2024-02-27 11:49:48,116][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.51619
[2024-02-27 11:50:08,939][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.51903
[2024-02-27 11:50:08,939][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.52487
[2024-02-27 11:50:30,114][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.65118
[2024-02-27 11:50:30,114][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.52931
[2024-02-27 11:50:49,769][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.66079
[2024-02-27 11:50:49,769][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.53767
[2024-02-27 11:51:10,764][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 1.09303
[2024-02-27 11:51:10,764][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.52288
[2024-02-27 11:51:32,217][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.51368
[2024-02-27 11:51:32,217][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.51047
[2024-02-27 11:51:51,940][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 1.25285
[2024-02-27 11:51:51,940][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.77854
[2024-02-27 11:52:12,216][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.63785
[2024-02-27 11:52:12,216][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.51161
[2024-02-27 11:52:32,658][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.89563
[2024-02-27 11:52:32,659][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.21778 - val_accuracy: 0.18640 - train_loss: 2.59604 - val_loss: 2.81126 - loss: 0.53425
[2024-02-27 11:53:15,723][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.56104
[2024-02-27 11:53:15,723][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.51797
[2024-02-27 11:53:36,638][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 1.05395
[2024-02-27 11:53:36,638][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.64725
[2024-02-27 11:53:57,920][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.51698
[2024-02-27 11:53:57,920][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.54967
[2024-02-27 11:54:19,361][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.83810
[2024-02-27 11:54:19,361][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.63904
[2024-02-27 11:54:40,878][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 1.90366
[2024-02-27 11:54:40,878][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.51761
[2024-02-27 11:55:01,595][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.51633
[2024-02-27 11:55:01,595][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.52155
[2024-02-27 11:55:22,664][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.53166
[2024-02-27 11:55:22,665][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.54663
[2024-02-27 11:55:44,321][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 1.86274
[2024-02-27 11:55:44,321][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.53366
[2024-02-27 11:56:04,505][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.51904
[2024-02-27 11:56:04,505][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.20832 - val_accuracy: 0.18370 - train_loss: 2.30405 - val_loss: 2.34904 - loss: 0.53243
[2024-02-27 11:56:46,354][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.50743
[2024-02-27 11:56:46,354][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.50789
[2024-02-27 11:57:06,636][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.53387
[2024-02-27 11:57:06,636][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.55698
[2024-02-27 11:57:27,514][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 1.55116
[2024-02-27 11:57:27,514][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.59045
[2024-02-27 11:57:48,297][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 1.47338
[2024-02-27 11:57:48,297][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 1.89151
[2024-02-27 11:58:09,955][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.58246
[2024-02-27 11:58:09,956][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.50394
[2024-02-27 11:58:29,749][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 1.29541
[2024-02-27 11:58:29,749][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.59421
[2024-02-27 11:58:50,723][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.51597
[2024-02-27 11:58:50,723][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.57479
[2024-02-27 11:59:11,497][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.51051
[2024-02-27 11:59:11,497][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.50823
[2024-02-27 11:59:32,474][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.91801
[2024-02-27 11:59:32,474][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.74511
[2024-02-27 11:59:52,552][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.54832
[2024-02-27 11:59:52,552][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.28109 - val_accuracy: 0.30150 - train_loss: 2.28340 - val_loss: 2.19803 - loss: 0.50520
[2024-02-27 12:00:35,528][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.54349
[2024-02-27 12:00:35,528][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.55226
[2024-02-27 12:00:56,098][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.53033
[2024-02-27 12:00:56,098][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.51563
[2024-02-27 12:01:16,349][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.52182
[2024-02-27 12:01:16,349][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.51708
[2024-02-27 12:01:36,445][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.53072
[2024-02-27 12:01:36,446][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.53136
[2024-02-27 12:01:57,403][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.51872
[2024-02-27 12:01:57,403][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.53717
[2024-02-27 12:02:18,156][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.56437
[2024-02-27 12:02:18,156][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 1.80985
[2024-02-27 12:02:38,730][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.91723
[2024-02-27 12:02:38,730][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.50708
[2024-02-27 12:02:59,374][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 1.42301
[2024-02-27 12:02:59,374][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.52363
[2024-02-27 12:03:20,252][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 1.65562
[2024-02-27 12:03:20,252][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.50986
[2024-02-27 12:03:40,609][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.52989
[2024-02-27 12:03:40,609][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.19050 - val_accuracy: 0.13760 - train_loss: 2.68303 - val_loss: 3.03322 - loss: 0.52590
[2024-02-27 12:04:21,439][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.58355
[2024-02-27 12:04:21,439][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.51618
[2024-02-27 12:04:41,804][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.87354
[2024-02-27 12:04:41,804][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 1.05677
[2024-02-27 12:05:03,446][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.65384
[2024-02-27 12:05:03,446][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.51880
[2024-02-27 12:05:23,929][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.54470
[2024-02-27 12:05:23,929][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.50962
[2024-02-27 12:05:44,054][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.53162
[2024-02-27 12:05:44,054][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.51079
[2024-02-27 12:06:04,833][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.61770
[2024-02-27 12:06:04,833][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.57887
[2024-02-27 12:06:25,666][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.61387
[2024-02-27 12:06:25,666][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.53410
[2024-02-27 12:06:45,483][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.51094
[2024-02-27 12:06:45,483][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.50334
[2024-02-27 12:07:06,107][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.72960
[2024-02-27 12:07:06,107][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.26379 - val_accuracy: 0.21650 - train_loss: 2.50028 - val_loss: 2.60646 - loss: 0.58395
[2024-02-27 12:07:49,076][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51227
[2024-02-27 12:07:49,076][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.50761
[2024-02-27 12:08:08,761][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.69551
[2024-02-27 12:08:08,761][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.52571
[2024-02-27 12:08:29,330][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.50428
[2024-02-27 12:08:29,330][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51871
[2024-02-27 12:08:49,565][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51730
[2024-02-27 12:08:49,565][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.73662
[2024-02-27 12:09:11,636][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51363
[2024-02-27 12:09:11,636][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.72778
[2024-02-27 12:09:32,565][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.93047
[2024-02-27 12:09:32,565][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51438
[2024-02-27 12:09:54,656][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.50484
[2024-02-27 12:09:54,656][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.73280
[2024-02-27 12:10:15,517][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.70239
[2024-02-27 12:10:15,517][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51529
[2024-02-27 12:10:37,324][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51161
[2024-02-27 12:10:37,324][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.50920
[2024-02-27 12:10:58,332][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.69558
[2024-02-27 12:10:58,332][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.22473 - val_accuracy: 0.23140 - train_loss: 2.34181 - val_loss: 2.35625 - loss: 0.51534
[2024-02-27 12:11:39,279][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51029
[2024-02-27 12:11:39,279][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.54981
[2024-02-27 12:12:00,082][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.59101
[2024-02-27 12:12:00,082][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51498
[2024-02-27 12:12:20,677][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51637
[2024-02-27 12:12:20,677][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.91395
[2024-02-27 12:12:41,255][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.56663
[2024-02-27 12:12:41,255][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.63519
[2024-02-27 12:13:02,664][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 1.06833
[2024-02-27 12:13:02,664][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.90325
[2024-02-27 12:13:22,843][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.64010
[2024-02-27 12:13:22,843][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.54459
[2024-02-27 12:13:45,179][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.53530
[2024-02-27 12:13:45,179][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 1.09589
[2024-02-27 12:14:06,271][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.50682
[2024-02-27 12:14:06,271][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51870
[2024-02-27 12:14:27,126][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51849
[2024-02-27 12:14:27,126][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.51750
[2024-02-27 12:14:48,770][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 0.54478
[2024-02-27 12:14:48,770][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.17576 - val_accuracy: 0.18400 - train_loss: 2.51614 - val_loss: 2.49444 - loss: 1.95163
[2024-02-27 12:15:30,533][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.41967
[2024-02-27 12:15:30,533][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50926
[2024-02-27 12:15:51,073][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.51471
[2024-02-27 12:15:51,073][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.17591
[2024-02-27 12:16:12,112][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50963
[2024-02-27 12:16:12,112][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50735
[2024-02-27 12:16:33,054][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.52997
[2024-02-27 12:16:33,054][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50314
[2024-02-27 12:16:54,920][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.00256
[2024-02-27 12:16:54,920][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.53207
[2024-02-27 12:17:14,783][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.07281
[2024-02-27 12:17:14,783][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50972
[2024-02-27 12:17:35,744][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.93094
[2024-02-27 12:17:35,744][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50721
[2024-02-27 12:17:55,564][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50300
[2024-02-27 12:17:55,564][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.66520
[2024-02-27 12:18:15,831][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 1.55138
[2024-02-27 12:18:15,831][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.58411
[2024-02-27 12:18:37,063][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.54876
[2024-02-27 12:18:37,063][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 0.18470 - val_accuracy: 0.18830 - train_loss: 2.50976 - val_loss: 2.50489 - loss: 0.50695
[2024-02-27 12:19:20,691][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.50697
[2024-02-27 12:19:20,691][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.83205
[2024-02-27 12:19:41,127][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.83660
[2024-02-27 12:19:41,127][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.54490
[2024-02-27 12:20:03,308][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 1.16136
[2024-02-27 12:20:03,308][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.51151
[2024-02-27 12:20:23,979][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.50292
[2024-02-27 12:20:23,979][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.58060
[2024-02-27 12:20:44,733][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.51512
[2024-02-27 12:20:44,733][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.54145
[2024-02-27 12:21:06,151][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.50643
[2024-02-27 12:21:06,151][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.51083
[2024-02-27 12:21:26,887][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.52071
[2024-02-27 12:21:26,887][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.79586
[2024-02-27 12:21:48,439][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.51405
[2024-02-27 12:21:48,439][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.50574
[2024-02-27 12:22:09,390][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.70297
[2024-02-27 12:22:09,390][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.21964 - val_accuracy: 0.21500 - train_loss: 2.51268 - val_loss: 2.53711 - loss: 0.52727
[2024-02-27 12:22:51,124][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.55456
[2024-02-27 12:22:51,124][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 1.13111
[2024-02-27 12:23:11,120][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.51409
[2024-02-27 12:23:11,120][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 1.79496
[2024-02-27 12:23:32,067][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 1.16577
[2024-02-27 12:23:32,067][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.59233
[2024-02-27 12:23:52,100][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34600] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.67399
[2024-02-27 12:23:52,100][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34600] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50725
[2024-02-27 12:24:12,865][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34650] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.56045
[2024-02-27 12:24:12,865][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34650] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50432
[2024-02-27 12:24:33,267][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34700] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.64822
[2024-02-27 12:24:33,267][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34700] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.51140
[2024-02-27 12:24:53,974][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34750] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.53125
[2024-02-27 12:24:53,974][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34750] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 1.34082
[2024-02-27 12:25:14,492][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34800] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.74426
[2024-02-27 12:25:14,492][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34800] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50649
[2024-02-27 12:25:35,349][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34850] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50342
[2024-02-27 12:25:35,349][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34850] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50216
[2024-02-27 12:25:55,579][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34900] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.51049
[2024-02-27 12:25:55,579][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34900] - train_accuracy: 0.31135 - val_accuracy: 0.36050 - train_loss: 2.31576 - val_loss: 2.18332 - loss: 0.50648
[2024-02-27 12:26:38,625][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[34950] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 1.15652
[2024-02-27 12:26:38,625][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[34950] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.59318
[2024-02-27 12:26:59,255][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[35000] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.94977
[2024-02-27 12:26:59,255][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[35000] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.80554
[2024-02-27 12:27:19,923][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35050] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.51166
[2024-02-27 12:27:19,923][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35050] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.50949
[2024-02-27 12:27:41,892][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35100] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.52787
[2024-02-27 12:27:41,892][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35100] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.51732
[2024-02-27 12:28:02,317][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35150] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.52552
[2024-02-27 12:28:02,317][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35150] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.51643
[2024-02-27 12:28:23,544][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35200] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.50614
[2024-02-27 12:28:23,544][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35200] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 1.36599
[2024-02-27 12:28:45,132][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35250] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.52604
[2024-02-27 12:28:45,132][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35250] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.50297
[2024-02-27 12:29:05,928][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35300] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.50923
[2024-02-27 12:29:05,928][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35300] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.99732
[2024-02-27 12:29:26,419][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35350] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.50471
[2024-02-27 12:29:26,419][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35350] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.54132
[2024-02-27 12:29:47,769][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35400] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.58168
[2024-02-27 12:29:47,769][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35400] - train_accuracy: 0.18637 - val_accuracy: 0.15870 - train_loss: 2.60128 - val_loss: 2.75144 - loss: 0.51584
[2024-02-27 12:30:29,316][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35450] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.57043
[2024-02-27 12:30:29,316][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35450] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.62509
[2024-02-27 12:30:49,390][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35500] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 1.81384
[2024-02-27 12:30:49,390][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35500] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.50219
[2024-02-27 12:31:09,662][PyLogger][INFO]: Rank[0]: Epoch[367/500], iter[35550] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.51181
[2024-02-27 12:31:09,662][PyLogger][INFO]: Rank[1]: Epoch[367/500], iter[35550] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.91332
[2024-02-27 12:31:29,816][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35600] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.52631
[2024-02-27 12:31:29,816][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35600] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.50284
[2024-02-27 12:31:50,216][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35650] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.50699
[2024-02-27 12:31:50,216][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35650] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.50289
[2024-02-27 12:32:11,044][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35700] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.55161
[2024-02-27 12:32:11,044][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35700] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.53410
[2024-02-27 12:32:32,145][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35750] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.54617
[2024-02-27 12:32:32,145][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35750] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.54648
[2024-02-27 12:32:53,322][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35800] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.51310
[2024-02-27 12:32:53,322][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35800] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 1.34429
[2024-02-27 12:33:13,889][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35850] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 0.50987
[2024-02-27 12:33:13,889][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35850] - train_accuracy: 0.22864 - val_accuracy: 0.20530 - train_loss: 2.44305 - val_loss: 2.52021 - loss: 1.17506
[2024-02-27 12:33:55,080][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35900] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51382
[2024-02-27 12:33:55,080][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35900] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51207
[2024-02-27 12:34:16,521][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35950] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51347
[2024-02-27 12:34:16,521][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35950] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51730
[2024-02-27 12:34:38,008][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36000] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.99831
[2024-02-27 12:34:38,008][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36000] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 1.20339
[2024-02-27 12:34:58,195][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36050] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51954
[2024-02-27 12:34:58,195][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36050] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50602
[2024-02-27 12:35:19,323][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36100] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.88288
[2024-02-27 12:35:19,323][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36100] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.54768
[2024-02-27 12:35:39,645][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36150] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50622
[2024-02-27 12:35:39,645][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36150] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51003
[2024-02-27 12:36:00,788][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36200] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50670
[2024-02-27 12:36:00,788][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36200] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50372
[2024-02-27 12:36:20,778][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36250] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50325
[2024-02-27 12:36:20,778][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36250] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 1.86275
[2024-02-27 12:36:40,543][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36300] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.81100
[2024-02-27 12:36:40,543][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36300] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.50247
[2024-02-27 12:37:00,941][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36350] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.86097
[2024-02-27 12:37:00,941][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36350] - train_accuracy: 0.29653 - val_accuracy: 0.28440 - train_loss: 2.42465 - val_loss: 2.51734 - loss: 0.51583
[2024-02-27 12:37:43,202][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36400] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.51751
[2024-02-27 12:37:43,202][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36400] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 1.13537
[2024-02-27 12:38:03,625][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36450] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.50379
[2024-02-27 12:38:03,625][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36450] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.81625
[2024-02-27 12:38:24,626][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36500] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.55276
[2024-02-27 12:38:24,626][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36500] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.77566
[2024-02-27 12:38:45,309][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36550] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 1.35866
[2024-02-27 12:38:45,309][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36550] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.50467
[2024-02-27 12:39:06,593][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36600] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.86050
[2024-02-27 12:39:06,593][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36600] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.67651
[2024-02-27 12:39:27,182][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36650] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.64423
[2024-02-27 12:39:27,182][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36650] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.50239
[2024-02-27 12:39:47,157][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36700] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.99283
[2024-02-27 12:39:47,157][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36700] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.54882
[2024-02-27 12:40:08,080][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36750] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.62418
[2024-02-27 12:40:08,080][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36750] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.51512
[2024-02-27 12:40:27,596][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36800] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.50542
[2024-02-27 12:40:27,596][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36800] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.51895
[2024-02-27 12:40:47,171][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36850] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 1.09347
[2024-02-27 12:40:47,171][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36850] - train_accuracy: 0.17967 - val_accuracy: 0.14360 - train_loss: 2.45889 - val_loss: 2.52857 - loss: 0.54909
[2024-02-27 12:41:29,048][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36900] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.51844
[2024-02-27 12:41:29,048][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36900] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 1.85580
[2024-02-27 12:41:50,006][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36950] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50785
[2024-02-27 12:41:50,006][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36950] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50425
[2024-02-27 12:42:10,741][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37000] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50237
[2024-02-27 12:42:10,741][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37000] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50562
[2024-02-27 12:42:31,420][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37050] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50604
[2024-02-27 12:42:31,420][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37050] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.51120
[2024-02-27 12:42:53,493][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37100] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.51248
[2024-02-27 12:42:53,493][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37100] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 1.39185
[2024-02-27 12:43:14,983][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37150] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50764
[2024-02-27 12:43:14,983][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37150] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50610
[2024-02-27 12:43:35,348][PyLogger][INFO]: Rank[0]: Epoch[384/500], iter[37200] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.54754
[2024-02-27 12:43:35,348][PyLogger][INFO]: Rank[1]: Epoch[384/500], iter[37200] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50190
[2024-02-27 12:43:57,039][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37250] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 1.33672
[2024-02-27 12:43:57,039][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37250] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.71572
[2024-02-27 12:44:16,948][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37300] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.50164
[2024-02-27 12:44:16,948][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37300] - train_accuracy: 0.21919 - val_accuracy: 0.23990 - train_loss: 2.66803 - val_loss: 2.82473 - loss: 0.54663
[2024-02-27 12:44:57,962][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37350] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.85526
[2024-02-27 12:44:57,962][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37350] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50353
[2024-02-27 12:45:19,077][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37400] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.51256
[2024-02-27 12:45:19,077][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37400] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50238
[2024-02-27 12:45:39,883][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37450] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.56130
[2024-02-27 12:45:39,883][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37450] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 1.33355
[2024-02-27 12:46:00,468][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37500] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50405
[2024-02-27 12:46:00,468][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37500] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 1.32645
[2024-02-27 12:46:21,690][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37550] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.54754
[2024-02-27 12:46:21,690][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37550] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50550
[2024-02-27 12:46:42,444][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37600] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 1.32610
[2024-02-27 12:46:42,444][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37600] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50865
[2024-02-27 12:47:03,676][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37650] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50157
[2024-02-27 12:47:03,676][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37650] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50212
[2024-02-27 12:47:24,222][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37700] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.63386
[2024-02-27 12:47:24,222][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37700] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50137
[2024-02-27 12:47:45,638][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37750] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.51537
[2024-02-27 12:47:45,638][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37750] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50270
[2024-02-27 12:48:06,106][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37800] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 0.50398
[2024-02-27 12:48:06,106][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37800] - train_accuracy: 0.28010 - val_accuracy: 0.29770 - train_loss: 2.56922 - val_loss: 2.57712 - loss: 1.13514
[2024-02-27 12:48:47,650][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37850] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50229
[2024-02-27 12:48:47,650][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37850] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.51336
[2024-02-27 12:49:08,302][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37900] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.86331
[2024-02-27 12:49:08,302][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37900] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 1.88339
[2024-02-27 12:49:28,992][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[37950] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.63534
[2024-02-27 12:49:28,992][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[37950] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.51436
[2024-02-27 12:49:49,832][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[38000] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.55315
[2024-02-27 12:49:49,832][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[38000] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50102
[2024-02-27 12:50:11,401][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38050] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50178
[2024-02-27 12:50:11,401][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38050] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.51339
[2024-02-27 12:50:31,890][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38100] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50540
[2024-02-27 12:50:31,890][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38100] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50662
[2024-02-27 12:50:53,357][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38150] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.51024
[2024-02-27 12:50:53,357][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38150] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50166
[2024-02-27 12:51:13,806][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38200] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50528
[2024-02-27 12:51:13,806][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38200] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50895
[2024-02-27 12:51:35,954][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38250] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.75354
[2024-02-27 12:51:35,954][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38250] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50204
[2024-02-27 12:51:56,361][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38300] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.67216
[2024-02-27 12:51:56,361][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38300] - train_accuracy: 0.34377 - val_accuracy: 0.40770 - train_loss: 2.40952 - val_loss: 2.20350 - loss: 0.50197
[2024-02-27 12:52:38,298][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38350] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50508
[2024-02-27 12:52:38,298][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38350] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50528
[2024-02-27 12:52:59,051][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38400] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50433
[2024-02-27 12:52:59,051][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38400] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 1.04507
[2024-02-27 12:53:19,683][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38450] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50164
[2024-02-27 12:53:19,683][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38450] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 1.46821
[2024-02-27 12:53:39,781][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38500] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50105
[2024-02-27 12:53:39,781][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38500] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50151
[2024-02-27 12:54:01,026][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38550] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.91033
[2024-02-27 12:54:01,026][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38550] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.80149
[2024-02-27 12:54:21,380][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38600] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50169
[2024-02-27 12:54:21,380][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38600] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50175
[2024-02-27 12:54:42,222][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38650] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50946
[2024-02-27 12:54:42,222][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38650] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50733
[2024-02-27 12:55:02,275][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38700] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.51003
[2024-02-27 12:55:02,275][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38700] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50190
[2024-02-27 12:55:22,838][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38750] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.53529
[2024-02-27 12:55:22,838][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38750] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.50546
[2024-02-27 12:55:43,567][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38800] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 1.32277
[2024-02-27 12:55:43,567][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38800] - train_accuracy: 0.29351 - val_accuracy: 0.21020 - train_loss: 2.25443 - val_loss: 2.31313 - loss: 0.67555
[2024-02-27 12:56:25,727][PyLogger][INFO]: Rank[1]: Epoch[401/500], iter[38850] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.60535
[2024-02-27 12:56:25,727][PyLogger][INFO]: Rank[0]: Epoch[401/500], iter[38850] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50162
[2024-02-27 12:56:48,256][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38900] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.52581
[2024-02-27 12:56:48,256][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38900] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50258
[2024-02-27 12:57:08,204][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38950] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 1.27124
[2024-02-27 12:57:08,205][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38950] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.54528
[2024-02-27 12:57:29,281][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39000] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50146
[2024-02-27 12:57:29,281][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39000] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.51439
[2024-02-27 12:57:50,619][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39050] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.74871
[2024-02-27 12:57:50,619][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39050] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50202
[2024-02-27 12:58:11,895][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39100] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 1.87243
[2024-02-27 12:58:11,895][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39100] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50179
[2024-02-27 12:58:32,564][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39150] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50531
[2024-02-27 12:58:32,564][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39150] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.50308
[2024-02-27 12:58:53,867][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39200] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.61562
[2024-02-27 12:58:53,867][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39200] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.56894
[2024-02-27 12:59:14,762][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39250] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 1.27656
[2024-02-27 12:59:14,762][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39250] - train_accuracy: 0.21454 - val_accuracy: 0.21790 - train_loss: 2.44340 - val_loss: 2.41941 - loss: 0.51034
[2024-02-27 12:59:56,274][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39300] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.51070
[2024-02-27 12:59:56,274][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39300] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50391
[2024-02-27 13:00:16,977][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39350] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.51529
[2024-02-27 13:00:16,977][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39350] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50263
[2024-02-27 13:00:38,152][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39400] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.57121
[2024-02-27 13:00:38,152][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39400] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 1.10976
[2024-02-27 13:00:58,936][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39450] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50722
[2024-02-27 13:00:58,936][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39450] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.51366
[2024-02-27 13:01:19,633][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39500] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50946
[2024-02-27 13:01:19,633][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39500] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.51025
[2024-02-27 13:01:40,457][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39550] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.53501
[2024-02-27 13:01:40,457][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39550] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50248
[2024-02-27 13:02:01,148][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39600] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.65798
[2024-02-27 13:02:01,149][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39600] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50788
[2024-02-27 13:02:21,639][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39650] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 1.52434
[2024-02-27 13:02:21,639][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39650] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.54841
[2024-02-27 13:02:42,607][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39700] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50215
[2024-02-27 13:02:42,607][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39700] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.55212
[2024-02-27 13:03:03,655][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39750] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.50276
[2024-02-27 13:03:03,655][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39750] - train_accuracy: 0.20707 - val_accuracy: 0.25390 - train_loss: 2.49996 - val_loss: 2.41258 - loss: 0.51827
[2024-02-27 13:03:45,960][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39800] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50100
[2024-02-27 13:03:45,960][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39800] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50543
[2024-02-27 13:04:05,993][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39850] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.55562
[2024-02-27 13:04:05,993][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39850] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.53256
[2024-02-27 13:04:25,693][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39900] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.51871
[2024-02-27 13:04:25,693][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39900] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50116
[2024-02-27 13:04:45,945][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39950] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 1.87224
[2024-02-27 13:04:45,945][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39950] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.51303
[2024-02-27 13:05:07,010][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40000] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.63435
[2024-02-27 13:05:07,010][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40000] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50111
[2024-02-27 13:05:27,940][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40050] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.62126
[2024-02-27 13:05:27,940][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40050] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.60675
[2024-02-27 13:05:49,106][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40100] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50089
[2024-02-27 13:05:49,106][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40100] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.77166
[2024-02-27 13:06:09,138][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40150] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 1.26353
[2024-02-27 13:06:09,138][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40150] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50250
[2024-02-27 13:06:30,935][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40200] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 1.83964
[2024-02-27 13:06:30,935][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40200] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50118
[2024-02-27 13:06:51,106][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40250] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50561
[2024-02-27 13:06:51,106][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40250] - train_accuracy: 0.21025 - val_accuracy: 0.24110 - train_loss: 2.78520 - val_loss: 2.51024 - loss: 0.50080
[2024-02-27 13:07:33,302][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40300] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50112
[2024-02-27 13:07:33,302][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40300] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.87893
[2024-02-27 13:07:54,159][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40350] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.55486
[2024-02-27 13:07:54,159][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40350] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50208
[2024-02-27 13:08:15,417][PyLogger][INFO]: Rank[1]: Epoch[417/500], iter[40400] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.51178
[2024-02-27 13:08:15,417][PyLogger][INFO]: Rank[0]: Epoch[417/500], iter[40400] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.64125
[2024-02-27 13:08:36,957][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40450] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50107
[2024-02-27 13:08:36,957][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40450] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50678
[2024-02-27 13:08:57,116][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40500] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50206
[2024-02-27 13:08:57,116][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40500] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50827
[2024-02-27 13:09:18,338][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40550] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50117
[2024-02-27 13:09:18,338][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40550] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50575
[2024-02-27 13:09:38,965][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40600] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50141
[2024-02-27 13:09:38,965][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40600] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50664
[2024-02-27 13:10:00,170][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40650] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50208
[2024-02-27 13:10:00,170][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40650] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50978
[2024-02-27 13:10:20,380][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40700] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.55750
[2024-02-27 13:10:20,380][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40700] - train_accuracy: 0.28157 - val_accuracy: 0.33460 - train_loss: 2.50996 - val_loss: 2.37048 - loss: 0.50633
[2024-02-27 13:11:01,621][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40750] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50157
[2024-02-27 13:11:01,621][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40750] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50252
[2024-02-27 13:11:21,742][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40800] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.75529
[2024-02-27 13:11:21,742][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40800] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50795
[2024-02-27 13:11:42,490][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40850] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50095
[2024-02-27 13:11:42,490][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40850] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50954
[2024-02-27 13:12:03,240][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40900] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 1.86017
[2024-02-27 13:12:03,240][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40900] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50610
[2024-02-27 13:12:24,755][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[40950] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.51703
[2024-02-27 13:12:24,755][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[40950] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.56195
[2024-02-27 13:12:44,511][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[41000] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.68750
[2024-02-27 13:12:44,511][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[41000] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50803
[2024-02-27 13:13:05,630][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41050] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50105
[2024-02-27 13:13:05,630][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41050] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50359
[2024-02-27 13:13:25,633][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41100] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 1.01921
[2024-02-27 13:13:25,633][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41100] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.52264
[2024-02-27 13:13:47,825][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41150] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50357
[2024-02-27 13:13:47,825][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41150] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.50132
[2024-02-27 13:14:08,353][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41200] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 1.29435
[2024-02-27 13:14:08,353][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41200] - train_accuracy: 0.24803 - val_accuracy: 0.35410 - train_loss: 2.50109 - val_loss: 2.17852 - loss: 0.83309
[2024-02-27 13:14:51,425][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41250] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50283
[2024-02-27 13:14:51,425][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41250] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50116
[2024-02-27 13:15:11,529][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41300] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.57477
[2024-02-27 13:15:11,529][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41300] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50427
[2024-02-27 13:15:33,053][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41350] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50165
[2024-02-27 13:15:33,053][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41350] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50361
[2024-02-27 13:15:53,577][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41400] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50117
[2024-02-27 13:15:53,577][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41400] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 1.02331
[2024-02-27 13:16:14,370][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41450] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.73517
[2024-02-27 13:16:14,370][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41450] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50183
[2024-02-27 13:16:35,113][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41500] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50099
[2024-02-27 13:16:35,113][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41500] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50125
[2024-02-27 13:16:55,562][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41550] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 1.32228
[2024-02-27 13:16:55,563][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41550] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50081
[2024-02-27 13:17:15,692][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41600] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.51804
[2024-02-27 13:17:15,692][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41600] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 1.47586
[2024-02-27 13:17:37,947][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41650] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50079
[2024-02-27 13:17:37,947][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41650] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50167
[2024-02-27 13:17:58,834][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41700] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.50093
[2024-02-27 13:17:58,834][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41700] - train_accuracy: 0.32543 - val_accuracy: 0.41760 - train_loss: 2.43667 - val_loss: 2.27721 - loss: 0.61143
[2024-02-27 13:18:42,206][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41750] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50224
[2024-02-27 13:18:42,206][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41750] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50146
[2024-02-27 13:19:03,027][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41800] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50114
[2024-02-27 13:19:03,027][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41800] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.52556
[2024-02-27 13:19:24,162][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41850] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50078
[2024-02-27 13:19:24,162][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41850] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.53719
[2024-02-27 13:19:45,418][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41900] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50070
[2024-02-27 13:19:45,418][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41900] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50893
[2024-02-27 13:20:06,488][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[41950] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.52425
[2024-02-27 13:20:06,488][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[41950] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.54816
[2024-02-27 13:20:27,032][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[42000] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50105
[2024-02-27 13:20:27,032][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[42000] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50097
[2024-02-27 13:20:47,410][PyLogger][INFO]: Rank[1]: Epoch[434/500], iter[42050] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.63731
[2024-02-27 13:20:47,410][PyLogger][INFO]: Rank[0]: Epoch[434/500], iter[42050] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 1.84634
[2024-02-27 13:21:08,367][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42100] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.97339
[2024-02-27 13:21:08,367][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42100] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50118
[2024-02-27 13:21:28,811][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42150] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.73020
[2024-02-27 13:21:28,811][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42150] - train_accuracy: 0.15536 - val_accuracy: 0.18330 - train_loss: 2.87917 - val_loss: 2.72089 - loss: 0.50087
[2024-02-27 13:22:10,871][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42200] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50129
[2024-02-27 13:22:10,871][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42200] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.51267
[2024-02-27 13:22:31,559][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42250] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 1.30002
[2024-02-27 13:22:31,559][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42250] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50098
[2024-02-27 13:22:51,474][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42300] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50500
[2024-02-27 13:22:51,474][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42300] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.52177
[2024-02-27 13:23:12,441][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42350] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50187
[2024-02-27 13:23:12,441][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42350] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50092
[2024-02-27 13:23:33,143][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42400] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50083
[2024-02-27 13:23:33,143][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42400] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50843
[2024-02-27 13:23:52,860][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42450] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.53204
[2024-02-27 13:23:52,860][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42450] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50243
[2024-02-27 13:24:14,153][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42500] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50116
[2024-02-27 13:24:14,153][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42500] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50079
[2024-02-27 13:24:35,507][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42550] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50350
[2024-02-27 13:24:35,507][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42550] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50098
[2024-02-27 13:24:57,836][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42600] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50150
[2024-02-27 13:24:57,836][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42600] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.96015
[2024-02-27 13:25:18,611][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42650] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.67151
[2024-02-27 13:25:18,611][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42650] - train_accuracy: 0.35394 - val_accuracy: 0.31250 - train_loss: 2.21758 - val_loss: 2.39222 - loss: 0.50119
[2024-02-27 13:25:59,644][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42700] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50309
[2024-02-27 13:25:59,644][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42700] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50614
[2024-02-27 13:26:19,962][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42750] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50103
[2024-02-27 13:26:19,962][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42750] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.51813
[2024-02-27 13:26:40,297][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42800] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 1.20954
[2024-02-27 13:26:40,297][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42800] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.71910
[2024-02-27 13:26:59,856][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42850] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50071
[2024-02-27 13:26:59,856][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42850] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.68035
[2024-02-27 13:27:20,634][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42900] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.78330
[2024-02-27 13:27:20,634][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42900] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50232
[2024-02-27 13:27:40,806][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42950] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 1.22709
[2024-02-27 13:27:40,806][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42950] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50115
[2024-02-27 13:28:01,586][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43000] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50163
[2024-02-27 13:28:01,586][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43000] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50761
[2024-02-27 13:28:21,750][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43050] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 1.03042
[2024-02-27 13:28:21,750][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43050] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 1.06156
[2024-02-27 13:28:43,027][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43100] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.66199
[2024-02-27 13:28:43,027][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43100] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50093
[2024-02-27 13:29:03,558][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43150] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50107
[2024-02-27 13:29:03,558][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43150] - train_accuracy: 0.26635 - val_accuracy: 0.32380 - train_loss: 2.54306 - val_loss: 2.41215 - loss: 0.50086
[2024-02-27 13:29:44,813][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43200] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.79066
[2024-02-27 13:29:44,813][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43200] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50141
[2024-02-27 13:30:05,681][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43250] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50461
[2024-02-27 13:30:05,681][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43250] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50124
[2024-02-27 13:30:27,723][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43300] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50070
[2024-02-27 13:30:27,723][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43300] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.59484
[2024-02-27 13:30:48,806][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43350] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 1.81543
[2024-02-27 13:30:48,806][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43350] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.51060
[2024-02-27 13:31:10,423][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43400] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50073
[2024-02-27 13:31:10,423][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43400] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50342
[2024-02-27 13:31:31,262][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43450] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50400
[2024-02-27 13:31:31,263][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43450] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50100
[2024-02-27 13:31:53,164][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43500] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 1.30372
[2024-02-27 13:31:53,164][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43500] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50269
[2024-02-27 13:32:14,222][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43550] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.51978
[2024-02-27 13:32:14,222][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43550] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50082
[2024-02-27 13:32:35,548][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43600] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50077
[2024-02-27 13:32:35,548][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43600] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50109
[2024-02-27 13:32:56,504][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43650] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50073
[2024-02-27 13:32:56,504][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43650] - train_accuracy: 0.21978 - val_accuracy: 0.25490 - train_loss: 2.60191 - val_loss: 2.48540 - loss: 0.50164
[2024-02-27 13:33:39,642][PyLogger][INFO]: Rank[0]: Epoch[451/500], iter[43700] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50319
[2024-02-27 13:33:39,642][PyLogger][INFO]: Rank[1]: Epoch[451/500], iter[43700] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50148
[2024-02-27 13:34:00,671][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43750] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50089
[2024-02-27 13:34:00,671][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43750] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50082
[2024-02-27 13:34:21,167][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43800] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.51086
[2024-02-27 13:34:21,167][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43800] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50079
[2024-02-27 13:34:41,741][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43850] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50086
[2024-02-27 13:34:41,741][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43850] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.54214
[2024-02-27 13:35:01,907][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43900] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.52316
[2024-02-27 13:35:01,907][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43900] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50569
[2024-02-27 13:35:21,867][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[43950] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50326
[2024-02-27 13:35:21,867][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[43950] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50108
[2024-02-27 13:35:41,830][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[44000] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.60579
[2024-02-27 13:35:41,830][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[44000] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50242
[2024-02-27 13:36:02,143][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44050] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 1.88909
[2024-02-27 13:36:02,143][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44050] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 1.37860
[2024-02-27 13:36:23,358][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44100] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.66354
[2024-02-27 13:36:23,358][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44100] - train_accuracy: 0.44499 - val_accuracy: 0.49740 - train_loss: 2.39156 - val_loss: 1.98842 - loss: 0.50089
[2024-02-27 13:37:05,686][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44150] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50883
[2024-02-27 13:37:05,686][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44150] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50126
[2024-02-27 13:37:26,325][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44200] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.56729
[2024-02-27 13:37:26,325][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44200] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.51045
[2024-02-27 13:37:48,159][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44250] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.61888
[2024-02-27 13:37:48,159][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44250] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50075
[2024-02-27 13:38:09,724][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44300] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50165
[2024-02-27 13:38:09,724][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44300] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 1.84500
[2024-02-27 13:38:30,472][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44350] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.84009
[2024-02-27 13:38:30,472][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44350] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50340
[2024-02-27 13:38:50,008][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44400] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50128
[2024-02-27 13:38:50,008][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44400] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50061
[2024-02-27 13:39:11,082][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44450] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 1.83887
[2024-02-27 13:39:11,083][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44450] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50087
[2024-02-27 13:39:30,974][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44500] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50116
[2024-02-27 13:39:30,974][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44500] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 1.80766
[2024-02-27 13:39:52,465][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44550] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 1.84377
[2024-02-27 13:39:52,465][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44550] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.51159
[2024-02-27 13:40:12,980][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44600] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50087
[2024-02-27 13:40:12,980][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44600] - train_accuracy: 0.21458 - val_accuracy: 0.31870 - train_loss: 2.71793 - val_loss: 2.31799 - loss: 0.50425
[2024-02-27 13:40:55,909][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44650] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50104
[2024-02-27 13:40:55,909][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44650] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50115
[2024-02-27 13:41:16,061][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44700] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50166
[2024-02-27 13:41:16,061][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44700] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.66366
[2024-02-27 13:41:37,776][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44750] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.59528
[2024-02-27 13:41:37,776][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44750] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.51570
[2024-02-27 13:41:57,749][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44800] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.58031
[2024-02-27 13:41:57,749][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44800] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.51790
[2024-02-27 13:42:18,618][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44850] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50078
[2024-02-27 13:42:18,618][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44850] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50241
[2024-02-27 13:42:40,001][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44900] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.51173
[2024-02-27 13:42:40,001][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44900] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50393
[2024-02-27 13:43:01,709][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[44950] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50098
[2024-02-27 13:43:01,709][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[44950] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50085
[2024-02-27 13:43:22,155][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[45000] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 1.50380
[2024-02-27 13:43:22,155][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[45000] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50090
[2024-02-27 13:43:42,949][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45050] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50065
[2024-02-27 13:43:42,949][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45050] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50091
[2024-02-27 13:44:02,827][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45100] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 1.29543
[2024-02-27 13:44:02,827][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45100] - train_accuracy: 0.26772 - val_accuracy: 0.19610 - train_loss: 2.62689 - val_loss: 2.92468 - loss: 0.50072
[2024-02-27 13:44:45,057][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45150] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50236
[2024-02-27 13:44:45,057][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45150] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.60481
[2024-02-27 13:45:05,565][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45200] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50112
[2024-02-27 13:45:05,566][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45200] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50131
[2024-02-27 13:45:26,855][PyLogger][INFO]: Rank[0]: Epoch[467/500], iter[45250] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.76806
[2024-02-27 13:45:26,855][PyLogger][INFO]: Rank[1]: Epoch[467/500], iter[45250] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50066
[2024-02-27 13:45:48,165][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45300] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.57261
[2024-02-27 13:45:48,165][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45300] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50168
[2024-02-27 13:46:08,900][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45350] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50076
[2024-02-27 13:46:08,900][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45350] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 1.73902
[2024-02-27 13:46:29,561][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45400] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50058
[2024-02-27 13:46:29,560][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45400] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50143
[2024-02-27 13:46:50,345][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45450] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50126
[2024-02-27 13:46:50,345][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45450] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.77658
[2024-02-27 13:47:11,038][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45500] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50207
[2024-02-27 13:47:11,038][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45500] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.72788
[2024-02-27 13:47:31,932][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45550] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50346
[2024-02-27 13:47:31,932][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45550] - train_accuracy: 0.21351 - val_accuracy: 0.22750 - train_loss: 2.61113 - val_loss: 2.59235 - loss: 0.50126
[2024-02-27 13:48:13,507][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45600] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.54419
[2024-02-27 13:48:13,508][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45600] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50074
[2024-02-27 13:48:34,633][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45650] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50098
[2024-02-27 13:48:34,633][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45650] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50085
[2024-02-27 13:48:55,756][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45700] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 1.84182
[2024-02-27 13:48:55,756][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45700] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.52835
[2024-02-27 13:49:15,691][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45750] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 1.25757
[2024-02-27 13:49:15,691][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45750] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.51629
[2024-02-27 13:49:37,049][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45800] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 1.24647
[2024-02-27 13:49:37,049][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45800] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50072
[2024-02-27 13:49:57,218][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45850] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.52217
[2024-02-27 13:49:57,218][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45850] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.51422
[2024-02-27 13:50:17,331][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45900] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.88367
[2024-02-27 13:50:17,331][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45900] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50084
[2024-02-27 13:50:38,806][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45950] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 1.84335
[2024-02-27 13:50:38,806][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45950] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.81202
[2024-02-27 13:50:59,599][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46000] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50100
[2024-02-27 13:50:59,599][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46000] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50526
[2024-02-27 13:51:20,154][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46050] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50145
[2024-02-27 13:51:20,153][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46050] - train_accuracy: 0.15998 - val_accuracy: 0.15440 - train_loss: 2.57452 - val_loss: 2.71373 - loss: 0.50077
[2024-02-27 13:52:01,331][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46100] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50130
[2024-02-27 13:52:01,331][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46100] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50108
[2024-02-27 13:52:19,996][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46150] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.66404
[2024-02-27 13:52:19,996][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46150] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50088
[2024-02-27 13:52:40,632][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46200] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.68719
[2024-02-27 13:52:40,632][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46200] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.54057
[2024-02-27 13:53:02,126][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46250] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.90647
[2024-02-27 13:53:02,126][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46250] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50166
[2024-02-27 13:53:24,064][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46300] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50065
[2024-02-27 13:53:24,064][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46300] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 1.00289
[2024-02-27 13:53:45,183][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46350] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50168
[2024-02-27 13:53:45,183][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46350] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.51081
[2024-02-27 13:54:06,911][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46400] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50120
[2024-02-27 13:54:06,911][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46400] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.91763
[2024-02-27 13:54:27,790][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46450] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50302
[2024-02-27 13:54:27,790][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46450] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 1.29405
[2024-02-27 13:54:49,291][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46500] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50074
[2024-02-27 13:54:49,291][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46500] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50073
[2024-02-27 13:55:10,965][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46550] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 0.50065
[2024-02-27 13:55:10,965][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46550] - train_accuracy: 0.15506 - val_accuracy: 0.14970 - train_loss: 2.74659 - val_loss: 2.72844 - loss: 1.80919
[2024-02-27 13:55:52,377][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46600] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50674
[2024-02-27 13:55:52,377][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46600] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50086
[2024-02-27 13:56:13,725][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46650] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 1.41134
[2024-02-27 13:56:13,726][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46650] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.62670
[2024-02-27 13:56:34,588][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46700] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.67645
[2024-02-27 13:56:34,588][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46700] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50111
[2024-02-27 13:56:55,598][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46750] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50613
[2024-02-27 13:56:55,598][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46750] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50133
[2024-02-27 13:57:16,922][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46800] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.55241
[2024-02-27 13:57:16,922][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46800] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50115
[2024-02-27 13:57:37,465][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46850] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50071
[2024-02-27 13:57:37,465][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46850] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.54972
[2024-02-27 13:57:58,317][PyLogger][INFO]: Rank[0]: Epoch[484/500], iter[46900] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50137
[2024-02-27 13:57:58,317][PyLogger][INFO]: Rank[1]: Epoch[484/500], iter[46900] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 1.11428
[2024-02-27 13:58:19,951][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[46950] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.92210
[2024-02-27 13:58:19,951][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[46950] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50064
[2024-02-27 13:58:40,291][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[47000] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 1.86590
[2024-02-27 13:58:40,291][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[47000] - train_accuracy: 0.19801 - val_accuracy: 0.21290 - train_loss: 2.57122 - val_loss: 2.54880 - loss: 0.50086
[2024-02-27 13:59:22,280][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47050] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.98295
[2024-02-27 13:59:22,280][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47050] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50117
[2024-02-27 13:59:43,434][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47100] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50064
[2024-02-27 13:59:43,435][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47100] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50083
[2024-02-27 14:00:05,215][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47150] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.51447
[2024-02-27 14:00:05,215][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47150] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 1.47630
[2024-02-27 14:00:25,748][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47200] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50096
[2024-02-27 14:00:25,748][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47200] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50111
[2024-02-27 14:00:46,407][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47250] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50087
[2024-02-27 14:00:46,407][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47250] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.54818
[2024-02-27 14:01:06,063][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47300] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50072
[2024-02-27 14:01:06,063][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47300] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.52816
[2024-02-27 14:01:27,401][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47350] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50066
[2024-02-27 14:01:27,401][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47350] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50070
[2024-02-27 14:01:48,554][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47400] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 1.86009
[2024-02-27 14:01:48,554][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47400] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50070
[2024-02-27 14:02:09,819][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47450] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50087
[2024-02-27 14:02:09,819][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47450] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50068
[2024-02-27 14:02:31,164][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47500] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.62896
[2024-02-27 14:02:31,165][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47500] - train_accuracy: 0.28677 - val_accuracy: 0.23700 - train_loss: 2.55411 - val_loss: 2.86223 - loss: 0.50129
[2024-02-27 14:03:12,877][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47550] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50082
[2024-02-27 14:03:12,877][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47550] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50110
[2024-02-27 14:03:34,372][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47600] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50103
[2024-02-27 14:03:34,372][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47600] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50092
[2024-02-27 14:03:54,560][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47650] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.67467
[2024-02-27 14:03:54,560][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47650] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50173
[2024-02-27 14:04:15,141][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47700] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 1.23149
[2024-02-27 14:04:15,141][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47700] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50185
[2024-02-27 14:04:36,545][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47750] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.78366
[2024-02-27 14:04:36,545][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47750] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.51887
[2024-02-27 14:04:57,069][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47800] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50910
[2024-02-27 14:04:57,069][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47800] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.52006
[2024-02-27 14:05:18,846][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47850] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50070
[2024-02-27 14:05:18,846][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47850] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.52702
[2024-02-27 14:05:39,918][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47900] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50270
[2024-02-27 14:05:39,918][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47900] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50060
[2024-02-27 14:06:00,645][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[47950] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50083
[2024-02-27 14:06:00,645][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[47950] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50368
[2024-02-27 14:06:20,116][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[48000] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.54552
[2024-02-27 14:06:20,116][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[48000] - train_accuracy: 0.19267 - val_accuracy: 0.33330 - train_loss: 2.74392 - val_loss: 2.16609 - loss: 0.50125
[2024-02-27 14:07:02,014][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48050] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50088
[2024-02-27 14:07:02,014][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48050] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50876
[2024-02-27 14:07:22,400][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48100] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.51340
[2024-02-27 14:07:22,400][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48100] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50101
[2024-02-27 14:07:43,968][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48150] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.52133
[2024-02-27 14:07:43,968][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48150] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 1.00045
[2024-02-27 14:08:05,024][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48200] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50136
[2024-02-27 14:08:05,024][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48200] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50072
[2024-02-27 14:08:26,655][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48250] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50083
[2024-02-27 14:08:26,655][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48250] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50092
[2024-02-27 14:08:47,177][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48300] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.93815
[2024-02-27 14:08:47,177][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48300] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50108
[2024-02-27 14:09:07,647][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48350] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50080
[2024-02-27 14:09:07,647][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48350] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50166
[2024-02-27 14:09:27,793][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48400] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 1.36679
[2024-02-27 14:09:27,793][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48400] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 1.17092
[2024-02-27 14:09:49,706][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48450] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 1.41107
[2024-02-27 14:09:49,706][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48450] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.50094
[2024-02-27 14:10:09,829][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48500] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.94577
[2024-02-27 14:10:09,830][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48500] - train_accuracy: 0.24209 - val_accuracy: 0.24970 - train_loss: 2.66484 - val_loss: 2.84353 - loss: 0.94572
Files already downloaded and verified
Files already downloaded and verified
2024-02-27 14:10:32,968 ignite.distributed.launcher.Parallel INFO: End of run
2024-02-27 14:10:37,366 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:10:37,366 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:10:37,366 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1540f1f523e0>' in 2 processes
2024-02-27 14:10:45,712 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:10:46,130 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149051b1b110>}
[2024-02-27 14:10:46,737][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:10:46,737][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:10:46,737][PyLogger][INFO]: World size: 2
[2024-02-27 14:10:46,741][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:10:46,741][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:10:46,741][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:10:46,741][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:10:46,742][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:10:46,742][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:10:46,742][PyLogger][INFO]: World size: 2
[2024-02-27 14:10:50,353][PyLogger][INFO]: Rank[1]: val_accuracy: 0.11930
[2024-02-27 14:10:50,353][PyLogger][INFO]: Rank[0]: val_accuracy: 0.11930
2024-02-27 14:10:51,889 ignite.distributed.launcher.Parallel INFO: End of run
new_size=2 done.
2024-02-27 14:10:57,583 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:10:57,583 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:10:57,583 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15074faf63e0>' in 2 processes
2024-02-27 14:11:05,531 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:11:05,936 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14853ba0ce30>}
[2024-02-27 14:11:06,048][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:06,049][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:06,049][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:06,055][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:11:06,055][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:11:06,055][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:06,055][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:11:06,056][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:11:06,056][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:06,056][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:09,499][PyLogger][INFO]: Rank[1]: val_accuracy: 0.25200
[2024-02-27 14:11:09,499][PyLogger][INFO]: Rank[0]: val_accuracy: 0.25200
2024-02-27 14:11:10,533 ignite.distributed.launcher.Parallel INFO: End of run
new_size=3 done.
2024-02-27 14:11:14,176 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:11:14,176 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:11:14,176 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14b0e160a3e0>' in 2 processes
2024-02-27 14:11:22,078 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:11:22,475 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14fcad156c90>}
[2024-02-27 14:11:22,591][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:22,591][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:22,591][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:22,593][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:11:22,593][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:11:22,593][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:22,593][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:11:22,594][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:11:22,594][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:22,594][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:25,968][PyLogger][INFO]: Rank[1]: val_accuracy: 0.47500
[2024-02-27 14:11:25,968][PyLogger][INFO]: Rank[0]: val_accuracy: 0.47500
2024-02-27 14:11:27,531 ignite.distributed.launcher.Parallel INFO: End of run
new_size=4 done.
2024-02-27 14:11:31,177 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:11:31,177 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:11:31,177 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14ca555123e0>' in 2 processes
2024-02-27 14:11:39,161 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:11:39,557 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f016e7cb30>}
[2024-02-27 14:11:39,677][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:11:39,677][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:11:39,677][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:39,677][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:11:39,678][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:11:39,678][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:39,678][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:39,678][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:39,679][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:39,679][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:43,368][PyLogger][INFO]: Rank[0]: val_accuracy: 0.56860
[2024-02-27 14:11:43,368][PyLogger][INFO]: Rank[1]: val_accuracy: 0.56860
2024-02-27 14:11:44,947 ignite.distributed.launcher.Parallel INFO: End of run
new_size=5 done.
2024-02-27 14:11:48,929 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:11:48,929 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:11:48,929 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1487524ba3e0>' in 2 processes
2024-02-27 14:11:56,871 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:11:57,283 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1531e6515910>}
[2024-02-27 14:11:57,400][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:11:57,400][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:11:57,400][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:57,400][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:11:57,401][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:11:57,401][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:57,401][PyLogger][INFO]: World size: 2
[2024-02-27 14:11:57,405][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:11:57,405][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:11:57,405][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:01,059][PyLogger][INFO]: Rank[0]: val_accuracy: 0.54430
[2024-02-27 14:12:01,059][PyLogger][INFO]: Rank[1]: val_accuracy: 0.54430
2024-02-27 14:12:02,526 ignite.distributed.launcher.Parallel INFO: End of run
new_size=6 done.
2024-02-27 14:12:06,149 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:12:06,149 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:12:06,149 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14afab9da3e0>' in 2 processes
2024-02-27 14:12:14,178 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:12:14,577 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154c58330140>}
[2024-02-27 14:12:14,694][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:12:14,694][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:12:14,694][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:14,694][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:12:14,695][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:12:14,695][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:14,695][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:14,696][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:14,697][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:14,697][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:18,206][PyLogger][INFO]: Rank[0]: val_accuracy: 0.48690
[2024-02-27 14:12:18,206][PyLogger][INFO]: Rank[1]: val_accuracy: 0.48690
2024-02-27 14:12:19,688 ignite.distributed.launcher.Parallel INFO: End of run
new_size=7 done.
2024-02-27 14:12:23,351 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:12:23,351 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:12:23,351 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c1aeb523e0>' in 2 processes
2024-02-27 14:12:31,509 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:12:31,902 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f405cdddc0>}
[2024-02-27 14:12:32,018][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:12:32,018][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:12:32,018][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:32,018][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:12:32,019][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:12:32,019][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:32,019][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:32,021][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:32,021][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:32,021][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:35,521][PyLogger][INFO]: Rank[0]: val_accuracy: 0.42090
[2024-02-27 14:12:35,521][PyLogger][INFO]: Rank[1]: val_accuracy: 0.42090
2024-02-27 14:12:36,554 ignite.distributed.launcher.Parallel INFO: End of run
new_size=8 done.
2024-02-27 14:12:40,231 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:12:40,231 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:12:40,231 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x153d93c023e0>' in 2 processes
2024-02-27 14:12:47,024 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:12:47,440 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d7a2fb0830>}
[2024-02-27 14:12:47,554][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:12:47,554][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:12:47,554][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:47,554][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:12:47,555][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:12:47,555][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:47,555][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:47,558][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:12:47,558][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:12:47,558][PyLogger][INFO]: World size: 2
[2024-02-27 14:12:51,170][PyLogger][INFO]: Rank[0]: val_accuracy: 0.35200
[2024-02-27 14:12:51,170][PyLogger][INFO]: Rank[1]: val_accuracy: 0.35200
2024-02-27 14:12:52,612 ignite.distributed.launcher.Parallel INFO: End of run
new_size=9 done.
2024-02-27 14:12:56,663 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:12:56,663 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:12:56,663 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x149b667d63e0>' in 2 processes
2024-02-27 14:13:03,809 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:13:04,215 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14fa17794680>}
[2024-02-27 14:13:04,326][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:13:04,326][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:13:04,327][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:04,327][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:13:04,327][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:13:04,328][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:04,328][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:04,333][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:04,333][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:04,333][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:08,078][PyLogger][INFO]: Rank[1]: val_accuracy: 0.28810
[2024-02-27 14:13:08,078][PyLogger][INFO]: Rank[0]: val_accuracy: 0.28810
2024-02-27 14:13:09,519 ignite.distributed.launcher.Parallel INFO: End of run
new_size=10 done.
2024-02-27 14:13:13,193 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:13:13,193 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:13:13,193 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e4f9f5a3e0>' in 2 processes
2024-02-27 14:13:20,032 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:13:20,443 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1553518ec440>}
[2024-02-27 14:13:20,560][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:20,560][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:20,560][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:20,561][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:13:20,561][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:13:20,561][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:20,561][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:13:20,562][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:13:20,562][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:20,562][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:24,234][PyLogger][INFO]: Rank[0]: val_accuracy: 0.22050
[2024-02-27 14:13:24,234][PyLogger][INFO]: Rank[1]: val_accuracy: 0.22050
2024-02-27 14:13:25,663 ignite.distributed.launcher.Parallel INFO: End of run
new_size=11 done.
2024-02-27 14:13:29,750 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:13:29,750 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:13:29,750 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c867df23e0>' in 2 processes
2024-02-27 14:13:37,729 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:13:38,137 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14fa3e72cd70>}
[2024-02-27 14:13:38,249][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:38,249][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:38,249][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:38,250][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:13:38,250][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:13:38,250][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:38,250][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:13:38,251][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:13:38,251][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:38,251][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:41,928][PyLogger][INFO]: Rank[0]: val_accuracy: 0.18360
[2024-02-27 14:13:41,928][PyLogger][INFO]: Rank[1]: val_accuracy: 0.18360
2024-02-27 14:13:43,361 ignite.distributed.launcher.Parallel INFO: End of run
new_size=12 done.
2024-02-27 14:13:47,009 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:13:47,009 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:13:47,009 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14711393a3e0>' in 2 processes
2024-02-27 14:13:54,822 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:13:55,216 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d2463582c0>}
[2024-02-27 14:13:55,333][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:13:55,333][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:13:55,333][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:55,333][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:13:55,334][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:13:55,334][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:55,334][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:55,339][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:13:55,339][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:13:55,339][PyLogger][INFO]: World size: 2
[2024-02-27 14:13:59,015][PyLogger][INFO]: Rank[1]: val_accuracy: 0.13420
[2024-02-27 14:13:59,015][PyLogger][INFO]: Rank[0]: val_accuracy: 0.13420
2024-02-27 14:14:00,064 ignite.distributed.launcher.Parallel INFO: End of run
new_size=13 done.
2024-02-27 14:14:04,014 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:14:04,014 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:14:04,014 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154c5e4a63e0>' in 2 processes
2024-02-27 14:14:12,714 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:14:13,160 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148e0df1c5c0>}
[2024-02-27 14:14:13,273][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:13,273][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:13,273][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:13,280][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:14:13,280][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:14:13,280][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:13,280][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:14:13,281][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:14:13,281][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:13,281][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:17,318][PyLogger][INFO]: Rank[0]: val_accuracy: 0.11420
[2024-02-27 14:14:17,318][PyLogger][INFO]: Rank[1]: val_accuracy: 0.11420
2024-02-27 14:14:18,770 ignite.distributed.launcher.Parallel INFO: End of run
new_size=14 done.
2024-02-27 14:14:22,527 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:14:22,527 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:14:22,527 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14aa9612a3e0>' in 2 processes
2024-02-27 14:14:30,516 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:14:30,916 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154dddf52d20>}
[2024-02-27 14:14:31,034][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:14:31,034][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:14:31,034][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:31,034][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:14:31,036][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:14:31,036][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:31,036][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:31,036][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:31,036][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:31,036][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:34,859][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10580
[2024-02-27 14:14:34,859][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10580
2024-02-27 14:14:36,356 ignite.distributed.launcher.Parallel INFO: End of run
new_size=15 done.
2024-02-27 14:14:39,834 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:14:39,834 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:14:39,834 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14cea4d0e3e0>' in 2 processes
2024-02-27 14:14:46,714 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:14:47,139 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x153e59dbc380>}
[2024-02-27 14:14:47,254][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:14:47,254][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:14:47,254][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:47,254][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:14:47,255][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:14:47,255][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:47,255][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:47,259][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:14:47,259][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:14:47,259][PyLogger][INFO]: World size: 2
[2024-02-27 14:14:51,303][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10240
[2024-02-27 14:14:51,303][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10240
2024-02-27 14:14:52,717 ignite.distributed.launcher.Parallel INFO: End of run
new_size=16 done.
2024-02-27 14:14:56,474 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:14:56,474 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:14:56,474 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154f3ba523e0>' in 2 processes
2024-02-27 14:15:03,677 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:15:04,078 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d5e4f4c230>}
[2024-02-27 14:15:04,191][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:15:04,191][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:15:04,191][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:04,192][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:15:04,192][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:15:04,193][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:04,193][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:04,195][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:04,195][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:04,195][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:08,226][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10090
[2024-02-27 14:15:08,226][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10090
2024-02-27 14:15:09,640 ignite.distributed.launcher.Parallel INFO: End of run
new_size=17 done.
2024-02-27 14:15:13,608 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:15:13,608 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:15:13,608 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14ae4b0ea3e0>' in 2 processes
2024-02-27 14:15:20,824 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:15:21,237 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154d8d554740>}
[2024-02-27 14:15:21,350][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:21,350][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:21,350][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:21,353][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:15:21,353][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:15:21,353][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:21,353][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:15:21,354][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:15:21,354][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:21,354][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:25,383][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10050
[2024-02-27 14:15:25,383][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10050
2024-02-27 14:15:26,848 ignite.distributed.launcher.Parallel INFO: End of run
new_size=18 done.
2024-02-27 14:15:30,407 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:15:30,407 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:15:30,407 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x153beb0ba3e0>' in 2 processes
2024-02-27 14:15:38,706 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:15:39,122 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f30bf08b60>}
[2024-02-27 14:15:39,237][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:15:39,237][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:15:39,237][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:39,237][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:15:39,238][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:15:39,238][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:39,238][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:39,240][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:39,240][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:39,240][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:43,332][PyLogger][INFO]: Rank[1]: val_accuracy: 0.09990
[2024-02-27 14:15:43,332][PyLogger][INFO]: Rank[0]: val_accuracy: 0.09990
2024-02-27 14:15:44,807 ignite.distributed.launcher.Parallel INFO: End of run
new_size=19 done.
2024-02-27 14:15:48,419 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:15:48,419 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:15:48,419 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f6953b63e0>' in 2 processes
2024-02-27 14:15:55,300 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:15:55,698 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f328b00800>}
[2024-02-27 14:15:55,811][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:55,811][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:55,811][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:55,815][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:15:55,815][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:15:55,815][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:15:55,815][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:15:55,816][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:15:55,816][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:15:55,816][PyLogger][INFO]: World size: 2
[2024-02-27 14:15:59,935][PyLogger][INFO]: Rank[1]: val_accuracy: 0.09980
[2024-02-27 14:15:59,935][PyLogger][INFO]: Rank[0]: val_accuracy: 0.09980
2024-02-27 14:16:01,381 ignite.distributed.launcher.Parallel INFO: End of run
new_size=20 done.
2024-02-27 14:16:05,229 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:16:05,229 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:16:05,229 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14a565b5a3e0>' in 2 processes
2024-02-27 14:16:12,448 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:16:12,851 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1494ebabedb0>}
[2024-02-27 14:16:12,970][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:16:12,970][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:16:12,970][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:12,970][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:16:12,971][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:16:12,972][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:12,972][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:12,976][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:12,977][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:12,977][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:17,359][PyLogger][INFO]: Rank[0]: val_accuracy: 0.09980
[2024-02-27 14:16:17,359][PyLogger][INFO]: Rank[1]: val_accuracy: 0.09980
2024-02-27 14:16:18,851 ignite.distributed.launcher.Parallel INFO: End of run
new_size=21 done.
2024-02-27 14:16:23,071 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:16:23,071 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:16:23,071 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x151f9f0be3e0>' in 2 processes
2024-02-27 14:16:30,022 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:16:30,437 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14608e4c4c50>}
[2024-02-27 14:16:30,550][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:16:30,550][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:16:30,550][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:30,550][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:16:30,551][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:16:30,551][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:30,551][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:30,552][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:30,552][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:30,552][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:34,762][PyLogger][INFO]: Rank[1]: val_accuracy: 0.09990
[2024-02-27 14:16:34,762][PyLogger][INFO]: Rank[0]: val_accuracy: 0.09990
2024-02-27 14:16:36,236 ignite.distributed.launcher.Parallel INFO: End of run
new_size=22 done.
2024-02-27 14:16:39,867 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:16:39,867 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:16:39,867 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150fa831e3e0>' in 2 processes
2024-02-27 14:16:47,357 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:16:47,756 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1517b4986ae0>}
[2024-02-27 14:16:47,869][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:47,869][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:47,869][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:47,881][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:16:47,882][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:16:47,882][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:16:47,882][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:16:47,883][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:16:47,883][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:16:47,883][PyLogger][INFO]: World size: 2
[2024-02-27 14:16:52,335][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:16:52,335][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:16:53,371 ignite.distributed.launcher.Parallel INFO: End of run
new_size=23 done.
2024-02-27 14:16:56,986 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:16:56,986 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:16:56,986 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15167c57e3e0>' in 2 processes
2024-02-27 14:17:03,888 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:17:04,283 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149aa5ae1c70>}
[2024-02-27 14:17:04,395][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:04,396][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:04,396][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:04,397][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:17:04,397][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:17:04,397][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:04,397][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:17:04,398][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:17:04,398][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:04,398][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:08,796][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:17:08,796][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:17:10,251 ignite.distributed.launcher.Parallel INFO: End of run
new_size=24 done.
2024-02-27 14:17:13,987 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:17:13,987 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:17:13,987 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1476327f63e0>' in 2 processes
2024-02-27 14:17:21,963 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:17:22,362 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b34c66c8c0>}
[2024-02-27 14:17:22,480][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:22,480][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:22,480][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:22,487][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:17:22,487][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:17:22,487][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:22,487][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:17:22,488][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:17:22,488][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:22,488][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:27,227][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:17:27,227][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:17:28,747 ignite.distributed.launcher.Parallel INFO: End of run
new_size=25 done.
2024-02-27 14:17:32,834 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:17:32,834 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:17:32,834 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1509a21923e0>' in 2 processes
2024-02-27 14:17:39,764 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:17:40,184 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154365ad8e60>}
[2024-02-27 14:17:40,300][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:17:40,300][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:17:40,300][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:40,300][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:17:40,301][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:17:40,301][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:40,301][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:40,303][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:40,303][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:40,303][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:44,950][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:17:44,950][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:17:46,412 ignite.distributed.launcher.Parallel INFO: End of run
new_size=26 done.
2024-02-27 14:17:49,943 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:17:49,943 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:17:49,943 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1553798b23e0>' in 2 processes
2024-02-27 14:17:56,840 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:17:57,283 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1487ca0a88c0>}
[2024-02-27 14:17:57,401][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:57,401][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:57,401][PyLogger][INFO]: World size: 2
[2024-02-27 14:17:57,403][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:17:57,403][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:17:57,403][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:17:57,403][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:17:57,404][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:17:57,404][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:17:57,404][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:02,296][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:18:02,296][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:18:03,782 ignite.distributed.launcher.Parallel INFO: End of run
new_size=27 done.
2024-02-27 14:18:07,571 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:18:07,571 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:18:07,571 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1546ed3023e0>' in 2 processes
2024-02-27 14:18:15,454 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:18:15,860 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b6e55f9760>}
[2024-02-27 14:18:15,977][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:15,977][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:15,977][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:15,978][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:18:15,978][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:18:15,978][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:15,978][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:18:15,979][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:18:15,979][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:15,979][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:20,797][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:18:20,797][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:18:22,326 ignite.distributed.launcher.Parallel INFO: End of run
new_size=28 done.
2024-02-27 14:18:25,921 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:18:25,921 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:18:25,921 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1523e45da3e0>' in 2 processes
2024-02-27 14:18:32,799 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:18:33,207 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x153242a05580>}
[2024-02-27 14:18:33,323][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:33,324][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:33,324][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:33,326][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:18:33,326][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:18:33,326][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:33,326][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:18:33,327][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:18:33,327][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:33,327][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:38,174][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:18:38,174][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:18:39,246 ignite.distributed.launcher.Parallel INFO: End of run
new_size=29 done.
2024-02-27 14:18:43,333 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:18:43,333 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:18:43,333 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15312c54a3e0>' in 2 processes
2024-02-27 14:18:50,437 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:18:50,860 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a0c80d0440>}
[2024-02-27 14:18:50,975][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:50,975][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:50,975][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:50,976][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:18:50,976][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:18:50,976][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:18:50,976][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:18:50,977][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:18:50,977][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:18:50,977][PyLogger][INFO]: World size: 2
[2024-02-27 14:18:55,919][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:18:55,919][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:18:57,408 ignite.distributed.launcher.Parallel INFO: End of run
new_size=30 done.
2024-02-27 14:19:00,980 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:19:00,980 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:19:00,980 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14fd7a7e23e0>' in 2 processes
2024-02-27 14:19:08,801 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:19:09,199 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1550c07dc980>}
[2024-02-27 14:19:09,316][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:19:09,316][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:19:09,317][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:09,317][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:19:09,317][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:19:09,318][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:09,318][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:09,318][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:09,318][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:09,318][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:14,577][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:19:14,577][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:19:16,099 ignite.distributed.launcher.Parallel INFO: End of run
new_size=31 done.
2024-02-27 14:19:19,946 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:19:19,946 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:19:19,946 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14a35d4263e0>' in 2 processes
2024-02-27 14:19:26,993 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:19:27,394 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1454d4a701d0>}
[2024-02-27 14:19:27,507][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:27,507][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:27,507][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:27,512][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:19:27,512][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:19:27,513][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:27,513][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:19:27,513][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:19:27,514][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:27,514][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:32,631][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:19:32,631][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:19:34,123 ignite.distributed.launcher.Parallel INFO: End of run
new_size=32 done.
2024-02-27 14:19:37,827 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:19:37,828 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:19:37,828 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x149c309423e0>' in 2 processes
2024-02-27 14:19:45,742 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:19:46,148 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149726c80c80>}
[2024-02-27 14:19:46,260][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:46,260][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:46,260][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:46,262][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:19:46,262][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:19:46,262][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:19:46,262][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:19:46,263][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:19:46,263][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:19:46,263][PyLogger][INFO]: World size: 2
[2024-02-27 14:19:51,454][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:19:51,454][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:19:52,969 ignite.distributed.launcher.Parallel INFO: End of run
new_size=33 done.
2024-02-27 14:19:57,115 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:19:57,115 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:19:57,115 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1474cb2e23e0>' in 2 processes
2024-02-27 14:20:05,039 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:20:05,442 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148d58d64b30>}
[2024-02-27 14:20:05,557][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:05,557][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:05,557][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:05,560][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:20:05,560][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:20:05,560][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:05,560][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:20:05,561][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:20:05,561][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:05,561][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:10,858][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
[2024-02-27 14:20:10,858][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
2024-02-27 14:20:12,393 ignite.distributed.launcher.Parallel INFO: End of run
new_size=34 done.
2024-02-27 14:20:16,106 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:20:16,106 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:20:16,106 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x147779cf63e0>' in 2 processes
2024-02-27 14:20:23,024 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:20:23,430 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1520992430e0>}
[2024-02-27 14:20:23,543][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:20:23,543][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:20:23,543][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:23,543][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:20:23,544][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:20:23,545][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:23,545][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:23,547][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:23,547][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:23,547][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:28,715][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:20:28,715][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:20:30,234 ignite.distributed.launcher.Parallel INFO: End of run
new_size=35 done.
2024-02-27 14:20:33,908 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:20:33,908 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:20:33,908 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x149e35dd23e0>' in 2 processes
2024-02-27 14:20:41,985 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:20:42,394 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14dc13671a00>}
[2024-02-27 14:20:42,508][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:20:42,508][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:20:42,508][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:42,508][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:20:42,508][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:20:42,509][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:42,509][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:42,509][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:20:42,509][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:20:42,509][PyLogger][INFO]: World size: 2
[2024-02-27 14:20:47,679][PyLogger][INFO]: Rank[1]: val_accuracy: 0.10000
[2024-02-27 14:20:47,679][PyLogger][INFO]: Rank[0]: val_accuracy: 0.10000
2024-02-27 14:20:49,203 ignite.distributed.launcher.Parallel INFO: End of run
new_size=36 done.
2024-02-27 14:20:53,198 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 14:20:53,198 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 14:20:53,198 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x14848d3853a0>' in 2 processes
2024-02-27 14:21:00,457 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 14:21:01,305 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x150b2453ae40>}
2024-02-27 14:21:01,654 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x150b22ed98e0>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-27 14:21:01,660][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 14:21:01,660][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:21:01,660][PyLogger][INFO]: World size: 2
[2024-02-27 14:21:01,665][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 14:21:01,665][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 14:21:01,665][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 14:21:01,665][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 14:21:01,666][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 14:21:01,666][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 14:21:01,666][PyLogger][INFO]: World size: 2
[2024-02-27 14:21:29,730][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 5.10226
[2024-02-27 14:21:29,730][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 2.35529
[2024-02-27 14:21:56,705][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.30812
[2024-02-27 14:21:56,705][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.24277
[2024-02-27 14:22:23,054][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.15440
[2024-02-27 14:22:23,054][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.15661
[2024-02-27 14:22:49,885][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.11366
[2024-02-27 14:22:49,885][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.04006
[2024-02-27 14:23:16,466][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 2.03717
[2024-02-27 14:23:16,466][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.11357
[2024-02-27 14:23:43,185][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 1.96720
[2024-02-27 14:23:43,185][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.05422
[2024-02-27 14:24:09,436][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 1.97933
[2024-02-27 14:24:09,436][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 1.96867
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-27 14:24:36,161][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 1.89401
[2024-02-27 14:24:36,161][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 1.99099
[2024-02-27 14:25:02,398][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 2.04753
[2024-02-27 14:25:02,398][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 1.94950
[2024-02-27 14:25:56,769][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.93521
[2024-02-27 14:25:56,770][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.94632
[2024-02-27 14:26:23,012][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.85089
[2024-02-27 14:26:23,012][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.84938
[2024-02-27 14:26:49,921][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.86222
[2024-02-27 14:26:49,921][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.81697
[2024-02-27 14:27:16,255][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.75039
[2024-02-27 14:27:16,255][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.89591
[2024-02-27 14:27:43,236][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.73006
[2024-02-27 14:27:43,236][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.88712
[2024-02-27 14:28:09,572][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.61385
[2024-02-27 14:28:09,572][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.64786
[2024-02-27 14:28:36,295][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.65124
[2024-02-27 14:28:36,295][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.65577
[2024-02-27 14:29:02,787][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.59161
[2024-02-27 14:29:02,787][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 2.20951
[2024-02-27 14:29:29,538][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.65429
[2024-02-27 14:29:29,538][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.61191
[2024-02-27 14:29:55,874][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.64739
[2024-02-27 14:29:55,874][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.35301 - val_accuracy: 0.35590 - train_loss: 1.90623 - val_loss: 1.91508 - loss: 1.60532
[2024-02-27 14:30:50,492][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.54235
[2024-02-27 14:30:50,492][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.68061
[2024-02-27 14:31:16,755][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.73444
[2024-02-27 14:31:16,755][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.53069
[2024-02-27 14:31:43,387][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.51108
[2024-02-27 14:31:43,387][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.52856
[2024-02-27 14:32:09,758][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.44501
[2024-02-27 14:32:09,758][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.50038
[2024-02-27 14:32:36,531][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.52460
[2024-02-27 14:32:36,531][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.51901
[2024-02-27 14:33:02,974][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.56636
[2024-02-27 14:33:02,974][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.49909
[2024-02-27 14:33:29,865][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.45382
[2024-02-27 14:33:29,866][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.47983
[2024-02-27 14:33:56,353][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.38621
[2024-02-27 14:33:56,353][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.36163
[2024-02-27 14:34:23,221][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.47527
[2024-02-27 14:34:23,221][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.44757
[2024-02-27 14:34:49,556][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.55962
[2024-02-27 14:34:49,556][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.44322 - val_accuracy: 0.43760 - train_loss: 1.73702 - val_loss: 1.76637 - loss: 1.43659
[2024-02-27 14:35:45,602][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.35659
[2024-02-27 14:35:45,602][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.35262
[2024-02-27 14:36:11,884][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.42338
[2024-02-27 14:36:11,884][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 2.17629
[2024-02-27 14:36:38,740][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.43787
[2024-02-27 14:36:38,740][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.35200
[2024-02-27 14:37:05,486][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.41465
[2024-02-27 14:37:05,486][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.31672
[2024-02-27 14:37:32,008][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.37798
[2024-02-27 14:37:32,008][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.45170
[2024-02-27 14:37:58,712][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.25536
[2024-02-27 14:37:58,713][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.42792
[2024-02-27 14:38:25,058][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.34724
[2024-02-27 14:38:25,058][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.93590
[2024-02-27 14:38:51,830][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.25630
[2024-02-27 14:38:51,830][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.22570
[2024-02-27 14:39:18,126][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.29836
[2024-02-27 14:39:18,126][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.50280 - val_accuracy: 0.53440 - train_loss: 1.64819 - val_loss: 1.56794 - loss: 1.25178
[2024-02-27 14:40:13,917][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.19669
[2024-02-27 14:40:13,917][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.26354
[2024-02-27 14:40:40,169][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.15222
[2024-02-27 14:40:40,169][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.29569
[2024-02-27 14:41:07,053][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.22507
[2024-02-27 14:41:07,053][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.59923
[2024-02-27 14:41:33,337][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.19994
[2024-02-27 14:41:33,337][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.22879
[2024-02-27 14:42:00,080][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.23292
[2024-02-27 14:42:00,080][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.16577
[2024-02-27 14:42:26,451][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.21285
[2024-02-27 14:42:26,451][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.50097
[2024-02-27 14:42:53,270][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.63846
[2024-02-27 14:42:53,270][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.14325
[2024-02-27 14:43:19,572][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.20885
[2024-02-27 14:43:19,572][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.24097
[2024-02-27 14:43:46,235][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.22294
[2024-02-27 14:43:46,235][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.21347
[2024-02-27 14:44:12,581][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.24832
[2024-02-27 14:44:12,581][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.59154 - val_accuracy: 0.56220 - train_loss: 1.43940 - val_loss: 1.47901 - loss: 1.12977
[2024-02-27 14:45:08,373][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.20610
[2024-02-27 14:45:08,373][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.06566
[2024-02-27 14:45:34,633][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.14946
[2024-02-27 14:45:34,633][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.19113
[2024-02-27 14:46:01,402][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.19587
[2024-02-27 14:46:01,402][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.64223
[2024-02-27 14:46:27,760][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.82830
[2024-02-27 14:46:27,760][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.05692
[2024-02-27 14:46:54,598][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.04992
[2024-02-27 14:46:54,599][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.15165
[2024-02-27 14:47:21,141][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.23900
[2024-02-27 14:47:21,141][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.04396
[2024-02-27 14:47:47,947][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.07458
[2024-02-27 14:47:47,947][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.85065
[2024-02-27 14:48:14,262][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.18526
[2024-02-27 14:48:14,262][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.12382
[2024-02-27 14:48:40,901][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.07156
[2024-02-27 14:48:40,901][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.84143
[2024-02-27 14:49:07,216][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.04199
[2024-02-27 14:49:07,216][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.62738 - val_accuracy: 0.61640 - train_loss: 1.37222 - val_loss: 1.43146 - loss: 1.13522
[2024-02-27 14:50:01,532][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.07860
[2024-02-27 14:50:01,532][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.11761
[2024-02-27 14:50:27,782][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.33299
[2024-02-27 14:50:27,782][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.97001
[2024-02-27 14:50:54,454][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.17011
[2024-02-27 14:50:54,454][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.99572
[2024-02-27 14:51:20,790][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.23463
[2024-02-27 14:51:20,790][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.06741
[2024-02-27 14:51:47,527][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.00380
[2024-02-27 14:51:47,527][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.05976
[2024-02-27 14:52:13,916][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 1.82657
[2024-02-27 14:52:13,916][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.99768
[2024-02-27 14:52:40,673][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.97547
[2024-02-27 14:52:40,673][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.97427
[2024-02-27 14:53:07,480][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.99888
[2024-02-27 14:53:07,480][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.93206
[2024-02-27 14:53:33,890][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.98132
[2024-02-27 14:53:33,890][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.65265 - val_accuracy: 0.64390 - train_loss: 1.32687 - val_loss: 1.32685 - loss: 0.94737
[2024-02-27 14:54:28,092][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.93088
[2024-02-27 14:54:28,093][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.97927
[2024-02-27 14:54:54,455][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.62200
[2024-02-27 14:54:54,456][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.14584
[2024-02-27 14:55:21,271][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.95727
[2024-02-27 14:55:21,271][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.94513
[2024-02-27 14:55:47,559][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.02308
[2024-02-27 14:55:47,559][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.54569
[2024-02-27 14:56:14,344][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.03221
[2024-02-27 14:56:14,344][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.93130
[2024-02-27 14:56:40,801][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.89847
[2024-02-27 14:56:40,802][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.94316
[2024-02-27 14:57:07,719][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.91924
[2024-02-27 14:57:07,719][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.46193
[2024-02-27 14:57:34,060][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.68451
[2024-02-27 14:57:34,060][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.87122
[2024-02-27 14:58:01,002][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.92823
[2024-02-27 14:58:01,002][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.01988
[2024-02-27 14:58:27,396][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 0.92303
[2024-02-27 14:58:27,396][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.65009 - val_accuracy: 0.67620 - train_loss: 1.34217 - val_loss: 1.25450 - loss: 1.79865
[2024-02-27 14:59:21,468][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.93229
[2024-02-27 14:59:21,468][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.87401
[2024-02-27 14:59:47,883][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 1.02633
[2024-02-27 14:59:47,883][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 1.47657
[2024-02-27 15:00:14,713][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.84770
[2024-02-27 15:00:14,713][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 1.59985
[2024-02-27 15:00:40,954][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 1.02717
[2024-02-27 15:00:40,954][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.82793
[2024-02-27 15:01:07,827][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.91313
[2024-02-27 15:01:07,827][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.88915
[2024-02-27 15:01:34,226][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.84114
[2024-02-27 15:01:34,226][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.86107
[2024-02-27 15:02:01,035][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.86771
[2024-02-27 15:02:01,036][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.89533
[2024-02-27 15:02:27,409][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.80800
[2024-02-27 15:02:27,409][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.82736
[2024-02-27 15:02:54,395][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.89208
[2024-02-27 15:02:54,395][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 1.58028
[2024-02-27 15:03:20,762][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.85434
[2024-02-27 15:03:20,762][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.68043 - val_accuracy: 0.63040 - train_loss: 1.47935 - val_loss: 1.50160 - loss: 0.80052
[2024-02-27 15:04:16,008][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.81477
[2024-02-27 15:04:16,008][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.79712
[2024-02-27 15:04:42,287][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.42744
[2024-02-27 15:04:42,287][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.88672
[2024-02-27 15:05:09,164][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.31086
[2024-02-27 15:05:09,164][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.83676
[2024-02-27 15:05:35,512][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.87694
[2024-02-27 15:05:35,512][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.82946
[2024-02-27 15:06:02,286][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.81985
[2024-02-27 15:06:02,286][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.25421
[2024-02-27 15:06:28,602][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.04963
[2024-02-27 15:06:28,602][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.91456
[2024-02-27 15:06:55,418][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.92253
[2024-02-27 15:06:55,418][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.81089
[2024-02-27 15:07:21,722][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.83312
[2024-02-27 15:07:21,722][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.61248
[2024-02-27 15:07:48,655][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 1.49247
[2024-02-27 15:07:48,655][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.98913
[2024-02-27 15:08:14,977][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.78329
[2024-02-27 15:08:14,977][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.71996 - val_accuracy: 0.69600 - train_loss: 1.17133 - val_loss: 1.23081 - loss: 0.92288
[2024-02-27 15:09:09,282][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.78835
[2024-02-27 15:09:09,282][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.76767
[2024-02-27 15:09:36,021][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.81346
[2024-02-27 15:09:36,021][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.76899
[2024-02-27 15:10:02,398][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.79492
[2024-02-27 15:10:02,398][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.74822
[2024-02-27 15:10:29,185][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.74478
[2024-02-27 15:10:29,185][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.82957
[2024-02-27 15:10:55,515][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.76045
[2024-02-27 15:10:55,515][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.75896
[2024-02-27 15:11:22,313][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.99514
[2024-02-27 15:11:22,313][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.77543
[2024-02-27 15:11:48,716][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.79665
[2024-02-27 15:11:48,716][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.92464
[2024-02-27 15:12:15,711][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.82410
[2024-02-27 15:12:15,711][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.78646
[2024-02-27 15:12:41,934][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 0.79662
[2024-02-27 15:12:41,935][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.72914 - val_accuracy: 0.71070 - train_loss: 1.17692 - val_loss: 1.21481 - loss: 1.70978
[2024-02-27 15:13:38,150][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.71235
[2024-02-27 15:13:38,150][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.77027
[2024-02-27 15:14:04,426][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.73281
[2024-02-27 15:14:04,426][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.94700
[2024-02-27 15:14:31,275][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.85672
[2024-02-27 15:14:31,275][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.78321
[2024-02-27 15:14:57,468][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.83613
[2024-02-27 15:14:57,468][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.76776
[2024-02-27 15:15:24,187][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.74889
[2024-02-27 15:15:24,187][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.76035
[2024-02-27 15:15:50,495][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.84874
[2024-02-27 15:15:50,495][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 1.23201
[2024-02-27 15:16:17,423][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.97547
[2024-02-27 15:16:17,423][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.84928
[2024-02-27 15:16:43,888][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 1.04059
[2024-02-27 15:16:43,888][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.79949
[2024-02-27 15:17:10,557][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.76549
[2024-02-27 15:17:10,557][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 0.73914
[2024-02-27 15:17:36,852][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 1.07635
[2024-02-27 15:17:36,852][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.76943 - val_accuracy: 0.67700 - train_loss: 1.07017 - val_loss: 1.29605 - loss: 1.22707
[2024-02-27 15:18:32,170][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.73794
[2024-02-27 15:18:32,170][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.76828
[2024-02-27 15:18:58,359][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.73657
[2024-02-27 15:18:58,359][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.75285
[2024-02-27 15:19:25,106][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.82257
[2024-02-27 15:19:25,106][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.76383
[2024-02-27 15:19:51,261][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.48744
[2024-02-27 15:19:51,261][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.95853
[2024-02-27 15:20:18,269][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.28648
[2024-02-27 15:20:18,269][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.13108
[2024-02-27 15:20:44,327][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.69872
[2024-02-27 15:20:44,327][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.19487
[2024-02-27 15:21:11,277][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.88183
[2024-02-27 15:21:11,277][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.69495
[2024-02-27 15:21:37,531][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.71798
[2024-02-27 15:21:37,531][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 1.40004
[2024-02-27 15:22:04,434][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.92232
[2024-02-27 15:22:04,434][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.76287
[2024-02-27 15:22:30,765][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.73308
[2024-02-27 15:22:30,765][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.75926 - val_accuracy: 0.77620 - train_loss: 1.11388 - val_loss: 1.01234 - loss: 0.72876
[2024-02-27 15:23:24,293][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.75753
[2024-02-27 15:23:24,293][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.89475
[2024-02-27 15:23:50,393][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.76360
[2024-02-27 15:23:50,393][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.73005
[2024-02-27 15:24:17,148][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.96574
[2024-02-27 15:24:17,148][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.73565
[2024-02-27 15:24:44,024][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.67071
[2024-02-27 15:24:44,024][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.67898
[2024-02-27 15:25:10,434][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.76349
[2024-02-27 15:25:10,434][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.96805
[2024-02-27 15:25:37,108][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.70567
[2024-02-27 15:25:37,108][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.78983
[2024-02-27 15:26:03,429][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 1.16587
[2024-02-27 15:26:03,429][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.83229
[2024-02-27 15:26:30,254][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.69424
[2024-02-27 15:26:30,254][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.71291
[2024-02-27 15:26:56,835][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 1.68138
[2024-02-27 15:26:56,835][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.78812 - val_accuracy: 0.77610 - train_loss: 1.01525 - val_loss: 1.06115 - loss: 0.73220
[2024-02-27 15:27:51,724][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.68865
[2024-02-27 15:27:51,724][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.89960
[2024-02-27 15:28:17,907][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 1.56969
[2024-02-27 15:28:17,907][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.83897
[2024-02-27 15:28:44,792][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.69211
[2024-02-27 15:28:44,792][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.78312
[2024-02-27 15:29:11,116][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.67945
[2024-02-27 15:29:11,116][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.74316
[2024-02-27 15:29:38,186][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.74790
[2024-02-27 15:29:38,187][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.66054
[2024-02-27 15:30:04,483][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.68674
[2024-02-27 15:30:04,483][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.68767
[2024-02-27 15:30:31,314][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.68186
[2024-02-27 15:30:31,314][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 1.69373
[2024-02-27 15:30:57,544][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.92795
[2024-02-27 15:30:57,544][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 1.30203
[2024-02-27 15:31:24,303][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.73479
[2024-02-27 15:31:24,303][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.94656
[2024-02-27 15:31:50,712][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.68754
[2024-02-27 15:31:50,712][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.79267 - val_accuracy: 0.72240 - train_loss: 1.02005 - val_loss: 1.20729 - loss: 0.71361
[2024-02-27 15:32:44,674][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.66318
[2024-02-27 15:32:44,674][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.67156
[2024-02-27 15:33:10,880][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.81117
[2024-02-27 15:33:10,880][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.66137
[2024-02-27 15:33:37,542][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.71644
[2024-02-27 15:33:37,542][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.67673
[2024-02-27 15:34:03,646][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 1.03765
[2024-02-27 15:34:03,646][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.70310
[2024-02-27 15:34:30,203][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.66781
[2024-02-27 15:34:30,203][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 1.25182
[2024-02-27 15:34:56,319][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.71331
[2024-02-27 15:34:56,319][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.67964
[2024-02-27 15:35:23,019][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.65372
[2024-02-27 15:35:23,019][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.67808
[2024-02-27 15:35:49,377][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.64531
[2024-02-27 15:35:49,377][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.64514
[2024-02-27 15:36:16,096][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.64916
[2024-02-27 15:36:16,096][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 1.09381
[2024-02-27 15:36:42,470][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 1.92711
[2024-02-27 15:36:42,470][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.77752 - val_accuracy: 0.75090 - train_loss: 1.01201 - val_loss: 1.07087 - loss: 0.64480
[2024-02-27 15:37:38,735][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.74234
[2024-02-27 15:37:38,735][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 1.51499
[2024-02-27 15:38:04,929][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.69075
[2024-02-27 15:38:04,929][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.92368
[2024-02-27 15:38:31,768][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.63130
[2024-02-27 15:38:31,768][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.68134
[2024-02-27 15:38:58,020][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.65718
[2024-02-27 15:38:58,020][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.72353
[2024-02-27 15:39:24,833][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 1.86629
[2024-02-27 15:39:24,833][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.64600
[2024-02-27 15:39:50,913][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.64636
[2024-02-27 15:39:50,913][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.71318
[2024-02-27 15:40:17,732][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 1.97443
[2024-02-27 15:40:17,732][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 1.26989
[2024-02-27 15:40:44,524][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.63149
[2024-02-27 15:40:44,524][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.67433
[2024-02-27 15:41:10,708][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 1.98208
[2024-02-27 15:41:10,708][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.81488 - val_accuracy: 0.74660 - train_loss: 0.96435 - val_loss: 1.12400 - loss: 0.86137
[2024-02-27 15:42:04,714][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.64036
[2024-02-27 15:42:04,714][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.61870
[2024-02-27 15:42:30,868][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.70445
[2024-02-27 15:42:30,868][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.69632
[2024-02-27 15:42:57,536][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.64827
[2024-02-27 15:42:57,536][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.70019
[2024-02-27 15:43:23,730][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.65474
[2024-02-27 15:43:23,730][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.62486
[2024-02-27 15:43:50,677][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 1.70556
[2024-02-27 15:43:50,677][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.62240
[2024-02-27 15:44:16,881][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.62990
[2024-02-27 15:44:16,881][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.66562
[2024-02-27 15:44:43,496][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.66603
[2024-02-27 15:44:43,496][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.67174
[2024-02-27 15:45:09,593][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.72867
[2024-02-27 15:45:09,593][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.67458
[2024-02-27 15:45:36,539][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.66711
[2024-02-27 15:45:36,539][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.69394
[2024-02-27 15:46:02,817][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 1.94664
[2024-02-27 15:46:02,817][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.80908 - val_accuracy: 0.77300 - train_loss: 0.97417 - val_loss: 1.04524 - loss: 0.63082
[2024-02-27 15:46:56,584][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.64253
[2024-02-27 15:46:56,584][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 1.51246
[2024-02-27 15:47:22,859][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.96399
[2024-02-27 15:47:22,859][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.75984
[2024-02-27 15:47:49,852][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.63861
[2024-02-27 15:47:49,852][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 1.17912
[2024-02-27 15:48:16,014][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.65572
[2024-02-27 15:48:16,014][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 1.20952
[2024-02-27 15:48:42,569][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.60990
[2024-02-27 15:48:42,569][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.66309
[2024-02-27 15:49:08,744][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.65379
[2024-02-27 15:49:08,744][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.65358
[2024-02-27 15:49:35,342][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.62676
[2024-02-27 15:49:35,342][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.63230
[2024-02-27 15:50:01,549][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.67731
[2024-02-27 15:50:01,549][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.63686
[2024-02-27 15:50:28,158][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.69171
[2024-02-27 15:50:28,158][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 0.61806
[2024-02-27 15:50:54,296][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 1.12751
[2024-02-27 15:50:54,296][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.78572 - val_accuracy: 0.70610 - train_loss: 1.02080 - val_loss: 1.23567 - loss: 2.00017
[2024-02-27 15:51:48,336][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.60977
[2024-02-27 15:51:48,336][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.62074
[2024-02-27 15:52:14,576][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 1.02442
[2024-02-27 15:52:14,576][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 1.63164
[2024-02-27 15:52:41,302][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.64578
[2024-02-27 15:52:41,302][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.66473
[2024-02-27 15:53:07,623][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.62698
[2024-02-27 15:53:07,623][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.63465
[2024-02-27 15:53:34,240][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.66639
[2024-02-27 15:53:34,240][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 1.97780
[2024-02-27 15:54:00,508][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.87882
[2024-02-27 15:54:00,508][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.67310
[2024-02-27 15:54:27,235][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.63331
[2024-02-27 15:54:27,235][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.85315
[2024-02-27 15:54:53,609][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.66763
[2024-02-27 15:54:53,609][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.63328
[2024-02-27 15:55:20,406][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 1.12448
[2024-02-27 15:55:20,406][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.59722
[2024-02-27 15:55:46,666][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.61022
[2024-02-27 15:55:46,666][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.82730 - val_accuracy: 0.77050 - train_loss: 0.94770 - val_loss: 1.07622 - loss: 0.64929
[2024-02-27 15:56:40,711][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 1.54621
[2024-02-27 15:56:40,711][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.82499
[2024-02-27 15:57:07,213][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.61261
[2024-02-27 15:57:07,213][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.65107
[2024-02-27 15:57:33,372][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.64683
[2024-02-27 15:57:33,372][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.63311
[2024-02-27 15:57:59,891][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.64366
[2024-02-27 15:57:59,891][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.62672
[2024-02-27 15:58:26,014][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.80425
[2024-02-27 15:58:26,014][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.71135
[2024-02-27 15:58:52,554][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.63577
[2024-02-27 15:58:52,554][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.61212
[2024-02-27 15:59:18,758][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.68355
[2024-02-27 15:59:18,758][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.66578
[2024-02-27 15:59:45,361][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.66716
[2024-02-27 15:59:45,361][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.65085
[2024-02-27 16:00:11,551][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.63604
[2024-02-27 16:00:11,551][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.76707 - val_accuracy: 0.73890 - train_loss: 1.08596 - val_loss: 1.14860 - loss: 0.61433
[2024-02-27 16:01:05,206][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.56164
[2024-02-27 16:01:05,206][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.60940
[2024-02-27 16:01:31,428][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.74840
[2024-02-27 16:01:31,428][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.65208
[2024-02-27 16:01:57,957][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 1.62519
[2024-02-27 16:01:57,957][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.59972
[2024-02-27 16:02:23,996][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 1.07291
[2024-02-27 16:02:23,996][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.59932
[2024-02-27 16:02:50,623][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.81623
[2024-02-27 16:02:50,624][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.66283
[2024-02-27 16:03:16,741][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.62881
[2024-02-27 16:03:16,741][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.66586
[2024-02-27 16:03:43,375][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.66944
[2024-02-27 16:03:43,375][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.77801
[2024-02-27 16:04:09,668][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.60408
[2024-02-27 16:04:09,668][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.68860
[2024-02-27 16:04:36,343][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.60457
[2024-02-27 16:04:36,343][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 0.64953
[2024-02-27 16:05:02,596][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 1.52065
[2024-02-27 16:05:02,596][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.80348 - val_accuracy: 0.75100 - train_loss: 0.98603 - val_loss: 1.10768 - loss: 1.39097
[2024-02-27 16:05:56,509][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.68096
[2024-02-27 16:05:56,509][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 1.91669
[2024-02-27 16:06:22,670][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.60888
[2024-02-27 16:06:22,670][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.59263
[2024-02-27 16:06:49,234][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.73604
[2024-02-27 16:06:49,234][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.59263
[2024-02-27 16:07:15,445][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.60773
[2024-02-27 16:07:15,445][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.80569
[2024-02-27 16:07:42,088][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.68964
[2024-02-27 16:07:42,088][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.58392
[2024-02-27 16:08:08,168][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.59012
[2024-02-27 16:08:08,169][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.58284
[2024-02-27 16:08:34,735][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.67469
[2024-02-27 16:08:34,735][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.60335
[2024-02-27 16:09:00,919][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.58353
[2024-02-27 16:09:00,919][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.62013
[2024-02-27 16:09:27,525][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.64717
[2024-02-27 16:09:27,525][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.63291
[2024-02-27 16:09:53,560][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 0.61490
[2024-02-27 16:09:53,560][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.81955 - val_accuracy: 0.72410 - train_loss: 0.96910 - val_loss: 1.21581 - loss: 1.03858
[2024-02-27 16:10:48,257][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 1.12006
[2024-02-27 16:10:48,258][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.58985
[2024-02-27 16:11:14,462][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.66633
[2024-02-27 16:11:14,462][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.71383
[2024-02-27 16:11:41,144][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.64158
[2024-02-27 16:11:41,144][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.67834
[2024-02-27 16:12:07,918][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.96835
[2024-02-27 16:12:07,918][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.60443
[2024-02-27 16:12:33,999][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.56263
[2024-02-27 16:12:33,999][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.62047
[2024-02-27 16:13:00,660][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.54515
[2024-02-27 16:13:00,660][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.62418
[2024-02-27 16:13:26,776][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.62387
[2024-02-27 16:13:26,776][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.61329
[2024-02-27 16:13:53,224][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.55587
[2024-02-27 16:13:53,224][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.79909
[2024-02-27 16:14:19,385][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.57414
[2024-02-27 16:14:19,385][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.81989 - val_accuracy: 0.78780 - train_loss: 0.98582 - val_loss: 1.01225 - loss: 0.68709
[2024-02-27 16:15:13,390][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.58499
[2024-02-27 16:15:13,390][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 1.64419
[2024-02-27 16:15:39,472][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.73245
[2024-02-27 16:15:39,472][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.57930
[2024-02-27 16:16:06,116][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.58353
[2024-02-27 16:16:06,117][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.59169
[2024-02-27 16:16:32,286][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.55161
[2024-02-27 16:16:32,286][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.65726
[2024-02-27 16:16:58,909][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.71267
[2024-02-27 16:16:58,909][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 1.68032
[2024-02-27 16:17:25,231][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.61141
[2024-02-27 16:17:25,231][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.59063
[2024-02-27 16:17:52,118][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.56259
[2024-02-27 16:17:52,118][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.60876
[2024-02-27 16:18:18,196][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.59606
[2024-02-27 16:18:18,196][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.55829
[2024-02-27 16:18:45,037][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.57324
[2024-02-27 16:18:45,037][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.57752
[2024-02-27 16:19:11,150][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.58430
[2024-02-27 16:19:11,150][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.80906 - val_accuracy: 0.68640 - train_loss: 1.02164 - val_loss: 1.33831 - loss: 0.61476
[2024-02-27 16:20:06,681][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.59113
[2024-02-27 16:20:06,681][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 1.88111
[2024-02-27 16:20:32,869][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57758
[2024-02-27 16:20:32,869][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57828
[2024-02-27 16:20:59,573][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.56955
[2024-02-27 16:20:59,573][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57154
[2024-02-27 16:21:25,723][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.59510
[2024-02-27 16:21:25,723][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.58843
[2024-02-27 16:21:52,812][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 1.87172
[2024-02-27 16:21:52,812][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57995
[2024-02-27 16:22:19,031][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.58470
[2024-02-27 16:22:19,031][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.59121
[2024-02-27 16:22:45,769][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57154
[2024-02-27 16:22:45,769][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.58205
[2024-02-27 16:23:11,890][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.64589
[2024-02-27 16:23:11,890][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 1.10493
[2024-02-27 16:23:38,675][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.55615
[2024-02-27 16:23:38,675][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57062
[2024-02-27 16:24:04,743][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.57917
[2024-02-27 16:24:04,743][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.82023 - val_accuracy: 0.70020 - train_loss: 1.00241 - val_loss: 1.36050 - loss: 0.58805
[2024-02-27 16:24:58,657][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.60223
[2024-02-27 16:24:58,657][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.55049
[2024-02-27 16:25:24,819][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.67205
[2024-02-27 16:25:24,819][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.73764
[2024-02-27 16:25:51,775][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.64791
[2024-02-27 16:25:51,775][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.82657
[2024-02-27 16:26:17,813][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.58360
[2024-02-27 16:26:17,813][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.62569
[2024-02-27 16:26:44,555][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.55940
[2024-02-27 16:26:44,555][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.59606
[2024-02-27 16:27:10,662][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.63264
[2024-02-27 16:27:10,662][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 1.06951
[2024-02-27 16:27:37,550][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.60597
[2024-02-27 16:27:37,550][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.56421
[2024-02-27 16:28:04,655][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.55992
[2024-02-27 16:28:04,655][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.54551
[2024-02-27 16:28:30,780][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 1.15529
[2024-02-27 16:28:30,781][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.82287 - val_accuracy: 0.76910 - train_loss: 1.01083 - val_loss: 1.13930 - loss: 0.55601
[2024-02-27 16:29:24,563][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.57311
[2024-02-27 16:29:24,563][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.69828
[2024-02-27 16:29:50,731][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.60815
[2024-02-27 16:29:50,731][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.97971
[2024-02-27 16:30:17,409][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.68973
[2024-02-27 16:30:17,409][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.67932
[2024-02-27 16:30:43,643][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.57397
[2024-02-27 16:30:43,643][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.82571
[2024-02-27 16:31:10,483][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.81858
[2024-02-27 16:31:10,483][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.58634
[2024-02-27 16:31:36,675][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.63140
[2024-02-27 16:31:36,675][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.57164
[2024-02-27 16:32:03,479][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.57344
[2024-02-27 16:32:03,479][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.58856
[2024-02-27 16:32:29,638][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.55378
[2024-02-27 16:32:29,638][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.57762
[2024-02-27 16:32:56,248][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.91784
[2024-02-27 16:32:56,248][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.55069
[2024-02-27 16:33:22,426][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.56457
[2024-02-27 16:33:22,426][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.84260 - val_accuracy: 0.78270 - train_loss: 0.89476 - val_loss: 1.03932 - loss: 0.60642
[2024-02-27 16:34:16,315][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.53914
[2024-02-27 16:34:16,315][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.57432
[2024-02-27 16:34:42,402][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 1.03011
[2024-02-27 16:34:42,402][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.56212
[2024-02-27 16:35:08,818][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.59883
[2024-02-27 16:35:08,818][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.54083
[2024-02-27 16:35:34,998][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 1.08611
[2024-02-27 16:35:34,998][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.55129
[2024-02-27 16:36:01,812][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.56355
[2024-02-27 16:36:01,812][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.54939
[2024-02-27 16:36:28,135][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.60863
[2024-02-27 16:36:28,135][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 1.01958
[2024-02-27 16:36:54,897][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.59329
[2024-02-27 16:36:54,898][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.58456
[2024-02-27 16:37:21,216][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.59593
[2024-02-27 16:37:21,216][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.77009
[2024-02-27 16:37:48,212][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.59185
[2024-02-27 16:37:48,212][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.60466
[2024-02-27 16:38:14,360][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.57860
[2024-02-27 16:38:14,360][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.82615 - val_accuracy: 0.75460 - train_loss: 0.94092 - val_loss: 1.11571 - loss: 0.55831
[2024-02-27 16:39:08,044][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 1.95046
[2024-02-27 16:39:08,045][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 1.00835
[2024-02-27 16:39:34,200][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.59034
[2024-02-27 16:39:34,200][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.65559
[2024-02-27 16:40:00,951][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.58972
[2024-02-27 16:40:00,951][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.90270
[2024-02-27 16:40:27,300][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.56591
[2024-02-27 16:40:27,300][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.56974
[2024-02-27 16:40:54,024][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.57201
[2024-02-27 16:40:54,024][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.56775
[2024-02-27 16:41:20,269][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.57564
[2024-02-27 16:41:20,269][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.58046
[2024-02-27 16:41:47,188][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.57373
[2024-02-27 16:41:47,188][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.56916
[2024-02-27 16:42:13,454][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 1.01219
[2024-02-27 16:42:13,454][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.57816
[2024-02-27 16:42:40,414][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.54416
[2024-02-27 16:42:40,414][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.56760
[2024-02-27 16:43:06,700][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.75001
[2024-02-27 16:43:06,700][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.84327 - val_accuracy: 0.76630 - train_loss: 0.89391 - val_loss: 1.07968 - loss: 0.59098
[2024-02-27 16:44:01,962][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.54002
[2024-02-27 16:44:01,962][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.87777
[2024-02-27 16:44:28,571][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.54455
[2024-02-27 16:44:28,571][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.53483
[2024-02-27 16:44:54,748][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.58023
[2024-02-27 16:44:54,748][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 1.09337
[2024-02-27 16:45:21,373][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.56037
[2024-02-27 16:45:21,373][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.99532
[2024-02-27 16:45:47,546][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.53661
[2024-02-27 16:45:47,546][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.55910
[2024-02-27 16:46:14,266][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.57126
[2024-02-27 16:46:14,266][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.54456
[2024-02-27 16:46:40,499][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 1.22864
[2024-02-27 16:46:40,499][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.57626
[2024-02-27 16:47:07,465][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.57483
[2024-02-27 16:47:07,465][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.98438
[2024-02-27 16:47:33,588][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.60568
[2024-02-27 16:47:33,588][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.85277 - val_accuracy: 0.78490 - train_loss: 0.88722 - val_loss: 1.06890 - loss: 0.54899
[2024-02-27 16:48:27,348][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.54868
[2024-02-27 16:48:27,348][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.75156
[2024-02-27 16:48:53,496][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.87257
[2024-02-27 16:48:53,496][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.54704
[2024-02-27 16:49:20,172][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.66112
[2024-02-27 16:49:20,172][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.87061
[2024-02-27 16:49:46,323][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.53930
[2024-02-27 16:49:46,323][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.61297
[2024-02-27 16:50:13,472][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.54549
[2024-02-27 16:50:13,472][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 1.67478
[2024-02-27 16:50:39,460][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.57312
[2024-02-27 16:50:39,460][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.55949
[2024-02-27 16:51:06,187][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.65369
[2024-02-27 16:51:06,187][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.55765
[2024-02-27 16:51:32,383][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.54832
[2024-02-27 16:51:32,383][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 1.05324
[2024-02-27 16:51:59,200][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.54680
[2024-02-27 16:51:59,200][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.52342
[2024-02-27 16:52:25,406][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.55406
[2024-02-27 16:52:25,406][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.83022 - val_accuracy: 0.64100 - train_loss: 0.95940 - val_loss: 1.48954 - loss: 0.56328
[2024-02-27 16:53:19,486][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.66113
[2024-02-27 16:53:19,486][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.14858
[2024-02-27 16:53:45,670][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.58981
[2024-02-27 16:53:45,670][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.55031
[2024-02-27 16:54:12,686][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.07610
[2024-02-27 16:54:12,686][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.58371
[2024-02-27 16:54:39,008][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.57255
[2024-02-27 16:54:39,008][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.56096
[2024-02-27 16:55:05,610][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.42324
[2024-02-27 16:55:05,610][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.54316
[2024-02-27 16:55:31,815][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.88702
[2024-02-27 16:55:31,815][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.55565
[2024-02-27 16:55:58,669][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.57116
[2024-02-27 16:55:58,669][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.55282
[2024-02-27 16:56:24,894][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.42965
[2024-02-27 16:56:24,894][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.56946
[2024-02-27 16:56:51,620][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.66854
[2024-02-27 16:56:51,620][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.24810
[2024-02-27 16:57:17,915][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 1.60196
[2024-02-27 16:57:17,915][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.87017 - val_accuracy: 0.74490 - train_loss: 0.84343 - val_loss: 1.18977 - loss: 0.55632
[2024-02-27 16:58:13,988][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.60408
[2024-02-27 16:58:13,988][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 1.61876
[2024-02-27 16:58:40,331][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.56043
[2024-02-27 16:58:40,331][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.56760
[2024-02-27 16:59:06,988][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.54854
[2024-02-27 16:59:06,988][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.56668
[2024-02-27 16:59:33,566][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 1.41571
[2024-02-27 16:59:33,566][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.54435
[2024-02-27 16:59:59,797][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.59352
[2024-02-27 16:59:59,797][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.53566
[2024-02-27 17:00:26,423][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.53551
[2024-02-27 17:00:26,423][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.54859
[2024-02-27 17:00:52,595][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.58407
[2024-02-27 17:00:52,595][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.87701
[2024-02-27 17:01:19,035][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.54820
[2024-02-27 17:01:19,035][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.94603
[2024-02-27 17:01:45,046][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.54953
[2024-02-27 17:01:45,046][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.83765 - val_accuracy: 0.79080 - train_loss: 0.91347 - val_loss: 1.01249 - loss: 0.61310
[2024-02-27 17:02:39,231][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.72473
[2024-02-27 17:02:39,231][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.55930
[2024-02-27 17:03:05,307][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.55522
[2024-02-27 17:03:05,307][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.53427
[2024-02-27 17:03:31,930][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 1.30940
[2024-02-27 17:03:31,930][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.54125
[2024-02-27 17:03:58,086][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.58098
[2024-02-27 17:03:58,086][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.70118
[2024-02-27 17:04:24,596][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.58383
[2024-02-27 17:04:24,596][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.53775
[2024-02-27 17:04:50,871][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 1.37573
[2024-02-27 17:04:50,871][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.56011
[2024-02-27 17:05:17,537][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.52166
[2024-02-27 17:05:17,537][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.54684
[2024-02-27 17:05:43,776][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.54323
[2024-02-27 17:05:43,776][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.53532
[2024-02-27 17:06:10,363][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 1.84981
[2024-02-27 17:06:10,363][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.53192
[2024-02-27 17:06:36,538][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.56575
[2024-02-27 17:06:36,538][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.87548 - val_accuracy: 0.77500 - train_loss: 0.84784 - val_loss: 1.12849 - loss: 0.56105
[2024-02-27 17:07:30,456][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.52177
[2024-02-27 17:07:30,456][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.54799
[2024-02-27 17:07:56,603][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.56700
[2024-02-27 17:07:56,603][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.56652
[2024-02-27 17:08:23,187][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.54810
[2024-02-27 17:08:23,187][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.52816
[2024-02-27 17:08:49,288][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.71745
[2024-02-27 17:08:49,288][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.53984
[2024-02-27 17:09:15,856][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.62382
[2024-02-27 17:09:15,856][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.55257
[2024-02-27 17:09:42,111][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.52374
[2024-02-27 17:09:42,111][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.54771
[2024-02-27 17:10:08,729][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.53643
[2024-02-27 17:10:08,729][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.55212
[2024-02-27 17:10:34,905][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.55112
[2024-02-27 17:10:34,905][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 1.07046
[2024-02-27 17:11:01,420][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.78875
[2024-02-27 17:11:01,420][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.55912
[2024-02-27 17:11:27,435][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.52671
[2024-02-27 17:11:27,435][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.86141 - val_accuracy: 0.79720 - train_loss: 0.85739 - val_loss: 1.01138 - loss: 0.57327
[2024-02-27 17:12:21,153][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.54229
[2024-02-27 17:12:21,153][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.55836
[2024-02-27 17:12:47,250][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.53283
[2024-02-27 17:12:47,251][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.53817
[2024-02-27 17:13:13,977][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.51733
[2024-02-27 17:13:13,977][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.65859
[2024-02-27 17:13:40,095][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.55489
[2024-02-27 17:13:40,095][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.54646
[2024-02-27 17:14:06,600][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 1.37584
[2024-02-27 17:14:06,600][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.54009
[2024-02-27 17:14:32,817][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 1.04167
[2024-02-27 17:14:32,817][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.55267
[2024-02-27 17:14:59,212][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.54846
[2024-02-27 17:14:59,212][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.55168
[2024-02-27 17:15:25,967][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.52645
[2024-02-27 17:15:25,967][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.60490
[2024-02-27 17:15:52,117][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.52069
[2024-02-27 17:15:52,117][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.87119 - val_accuracy: 0.84270 - train_loss: 0.87210 - val_loss: 0.90111 - loss: 0.56913
[2024-02-27 17:16:45,919][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.51807
[2024-02-27 17:16:45,919][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 1.67239
[2024-02-27 17:17:12,098][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.55489
[2024-02-27 17:17:12,098][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.52484
[2024-02-27 17:17:38,596][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.66614
[2024-02-27 17:17:38,596][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.54711
[2024-02-27 17:18:04,679][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.55619
[2024-02-27 17:18:04,679][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.81793
[2024-02-27 17:18:31,382][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.51880
[2024-02-27 17:18:31,382][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.82617
[2024-02-27 17:18:57,504][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 1.35875
[2024-02-27 17:18:57,505][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.99295
[2024-02-27 17:19:24,122][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.57598
[2024-02-27 17:19:24,122][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.54408
[2024-02-27 17:19:50,191][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.53127
[2024-02-27 17:19:50,191][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 1.35953
[2024-02-27 17:20:16,791][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.57705
[2024-02-27 17:20:16,791][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.52981
[2024-02-27 17:20:42,948][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.54974
[2024-02-27 17:20:42,948][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.85871 - val_accuracy: 0.73290 - train_loss: 0.87602 - val_loss: 1.23024 - loss: 0.86099
[2024-02-27 17:21:36,634][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.52628
[2024-02-27 17:21:36,635][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.54667
[2024-02-27 17:22:02,898][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.53640
[2024-02-27 17:22:02,898][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.54090
[2024-02-27 17:22:29,535][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.54416
[2024-02-27 17:22:29,535][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.76099
[2024-02-27 17:22:55,695][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.58802
[2024-02-27 17:22:55,695][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.56379
[2024-02-27 17:23:22,251][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.55023
[2024-02-27 17:23:22,252][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.61462
[2024-02-27 17:23:48,317][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.58202
[2024-02-27 17:23:48,317][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.56707
[2024-02-27 17:24:15,098][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.54407
[2024-02-27 17:24:15,098][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.53089
[2024-02-27 17:24:41,251][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.52051
[2024-02-27 17:24:41,251][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 1.42932
[2024-02-27 17:25:07,876][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.74790
[2024-02-27 17:25:07,876][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.57053
[2024-02-27 17:25:33,997][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.53646
[2024-02-27 17:25:33,997][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.83660 - val_accuracy: 0.76550 - train_loss: 0.93155 - val_loss: 1.08757 - loss: 0.67710
[2024-02-27 17:26:27,674][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.52444
[2024-02-27 17:26:27,674][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.53897
[2024-02-27 17:26:53,919][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 1.29639
[2024-02-27 17:26:53,919][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.57717
[2024-02-27 17:27:20,573][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.61791
[2024-02-27 17:27:20,573][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.62115
[2024-02-27 17:27:46,700][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.55349
[2024-02-27 17:27:46,700][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.80223
[2024-02-27 17:28:13,365][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 1.35983
[2024-02-27 17:28:13,365][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.54700
[2024-02-27 17:28:39,522][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.57337
[2024-02-27 17:28:39,522][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.54492
[2024-02-27 17:29:06,154][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 1.09922
[2024-02-27 17:29:06,154][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.54290
[2024-02-27 17:29:32,447][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.56947
[2024-02-27 17:29:32,447][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.76180
[2024-02-27 17:29:59,093][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.57218
[2024-02-27 17:29:59,093][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.67985
[2024-02-27 17:30:25,278][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.55158
[2024-02-27 17:30:25,278][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.86898 - val_accuracy: 0.80420 - train_loss: 0.86521 - val_loss: 1.00802 - loss: 0.54072
[2024-02-27 17:31:19,402][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53527
[2024-02-27 17:31:19,402][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53041
[2024-02-27 17:31:46,045][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 1.93376
[2024-02-27 17:31:46,045][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53553
[2024-02-27 17:32:12,170][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.56920
[2024-02-27 17:32:12,170][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.52187
[2024-02-27 17:32:38,723][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.54546
[2024-02-27 17:32:38,723][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 1.93611
[2024-02-27 17:33:04,876][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 1.17051
[2024-02-27 17:33:04,876][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.77649
[2024-02-27 17:33:31,508][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.54303
[2024-02-27 17:33:31,508][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.52629
[2024-02-27 17:33:57,640][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.61970
[2024-02-27 17:33:57,640][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53453
[2024-02-27 17:34:24,320][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53932
[2024-02-27 17:34:24,320][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.53641
[2024-02-27 17:34:50,557][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 1.09605
[2024-02-27 17:34:50,557][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.86197 - val_accuracy: 0.66970 - train_loss: 0.88324 - val_loss: 1.42888 - loss: 0.79827
[2024-02-27 17:35:44,404][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.51563
[2024-02-27 17:35:44,404][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.53404
[2024-02-27 17:36:10,569][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.52824
[2024-02-27 17:36:10,569][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 1.91400
[2024-02-27 17:36:37,181][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.54098
[2024-02-27 17:36:37,181][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.55470
[2024-02-27 17:37:03,509][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 1.58104
[2024-02-27 17:37:03,509][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.53181
[2024-02-27 17:37:30,279][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.55704
[2024-02-27 17:37:30,279][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.52513
[2024-02-27 17:37:56,420][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.52641
[2024-02-27 17:37:56,421][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.55259
[2024-02-27 17:38:22,932][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.93797
[2024-02-27 17:38:22,932][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.67821
[2024-02-27 17:38:49,248][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.71642
[2024-02-27 17:38:49,248][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.53588
[2024-02-27 17:39:15,930][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.55902
[2024-02-27 17:39:15,930][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.52715
[2024-02-27 17:39:41,974][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.54858
[2024-02-27 17:39:41,974][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.87993 - val_accuracy: 0.77200 - train_loss: 0.80195 - val_loss: 1.05979 - loss: 0.79195
[2024-02-27 17:40:35,842][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.52118
[2024-02-27 17:40:35,842][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.87408
[2024-02-27 17:41:02,051][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.92644
[2024-02-27 17:41:02,051][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.53488
[2024-02-27 17:41:28,652][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.53843
[2024-02-27 17:41:28,652][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.53149
[2024-02-27 17:41:54,802][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.66540
[2024-02-27 17:41:54,802][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.08495
[2024-02-27 17:42:21,506][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.37685
[2024-02-27 17:42:21,506][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.62067
[2024-02-27 17:42:47,559][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.54046
[2024-02-27 17:42:47,559][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.36987
[2024-02-27 17:43:14,074][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.54154
[2024-02-27 17:43:14,074][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.52144
[2024-02-27 17:43:40,402][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.52755
[2024-02-27 17:43:40,402][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.53874
[2024-02-27 17:44:07,050][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 1.89737
[2024-02-27 17:44:07,050][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.53147
[2024-02-27 17:44:33,148][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.56222
[2024-02-27 17:44:33,148][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.86676 - val_accuracy: 0.73410 - train_loss: 0.89401 - val_loss: 1.26990 - loss: 0.55429
[2024-02-27 17:45:27,054][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.51783
[2024-02-27 17:45:27,054][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.53095
[2024-02-27 17:45:53,153][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.54539
[2024-02-27 17:45:53,153][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.51684
[2024-02-27 17:46:19,692][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.61858
[2024-02-27 17:46:19,693][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.53306
[2024-02-27 17:46:46,294][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.51825
[2024-02-27 17:46:46,294][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.85794
[2024-02-27 17:47:12,427][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.52557
[2024-02-27 17:47:12,427][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.25201
[2024-02-27 17:47:39,086][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.51785
[2024-02-27 17:47:39,086][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.53094
[2024-02-27 17:48:05,104][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.54937
[2024-02-27 17:48:05,104][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.52945
[2024-02-27 17:48:31,706][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.30661
[2024-02-27 17:48:31,706][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.55976
[2024-02-27 17:48:57,858][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 1.13144
[2024-02-27 17:48:57,858][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.83362 - val_accuracy: 0.70510 - train_loss: 0.93902 - val_loss: 1.25883 - loss: 0.54645
[2024-02-27 17:49:53,066][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 1.03949
[2024-02-27 17:49:53,066][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52716
[2024-02-27 17:50:19,180][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.53059
[2024-02-27 17:50:19,180][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.53656
[2024-02-27 17:50:45,790][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 1.24258
[2024-02-27 17:50:45,790][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.53814
[2024-02-27 17:51:11,932][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52910
[2024-02-27 17:51:11,932][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52951
[2024-02-27 17:51:38,429][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.53901
[2024-02-27 17:51:38,430][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52365
[2024-02-27 17:52:04,578][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.54547
[2024-02-27 17:52:04,578][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 1.36398
[2024-02-27 17:52:31,264][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.63555
[2024-02-27 17:52:31,264][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52799
[2024-02-27 17:52:57,578][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52321
[2024-02-27 17:52:57,578][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.50938
[2024-02-27 17:53:24,307][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.54357
[2024-02-27 17:53:24,308][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 1.57645
[2024-02-27 17:53:50,497][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.52092
[2024-02-27 17:53:50,497][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.87049 - val_accuracy: 0.82750 - train_loss: 0.87203 - val_loss: 0.92952 - loss: 0.51932
[2024-02-27 17:54:44,485][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.52057
[2024-02-27 17:54:44,485][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.61420
[2024-02-27 17:55:10,652][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51846
[2024-02-27 17:55:10,652][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.53186
[2024-02-27 17:55:37,244][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.53682
[2024-02-27 17:55:37,244][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51679
[2024-02-27 17:56:03,320][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.52992
[2024-02-27 17:56:03,320][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.54635
[2024-02-27 17:56:29,816][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.53562
[2024-02-27 17:56:29,816][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.52459
[2024-02-27 17:56:55,937][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.55519
[2024-02-27 17:56:55,937][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51382
[2024-02-27 17:57:22,812][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.54005
[2024-02-27 17:57:22,812][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51574
[2024-02-27 17:57:48,900][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.56678
[2024-02-27 17:57:48,900][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51198
[2024-02-27 17:58:15,294][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.51592
[2024-02-27 17:58:15,294][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.52997
[2024-02-27 17:58:41,556][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.54433
[2024-02-27 17:58:41,556][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.86527 - val_accuracy: 0.81760 - train_loss: 0.88665 - val_loss: 0.95930 - loss: 0.54341
[2024-02-27 17:59:36,760][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.54161
[2024-02-27 17:59:36,760][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.53368
[2024-02-27 18:00:02,910][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52495
[2024-02-27 18:00:02,910][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.51680
[2024-02-27 18:00:29,441][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52359
[2024-02-27 18:00:29,441][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.79155
[2024-02-27 18:00:55,647][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52639
[2024-02-27 18:00:55,647][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.55395
[2024-02-27 18:01:22,258][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52757
[2024-02-27 18:01:22,258][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52681
[2024-02-27 18:01:48,359][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52512
[2024-02-27 18:01:48,359][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.53595
[2024-02-27 18:02:14,772][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52627
[2024-02-27 18:02:14,772][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.59060
[2024-02-27 18:02:41,685][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 1.85673
[2024-02-27 18:02:41,685][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52152
[2024-02-27 18:03:07,946][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.52901
[2024-02-27 18:03:07,946][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.88281 - val_accuracy: 0.77220 - train_loss: 0.86257 - val_loss: 1.15753 - loss: 0.51539
[2024-02-27 18:04:01,739][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.57420
[2024-02-27 18:04:01,739][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52695
[2024-02-27 18:04:27,870][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 1.28277
[2024-02-27 18:04:27,870][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52544
[2024-02-27 18:04:54,413][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.53651
[2024-02-27 18:04:54,413][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.51274
[2024-02-27 18:05:20,683][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 1.15790
[2024-02-27 18:05:20,683][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.55583
[2024-02-27 18:05:47,444][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.53415
[2024-02-27 18:05:47,444][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52013
[2024-02-27 18:06:13,564][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 1.08471
[2024-02-27 18:06:13,564][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.51542
[2024-02-27 18:06:39,971][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 1.39436
[2024-02-27 18:06:39,971][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52749
[2024-02-27 18:07:06,006][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.53285
[2024-02-27 18:07:06,006][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52294
[2024-02-27 18:07:32,644][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.53342
[2024-02-27 18:07:32,644][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.51750
[2024-02-27 18:07:58,843][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.52771
[2024-02-27 18:07:58,843][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.84343 - val_accuracy: 0.74580 - train_loss: 0.95714 - val_loss: 1.20482 - loss: 0.59670
[2024-02-27 18:08:52,856][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.52352
[2024-02-27 18:08:52,856][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.50704
[2024-02-27 18:09:19,058][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.91513
[2024-02-27 18:09:19,057][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.53948
[2024-02-27 18:09:45,717][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.52068
[2024-02-27 18:09:45,717][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.51663
[2024-02-27 18:10:11,923][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.52482
[2024-02-27 18:10:11,923][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.54497
[2024-02-27 18:10:38,505][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.53033
[2024-02-27 18:10:38,505][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.89979
[2024-02-27 18:11:04,539][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.52056
[2024-02-27 18:11:04,539][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.51971
[2024-02-27 18:11:31,322][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.53860
[2024-02-27 18:11:31,322][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.52603
[2024-02-27 18:11:57,550][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.56075
[2024-02-27 18:11:57,550][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.51285
[2024-02-27 18:12:24,332][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.51215
[2024-02-27 18:12:24,332][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.58723
[2024-02-27 18:12:50,589][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 0.51363
[2024-02-27 18:12:50,589][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.86177 - val_accuracy: 0.73720 - train_loss: 0.88041 - val_loss: 1.20074 - loss: 1.61405
[2024-02-27 18:13:44,900][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.57752
[2024-02-27 18:13:44,900][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.79678
[2024-02-27 18:14:11,121][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.91203
[2024-02-27 18:14:11,121][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.53524
[2024-02-27 18:14:37,724][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.53639
[2024-02-27 18:14:37,724][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 1.34162
[2024-02-27 18:15:03,802][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.51440
[2024-02-27 18:15:03,802][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.54025
[2024-02-27 18:15:30,397][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.52439
[2024-02-27 18:15:30,397][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.52292
[2024-02-27 18:15:56,571][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.55404
[2024-02-27 18:15:56,571][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.51527
[2024-02-27 18:16:23,327][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 1.01246
[2024-02-27 18:16:23,327][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.52902
[2024-02-27 18:16:49,466][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.51041
[2024-02-27 18:16:49,466][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.76767
[2024-02-27 18:17:16,231][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.54078
[2024-02-27 18:17:16,231][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.52240
[2024-02-27 18:17:42,537][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 0.52006
[2024-02-27 18:17:42,537][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.87832 - val_accuracy: 0.75930 - train_loss: 0.85567 - val_loss: 1.16677 - loss: 1.84658
[2024-02-27 18:18:37,520][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.54247
[2024-02-27 18:18:37,520][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.53779
[2024-02-27 18:19:04,139][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 1.23387
[2024-02-27 18:19:04,139][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.51753
[2024-02-27 18:19:30,336][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.57501
[2024-02-27 18:19:30,336][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.52911
[2024-02-27 18:19:56,984][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.56801
[2024-02-27 18:19:56,984][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.80785
[2024-02-27 18:20:23,136][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.86328
[2024-02-27 18:20:23,136][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.51437
[2024-02-27 18:20:49,743][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.52529
[2024-02-27 18:20:49,743][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 1.50687
[2024-02-27 18:21:15,853][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 1.04230
[2024-02-27 18:21:15,853][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 1.01660
[2024-02-27 18:21:42,546][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.51762
[2024-02-27 18:21:42,546][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.53700
[2024-02-27 18:22:08,791][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.50847
[2024-02-27 18:22:08,791][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.87097 - val_accuracy: 0.74460 - train_loss: 0.83994 - val_loss: 1.14151 - loss: 0.52330
[2024-02-27 18:23:02,845][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.50960
[2024-02-27 18:23:02,845][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51847
[2024-02-27 18:23:28,934][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.54163
[2024-02-27 18:23:28,934][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.53366
[2024-02-27 18:23:55,421][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 1.11645
[2024-02-27 18:23:55,421][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 1.27905
[2024-02-27 18:24:21,538][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51255
[2024-02-27 18:24:21,538][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51185
[2024-02-27 18:24:48,118][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.52445
[2024-02-27 18:24:48,118][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.52918
[2024-02-27 18:25:14,301][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.52592
[2024-02-27 18:25:14,301][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.60308
[2024-02-27 18:25:40,941][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51413
[2024-02-27 18:25:40,941][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.80638
[2024-02-27 18:26:07,190][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51779
[2024-02-27 18:26:07,190][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.67551
[2024-02-27 18:26:33,815][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.64084
[2024-02-27 18:26:33,815][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.52986
[2024-02-27 18:26:59,946][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.86108
[2024-02-27 18:26:59,946][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.90138 - val_accuracy: 0.66830 - train_loss: 0.78150 - val_loss: 1.48875 - loss: 0.51258
[2024-02-27 18:27:53,489][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.56208
[2024-02-27 18:27:53,489][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.52759
[2024-02-27 18:28:19,583][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 1.00114
[2024-02-27 18:28:19,583][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51854
[2024-02-27 18:28:46,123][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51242
[2024-02-27 18:28:46,123][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.50962
[2024-02-27 18:29:12,241][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 1.26460
[2024-02-27 18:29:12,241][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.57771
[2024-02-27 18:29:38,981][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51264
[2024-02-27 18:29:38,981][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51356
[2024-02-27 18:30:05,186][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.52032
[2024-02-27 18:30:05,186][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51354
[2024-02-27 18:30:31,859][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.52227
[2024-02-27 18:30:31,859][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.73085
[2024-02-27 18:30:58,137][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.65786
[2024-02-27 18:30:58,137][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.51678
[2024-02-27 18:31:24,743][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.50925
[2024-02-27 18:31:24,743][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.53719
[2024-02-27 18:31:50,856][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.50880
[2024-02-27 18:31:50,856][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.86324 - val_accuracy: 0.70650 - train_loss: 0.86877 - val_loss: 1.24467 - loss: 0.50966
[2024-02-27 18:32:45,517][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.55509
[2024-02-27 18:32:45,517][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 1.05853
[2024-02-27 18:33:11,607][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.53526
[2024-02-27 18:33:11,607][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.52564
[2024-02-27 18:33:38,118][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.50904
[2024-02-27 18:33:38,118][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.79738
[2024-02-27 18:34:04,717][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.51145
[2024-02-27 18:34:04,717][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.50630
[2024-02-27 18:34:30,920][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.52767
[2024-02-27 18:34:30,920][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 1.57348
[2024-02-27 18:34:58,007][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.83922
[2024-02-27 18:34:58,007][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 1.60259
[2024-02-27 18:35:24,156][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.50450
[2024-02-27 18:35:24,156][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 1.06550
[2024-02-27 18:35:50,761][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.51731
[2024-02-27 18:35:50,761][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.52354
[2024-02-27 18:36:16,950][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 0.52576
[2024-02-27 18:36:16,950][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.89578 - val_accuracy: 0.77000 - train_loss: 0.81880 - val_loss: 1.16063 - loss: 1.85146
[2024-02-27 18:37:10,656][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 1.63406
[2024-02-27 18:37:10,656][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50487
[2024-02-27 18:37:36,803][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.81867
[2024-02-27 18:37:36,803][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.54331
[2024-02-27 18:38:03,534][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 1.85177
[2024-02-27 18:38:03,534][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.52238
[2024-02-27 18:38:29,737][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51602
[2024-02-27 18:38:29,737][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50959
[2024-02-27 18:38:56,440][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51193
[2024-02-27 18:38:56,440][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51196
[2024-02-27 18:39:22,563][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.82825
[2024-02-27 18:39:22,563][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51107
[2024-02-27 18:39:49,169][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51688
[2024-02-27 18:39:49,169][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50669
[2024-02-27 18:40:15,435][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50785
[2024-02-27 18:40:15,436][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.68052
[2024-02-27 18:40:42,163][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50833
[2024-02-27 18:40:42,163][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51859
[2024-02-27 18:41:08,452][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.51096
[2024-02-27 18:41:08,452][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.88426 - val_accuracy: 0.71760 - train_loss: 0.87982 - val_loss: 1.42449 - loss: 0.50815
[2024-02-27 18:42:02,696][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.56157
[2024-02-27 18:42:02,696][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.99055
[2024-02-27 18:42:28,896][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51031
[2024-02-27 18:42:28,896][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50572
[2024-02-27 18:42:55,614][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51483
[2024-02-27 18:42:55,614][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50991
[2024-02-27 18:43:21,779][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.52710
[2024-02-27 18:43:21,779][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51345
[2024-02-27 18:43:48,484][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50637
[2024-02-27 18:43:48,484][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51018
[2024-02-27 18:44:14,665][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51300
[2024-02-27 18:44:14,665][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.52789
[2024-02-27 18:44:41,294][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.57334
[2024-02-27 18:44:41,294][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50845
[2024-02-27 18:45:07,488][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51159
[2024-02-27 18:45:07,488][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 1.89166
[2024-02-27 18:45:34,189][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.54421
[2024-02-27 18:45:34,189][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.51195
[2024-02-27 18:46:00,227][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50849
[2024-02-27 18:46:00,227][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.89038 - val_accuracy: 0.77370 - train_loss: 0.80630 - val_loss: 1.10200 - loss: 0.50955
[2024-02-27 18:46:54,452][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.78554
[2024-02-27 18:46:54,452][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.50608
[2024-02-27 18:47:20,430][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51147
[2024-02-27 18:47:20,430][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51586
[2024-02-27 18:47:47,063][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.52060
[2024-02-27 18:47:47,063][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.55966
[2024-02-27 18:48:13,181][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.50474
[2024-02-27 18:48:13,181][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51352
[2024-02-27 18:48:39,752][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 1.45823
[2024-02-27 18:48:39,752][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51910
[2024-02-27 18:49:05,846][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51908
[2024-02-27 18:49:05,846][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.50712
[2024-02-27 18:49:32,494][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.52161
[2024-02-27 18:49:32,494][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51888
[2024-02-27 18:49:59,065][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.52156
[2024-02-27 18:49:59,065][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 1.77295
[2024-02-27 18:50:25,141][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 1.85636
[2024-02-27 18:50:25,141][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.88950 - val_accuracy: 0.79190 - train_loss: 0.82936 - val_loss: 1.05587 - loss: 0.51429
[2024-02-27 18:51:20,335][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.52191
[2024-02-27 18:51:20,335][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.51668
[2024-02-27 18:51:46,491][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.50782
[2024-02-27 18:51:46,491][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.74701
[2024-02-27 18:52:13,205][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.52364
[2024-02-27 18:52:13,205][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.51262
[2024-02-27 18:52:39,269][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.79366
[2024-02-27 18:52:39,270][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 1.85974
[2024-02-27 18:53:05,859][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.59374
[2024-02-27 18:53:05,859][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.50676
[2024-02-27 18:53:32,026][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.52934
[2024-02-27 18:53:32,026][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.51342
[2024-02-27 18:53:58,552][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.51875
[2024-02-27 18:53:58,552][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.51421
[2024-02-27 18:54:24,532][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.50678
[2024-02-27 18:54:24,532][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.50785
[2024-02-27 18:54:51,074][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.61315
[2024-02-27 18:54:51,074][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.60306
[2024-02-27 18:55:17,293][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.52625
[2024-02-27 18:55:17,293][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.90629 - val_accuracy: 0.83120 - train_loss: 0.78007 - val_loss: 0.96490 - loss: 0.81725
[2024-02-27 18:56:11,275][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51296
[2024-02-27 18:56:11,275][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.55156
[2024-02-27 18:56:37,438][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51353
[2024-02-27 18:56:37,438][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51037
[2024-02-27 18:57:03,977][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51574
[2024-02-27 18:57:03,977][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.64848
[2024-02-27 18:57:30,102][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.53037
[2024-02-27 18:57:30,102][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51248
[2024-02-27 18:57:56,677][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.52123
[2024-02-27 18:57:56,677][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50570
[2024-02-27 18:58:22,748][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50675
[2024-02-27 18:58:22,748][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51213
[2024-02-27 18:58:49,335][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.52239
[2024-02-27 18:58:49,335][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50858
[2024-02-27 18:59:15,539][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.51125
[2024-02-27 18:59:15,539][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50371
[2024-02-27 18:59:42,182][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50625
[2024-02-27 18:59:42,182][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.96596
[2024-02-27 19:00:08,345][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50737
[2024-02-27 19:00:08,345][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.90325 - val_accuracy: 0.71420 - train_loss: 0.79097 - val_loss: 1.34101 - loss: 0.50635
[2024-02-27 19:01:02,111][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.50446
[2024-02-27 19:01:02,111][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.52602
[2024-02-27 19:01:28,318][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 1.87104
[2024-02-27 19:01:28,318][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.53289
[2024-02-27 19:01:54,815][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 1.57062
[2024-02-27 19:01:54,815][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.51163
[2024-02-27 19:02:21,014][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.50486
[2024-02-27 19:02:21,014][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.50616
[2024-02-27 19:02:47,435][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.55458
[2024-02-27 19:02:47,435][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.95802
[2024-02-27 19:03:13,512][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.51833
[2024-02-27 19:03:13,512][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.74989
[2024-02-27 19:03:40,258][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.56732
[2024-02-27 19:03:40,258][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.59331
[2024-02-27 19:04:06,344][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.64457
[2024-02-27 19:04:06,344][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.50954
[2024-02-27 19:04:32,984][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.51082
[2024-02-27 19:04:32,984][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.99178
[2024-02-27 19:04:59,111][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.51066
[2024-02-27 19:04:59,112][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.88666 - val_accuracy: 0.73530 - train_loss: 0.84777 - val_loss: 1.28185 - loss: 0.51113
[2024-02-27 19:05:52,960][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.96090
[2024-02-27 19:05:52,960][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.51494
[2024-02-27 19:06:19,619][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 1.45646
[2024-02-27 19:06:19,619][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.59360
[2024-02-27 19:06:45,670][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.50463
[2024-02-27 19:06:45,670][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.65429
[2024-02-27 19:07:12,244][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.51273
[2024-02-27 19:07:12,244][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.50826
[2024-02-27 19:07:38,271][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 1.08445
[2024-02-27 19:07:38,271][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 1.49581
[2024-02-27 19:08:04,908][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.68342
[2024-02-27 19:08:04,909][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.50409
[2024-02-27 19:08:31,005][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.66774
[2024-02-27 19:08:31,005][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.51377
[2024-02-27 19:08:57,672][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.58269
[2024-02-27 19:08:57,672][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.52014
[2024-02-27 19:09:23,846][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.51252
[2024-02-27 19:09:23,846][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.89892 - val_accuracy: 0.80440 - train_loss: 0.76923 - val_loss: 0.99156 - loss: 0.50289
[2024-02-27 19:10:17,532][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51343
[2024-02-27 19:10:17,532][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51317
[2024-02-27 19:10:43,621][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.89403
[2024-02-27 19:10:43,621][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.52922
[2024-02-27 19:11:10,130][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.50925
[2024-02-27 19:11:10,130][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51314
[2024-02-27 19:11:36,322][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51077
[2024-02-27 19:11:36,322][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.73364
[2024-02-27 19:12:02,928][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 1.02596
[2024-02-27 19:12:02,928][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.50286
[2024-02-27 19:12:29,102][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.58592
[2024-02-27 19:12:29,103][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.50550
[2024-02-27 19:12:55,674][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 1.01283
[2024-02-27 19:12:55,674][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51923
[2024-02-27 19:13:21,942][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51434
[2024-02-27 19:13:21,942][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51596
[2024-02-27 19:13:48,509][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 1.48766
[2024-02-27 19:13:48,509][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.50528
[2024-02-27 19:14:14,685][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.51453
[2024-02-27 19:14:14,686][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.89995 - val_accuracy: 0.69050 - train_loss: 0.78175 - val_loss: 1.36133 - loss: 0.53614
[2024-02-27 19:15:08,605][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 1.53095
[2024-02-27 19:15:08,605][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51004
[2024-02-27 19:15:34,829][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.50514
[2024-02-27 19:15:34,829][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.57008
[2024-02-27 19:16:01,391][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.50574
[2024-02-27 19:16:01,392][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51018
[2024-02-27 19:16:27,697][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51034
[2024-02-27 19:16:27,697][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51016
[2024-02-27 19:16:54,421][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.50493
[2024-02-27 19:16:54,421][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.53267
[2024-02-27 19:17:20,446][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51153
[2024-02-27 19:17:20,446][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.73312
[2024-02-27 19:17:47,040][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.50347
[2024-02-27 19:17:47,040][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.50769
[2024-02-27 19:18:13,247][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.55448
[2024-02-27 19:18:13,247][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.93725
[2024-02-27 19:18:39,797][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51071
[2024-02-27 19:18:39,797][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51588
[2024-02-27 19:19:06,030][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.51531
[2024-02-27 19:19:06,030][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.90146 - val_accuracy: 0.79440 - train_loss: 0.78935 - val_loss: 1.09516 - loss: 0.57564
[2024-02-27 19:19:59,948][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50439
[2024-02-27 19:19:59,948][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.52412
[2024-02-27 19:20:26,128][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.53905
[2024-02-27 19:20:26,128][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.77848
[2024-02-27 19:20:53,066][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.52049
[2024-02-27 19:20:53,066][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50417
[2024-02-27 19:21:19,628][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.56588
[2024-02-27 19:21:19,628][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.52550
[2024-02-27 19:21:45,736][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.51527
[2024-02-27 19:21:45,736][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 1.81033
[2024-02-27 19:22:12,771][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50289
[2024-02-27 19:22:12,771][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50429
[2024-02-27 19:22:38,931][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50500
[2024-02-27 19:22:38,931][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.51133
[2024-02-27 19:23:05,905][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 1.83419
[2024-02-27 19:23:05,905][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.50428
[2024-02-27 19:23:32,018][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.51435
[2024-02-27 19:23:32,018][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.84431 - val_accuracy: 0.73880 - train_loss: 0.92603 - val_loss: 1.18382 - loss: 0.51154
[2024-02-27 19:24:26,875][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50516
[2024-02-27 19:24:26,875][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50881
[2024-02-27 19:24:53,063][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50779
[2024-02-27 19:24:53,063][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50481
[2024-02-27 19:25:19,539][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 1.45791
[2024-02-27 19:25:19,539][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50819
[2024-02-27 19:25:45,673][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 1.87943
[2024-02-27 19:25:45,673][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 1.22465
[2024-02-27 19:26:12,384][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50450
[2024-02-27 19:26:12,384][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.51880
[2024-02-27 19:26:38,470][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.52034
[2024-02-27 19:26:38,470][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 1.00747
[2024-02-27 19:27:05,138][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50491
[2024-02-27 19:27:05,138][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50382
[2024-02-27 19:27:31,359][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50712
[2024-02-27 19:27:31,359][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50803
[2024-02-27 19:27:57,968][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.52058
[2024-02-27 19:27:57,968][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.61248
[2024-02-27 19:28:24,087][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50456
[2024-02-27 19:28:24,087][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.84057 - val_accuracy: 0.81400 - train_loss: 1.00652 - val_loss: 1.03723 - loss: 0.50251
[2024-02-27 19:29:17,877][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.51765
[2024-02-27 19:29:17,877][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50460
[2024-02-27 19:29:44,061][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50873
[2024-02-27 19:29:44,060][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50337
[2024-02-27 19:30:10,749][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50368
[2024-02-27 19:30:10,749][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.51052
[2024-02-27 19:30:36,967][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50828
[2024-02-27 19:30:36,967][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50290
[2024-02-27 19:31:03,580][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.51955
[2024-02-27 19:31:03,580][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50859
[2024-02-27 19:31:29,710][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50629
[2024-02-27 19:31:29,710][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 1.79743
[2024-02-27 19:31:56,274][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.59831
[2024-02-27 19:31:56,274][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50779
[2024-02-27 19:32:22,558][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50393
[2024-02-27 19:32:22,558][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 1.25181
[2024-02-27 19:32:49,145][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 1.47648
[2024-02-27 19:32:49,145][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50620
[2024-02-27 19:33:15,267][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50387
[2024-02-27 19:33:15,267][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.87107 - val_accuracy: 0.82550 - train_loss: 0.88020 - val_loss: 0.95476 - loss: 0.50675
[2024-02-27 19:34:09,166][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50617
[2024-02-27 19:34:09,166][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50919
[2024-02-27 19:34:35,334][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.55290
[2024-02-27 19:34:35,334][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.69312
[2024-02-27 19:35:01,889][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50257
[2024-02-27 19:35:01,889][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.52561
[2024-02-27 19:35:27,935][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.51439
[2024-02-27 19:35:27,935][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50390
[2024-02-27 19:35:54,464][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50594
[2024-02-27 19:35:54,464][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50795
[2024-02-27 19:36:20,701][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50412
[2024-02-27 19:36:20,701][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50628
[2024-02-27 19:36:47,212][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.52199
[2024-02-27 19:36:47,212][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.51336
[2024-02-27 19:37:13,770][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50764
[2024-02-27 19:37:13,770][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.51947
[2024-02-27 19:37:39,844][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.50623
[2024-02-27 19:37:39,844][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.90782 - val_accuracy: 0.80850 - train_loss: 0.78118 - val_loss: 1.03133 - loss: 0.52454
[2024-02-27 19:38:33,602][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50357
[2024-02-27 19:38:33,602][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.51046
[2024-02-27 19:38:59,772][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.52144
[2024-02-27 19:38:59,772][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50356
[2024-02-27 19:39:26,262][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50331
[2024-02-27 19:39:26,262][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50276
[2024-02-27 19:39:52,422][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50844
[2024-02-27 19:39:52,422][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.52299
[2024-02-27 19:40:19,249][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50172
[2024-02-27 19:40:19,249][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.51616
[2024-02-27 19:40:45,341][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.59061
[2024-02-27 19:40:45,341][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50714
[2024-02-27 19:41:11,895][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50155
[2024-02-27 19:41:11,895][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.53930
[2024-02-27 19:41:38,004][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.52370
[2024-02-27 19:41:38,004][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50546
[2024-02-27 19:42:04,525][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50440
[2024-02-27 19:42:04,525][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50585
[2024-02-27 19:42:30,664][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.50402
[2024-02-27 19:42:30,664][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.91273 - val_accuracy: 0.78990 - train_loss: 0.74668 - val_loss: 1.07868 - loss: 0.52537
[2024-02-27 19:43:24,285][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.51484
[2024-02-27 19:43:24,285][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50198
[2024-02-27 19:43:50,484][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50453
[2024-02-27 19:43:50,484][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50930
[2024-02-27 19:44:17,542][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50395
[2024-02-27 19:44:17,542][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.59137
[2024-02-27 19:44:43,790][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50743
[2024-02-27 19:44:43,790][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50492
[2024-02-27 19:45:10,404][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.66353
[2024-02-27 19:45:10,404][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.58508
[2024-02-27 19:45:36,494][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50673
[2024-02-27 19:45:36,494][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50639
[2024-02-27 19:46:03,085][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.51164
[2024-02-27 19:46:03,085][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.69782
[2024-02-27 19:46:29,291][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50819
[2024-02-27 19:46:29,291][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50240
[2024-02-27 19:46:55,851][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50294
[2024-02-27 19:46:55,851][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.50426
[2024-02-27 19:47:21,954][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 0.51558
[2024-02-27 19:47:21,954][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.91112 - val_accuracy: 0.72860 - train_loss: 0.75102 - val_loss: 1.22787 - loss: 1.90884
[2024-02-27 19:48:15,701][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 1.13231
[2024-02-27 19:48:15,701][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50179
[2024-02-27 19:48:41,906][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.92500
[2024-02-27 19:48:41,906][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.51059
[2024-02-27 19:49:08,599][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50173
[2024-02-27 19:49:08,599][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50243
[2024-02-27 19:49:34,836][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50214
[2024-02-27 19:49:34,836][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50291
[2024-02-27 19:50:01,632][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50969
[2024-02-27 19:50:01,632][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.71171
[2024-02-27 19:50:27,719][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50527
[2024-02-27 19:50:27,719][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.74309
[2024-02-27 19:50:54,283][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 1.89945
[2024-02-27 19:50:54,283][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50525
[2024-02-27 19:51:20,556][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.51981
[2024-02-27 19:51:20,556][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50645
[2024-02-27 19:51:47,095][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 1.43639
[2024-02-27 19:51:47,095][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50294
[2024-02-27 19:52:13,212][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50205
[2024-02-27 19:52:13,212][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 0.90647 - val_accuracy: 0.70250 - train_loss: 0.76412 - val_loss: 1.30417 - loss: 0.50216
[2024-02-27 19:53:07,104][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50381
[2024-02-27 19:53:07,104][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.56638
[2024-02-27 19:53:33,593][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.53559
[2024-02-27 19:53:33,593][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50822
[2024-02-27 19:53:59,827][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.86579
[2024-02-27 19:53:59,827][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50314
[2024-02-27 19:54:26,545][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50483
[2024-02-27 19:54:26,545][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50320
[2024-02-27 19:54:52,596][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50391
[2024-02-27 19:54:52,596][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50158
[2024-02-27 19:55:19,200][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50551
[2024-02-27 19:55:19,200][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50274
[2024-02-27 19:55:45,268][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50239
[2024-02-27 19:55:45,268][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.52464
[2024-02-27 19:56:12,066][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50513
[2024-02-27 19:56:12,066][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50255
[2024-02-27 19:56:38,154][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.50375
[2024-02-27 19:56:38,154][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.88825 - val_accuracy: 0.75400 - train_loss: 0.83742 - val_loss: 1.21109 - loss: 0.51496
[2024-02-27 19:57:31,893][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 0.50484
[2024-02-27 19:57:31,893][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 0.81262
[2024-02-27 19:57:57,948][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 0.50242
[2024-02-27 19:57:57,948][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 1.74141
[2024-02-27 19:58:24,383][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 0.51424
[2024-02-27 19:58:24,383][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.88775 - val_accuracy: 0.73650 - train_loss: 0.85823 - val_loss: 1.31369 - loss: 0.80718
slurmstepd: error: *** JOB 55705874 ON r22g39 CANCELLED AT 2024-02-27T19:58:41 DUE TO TIME LIMIT ***
