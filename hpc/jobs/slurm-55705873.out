SLURM_JOB_ID: 55705873
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: dct_cifar10_com
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r23g36
SLURM_JOB_CPUS_PER_NODE: 18
SLURM_JOB_GPUS: 0,1
Date: Tue Feb 27 06:27:19 CET 2024
Walltime: 00-12:00:00
========================================================================
2024-02-27 06:27:29,279 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 06:27:29,279 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 06:27:29,279 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x15490b4d13a0>' in 2 processes
2024-02-27 06:27:39,992 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 06:27:42,572 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1471c79ceab0>}
2024-02-27 06:27:42,906 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1471c79fe390>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-27 06:27:42,918][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 06:27:42,918][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 06:27:42,918][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 06:27:42,918][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 06:27:42,918][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 06:27:42,918][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 06:27:42,918][PyLogger][INFO]: World size: 2
[2024-02-27 06:27:42,938][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 06:27:42,938][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 06:27:42,938][PyLogger][INFO]: World size: 2
[2024-02-27 06:28:10,139][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 2.44395
[2024-02-27 06:28:10,139][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 3.45052
[2024-02-27 06:28:31,281][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.35863
[2024-02-27 06:28:31,281][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.50364
[2024-02-27 06:28:52,372][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.29244
[2024-02-27 06:28:52,372][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.40310
[2024-02-27 06:29:13,635][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.34553
[2024-02-27 06:29:13,635][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.27925
[2024-02-27 06:29:35,387][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.30216
[2024-02-27 06:29:35,387][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 2.36650
[2024-02-27 06:29:55,826][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 2.17901
[2024-02-27 06:29:55,826][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.20821
[2024-02-27 06:30:16,766][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 2.17000
[2024-02-27 06:30:16,766][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 2.17289
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-27 06:30:36,895][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 2.03529
[2024-02-27 06:30:36,895][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 2.04474
[2024-02-27 06:30:57,716][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 2.23439
[2024-02-27 06:30:57,716][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 2.22896
[2024-02-27 06:31:39,383][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 2.03859
[2024-02-27 06:31:39,383][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.99124
[2024-02-27 06:32:00,886][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.96082
[2024-02-27 06:32:00,886][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.94663
[2024-02-27 06:32:21,630][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.91169
[2024-02-27 06:32:21,630][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 2.01305
[2024-02-27 06:32:43,427][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 2.07063
[2024-02-27 06:32:43,427][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.88708
[2024-02-27 06:33:04,403][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 2.03636
[2024-02-27 06:33:04,403][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.73737
[2024-02-27 06:33:25,353][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.67390
[2024-02-27 06:33:25,353][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.78137
[2024-02-27 06:33:46,567][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.83068
[2024-02-27 06:33:46,567][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.72524
[2024-02-27 06:34:06,939][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 2.17526
[2024-02-27 06:34:06,939][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.70689
[2024-02-27 06:34:28,352][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.73263
[2024-02-27 06:34:28,352][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.78530
[2024-02-27 06:34:48,862][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.77656
[2024-02-27 06:34:48,862][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.15430 - val_accuracy: 0.16730 - train_loss: 2.40734 - val_loss: 2.49227 - loss: 1.78973
[2024-02-27 06:35:30,690][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.82552
[2024-02-27 06:35:30,690][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.63856
[2024-02-27 06:35:51,054][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.62457
[2024-02-27 06:35:51,054][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.94140
[2024-02-27 06:36:12,059][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.61692
[2024-02-27 06:36:12,059][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.54209
[2024-02-27 06:36:32,506][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.57011
[2024-02-27 06:36:32,506][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.58897
[2024-02-27 06:36:53,538][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.58455
[2024-02-27 06:36:53,538][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.65129
[2024-02-27 06:37:14,368][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.64409
[2024-02-27 06:37:14,368][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.64886
[2024-02-27 06:37:34,540][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.52031
[2024-02-27 06:37:34,540][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.58597
[2024-02-27 06:37:55,130][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.52845
[2024-02-27 06:37:55,130][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.53054
[2024-02-27 06:38:16,125][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.67609
[2024-02-27 06:38:16,125][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.63264
[2024-02-27 06:38:37,418][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.55519
[2024-02-27 06:38:37,418][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.25938 - val_accuracy: 0.25950 - train_loss: 2.27662 - val_loss: 2.41649 - loss: 1.74699
[2024-02-27 06:39:19,620][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.45182
[2024-02-27 06:39:19,620][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.50535
[2024-02-27 06:39:40,857][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 2.14731
[2024-02-27 06:39:40,858][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.64876
[2024-02-27 06:40:03,271][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.50864
[2024-02-27 06:40:03,271][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.51621
[2024-02-27 06:40:24,756][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.49698
[2024-02-27 06:40:24,756][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.43170
[2024-02-27 06:40:45,001][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.65445
[2024-02-27 06:40:45,001][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.55058
[2024-02-27 06:41:06,014][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.70024
[2024-02-27 06:41:06,014][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.49921
[2024-02-27 06:41:26,516][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 2.03445
[2024-02-27 06:41:26,516][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.53469
[2024-02-27 06:41:47,892][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.47052
[2024-02-27 06:41:47,892][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.54352
[2024-02-27 06:42:08,487][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.53669
[2024-02-27 06:42:08,488][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.29428 - val_accuracy: 0.31500 - train_loss: 2.13295 - val_loss: 2.06559 - loss: 1.51331
[2024-02-27 06:42:49,706][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.42920
[2024-02-27 06:42:49,706][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.38504
[2024-02-27 06:43:10,495][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.45397
[2024-02-27 06:43:10,495][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.45670
[2024-02-27 06:43:31,579][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.75897
[2024-02-27 06:43:31,579][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.48189
[2024-02-27 06:43:53,481][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.43353
[2024-02-27 06:43:53,481][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.50383
[2024-02-27 06:44:15,266][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.49024
[2024-02-27 06:44:15,266][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.39029
[2024-02-27 06:44:37,133][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.38148
[2024-02-27 06:44:37,133][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.67925
[2024-02-27 06:44:59,063][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.46110
[2024-02-27 06:44:59,063][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.78264
[2024-02-27 06:45:19,186][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.56530
[2024-02-27 06:45:19,186][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.46562
[2024-02-27 06:45:40,249][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.44139
[2024-02-27 06:45:40,249][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.53249
[2024-02-27 06:46:00,664][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.54172
[2024-02-27 06:46:00,665][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.35597 - val_accuracy: 0.39930 - train_loss: 1.92859 - val_loss: 1.87809 - loss: 1.43987
[2024-02-27 06:46:43,173][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.36637
[2024-02-27 06:46:43,173][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.42400
[2024-02-27 06:47:04,274][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.36477
[2024-02-27 06:47:04,274][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.41041
[2024-02-27 06:47:25,281][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.82155
[2024-02-27 06:47:25,281][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.51374
[2024-02-27 06:47:46,579][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.90858
[2024-02-27 06:47:46,579][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.31077
[2024-02-27 06:48:06,966][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.45662
[2024-02-27 06:48:06,967][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.32209
[2024-02-27 06:48:28,361][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.34543
[2024-02-27 06:48:28,361][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.49304
[2024-02-27 06:48:48,654][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.91365
[2024-02-27 06:48:48,654][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.42307
[2024-02-27 06:49:09,649][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.50165
[2024-02-27 06:49:09,649][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.41574
[2024-02-27 06:49:31,074][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.89246
[2024-02-27 06:49:31,074][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.36005
[2024-02-27 06:49:51,687][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.42609
[2024-02-27 06:49:51,687][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.42977 - val_accuracy: 0.44460 - train_loss: 1.81679 - val_loss: 1.87344 - loss: 1.34564
[2024-02-27 06:50:34,799][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.43948
[2024-02-27 06:50:34,799][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.43254
[2024-02-27 06:50:54,851][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.36888
[2024-02-27 06:50:54,851][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.55643
[2024-02-27 06:51:16,875][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.32816
[2024-02-27 06:51:16,875][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.46430
[2024-02-27 06:51:37,040][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.56136
[2024-02-27 06:51:37,040][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.38341
[2024-02-27 06:51:58,178][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.32992
[2024-02-27 06:51:58,178][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.37082
[2024-02-27 06:52:18,949][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.87819
[2024-02-27 06:52:18,949][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.31681
[2024-02-27 06:52:40,935][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.38542
[2024-02-27 06:52:40,935][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.27229
[2024-02-27 06:53:01,977][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.33889
[2024-02-27 06:53:01,977][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.24761
[2024-02-27 06:53:22,905][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.36884
[2024-02-27 06:53:22,905][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.48262 - val_accuracy: 0.49390 - train_loss: 1.76278 - val_loss: 1.77588 - loss: 1.32308
[2024-02-27 06:54:05,178][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.34857
[2024-02-27 06:54:05,178][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.29494
[2024-02-27 06:54:26,180][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.50078
[2024-02-27 06:54:26,180][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.74882
[2024-02-27 06:54:47,983][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.41933
[2024-02-27 06:54:47,983][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.39194
[2024-02-27 06:55:08,266][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.45272
[2024-02-27 06:55:08,266][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.60592
[2024-02-27 06:55:29,134][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.40489
[2024-02-27 06:55:29,134][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.23398
[2024-02-27 06:55:49,516][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.22115
[2024-02-27 06:55:49,516][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.35189
[2024-02-27 06:56:10,961][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.24924
[2024-02-27 06:56:10,961][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.70979
[2024-02-27 06:56:31,942][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.81550
[2024-02-27 06:56:31,942][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.33160
[2024-02-27 06:56:53,099][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.30121
[2024-02-27 06:56:53,098][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.39510
[2024-02-27 06:57:13,312][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.31944
[2024-02-27 06:57:13,312][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.42016 - val_accuracy: 0.47130 - train_loss: 1.83451 - val_loss: 1.73080 - loss: 1.91337
[2024-02-27 06:57:54,945][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.28695
[2024-02-27 06:57:54,945][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.28616
[2024-02-27 06:58:15,287][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.64552
[2024-02-27 06:58:15,287][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.34380
[2024-02-27 06:58:36,276][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.75407
[2024-02-27 06:58:36,276][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.26550
[2024-02-27 06:58:57,902][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.35017
[2024-02-27 06:58:57,902][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.20133
[2024-02-27 06:59:18,653][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.32013
[2024-02-27 06:59:18,653][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.23992
[2024-02-27 06:59:39,083][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.19762
[2024-02-27 06:59:39,083][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.23384
[2024-02-27 07:00:00,577][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.28580
[2024-02-27 07:00:00,577][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.22016
[2024-02-27 07:00:22,134][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.20906
[2024-02-27 07:00:22,134][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.13487
[2024-02-27 07:00:43,281][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.29280
[2024-02-27 07:00:43,281][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.78223
[2024-02-27 07:01:03,599][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.16698
[2024-02-27 07:01:03,599][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.38565 - val_accuracy: 0.42710 - train_loss: 1.88144 - val_loss: 1.81704 - loss: 1.24601
[2024-02-27 07:01:45,604][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.15859
[2024-02-27 07:01:45,604][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.20454
[2024-02-27 07:02:06,149][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.27689
[2024-02-27 07:02:06,149][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.64977
[2024-02-27 07:02:26,920][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.20009
[2024-02-27 07:02:26,920][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.47897
[2024-02-27 07:02:47,833][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.16447
[2024-02-27 07:02:47,833][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.18005
[2024-02-27 07:03:08,662][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.53902
[2024-02-27 07:03:08,662][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.35129
[2024-02-27 07:03:29,869][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.36132
[2024-02-27 07:03:29,869][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.42870
[2024-02-27 07:03:51,254][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.32781
[2024-02-27 07:03:51,254][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.24059
[2024-02-27 07:04:12,480][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.75109
[2024-02-27 07:04:12,480][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.27205
[2024-02-27 07:04:33,621][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.63663
[2024-02-27 07:04:33,621][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.37084
[2024-02-27 07:04:54,508][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.26069
[2024-02-27 07:04:54,508][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.38668 - val_accuracy: 0.40000 - train_loss: 2.00255 - val_loss: 1.95980 - loss: 1.16525
[2024-02-27 07:05:36,617][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.17498
[2024-02-27 07:05:36,617][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.14170
[2024-02-27 07:05:57,489][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.16956
[2024-02-27 07:05:57,489][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.19851
[2024-02-27 07:06:18,287][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.21554
[2024-02-27 07:06:18,287][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.27851
[2024-02-27 07:06:40,144][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.21205
[2024-02-27 07:06:40,144][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.32264
[2024-02-27 07:07:00,881][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.20826
[2024-02-27 07:07:00,881][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.20831
[2024-02-27 07:07:22,000][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.13076
[2024-02-27 07:07:22,000][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.48649
[2024-02-27 07:07:42,581][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.35897
[2024-02-27 07:07:42,581][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.16849
[2024-02-27 07:08:05,274][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.31486
[2024-02-27 07:08:05,274][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.08422
[2024-02-27 07:08:26,375][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.74401
[2024-02-27 07:08:26,375][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.49122 - val_accuracy: 0.53020 - train_loss: 1.87585 - val_loss: 1.81602 - loss: 1.22887
[2024-02-27 07:09:10,271][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.19446
[2024-02-27 07:09:10,271][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.15100
[2024-02-27 07:09:30,021][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.06477
[2024-02-27 07:09:30,021][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.30040
[2024-02-27 07:09:51,041][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.25452
[2024-02-27 07:09:51,041][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.24683
[2024-02-27 07:10:12,634][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.27608
[2024-02-27 07:10:12,634][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.20056
[2024-02-27 07:10:34,218][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.07585
[2024-02-27 07:10:34,218][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.16361
[2024-02-27 07:10:55,033][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.48961
[2024-02-27 07:10:55,033][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.21342
[2024-02-27 07:11:16,008][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.33243
[2024-02-27 07:11:16,008][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.17799
[2024-02-27 07:11:36,116][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.40959
[2024-02-27 07:11:36,116][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.19567
[2024-02-27 07:11:58,570][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.13001
[2024-02-27 07:11:58,570][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.23845
[2024-02-27 07:12:19,738][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.47291
[2024-02-27 07:12:19,738][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.51144 - val_accuracy: 0.49890 - train_loss: 1.66630 - val_loss: 1.74494 - loss: 1.45636
[2024-02-27 07:13:01,961][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.11586
[2024-02-27 07:13:01,961][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.15701
[2024-02-27 07:13:22,664][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.09420
[2024-02-27 07:13:22,664][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.21581
[2024-02-27 07:13:43,794][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.24508
[2024-02-27 07:13:43,794][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.13083
[2024-02-27 07:14:04,521][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.37219
[2024-02-27 07:14:04,521][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.63907
[2024-02-27 07:14:25,734][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.50541
[2024-02-27 07:14:25,734][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.60309
[2024-02-27 07:14:47,197][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.41646
[2024-02-27 07:14:47,197][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.13030
[2024-02-27 07:15:08,039][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.98069
[2024-02-27 07:15:08,039][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.11913
[2024-02-27 07:15:28,553][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.52067
[2024-02-27 07:15:28,553][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.10412
[2024-02-27 07:15:50,241][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.33978
[2024-02-27 07:15:50,241][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.22936
[2024-02-27 07:16:10,959][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.12991
[2024-02-27 07:16:10,959][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.48111 - val_accuracy: 0.53090 - train_loss: 1.73614 - val_loss: 1.61541 - loss: 1.09501
[2024-02-27 07:16:52,187][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.22053
[2024-02-27 07:16:52,187][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.24756
[2024-02-27 07:17:13,473][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.16464
[2024-02-27 07:17:13,473][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.15397
[2024-02-27 07:17:34,358][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.09468
[2024-02-27 07:17:34,358][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.37439
[2024-02-27 07:17:55,465][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.01521
[2024-02-27 07:17:55,465][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.02599
[2024-02-27 07:18:16,411][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.35878
[2024-02-27 07:18:16,411][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.15431
[2024-02-27 07:18:37,546][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.12229
[2024-02-27 07:18:37,546][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.11740
[2024-02-27 07:18:57,439][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.20571
[2024-02-27 07:18:57,439][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.41913
[2024-02-27 07:19:18,153][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.15098
[2024-02-27 07:19:18,153][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.09441
[2024-02-27 07:19:39,658][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.77610
[2024-02-27 07:19:39,658][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.46001 - val_accuracy: 0.39860 - train_loss: 1.74586 - val_loss: 1.87636 - loss: 1.17893
[2024-02-27 07:20:20,827][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.27776
[2024-02-27 07:20:20,827][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.08190
[2024-02-27 07:20:41,534][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.69356
[2024-02-27 07:20:41,535][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.24568
[2024-02-27 07:21:02,251][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.23108
[2024-02-27 07:21:02,251][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.14675
[2024-02-27 07:21:23,415][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.00786
[2024-02-27 07:21:23,415][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.11506
[2024-02-27 07:21:44,519][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.08448
[2024-02-27 07:21:44,519][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.02209
[2024-02-27 07:22:03,950][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.06055
[2024-02-27 07:22:03,950][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.07994
[2024-02-27 07:22:24,681][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.76869
[2024-02-27 07:22:24,681][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.06500
[2024-02-27 07:22:45,775][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.18108
[2024-02-27 07:22:45,775][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.49633
[2024-02-27 07:23:07,237][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.07740
[2024-02-27 07:23:07,237][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.40139
[2024-02-27 07:23:27,560][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.03154
[2024-02-27 07:23:27,560][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.59091 - val_accuracy: 0.55560 - train_loss: 1.52172 - val_loss: 1.62530 - loss: 1.02312
[2024-02-27 07:24:09,810][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.03904
[2024-02-27 07:24:09,810][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.17265
[2024-02-27 07:24:30,864][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.98974
[2024-02-27 07:24:30,864][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.23824
[2024-02-27 07:24:52,151][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.01356
[2024-02-27 07:24:52,151][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.05311
[2024-02-27 07:25:12,450][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.40254
[2024-02-27 07:25:12,450][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.13777
[2024-02-27 07:25:33,290][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.47342
[2024-02-27 07:25:33,290][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.03782
[2024-02-27 07:25:53,712][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.95069
[2024-02-27 07:25:53,712][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.10701
[2024-02-27 07:26:15,281][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.01943
[2024-02-27 07:26:15,281][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.97670
[2024-02-27 07:26:36,374][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.99639
[2024-02-27 07:26:36,374][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.98940
[2024-02-27 07:26:57,611][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.93059
[2024-02-27 07:26:57,611][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 1.33008
[2024-02-27 07:27:18,730][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 2.00742
[2024-02-27 07:27:18,731][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.41728 - val_accuracy: 0.42980 - train_loss: 1.84417 - val_loss: 1.80750 - loss: 0.97964
[2024-02-27 07:28:00,197][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.66659
[2024-02-27 07:28:00,197][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.10042
[2024-02-27 07:28:21,368][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.05567
[2024-02-27 07:28:21,368][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.25709
[2024-02-27 07:28:41,889][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 0.98099
[2024-02-27 07:28:41,889][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.03868
[2024-02-27 07:29:02,696][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.14897
[2024-02-27 07:29:02,696][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.05131
[2024-02-27 07:29:23,365][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.93133
[2024-02-27 07:29:23,365][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.10715
[2024-02-27 07:29:43,655][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.03368
[2024-02-27 07:29:43,655][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.01535
[2024-02-27 07:30:04,782][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.97635
[2024-02-27 07:30:04,782][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.46101
[2024-02-27 07:30:26,258][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 0.91651
[2024-02-27 07:30:26,258][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 0.88488
[2024-02-27 07:30:46,963][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 1.27581
[2024-02-27 07:30:46,963][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.56355 - val_accuracy: 0.54810 - train_loss: 1.57667 - val_loss: 1.61782 - loss: 2.01983
[2024-02-27 07:31:27,370][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.96255
[2024-02-27 07:31:27,370][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.95385
[2024-02-27 07:31:47,109][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.03499
[2024-02-27 07:31:47,109][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.02112
[2024-02-27 07:32:08,978][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.00184
[2024-02-27 07:32:08,978][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.87726
[2024-02-27 07:32:29,700][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.02544
[2024-02-27 07:32:29,700][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.96735
[2024-02-27 07:32:50,641][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.78438
[2024-02-27 07:32:50,641][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.01786
[2024-02-27 07:33:12,301][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.99527
[2024-02-27 07:33:12,301][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.98331
[2024-02-27 07:33:34,244][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.04443
[2024-02-27 07:33:34,244][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.09264
[2024-02-27 07:33:54,104][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.07986
[2024-02-27 07:33:54,104][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.07550
[2024-02-27 07:34:15,168][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.03819
[2024-02-27 07:34:15,168][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.07245
[2024-02-27 07:34:36,245][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 1.97186
[2024-02-27 07:34:36,245][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.53596 - val_accuracy: 0.56010 - train_loss: 1.59152 - val_loss: 1.53424 - loss: 0.94797
[2024-02-27 07:35:18,018][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.91839
[2024-02-27 07:35:18,017][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.57685
[2024-02-27 07:35:38,878][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.40213
[2024-02-27 07:35:38,878][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.16808
[2024-02-27 07:36:00,004][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.41907
[2024-02-27 07:36:00,004][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.06923
[2024-02-27 07:36:20,987][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.44901
[2024-02-27 07:36:20,987][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.07619
[2024-02-27 07:36:42,058][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.01280
[2024-02-27 07:36:42,058][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.07894
[2024-02-27 07:37:01,781][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.99946
[2024-02-27 07:37:01,781][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.95056
[2024-02-27 07:37:23,227][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.08649
[2024-02-27 07:37:23,227][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.01255
[2024-02-27 07:37:42,932][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.98774
[2024-02-27 07:37:42,932][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.94974
[2024-02-27 07:38:03,675][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.00952
[2024-02-27 07:38:03,675][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 0.91438
[2024-02-27 07:38:23,268][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 1.32170
[2024-02-27 07:38:23,268][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.50681 - val_accuracy: 0.48530 - train_loss: 1.66844 - val_loss: 1.76532 - loss: 2.04607
[2024-02-27 07:39:06,078][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.90746
[2024-02-27 07:39:06,078][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.95289
[2024-02-27 07:39:26,467][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.73505
[2024-02-27 07:39:26,468][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.33332
[2024-02-27 07:39:47,464][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.93346
[2024-02-27 07:39:47,464][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.03850
[2024-02-27 07:40:08,728][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.93569
[2024-02-27 07:40:08,728][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.89206
[2024-02-27 07:40:30,060][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.98459
[2024-02-27 07:40:30,060][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 2.05132
[2024-02-27 07:40:50,381][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.17755
[2024-02-27 07:40:50,381][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.07059
[2024-02-27 07:41:11,238][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.25444
[2024-02-27 07:41:11,238][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.93569
[2024-02-27 07:41:31,592][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.92348
[2024-02-27 07:41:31,592][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.91340
[2024-02-27 07:41:53,229][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 1.38276
[2024-02-27 07:41:53,229][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.86342
[2024-02-27 07:42:14,041][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.96163
[2024-02-27 07:42:14,041][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.45947 - val_accuracy: 0.45120 - train_loss: 1.71206 - val_loss: 1.76318 - loss: 0.99703
[2024-02-27 07:42:54,982][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 1.61603
[2024-02-27 07:42:54,982][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 1.00419
[2024-02-27 07:43:15,736][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.88650
[2024-02-27 07:43:15,736][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.88967
[2024-02-27 07:43:36,154][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.86763
[2024-02-27 07:43:36,154][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.92244
[2024-02-27 07:43:56,140][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.91841
[2024-02-27 07:43:56,140][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.88329
[2024-02-27 07:44:16,498][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 1.10147
[2024-02-27 07:44:16,498][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 1.01655
[2024-02-27 07:44:37,004][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.86946
[2024-02-27 07:44:37,004][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.88952
[2024-02-27 07:44:56,816][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.89044
[2024-02-27 07:44:56,816][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 1.01754
[2024-02-27 07:45:18,025][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.93568
[2024-02-27 07:45:18,025][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.89021
[2024-02-27 07:45:38,214][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.93631
[2024-02-27 07:45:38,214][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.40039 - val_accuracy: 0.38370 - train_loss: 1.92850 - val_loss: 1.99195 - loss: 0.97309
[2024-02-27 07:46:20,523][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.82053
[2024-02-27 07:46:20,523][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.83146
[2024-02-27 07:46:42,590][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.05896
[2024-02-27 07:46:42,590][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.90714
[2024-02-27 07:47:03,635][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.65953
[2024-02-27 07:47:03,635][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.83149
[2024-02-27 07:47:24,711][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.32483
[2024-02-27 07:47:24,711][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.91193
[2024-02-27 07:47:45,981][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.07494
[2024-02-27 07:47:45,981][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.90809
[2024-02-27 07:48:06,069][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.98763
[2024-02-27 07:48:06,069][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.89110
[2024-02-27 07:48:26,473][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.92715
[2024-02-27 07:48:26,473][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.16103
[2024-02-27 07:48:47,253][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.87605
[2024-02-27 07:48:47,253][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.02076
[2024-02-27 07:49:07,826][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.81020
[2024-02-27 07:49:07,826][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 0.77901
[2024-02-27 07:49:29,048][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.49684
[2024-02-27 07:49:29,048][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.45131 - val_accuracy: 0.47180 - train_loss: 1.82564 - val_loss: 1.83964 - loss: 1.61920
[2024-02-27 07:50:09,425][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 1.98386
[2024-02-27 07:50:09,425][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 1.03155
[2024-02-27 07:50:30,127][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.86421
[2024-02-27 07:50:30,127][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.89482
[2024-02-27 07:50:51,465][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 1.00535
[2024-02-27 07:50:51,466][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.82472
[2024-02-27 07:51:11,831][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.87490
[2024-02-27 07:51:11,831][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 1.05464
[2024-02-27 07:51:33,062][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.96093
[2024-02-27 07:51:33,062][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.83483
[2024-02-27 07:51:53,804][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.85326
[2024-02-27 07:51:53,804][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.82027
[2024-02-27 07:52:14,424][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.90592
[2024-02-27 07:52:14,424][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.84939
[2024-02-27 07:52:34,990][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.87508
[2024-02-27 07:52:34,990][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.82801
[2024-02-27 07:52:56,870][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.78666
[2024-02-27 07:52:56,870][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.93351
[2024-02-27 07:53:17,145][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 1.17249
[2024-02-27 07:53:17,145][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.53808 - val_accuracy: 0.50040 - train_loss: 1.68380 - val_loss: 1.92634 - loss: 0.82902
[2024-02-27 07:53:58,573][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.87248
[2024-02-27 07:53:58,573][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 1.20239
[2024-02-27 07:54:19,305][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.98691
[2024-02-27 07:54:19,305][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.91672
[2024-02-27 07:54:40,612][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.96289
[2024-02-27 07:54:40,612][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.89923
[2024-02-27 07:55:01,295][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 1.21688
[2024-02-27 07:55:01,295][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.73591
[2024-02-27 07:55:21,120][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.82548
[2024-02-27 07:55:21,120][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.83154
[2024-02-27 07:55:41,841][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.81612
[2024-02-27 07:55:41,841][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.86254
[2024-02-27 07:56:02,620][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.82928
[2024-02-27 07:56:02,620][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.82159
[2024-02-27 07:56:23,892][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.99920
[2024-02-27 07:56:23,892][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.81112
[2024-02-27 07:56:44,133][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.94916
[2024-02-27 07:56:44,133][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.51287 - val_accuracy: 0.50990 - train_loss: 1.78344 - val_loss: 1.79208 - loss: 0.83178
[2024-02-27 07:57:25,556][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.83557
[2024-02-27 07:57:25,556][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 1.70333
[2024-02-27 07:57:46,372][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.96497
[2024-02-27 07:57:46,372][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.82027
[2024-02-27 07:58:07,177][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.80792
[2024-02-27 07:58:07,177][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.74834
[2024-02-27 07:58:27,800][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.94007
[2024-02-27 07:58:27,800][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.77015
[2024-02-27 07:58:48,289][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 1.69807
[2024-02-27 07:58:48,289][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.87733
[2024-02-27 07:59:08,165][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.78135
[2024-02-27 07:59:08,165][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.77196
[2024-02-27 07:59:29,148][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.87382
[2024-02-27 07:59:29,148][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.72554
[2024-02-27 07:59:49,536][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.77184
[2024-02-27 07:59:49,536][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.74963
[2024-02-27 08:00:09,781][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.75066
[2024-02-27 08:00:09,781][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.74407
[2024-02-27 08:00:30,146][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.86305
[2024-02-27 08:00:30,146][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.53298 - val_accuracy: 0.49230 - train_loss: 1.77010 - val_loss: 2.00915 - loss: 0.81773
[2024-02-27 08:01:12,104][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 1.90086
[2024-02-27 08:01:12,104][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.73429
[2024-02-27 08:01:33,097][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.73435
[2024-02-27 08:01:33,097][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.71378
[2024-02-27 08:01:54,394][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.76521
[2024-02-27 08:01:54,394][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.70792
[2024-02-27 08:02:14,142][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.84304
[2024-02-27 08:02:14,142][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.82782
[2024-02-27 08:02:34,431][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 1.94458
[2024-02-27 08:02:34,431][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.76558
[2024-02-27 08:02:54,739][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.81047
[2024-02-27 08:02:54,739][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.81250
[2024-02-27 08:03:14,489][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.75817
[2024-02-27 08:03:14,489][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.74586
[2024-02-27 08:03:34,801][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 1.17703
[2024-02-27 08:03:34,801][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.79380
[2024-02-27 08:03:56,489][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.67411
[2024-02-27 08:03:56,489][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.72633
[2024-02-27 08:04:16,251][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.74895
[2024-02-27 08:04:16,251][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.63007 - val_accuracy: 0.53500 - train_loss: 1.59212 - val_loss: 2.02062 - loss: 0.75060
[2024-02-27 08:04:58,035][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.68276
[2024-02-27 08:04:58,035][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.74137
[2024-02-27 08:05:18,054][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.93781
[2024-02-27 08:05:18,054][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.89734
[2024-02-27 08:05:38,018][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 1.02596
[2024-02-27 08:05:38,018][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.77004
[2024-02-27 08:05:58,058][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.76699
[2024-02-27 08:05:58,058][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.82487
[2024-02-27 08:06:19,483][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.69410
[2024-02-27 08:06:19,483][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.72502
[2024-02-27 08:06:40,739][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 1.20535
[2024-02-27 08:06:40,739][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.79700
[2024-02-27 08:07:02,779][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.67197
[2024-02-27 08:07:02,779][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.70879
[2024-02-27 08:07:22,949][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.69845
[2024-02-27 08:07:22,949][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.65124
[2024-02-27 08:07:43,841][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 1.27753
[2024-02-27 08:07:43,841][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.70840 - val_accuracy: 0.60830 - train_loss: 1.42990 - val_loss: 1.63518 - loss: 0.67699
[2024-02-27 08:08:26,278][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.82361
[2024-02-27 08:08:26,278][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.68123
[2024-02-27 08:08:46,427][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 1.11149
[2024-02-27 08:08:46,427][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.70799
[2024-02-27 08:09:06,511][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.83628
[2024-02-27 08:09:06,511][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.79144
[2024-02-27 08:09:27,572][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.70325
[2024-02-27 08:09:27,572][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 1.03578
[2024-02-27 08:09:48,267][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 1.02802
[2024-02-27 08:09:48,267][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.71073
[2024-02-27 08:10:08,798][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.76074
[2024-02-27 08:10:08,797][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.80610
[2024-02-27 08:10:30,128][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.63970
[2024-02-27 08:10:30,128][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.67170
[2024-02-27 08:10:50,977][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.77483
[2024-02-27 08:10:50,977][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.68172
[2024-02-27 08:11:13,467][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.67344
[2024-02-27 08:11:13,467][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.98380
[2024-02-27 08:11:33,898][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.68299
[2024-02-27 08:11:33,898][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.56508 - val_accuracy: 0.53240 - train_loss: 1.66500 - val_loss: 1.69921 - loss: 0.71146
[2024-02-27 08:12:14,174][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.69354
[2024-02-27 08:12:14,174][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.65169
[2024-02-27 08:12:34,660][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 1.12550
[2024-02-27 08:12:34,661][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.69807
[2024-02-27 08:12:55,498][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.76703
[2024-02-27 08:12:55,498][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.65472
[2024-02-27 08:13:15,564][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 1.08460
[2024-02-27 08:13:15,564][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.76031
[2024-02-27 08:13:38,216][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.65188
[2024-02-27 08:13:38,216][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.66910
[2024-02-27 08:13:58,510][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 1.14446
[2024-02-27 08:13:58,510][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.79657
[2024-02-27 08:14:19,605][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.73933
[2024-02-27 08:14:19,605][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.66050
[2024-02-27 08:14:40,458][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.94377
[2024-02-27 08:14:40,458][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.67300
[2024-02-27 08:15:01,407][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.69553
[2024-02-27 08:15:01,407][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.65561
[2024-02-27 08:15:22,112][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.69455
[2024-02-27 08:15:22,112][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.58282 - val_accuracy: 0.53290 - train_loss: 1.61384 - val_loss: 1.69307 - loss: 0.66583
[2024-02-27 08:16:03,547][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 2.04777
[2024-02-27 08:16:03,547][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 1.01303
[2024-02-27 08:16:24,239][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.77919
[2024-02-27 08:16:24,239][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.69916
[2024-02-27 08:16:44,757][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.64296
[2024-02-27 08:16:44,757][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.93618
[2024-02-27 08:17:05,464][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.65849
[2024-02-27 08:17:05,464][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.66818
[2024-02-27 08:17:26,238][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.67231
[2024-02-27 08:17:26,239][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.71452
[2024-02-27 08:17:47,131][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.61414
[2024-02-27 08:17:47,131][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.66907
[2024-02-27 08:18:07,712][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.67434
[2024-02-27 08:18:07,712][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.69752
[2024-02-27 08:18:28,022][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 1.14126
[2024-02-27 08:18:28,022][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.66282
[2024-02-27 08:18:49,432][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.62995
[2024-02-27 08:18:49,432][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.66197
[2024-02-27 08:19:10,550][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 1.02125
[2024-02-27 08:19:10,550][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.59810 - val_accuracy: 0.54220 - train_loss: 1.54469 - val_loss: 1.70386 - loss: 0.66477
[2024-02-27 08:19:53,185][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.62717
[2024-02-27 08:19:53,185][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.91192
[2024-02-27 08:20:14,991][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.61440
[2024-02-27 08:20:14,991][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.64683
[2024-02-27 08:20:36,447][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 1.07201
[2024-02-27 08:20:36,447][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.68910
[2024-02-27 08:20:58,020][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.94092
[2024-02-27 08:20:58,020][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.64540
[2024-02-27 08:21:17,984][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.58482
[2024-02-27 08:21:17,984][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.60808
[2024-02-27 08:21:38,696][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.60281
[2024-02-27 08:21:38,696][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.63970
[2024-02-27 08:21:59,110][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 1.18691
[2024-02-27 08:21:59,110][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.69253
[2024-02-27 08:22:20,945][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.61184
[2024-02-27 08:22:20,944][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 1.03614
[2024-02-27 08:22:41,921][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.64679
[2024-02-27 08:22:41,921][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.64977 - val_accuracy: 0.54140 - train_loss: 1.47377 - val_loss: 1.78821 - loss: 0.73357
[2024-02-27 08:23:22,850][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.81203
[2024-02-27 08:23:22,850][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.63788
[2024-02-27 08:23:43,845][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 1.11868
[2024-02-27 08:23:43,845][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.78723
[2024-02-27 08:24:04,546][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.92066
[2024-02-27 08:24:04,546][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.81738
[2024-02-27 08:24:25,002][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.70860
[2024-02-27 08:24:25,002][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.70943
[2024-02-27 08:24:45,765][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 1.71611
[2024-02-27 08:24:45,765][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.62693
[2024-02-27 08:25:06,547][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.65625
[2024-02-27 08:25:06,547][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.63071
[2024-02-27 08:25:27,277][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.63243
[2024-02-27 08:25:27,277][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.67745
[2024-02-27 08:25:47,908][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 1.02798
[2024-02-27 08:25:47,909][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.62732
[2024-02-27 08:26:09,587][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.65689
[2024-02-27 08:26:09,587][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.62196
[2024-02-27 08:26:29,403][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.64009
[2024-02-27 08:26:29,403][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.67377 - val_accuracy: 0.50970 - train_loss: 1.46338 - val_loss: 2.03177 - loss: 0.67005
[2024-02-27 08:27:10,856][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.07743
[2024-02-27 08:27:10,856][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.73122
[2024-02-27 08:27:30,599][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.62994
[2024-02-27 08:27:30,599][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.64876
[2024-02-27 08:27:51,752][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.01357
[2024-02-27 08:27:51,752][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.65906
[2024-02-27 08:28:11,921][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.61927
[2024-02-27 08:28:11,921][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.71415
[2024-02-27 08:28:33,580][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.43960
[2024-02-27 08:28:33,580][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.61285
[2024-02-27 08:28:53,868][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.92000
[2024-02-27 08:28:53,868][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.64643
[2024-02-27 08:29:15,270][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.62307
[2024-02-27 08:29:15,270][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.59331
[2024-02-27 08:29:36,067][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.50751
[2024-02-27 08:29:36,067][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.62062
[2024-02-27 08:29:57,232][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.16391
[2024-02-27 08:29:57,232][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.69952
[2024-02-27 08:30:18,686][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 1.65867
[2024-02-27 08:30:18,686][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.71557 - val_accuracy: 0.55280 - train_loss: 1.34655 - val_loss: 1.87756 - loss: 0.66866
[2024-02-27 08:31:00,759][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 1.65368
[2024-02-27 08:31:00,759][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.67445
[2024-02-27 08:31:21,485][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.62838
[2024-02-27 08:31:21,485][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.63034
[2024-02-27 08:31:43,111][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.67172
[2024-02-27 08:31:43,111][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.60922
[2024-02-27 08:32:03,720][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 1.44688
[2024-02-27 08:32:03,721][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.60618
[2024-02-27 08:32:24,293][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.65354
[2024-02-27 08:32:24,293][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.65236
[2024-02-27 08:32:44,501][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.62184
[2024-02-27 08:32:44,501][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.64050
[2024-02-27 08:33:05,139][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.93898
[2024-02-27 08:33:05,139][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.72987
[2024-02-27 08:33:26,699][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.91903
[2024-02-27 08:33:26,699][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.64876
[2024-02-27 08:33:46,739][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.77354
[2024-02-27 08:33:46,739][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.56759 - val_accuracy: 0.51610 - train_loss: 1.66399 - val_loss: 1.73040 - loss: 0.60655
[2024-02-27 08:34:30,075][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.59721
[2024-02-27 08:34:30,075][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.89754
[2024-02-27 08:34:51,460][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.58649
[2024-02-27 08:34:51,460][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.60440
[2024-02-27 08:35:13,597][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.68048
[2024-02-27 08:35:13,597][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 1.40328
[2024-02-27 08:35:34,689][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.74980
[2024-02-27 08:35:34,690][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.61018
[2024-02-27 08:35:55,580][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.59422
[2024-02-27 08:35:55,580][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.73259
[2024-02-27 08:36:16,073][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.61390
[2024-02-27 08:36:16,073][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 1.44161
[2024-02-27 08:36:36,557][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.58012
[2024-02-27 08:36:36,557][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.63900
[2024-02-27 08:36:57,372][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.59528
[2024-02-27 08:36:57,372][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.59526
[2024-02-27 08:37:17,932][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.60864
[2024-02-27 08:37:17,932][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 1.90609
[2024-02-27 08:37:38,760][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.60298
[2024-02-27 08:37:38,760][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.79349 - val_accuracy: 0.61040 - train_loss: 1.25486 - val_loss: 1.73222 - loss: 0.56706
[2024-02-27 08:38:20,291][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.56819
[2024-02-27 08:38:20,291][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.60089
[2024-02-27 08:38:41,183][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.69252
[2024-02-27 08:38:41,183][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.60499
[2024-02-27 08:39:01,415][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.57704
[2024-02-27 08:39:01,415][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.62845
[2024-02-27 08:39:21,631][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.57418
[2024-02-27 08:39:21,631][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.75016
[2024-02-27 08:39:42,228][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.60635
[2024-02-27 08:39:42,228][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.69381
[2024-02-27 08:40:03,181][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.62382
[2024-02-27 08:40:03,181][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.60110
[2024-02-27 08:40:24,346][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.60592
[2024-02-27 08:40:24,347][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.57250
[2024-02-27 08:40:44,575][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.93294
[2024-02-27 08:40:44,575][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.59888
[2024-02-27 08:41:04,833][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.56828
[2024-02-27 08:41:04,833][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.81850
[2024-02-27 08:41:24,735][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.61599
[2024-02-27 08:41:24,735][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.73713 - val_accuracy: 0.60470 - train_loss: 1.33554 - val_loss: 1.57854 - loss: 0.57636
[2024-02-27 08:42:07,403][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.61227
[2024-02-27 08:42:07,403][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.59274
[2024-02-27 08:42:28,708][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.59429
[2024-02-27 08:42:28,708][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.61586
[2024-02-27 08:42:49,700][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.58669
[2024-02-27 08:42:49,700][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.63971
[2024-02-27 08:43:08,945][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.59251
[2024-02-27 08:43:08,945][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.60850
[2024-02-27 08:43:30,439][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 1.44788
[2024-02-27 08:43:30,439][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.58804
[2024-02-27 08:43:51,168][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.91218
[2024-02-27 08:43:51,168][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.58917
[2024-02-27 08:44:11,549][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.57489
[2024-02-27 08:44:11,549][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.59273
[2024-02-27 08:44:32,168][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.62893
[2024-02-27 08:44:32,168][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.60140
[2024-02-27 08:44:53,464][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.57148
[2024-02-27 08:44:53,464][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.75602 - val_accuracy: 0.62970 - train_loss: 1.39580 - val_loss: 1.67383 - loss: 0.63296
[2024-02-27 08:45:35,422][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 1.66751
[2024-02-27 08:45:35,422][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.57229
[2024-02-27 08:45:55,295][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.56877
[2024-02-27 08:45:55,295][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.58731
[2024-02-27 08:46:16,335][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.66455
[2024-02-27 08:46:16,335][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.59165
[2024-02-27 08:46:37,126][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.60355
[2024-02-27 08:46:37,126][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.80027
[2024-02-27 08:46:58,645][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.76286
[2024-02-27 08:46:58,645][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 1.10520
[2024-02-27 08:47:18,900][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 1.48848
[2024-02-27 08:47:18,900][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 1.13048
[2024-02-27 08:47:40,293][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.66829
[2024-02-27 08:47:40,293][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.60496
[2024-02-27 08:48:00,617][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.59003
[2024-02-27 08:48:00,617][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 1.46867
[2024-02-27 08:48:21,753][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.63614
[2024-02-27 08:48:21,753][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.62274
[2024-02-27 08:48:40,886][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.96175
[2024-02-27 08:48:40,886][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.67113 - val_accuracy: 0.52910 - train_loss: 1.41841 - val_loss: 1.80608 - loss: 0.56628
[2024-02-27 08:49:21,970][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.63230
[2024-02-27 08:49:21,970][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57935
[2024-02-27 08:49:43,098][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57635
[2024-02-27 08:49:43,098][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.61809
[2024-02-27 08:50:03,878][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.59794
[2024-02-27 08:50:03,878][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.77572
[2024-02-27 08:50:24,646][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.67256
[2024-02-27 08:50:24,646][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57837
[2024-02-27 08:50:46,113][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57912
[2024-02-27 08:50:46,113][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.64031
[2024-02-27 08:51:06,828][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.64188
[2024-02-27 08:51:06,829][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.62793
[2024-02-27 08:51:27,744][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.58912
[2024-02-27 08:51:27,744][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57113
[2024-02-27 08:51:48,644][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 1.45762
[2024-02-27 08:51:48,644][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.56349
[2024-02-27 08:52:08,714][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.77684
[2024-02-27 08:52:08,714][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.63927
[2024-02-27 08:52:29,279][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.75051
[2024-02-27 08:52:29,279][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.68901 - val_accuracy: 0.58210 - train_loss: 1.42657 - val_loss: 1.70028 - loss: 0.57020
[2024-02-27 08:53:10,839][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.57462
[2024-02-27 08:53:10,839][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.57403
[2024-02-27 08:53:31,327][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 1.41151
[2024-02-27 08:53:31,327][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.60144
[2024-02-27 08:53:52,834][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.62546
[2024-02-27 08:53:52,834][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.62817
[2024-02-27 08:54:13,874][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.59490
[2024-02-27 08:54:13,874][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.81246
[2024-02-27 08:54:35,239][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 1.43356
[2024-02-27 08:54:35,239][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.56872
[2024-02-27 08:54:55,920][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.61274
[2024-02-27 08:54:55,920][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.63677
[2024-02-27 08:55:17,177][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 1.15616
[2024-02-27 08:55:17,177][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.54658
[2024-02-27 08:55:37,481][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.59827
[2024-02-27 08:55:37,481][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.78462
[2024-02-27 08:55:58,599][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.62686
[2024-02-27 08:55:58,599][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.67764
[2024-02-27 08:56:18,654][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.55855
[2024-02-27 08:56:18,654][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.76065 - val_accuracy: 0.59640 - train_loss: 1.28405 - val_loss: 1.70111 - loss: 0.55905
[2024-02-27 08:56:59,112][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.57120
[2024-02-27 08:56:59,112][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.59214
[2024-02-27 08:57:21,067][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 1.99066
[2024-02-27 08:57:21,067][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.60530
[2024-02-27 08:57:41,853][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.61296
[2024-02-27 08:57:41,853][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.59509
[2024-02-27 08:58:02,466][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 1.99974
[2024-02-27 08:58:02,466][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.55099
[2024-02-27 08:58:22,747][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 1.11588
[2024-02-27 08:58:22,747][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.71537
[2024-02-27 08:58:44,852][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.55486
[2024-02-27 08:58:44,852][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.60356
[2024-02-27 08:59:05,484][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.64533
[2024-02-27 08:59:05,484][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.58174
[2024-02-27 08:59:26,015][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.55786
[2024-02-27 08:59:26,015][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.57238
[2024-02-27 08:59:45,894][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 1.03247
[2024-02-27 08:59:45,894][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.69712 - val_accuracy: 0.49580 - train_loss: 1.43981 - val_loss: 2.14634 - loss: 0.83777
[2024-02-27 09:00:27,108][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.53722
[2024-02-27 09:00:27,108][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.56634
[2024-02-27 09:00:48,367][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 2.01018
[2024-02-27 09:00:48,367][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.53268
[2024-02-27 09:01:09,695][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.54520
[2024-02-27 09:01:09,695][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.61932
[2024-02-27 09:01:30,367][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 1.58948
[2024-02-27 09:01:30,368][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.59087
[2024-02-27 09:01:51,774][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.57598
[2024-02-27 09:01:51,774][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.54822
[2024-02-27 09:02:11,072][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.54495
[2024-02-27 09:02:11,072][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.55912
[2024-02-27 09:02:31,844][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.82986
[2024-02-27 09:02:31,844][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.71965
[2024-02-27 09:02:52,310][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.74194
[2024-02-27 09:02:52,310][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.55548
[2024-02-27 09:03:12,729][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.58864
[2024-02-27 09:03:12,729][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.56816
[2024-02-27 09:03:33,413][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.88764
[2024-02-27 09:03:33,413][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.62677 - val_accuracy: 0.51860 - train_loss: 1.47963 - val_loss: 1.79791 - loss: 0.57816
[2024-02-27 09:04:15,804][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.55926
[2024-02-27 09:04:15,804][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.80239
[2024-02-27 09:04:37,238][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.54402
[2024-02-27 09:04:37,238][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 1.93437
[2024-02-27 09:04:58,494][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.57106
[2024-02-27 09:04:58,494][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.54918
[2024-02-27 09:05:19,434][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.98717
[2024-02-27 09:05:19,434][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.66623
[2024-02-27 09:05:39,815][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 1.62549
[2024-02-27 09:05:39,815][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 1.27315
[2024-02-27 09:06:00,227][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 1.36966
[2024-02-27 09:06:00,227][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.56696
[2024-02-27 09:06:20,386][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.56035
[2024-02-27 09:06:20,386][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.54390
[2024-02-27 09:06:40,476][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.54547
[2024-02-27 09:06:40,476][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.54528
[2024-02-27 09:07:01,754][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.56054
[2024-02-27 09:07:01,754][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 1.92186
[2024-02-27 09:07:22,857][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.59564
[2024-02-27 09:07:22,857][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.75004 - val_accuracy: 0.54430 - train_loss: 1.38248 - val_loss: 2.08001 - loss: 0.59775
[2024-02-27 09:08:04,329][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.59720
[2024-02-27 09:08:04,330][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.57029
[2024-02-27 09:08:25,673][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.54824
[2024-02-27 09:08:25,674][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.55615
[2024-02-27 09:08:46,095][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.66548
[2024-02-27 09:08:46,095][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.55972
[2024-02-27 09:09:07,285][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.54939
[2024-02-27 09:09:07,285][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.89942
[2024-02-27 09:09:27,681][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.33499
[2024-02-27 09:09:27,682][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.56465
[2024-02-27 09:09:47,903][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.55147
[2024-02-27 09:09:47,903][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.54188
[2024-02-27 09:10:08,379][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.59960
[2024-02-27 09:10:08,379][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.55466
[2024-02-27 09:10:29,180][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.35426
[2024-02-27 09:10:29,180][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.54657
[2024-02-27 09:10:49,313][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 1.04537
[2024-02-27 09:10:49,313][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.69791 - val_accuracy: 0.52970 - train_loss: 1.45048 - val_loss: 1.77234 - loss: 0.57038
[2024-02-27 09:11:30,765][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.90595
[2024-02-27 09:11:30,765][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.56862
[2024-02-27 09:11:51,038][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.55437
[2024-02-27 09:11:51,038][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.56560
[2024-02-27 09:12:11,670][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 1.29746
[2024-02-27 09:12:11,670][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.53999
[2024-02-27 09:12:31,826][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.54869
[2024-02-27 09:12:31,826][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.53391
[2024-02-27 09:12:51,757][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.52653
[2024-02-27 09:12:51,757][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.54873
[2024-02-27 09:13:11,405][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 1.36294
[2024-02-27 09:13:11,405][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.59286
[2024-02-27 09:13:32,822][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.57469
[2024-02-27 09:13:32,822][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.53921
[2024-02-27 09:13:53,670][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.53785
[2024-02-27 09:13:53,670][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.52663
[2024-02-27 09:14:14,440][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 1.55101
[2024-02-27 09:14:14,440][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.54091
[2024-02-27 09:14:34,684][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.58269
[2024-02-27 09:14:34,684][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.75320 - val_accuracy: 0.60760 - train_loss: 1.29362 - val_loss: 1.59159 - loss: 0.55701
[2024-02-27 09:15:15,812][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.62831
[2024-02-27 09:15:15,812][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53353
[2024-02-27 09:15:35,765][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.55556
[2024-02-27 09:15:35,765][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53052
[2024-02-27 09:15:56,375][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53910
[2024-02-27 09:15:56,375][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.55651
[2024-02-27 09:16:17,888][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.57305
[2024-02-27 09:16:17,888][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53992
[2024-02-27 09:16:38,719][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.55828
[2024-02-27 09:16:38,719][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.55863
[2024-02-27 09:17:00,238][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.54569
[2024-02-27 09:17:00,238][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53876
[2024-02-27 09:17:21,017][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.57592
[2024-02-27 09:17:21,017][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53829
[2024-02-27 09:17:41,127][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.61766
[2024-02-27 09:17:41,127][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53707
[2024-02-27 09:18:02,404][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.54232
[2024-02-27 09:18:02,404][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.55401
[2024-02-27 09:18:23,708][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.54727
[2024-02-27 09:18:23,708][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.81983 - val_accuracy: 0.64190 - train_loss: 1.17995 - val_loss: 1.55068 - loss: 0.53367
[2024-02-27 09:19:06,228][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.56690
[2024-02-27 09:19:06,228][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.51610
[2024-02-27 09:19:27,254][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53367
[2024-02-27 09:19:27,254][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53695
[2024-02-27 09:19:47,903][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.75742
[2024-02-27 09:19:47,903][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53500
[2024-02-27 09:20:08,254][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53753
[2024-02-27 09:20:08,254][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.55627
[2024-02-27 09:20:29,164][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.55857
[2024-02-27 09:20:29,164][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.54112
[2024-02-27 09:20:49,999][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.56918
[2024-02-27 09:20:49,999][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.57020
[2024-02-27 09:21:09,774][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.54914
[2024-02-27 09:21:09,774][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.61141
[2024-02-27 09:21:31,068][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 1.92353
[2024-02-27 09:21:31,068][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53102
[2024-02-27 09:21:51,164][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.53571
[2024-02-27 09:21:51,164][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.83360 - val_accuracy: 0.58110 - train_loss: 1.14351 - val_loss: 1.98312 - loss: 0.55128
[2024-02-27 09:22:32,310][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.59909
[2024-02-27 09:22:32,310][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.51568
[2024-02-27 09:22:53,602][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 1.15432
[2024-02-27 09:22:53,602][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53294
[2024-02-27 09:23:15,245][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.55647
[2024-02-27 09:23:15,245][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.54969
[2024-02-27 09:23:35,946][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 1.02238
[2024-02-27 09:23:35,946][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.57333
[2024-02-27 09:23:55,849][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53257
[2024-02-27 09:23:55,849][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53530
[2024-02-27 09:24:15,787][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.92279
[2024-02-27 09:24:15,787][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.55567
[2024-02-27 09:24:36,197][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 1.28902
[2024-02-27 09:24:36,197][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.54120
[2024-02-27 09:24:57,857][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53595
[2024-02-27 09:24:57,857][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.56318
[2024-02-27 09:25:19,033][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53535
[2024-02-27 09:25:19,033][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.54231
[2024-02-27 09:25:38,972][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.62527
[2024-02-27 09:25:38,972][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.75485 - val_accuracy: 0.56880 - train_loss: 1.28623 - val_loss: 1.72137 - loss: 0.53811
[2024-02-27 09:26:21,475][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.54425
[2024-02-27 09:26:21,475][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.54495
[2024-02-27 09:26:42,758][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.76657
[2024-02-27 09:26:42,758][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.55225
[2024-02-27 09:27:03,564][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.54547
[2024-02-27 09:27:03,564][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.55043
[2024-02-27 09:27:25,183][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.51812
[2024-02-27 09:27:25,183][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.55531
[2024-02-27 09:27:45,444][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.76535
[2024-02-27 09:27:45,444][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.54223
[2024-02-27 09:28:05,264][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.54221
[2024-02-27 09:28:05,264][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.53144
[2024-02-27 09:28:26,833][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.56171
[2024-02-27 09:28:26,833][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.55700
[2024-02-27 09:28:47,641][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.56223
[2024-02-27 09:28:47,641][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.56295
[2024-02-27 09:29:08,450][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.60285
[2024-02-27 09:29:08,450][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.53615
[2024-02-27 09:29:29,083][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 1.56905
[2024-02-27 09:29:29,083][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.64314 - val_accuracy: 0.51110 - train_loss: 1.48617 - val_loss: 1.84220 - loss: 0.56376
[2024-02-27 09:30:10,612][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.66653
[2024-02-27 09:30:10,612][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.56653
[2024-02-27 09:30:31,470][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.79137
[2024-02-27 09:30:31,470][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.54101
[2024-02-27 09:30:52,386][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 1.28737
[2024-02-27 09:30:52,386][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53835
[2024-02-27 09:31:13,366][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53714
[2024-02-27 09:31:13,366][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.52115
[2024-02-27 09:31:34,185][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.52798
[2024-02-27 09:31:34,185][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53690
[2024-02-27 09:31:55,198][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.58509
[2024-02-27 09:31:55,198][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53723
[2024-02-27 09:32:17,228][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.99536
[2024-02-27 09:32:17,228][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.54954
[2024-02-27 09:32:36,837][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53922
[2024-02-27 09:32:36,838][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.67161
[2024-02-27 09:32:56,795][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.54797
[2024-02-27 09:32:56,795][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.55340
[2024-02-27 09:33:17,451][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 1.88645
[2024-02-27 09:33:17,451][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.83040 - val_accuracy: 0.58510 - train_loss: 1.15257 - val_loss: 1.85742 - loss: 0.53394
[2024-02-27 09:33:59,421][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.56988
[2024-02-27 09:33:59,421][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.54213
[2024-02-27 09:34:20,595][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 1.19574
[2024-02-27 09:34:20,595][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.53418
[2024-02-27 09:34:41,732][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.55567
[2024-02-27 09:34:41,732][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.62607
[2024-02-27 09:35:03,009][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.81022
[2024-02-27 09:35:03,009][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.54573
[2024-02-27 09:35:23,508][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.71731
[2024-02-27 09:35:23,508][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.54984
[2024-02-27 09:35:45,312][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 1.54600
[2024-02-27 09:35:45,312][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.53351
[2024-02-27 09:36:06,207][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.90540
[2024-02-27 09:36:06,207][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 1.00547
[2024-02-27 09:36:27,277][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.52458
[2024-02-27 09:36:27,277][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.57531
[2024-02-27 09:36:47,496][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.55951
[2024-02-27 09:36:47,496][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.62504 - val_accuracy: 0.50090 - train_loss: 1.47424 - val_loss: 1.78663 - loss: 0.52444
[2024-02-27 09:37:29,336][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.53447
[2024-02-27 09:37:29,336][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.52469
[2024-02-27 09:37:49,729][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.52365
[2024-02-27 09:37:49,729][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.54038
[2024-02-27 09:38:11,157][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 1.29073
[2024-02-27 09:38:11,157][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.87550
[2024-02-27 09:38:31,540][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.52966
[2024-02-27 09:38:31,540][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.55641
[2024-02-27 09:38:53,335][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.53258
[2024-02-27 09:38:53,335][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.51048
[2024-02-27 09:39:13,482][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.59499
[2024-02-27 09:39:13,482][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.53178
[2024-02-27 09:39:35,244][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.74744
[2024-02-27 09:39:35,244][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.53604
[2024-02-27 09:39:55,234][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.69649
[2024-02-27 09:39:55,234][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.50957
[2024-02-27 09:40:15,856][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.64937
[2024-02-27 09:40:15,856][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.51706
[2024-02-27 09:40:35,998][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.75010
[2024-02-27 09:40:35,998][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.76383 - val_accuracy: 0.49630 - train_loss: 1.24207 - val_loss: 2.11523 - loss: 0.53830
[2024-02-27 09:41:17,987][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.55204
[2024-02-27 09:41:17,987][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.57279
[2024-02-27 09:41:38,507][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51050
[2024-02-27 09:41:38,507][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.94355
[2024-02-27 09:41:58,350][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.52575
[2024-02-27 09:41:58,350][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51755
[2024-02-27 09:42:19,180][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 1.23742
[2024-02-27 09:42:19,180][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.54902
[2024-02-27 09:42:40,586][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51441
[2024-02-27 09:42:40,586][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.53936
[2024-02-27 09:43:01,170][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.57348
[2024-02-27 09:43:01,170][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.57181
[2024-02-27 09:43:22,226][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.64728
[2024-02-27 09:43:22,227][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.53391
[2024-02-27 09:43:42,523][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.54826
[2024-02-27 09:43:42,523][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.61742
[2024-02-27 09:44:04,493][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51470
[2024-02-27 09:44:04,493][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51590
[2024-02-27 09:44:24,665][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.53855
[2024-02-27 09:44:24,665][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.59454 - val_accuracy: 0.45490 - train_loss: 1.60010 - val_loss: 1.97244 - loss: 0.51771
[2024-02-27 09:45:06,004][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.59366
[2024-02-27 09:45:06,004][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.83266
[2024-02-27 09:45:26,962][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.53292
[2024-02-27 09:45:26,962][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.52687
[2024-02-27 09:45:48,511][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.68925
[2024-02-27 09:45:48,511][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.52757
[2024-02-27 09:46:09,752][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.51688
[2024-02-27 09:46:09,752][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.51540
[2024-02-27 09:46:29,990][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 1.57230
[2024-02-27 09:46:29,991][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.53259
[2024-02-27 09:46:50,993][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 1.47226
[2024-02-27 09:46:50,993][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.71576
[2024-02-27 09:47:12,091][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.90554
[2024-02-27 09:47:12,091][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.53806
[2024-02-27 09:47:32,129][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.52671
[2024-02-27 09:47:32,129][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.51673
[2024-02-27 09:47:52,668][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 1.92995
[2024-02-27 09:47:52,668][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.86366 - val_accuracy: 0.60100 - train_loss: 1.01676 - val_loss: 1.79771 - loss: 0.51269
[2024-02-27 09:48:34,454][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 1.59148
[2024-02-27 09:48:34,454][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.54545
[2024-02-27 09:48:54,621][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.68686
[2024-02-27 09:48:54,621][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.51920
[2024-02-27 09:49:16,207][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 1.90838
[2024-02-27 09:49:16,207][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52858
[2024-02-27 09:49:36,812][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.50955
[2024-02-27 09:49:36,812][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.51480
[2024-02-27 09:49:58,590][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.50860
[2024-02-27 09:49:58,590][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52359
[2024-02-27 09:50:19,660][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.69384
[2024-02-27 09:50:19,660][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52896
[2024-02-27 09:50:40,861][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.51885
[2024-02-27 09:50:40,861][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52544
[2024-02-27 09:51:01,669][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.55055
[2024-02-27 09:51:01,669][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.65867
[2024-02-27 09:51:22,461][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52362
[2024-02-27 09:51:22,461][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.52257
[2024-02-27 09:51:43,472][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.51965
[2024-02-27 09:51:43,472][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.87611 - val_accuracy: 0.58250 - train_loss: 0.98078 - val_loss: 1.91307 - loss: 0.51876
[2024-02-27 09:52:25,115][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.58079
[2024-02-27 09:52:25,115][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.80504
[2024-02-27 09:52:45,901][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52942
[2024-02-27 09:52:45,901][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52053
[2024-02-27 09:53:08,063][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.51222
[2024-02-27 09:53:08,063][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.53835
[2024-02-27 09:53:28,327][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52338
[2024-02-27 09:53:28,327][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.61300
[2024-02-27 09:53:49,653][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.50798
[2024-02-27 09:53:49,653][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52300
[2024-02-27 09:54:09,725][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.51637
[2024-02-27 09:54:09,725][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52013
[2024-02-27 09:54:30,674][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.50624
[2024-02-27 09:54:30,674][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.53655
[2024-02-27 09:54:51,906][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 1.94585
[2024-02-27 09:54:51,906][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.54605
[2024-02-27 09:55:13,765][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52475
[2024-02-27 09:55:13,765][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.52363
[2024-02-27 09:55:34,485][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.51792
[2024-02-27 09:55:34,485][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.79939 - val_accuracy: 0.58400 - train_loss: 1.18469 - val_loss: 1.69593 - loss: 0.54710
[2024-02-27 09:56:15,828][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.67712
[2024-02-27 09:56:15,828][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.52509
[2024-02-27 09:56:36,564][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.53712
[2024-02-27 09:56:36,564][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.53041
[2024-02-27 09:56:56,992][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.55399
[2024-02-27 09:56:56,992][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.51391
[2024-02-27 09:57:18,152][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.51950
[2024-02-27 09:57:18,152][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.51364
[2024-02-27 09:57:39,126][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 1.43973
[2024-02-27 09:57:39,126][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.52338
[2024-02-27 09:57:58,594][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.52574
[2024-02-27 09:57:58,594][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.54002
[2024-02-27 09:58:19,270][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.52990
[2024-02-27 09:58:19,270][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.51582
[2024-02-27 09:58:40,256][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 1.84146
[2024-02-27 09:58:40,256][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.53246
[2024-02-27 09:59:00,958][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 0.51731
[2024-02-27 09:59:00,958][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.74249 - val_accuracy: 0.55570 - train_loss: 1.24192 - val_loss: 1.67663 - loss: 1.91831
[2024-02-27 09:59:43,338][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53692
[2024-02-27 09:59:43,338][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53404
[2024-02-27 10:00:04,628][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.66460
[2024-02-27 10:00:04,628][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.51712
[2024-02-27 10:00:25,919][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53392
[2024-02-27 10:00:25,919][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.52575
[2024-02-27 10:00:46,251][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 1.89017
[2024-02-27 10:00:46,251][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.67877
[2024-02-27 10:01:07,218][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.54848
[2024-02-27 10:01:07,218][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53762
[2024-02-27 10:01:27,167][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.51481
[2024-02-27 10:01:27,167][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.51444
[2024-02-27 10:01:49,117][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53992
[2024-02-27 10:01:49,117][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.52794
[2024-02-27 10:02:10,309][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.53782
[2024-02-27 10:02:10,309][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.51271
[2024-02-27 10:02:31,798][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.55863
[2024-02-27 10:02:31,798][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.60103
[2024-02-27 10:02:52,662][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.71914
[2024-02-27 10:02:52,662][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.87506 - val_accuracy: 0.65370 - train_loss: 0.96277 - val_loss: 1.48189 - loss: 0.54463
[2024-02-27 10:03:34,937][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51882
[2024-02-27 10:03:34,937][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.54500
[2024-02-27 10:03:55,261][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51140
[2024-02-27 10:03:55,261][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.52328
[2024-02-27 10:04:16,230][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.64657
[2024-02-27 10:04:16,230][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51599
[2024-02-27 10:04:36,490][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.53254
[2024-02-27 10:04:36,490][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.53752
[2024-02-27 10:04:57,726][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.52765
[2024-02-27 10:04:57,726][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51497
[2024-02-27 10:05:16,865][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51463
[2024-02-27 10:05:16,865][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.54779
[2024-02-27 10:05:39,080][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51170
[2024-02-27 10:05:39,080][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51572
[2024-02-27 10:05:59,409][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.53450
[2024-02-27 10:05:59,409][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.53098
[2024-02-27 10:06:19,839][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.77340
[2024-02-27 10:06:19,839][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.50910
[2024-02-27 10:06:40,542][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.50944
[2024-02-27 10:06:40,542][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.79822 - val_accuracy: 0.53970 - train_loss: 1.12983 - val_loss: 1.91461 - loss: 0.51202
[2024-02-27 10:07:21,131][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.52413
[2024-02-27 10:07:21,131][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.56443
[2024-02-27 10:07:40,948][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 1.95100
[2024-02-27 10:07:40,948][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.53030
[2024-02-27 10:08:02,088][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 1.49512
[2024-02-27 10:08:02,088][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.52163
[2024-02-27 10:08:23,909][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.52067
[2024-02-27 10:08:23,909][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.50634
[2024-02-27 10:08:44,613][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.80968
[2024-02-27 10:08:44,613][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.55276
[2024-02-27 10:09:06,028][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.63277
[2024-02-27 10:09:06,028][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.51422
[2024-02-27 10:09:27,290][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.57644
[2024-02-27 10:09:27,290][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.58015
[2024-02-27 10:09:47,131][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.61415
[2024-02-27 10:09:47,131][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.52450
[2024-02-27 10:10:07,383][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.79333
[2024-02-27 10:10:07,383][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.51610
[2024-02-27 10:10:28,216][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.51259
[2024-02-27 10:10:28,217][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.84466 - val_accuracy: 0.57310 - train_loss: 1.03624 - val_loss: 1.75431 - loss: 0.50810
[2024-02-27 10:11:10,861][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.72226
[2024-02-27 10:11:10,861][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.55740
[2024-02-27 10:11:30,645][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 1.34138
[2024-02-27 10:11:30,645][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.59030
[2024-02-27 10:11:50,789][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.60664
[2024-02-27 10:11:50,789][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.51431
[2024-02-27 10:12:12,816][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.50668
[2024-02-27 10:12:12,816][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.51704
[2024-02-27 10:12:33,749][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 1.07515
[2024-02-27 10:12:33,749][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 1.39452
[2024-02-27 10:12:54,947][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.57178
[2024-02-27 10:12:54,947][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.50409
[2024-02-27 10:13:15,118][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.52081
[2024-02-27 10:13:15,118][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.60077
[2024-02-27 10:13:36,197][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.54537
[2024-02-27 10:13:36,197][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.56494
[2024-02-27 10:13:56,741][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.50596
[2024-02-27 10:13:56,741][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.68724 - val_accuracy: 0.54960 - train_loss: 1.37699 - val_loss: 1.67564 - loss: 0.53025
[2024-02-27 10:14:38,731][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.52063
[2024-02-27 10:14:38,731][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51245
[2024-02-27 10:14:59,306][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.74861
[2024-02-27 10:14:59,306][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51638
[2024-02-27 10:15:19,946][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51581
[2024-02-27 10:15:19,946][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51889
[2024-02-27 10:15:40,323][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.59782
[2024-02-27 10:15:40,323][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51658
[2024-02-27 10:16:01,753][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.74044
[2024-02-27 10:16:01,753][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.50744
[2024-02-27 10:16:21,772][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.59242
[2024-02-27 10:16:21,772][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51123
[2024-02-27 10:16:42,216][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.81322
[2024-02-27 10:16:42,216][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.52074
[2024-02-27 10:17:02,461][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.51786
[2024-02-27 10:17:02,461][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.52409
[2024-02-27 10:17:24,236][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 1.46380
[2024-02-27 10:17:24,236][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.52497
[2024-02-27 10:17:44,917][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.53339
[2024-02-27 10:17:44,917][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.78081 - val_accuracy: 0.50690 - train_loss: 1.22292 - val_loss: 1.91633 - loss: 0.54392
[2024-02-27 10:18:26,922][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 1.47493
[2024-02-27 10:18:26,922][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52914
[2024-02-27 10:18:47,152][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52197
[2024-02-27 10:18:47,153][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.50388
[2024-02-27 10:19:08,050][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52545
[2024-02-27 10:19:08,050][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.50929
[2024-02-27 10:19:29,175][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.53304
[2024-02-27 10:19:29,175][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.50946
[2024-02-27 10:19:48,952][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.51394
[2024-02-27 10:19:48,952][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.50853
[2024-02-27 10:20:09,991][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.64723
[2024-02-27 10:20:09,991][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52725
[2024-02-27 10:20:31,385][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.51187
[2024-02-27 10:20:31,385][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.51736
[2024-02-27 10:20:51,004][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.74117
[2024-02-27 10:20:51,004][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52836
[2024-02-27 10:21:11,505][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52168
[2024-02-27 10:21:11,505][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.52084
[2024-02-27 10:21:31,919][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.55041
[2024-02-27 10:21:31,919][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.76822 - val_accuracy: 0.56190 - train_loss: 1.22673 - val_loss: 1.84750 - loss: 0.50781
[2024-02-27 10:22:13,841][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50525
[2024-02-27 10:22:13,841][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50686
[2024-02-27 10:22:34,719][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.54038
[2024-02-27 10:22:34,719][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.62626
[2024-02-27 10:22:56,110][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50667
[2024-02-27 10:22:56,110][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50590
[2024-02-27 10:23:17,436][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.60091
[2024-02-27 10:23:17,436][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.53261
[2024-02-27 10:23:38,760][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 1.89821
[2024-02-27 10:23:38,760][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50353
[2024-02-27 10:23:59,680][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50565
[2024-02-27 10:23:59,680][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.51286
[2024-02-27 10:24:20,815][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.51410
[2024-02-27 10:24:20,815][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.51394
[2024-02-27 10:24:42,454][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 1.88390
[2024-02-27 10:24:42,454][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.50720
[2024-02-27 10:25:02,532][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.51909
[2024-02-27 10:25:02,532][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.77064 - val_accuracy: 0.55700 - train_loss: 1.32395 - val_loss: 1.71011 - loss: 0.51281
[2024-02-27 10:25:44,293][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50675
[2024-02-27 10:25:44,293][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50402
[2024-02-27 10:26:04,623][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51734
[2024-02-27 10:26:04,623][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50701
[2024-02-27 10:26:25,789][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 1.33768
[2024-02-27 10:26:25,789][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51066
[2024-02-27 10:26:46,618][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 1.89987
[2024-02-27 10:26:46,619][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 1.06750
[2024-02-27 10:27:08,511][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.52079
[2024-02-27 10:27:08,511][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50563
[2024-02-27 10:27:28,337][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.74109
[2024-02-27 10:27:28,337][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.53937
[2024-02-27 10:27:49,513][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50520
[2024-02-27 10:27:49,513][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51312
[2024-02-27 10:28:10,223][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50271
[2024-02-27 10:28:10,223][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51610
[2024-02-27 10:28:31,151][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.55040
[2024-02-27 10:28:31,151][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51765
[2024-02-27 10:28:51,409][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.51270
[2024-02-27 10:28:51,409][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.81300 - val_accuracy: 0.61780 - train_loss: 1.16347 - val_loss: 1.59571 - loss: 0.50872
[2024-02-27 10:29:33,310][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.51611
[2024-02-27 10:29:33,311][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50638
[2024-02-27 10:29:53,810][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50448
[2024-02-27 10:29:53,810][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50627
[2024-02-27 10:30:14,223][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50359
[2024-02-27 10:30:14,223][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.51551
[2024-02-27 10:30:34,303][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50990
[2024-02-27 10:30:34,303][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50647
[2024-02-27 10:30:55,566][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.51206
[2024-02-27 10:30:55,566][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.52563
[2024-02-27 10:31:16,203][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 1.81250
[2024-02-27 10:31:16,203][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50712
[2024-02-27 10:31:36,974][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.55020
[2024-02-27 10:31:36,974][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50404
[2024-02-27 10:31:57,380][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.51101
[2024-02-27 10:31:57,380][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 1.00360
[2024-02-27 10:32:18,227][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50648
[2024-02-27 10:32:18,227][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 1.36484
[2024-02-27 10:32:38,570][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.50377
[2024-02-27 10:32:38,570][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.71651 - val_accuracy: 0.57160 - train_loss: 1.32344 - val_loss: 1.64011 - loss: 0.51394
[2024-02-27 10:33:20,152][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50854
[2024-02-27 10:33:20,152][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.51810
[2024-02-27 10:33:40,498][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.61609
[2024-02-27 10:33:40,498][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.55721
[2024-02-27 10:34:02,604][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.53573
[2024-02-27 10:34:02,604][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50258
[2024-02-27 10:34:22,984][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50518
[2024-02-27 10:34:22,984][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50678
[2024-02-27 10:34:43,105][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.51434
[2024-02-27 10:34:43,105][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.52800
[2024-02-27 10:35:03,730][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50621
[2024-02-27 10:35:03,730][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50793
[2024-02-27 10:35:24,915][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.51849
[2024-02-27 10:35:24,915][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.51408
[2024-02-27 10:35:45,136][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50178
[2024-02-27 10:35:45,136][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.51329
[2024-02-27 10:36:05,792][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50297
[2024-02-27 10:36:05,793][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.83225 - val_accuracy: 0.61550 - train_loss: 1.03432 - val_loss: 1.60652 - loss: 0.50768
[2024-02-27 10:36:48,007][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50162
[2024-02-27 10:36:48,007][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50200
[2024-02-27 10:37:07,551][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.51463
[2024-02-27 10:37:07,551][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50229
[2024-02-27 10:37:28,569][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.51333
[2024-02-27 10:37:28,569][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50415
[2024-02-27 10:37:48,826][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.52195
[2024-02-27 10:37:48,826][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.52466
[2024-02-27 10:38:10,941][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50196
[2024-02-27 10:38:10,941][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.51149
[2024-02-27 10:38:31,773][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.53950
[2024-02-27 10:38:31,774][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50330
[2024-02-27 10:38:53,891][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.54651
[2024-02-27 10:38:53,891][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50547
[2024-02-27 10:39:14,838][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.51637
[2024-02-27 10:39:14,838][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50563
[2024-02-27 10:39:36,378][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50218
[2024-02-27 10:39:36,378][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50367
[2024-02-27 10:39:57,275][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.52153
[2024-02-27 10:39:57,275][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.87774 - val_accuracy: 0.60660 - train_loss: 1.07351 - val_loss: 1.60965 - loss: 0.50891
[2024-02-27 10:40:38,346][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.51221
[2024-02-27 10:40:38,346][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50150
[2024-02-27 10:40:59,116][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.51835
[2024-02-27 10:40:59,116][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.52036
[2024-02-27 10:41:19,814][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.55486
[2024-02-27 10:41:19,814][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50248
[2024-02-27 10:41:40,464][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.51429
[2024-02-27 10:41:40,464][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.51440
[2024-02-27 10:42:01,612][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.59725
[2024-02-27 10:42:01,612][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.53489
[2024-02-27 10:42:21,863][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50496
[2024-02-27 10:42:21,863][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50969
[2024-02-27 10:42:44,091][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50261
[2024-02-27 10:42:44,091][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.60788
[2024-02-27 10:43:05,269][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50200
[2024-02-27 10:43:05,269][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.51720
[2024-02-27 10:43:26,157][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.52193
[2024-02-27 10:43:26,157][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.50259
[2024-02-27 10:43:47,905][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 1.94820
[2024-02-27 10:43:47,905][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.81351 - val_accuracy: 0.54710 - train_loss: 1.17811 - val_loss: 1.70687 - loss: 0.52509
[2024-02-27 10:44:30,189][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.99232
[2024-02-27 10:44:30,189][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50296
[2024-02-27 10:44:50,626][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50170
[2024-02-27 10:44:50,626][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.74240
[2024-02-27 10:45:11,704][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50156
[2024-02-27 10:45:11,704][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50228
[2024-02-27 10:45:32,620][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50332
[2024-02-27 10:45:32,620][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.51217
[2024-02-27 10:45:54,346][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50561
[2024-02-27 10:45:54,346][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.56163
[2024-02-27 10:46:14,048][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.68662
[2024-02-27 10:46:14,048][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50186
[2024-02-27 10:46:34,719][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 1.93285
[2024-02-27 10:46:34,719][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50106
[2024-02-27 10:46:54,671][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50113
[2024-02-27 10:46:54,671][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.51303
[2024-02-27 10:47:14,814][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 1.32114
[2024-02-27 10:47:14,814][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50692
[2024-02-27 10:47:35,967][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50195
[2024-02-27 10:47:35,967][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 0.70012 - val_accuracy: 0.48940 - train_loss: 1.33687 - val_loss: 1.79983 - loss: 0.50879
[2024-02-27 10:48:18,149][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50168
[2024-02-27 10:48:18,149][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.53880
[2024-02-27 10:48:38,524][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.54199
[2024-02-27 10:48:38,524][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50218
[2024-02-27 10:49:00,738][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.66760
[2024-02-27 10:49:00,738][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.51387
[2024-02-27 10:49:21,241][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.51972
[2024-02-27 10:49:21,241][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.51057
[2024-02-27 10:49:42,055][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50208
[2024-02-27 10:49:42,055][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50280
[2024-02-27 10:50:03,341][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.51225
[2024-02-27 10:50:03,341][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50770
[2024-02-27 10:50:23,916][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50734
[2024-02-27 10:50:23,916][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.52905
[2024-02-27 10:50:45,500][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50276
[2024-02-27 10:50:45,500][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50111
[2024-02-27 10:51:06,266][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50898
[2024-02-27 10:51:06,266][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.78240 - val_accuracy: 0.55260 - train_loss: 1.15216 - val_loss: 1.71700 - loss: 0.50629
[2024-02-27 10:51:47,885][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50290
[2024-02-27 10:51:47,885][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.66711
[2024-02-27 10:52:08,108][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 1.83464
[2024-02-27 10:52:08,108][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50517
[2024-02-27 10:52:28,985][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.64429
[2024-02-27 10:52:28,985][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.51393
[2024-02-27 10:52:49,113][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34600] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50523
[2024-02-27 10:52:49,113][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34600] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50253
[2024-02-27 10:53:09,844][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34650] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50437
[2024-02-27 10:53:09,844][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34650] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50179
[2024-02-27 10:53:30,266][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34700] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50874
[2024-02-27 10:53:30,266][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34700] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50514
[2024-02-27 10:53:50,970][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34750] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.87476
[2024-02-27 10:53:50,970][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34750] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.51427
[2024-02-27 10:54:11,247][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34800] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.53433
[2024-02-27 10:54:11,247][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34800] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50683
[2024-02-27 10:54:32,119][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34850] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50109
[2024-02-27 10:54:32,119][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34850] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.51324
[2024-02-27 10:54:52,236][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34900] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50156
[2024-02-27 10:54:52,236][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34900] - train_accuracy: 0.88420 - val_accuracy: 0.58850 - train_loss: 0.93546 - val_loss: 1.81143 - loss: 0.50096
[2024-02-27 10:55:34,047][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[34950] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.67479
[2024-02-27 10:55:34,047][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[34950] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50574
[2024-02-27 10:55:54,793][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[35000] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.54645
[2024-02-27 10:55:54,793][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[35000] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.55820
[2024-02-27 10:56:15,384][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35050] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50156
[2024-02-27 10:56:15,384][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35050] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50970
[2024-02-27 10:56:37,545][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35100] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50139
[2024-02-27 10:56:37,545][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35100] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50253
[2024-02-27 10:56:57,896][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35150] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.52505
[2024-02-27 10:56:57,896][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35150] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50393
[2024-02-27 10:57:19,154][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35200] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.95312
[2024-02-27 10:57:19,154][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35200] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50493
[2024-02-27 10:57:40,734][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35250] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.51779
[2024-02-27 10:57:40,734][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35250] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50716
[2024-02-27 10:58:01,588][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35300] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.56038
[2024-02-27 10:58:01,588][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35300] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50248
[2024-02-27 10:58:22,061][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35350] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50235
[2024-02-27 10:58:22,061][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35350] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50485
[2024-02-27 10:58:43,184][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35400] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.52040
[2024-02-27 10:58:43,184][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35400] - train_accuracy: 0.80463 - val_accuracy: 0.58630 - train_loss: 1.19199 - val_loss: 1.61865 - loss: 0.50129
[2024-02-27 10:59:24,808][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35450] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50219
[2024-02-27 10:59:24,808][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35450] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.52010
[2024-02-27 10:59:44,774][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35500] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 1.83472
[2024-02-27 10:59:44,774][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35500] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50147
[2024-02-27 11:00:04,865][PyLogger][INFO]: Rank[1]: Epoch[367/500], iter[35550] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.54483
[2024-02-27 11:00:04,865][PyLogger][INFO]: Rank[0]: Epoch[367/500], iter[35550] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50516
[2024-02-27 11:00:25,248][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35600] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50308
[2024-02-27 11:00:25,248][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35600] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50157
[2024-02-27 11:00:45,539][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35650] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50097
[2024-02-27 11:00:45,539][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35650] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50094
[2024-02-27 11:01:06,087][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35700] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50227
[2024-02-27 11:01:06,087][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35700] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.51149
[2024-02-27 11:01:26,907][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35750] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50193
[2024-02-27 11:01:26,907][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35750] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50138
[2024-02-27 11:01:47,944][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35800] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.92417
[2024-02-27 11:01:47,944][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35800] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50083
[2024-02-27 11:02:08,467][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35850] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.66150
[2024-02-27 11:02:08,467][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35850] - train_accuracy: 0.81079 - val_accuracy: 0.55830 - train_loss: 1.10466 - val_loss: 1.72105 - loss: 0.50182
[2024-02-27 11:02:49,677][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35900] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50213
[2024-02-27 11:02:49,677][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35900] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50176
[2024-02-27 11:03:11,369][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35950] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50235
[2024-02-27 11:03:11,369][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35950] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50304
[2024-02-27 11:03:32,882][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36000] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.60203
[2024-02-27 11:03:32,882][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36000] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.55656
[2024-02-27 11:03:53,001][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36050] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50098
[2024-02-27 11:03:53,001][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36050] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50150
[2024-02-27 11:04:13,789][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36100] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.54129
[2024-02-27 11:04:13,789][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36100] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50175
[2024-02-27 11:04:34,040][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36150] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50710
[2024-02-27 11:04:34,040][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36150] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50129
[2024-02-27 11:04:54,880][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36200] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50497
[2024-02-27 11:04:54,880][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36200] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50108
[2024-02-27 11:05:14,794][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36250] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 1.91213
[2024-02-27 11:05:14,794][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36250] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50167
[2024-02-27 11:05:34,416][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36300] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.51683
[2024-02-27 11:05:34,416][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36300] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50094
[2024-02-27 11:05:54,620][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36350] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.53329
[2024-02-27 11:05:54,621][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36350] - train_accuracy: 0.90158 - val_accuracy: 0.63990 - train_loss: 0.88950 - val_loss: 1.55383 - loss: 0.50101
[2024-02-27 11:06:36,934][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36400] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50435
[2024-02-27 11:06:36,934][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36400] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.59929
[2024-02-27 11:06:57,249][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36450] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.52280
[2024-02-27 11:06:57,249][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36450] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50087
[2024-02-27 11:07:18,042][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36500] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.54029
[2024-02-27 11:07:18,042][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36500] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50180
[2024-02-27 11:07:38,772][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36550] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.91890
[2024-02-27 11:07:38,772][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36550] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50153
[2024-02-27 11:08:00,000][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36600] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.55963
[2024-02-27 11:08:00,001][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36600] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50440
[2024-02-27 11:08:20,701][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36650] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50255
[2024-02-27 11:08:20,701][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36650] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50109
[2024-02-27 11:08:40,944][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36700] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.54250
[2024-02-27 11:08:40,944][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36700] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50388
[2024-02-27 11:09:01,764][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36750] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50666
[2024-02-27 11:09:01,764][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36750] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50381
[2024-02-27 11:09:21,182][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36800] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50136
[2024-02-27 11:09:21,182][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36800] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50127
[2024-02-27 11:09:40,495][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36850] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.58254
[2024-02-27 11:09:40,495][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36850] - train_accuracy: 0.73639 - val_accuracy: 0.52050 - train_loss: 1.25920 - val_loss: 1.74418 - loss: 0.50560
[2024-02-27 11:10:22,480][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36900] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50278
[2024-02-27 11:10:22,480][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36900] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 1.86809
[2024-02-27 11:10:43,426][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36950] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50276
[2024-02-27 11:10:43,426][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36950] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50091
[2024-02-27 11:11:04,055][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37000] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50114
[2024-02-27 11:11:04,055][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37000] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50712
[2024-02-27 11:11:24,581][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37050] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.51230
[2024-02-27 11:11:24,581][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37050] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50100
[2024-02-27 11:11:46,745][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37100] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50545
[2024-02-27 11:11:46,745][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37100] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.86254
[2024-02-27 11:12:08,177][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37150] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50359
[2024-02-27 11:12:08,177][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37150] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50200
[2024-02-27 11:12:28,420][PyLogger][INFO]: Rank[0]: Epoch[384/500], iter[37200] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50130
[2024-02-27 11:12:28,420][PyLogger][INFO]: Rank[1]: Epoch[384/500], iter[37200] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50102
[2024-02-27 11:12:49,953][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37250] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.51407
[2024-02-27 11:12:49,953][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37250] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.80823
[2024-02-27 11:13:09,708][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37300] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.51071
[2024-02-27 11:13:09,708][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37300] - train_accuracy: 0.84182 - val_accuracy: 0.59580 - train_loss: 0.99180 - val_loss: 1.67944 - loss: 0.50110
[2024-02-27 11:13:50,828][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37350] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.55605
[2024-02-27 11:13:50,828][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37350] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50101
[2024-02-27 11:14:11,747][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37400] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50323
[2024-02-27 11:14:11,747][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37400] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50087
[2024-02-27 11:14:32,557][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37450] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50159
[2024-02-27 11:14:32,557][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37450] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.83243
[2024-02-27 11:14:53,164][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37500] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.86589
[2024-02-27 11:14:53,164][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37500] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50083
[2024-02-27 11:15:14,388][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37550] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50213
[2024-02-27 11:15:14,388][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37550] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50171
[2024-02-27 11:15:34,936][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37600] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.85744
[2024-02-27 11:15:34,936][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37600] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50123
[2024-02-27 11:15:56,182][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37650] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50092
[2024-02-27 11:15:56,182][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37650] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50076
[2024-02-27 11:16:16,668][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37700] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50493
[2024-02-27 11:16:16,668][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37700] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50645
[2024-02-27 11:16:38,100][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37750] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50175
[2024-02-27 11:16:38,100][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37750] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50147
[2024-02-27 11:16:58,530][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37800] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.58470
[2024-02-27 11:16:58,530][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37800] - train_accuracy: 0.89699 - val_accuracy: 0.60830 - train_loss: 0.88817 - val_loss: 1.72297 - loss: 0.50091
[2024-02-27 11:17:40,055][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37850] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50121
[2024-02-27 11:17:40,055][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37850] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50136
[2024-02-27 11:18:00,698][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37900] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 1.91048
[2024-02-27 11:18:00,698][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37900] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.52756
[2024-02-27 11:18:21,450][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[37950] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.51179
[2024-02-27 11:18:21,450][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[37950] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50132
[2024-02-27 11:18:41,957][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[38000] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50116
[2024-02-27 11:18:41,957][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[38000] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50084
[2024-02-27 11:19:03,583][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38050] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50214
[2024-02-27 11:19:03,583][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38050] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50071
[2024-02-27 11:19:24,092][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38100] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50080
[2024-02-27 11:19:24,092][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38100] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50104
[2024-02-27 11:19:45,417][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38150] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50097
[2024-02-27 11:19:45,418][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38150] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50085
[2024-02-27 11:20:05,846][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38200] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50117
[2024-02-27 11:20:05,846][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38200] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50694
[2024-02-27 11:20:27,809][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38250] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.55874
[2024-02-27 11:20:27,809][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38250] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50323
[2024-02-27 11:20:48,154][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38300] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50380
[2024-02-27 11:20:48,154][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38300] - train_accuracy: 0.90951 - val_accuracy: 0.65050 - train_loss: 0.86037 - val_loss: 1.67144 - loss: 0.50137
[2024-02-27 11:21:29,399][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38350] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50115
[2024-02-27 11:21:29,398][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38350] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50084
[2024-02-27 11:21:49,957][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38400] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.58192
[2024-02-27 11:21:49,957][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38400] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50094
[2024-02-27 11:22:10,612][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38450] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 1.08918
[2024-02-27 11:22:10,613][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38450] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50087
[2024-02-27 11:22:30,624][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38500] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50124
[2024-02-27 11:22:30,624][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38500] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50098
[2024-02-27 11:22:51,920][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38550] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.52658
[2024-02-27 11:22:51,920][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38550] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.52476
[2024-02-27 11:23:12,183][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38600] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50080
[2024-02-27 11:23:12,183][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38600] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50094
[2024-02-27 11:23:33,051][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38650] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50538
[2024-02-27 11:23:33,051][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38650] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50071
[2024-02-27 11:23:53,092][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38700] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50099
[2024-02-27 11:23:53,092][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38700] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50577
[2024-02-27 11:24:13,689][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38750] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50199
[2024-02-27 11:24:13,689][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38750] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50282
[2024-02-27 11:24:34,259][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38800] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.75881
[2024-02-27 11:24:34,259][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38800] - train_accuracy: 0.93488 - val_accuracy: 0.60320 - train_loss: 0.83992 - val_loss: 1.68369 - loss: 0.50988
[2024-02-27 11:25:15,861][PyLogger][INFO]: Rank[1]: Epoch[401/500], iter[38850] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50456
[2024-02-27 11:25:15,861][PyLogger][INFO]: Rank[0]: Epoch[401/500], iter[38850] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50107
[2024-02-27 11:25:38,311][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38900] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50101
[2024-02-27 11:25:38,311][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38900] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50072
[2024-02-27 11:25:58,079][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38950] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.83678
[2024-02-27 11:25:58,079][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38950] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50661
[2024-02-27 11:26:19,621][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39000] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50299
[2024-02-27 11:26:19,621][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39000] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50080
[2024-02-27 11:26:41,062][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39050] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.51822
[2024-02-27 11:26:41,062][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39050] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50061
[2024-02-27 11:27:02,247][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39100] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50066
[2024-02-27 11:27:02,246][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39100] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 1.89808
[2024-02-27 11:27:22,725][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39150] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50078
[2024-02-27 11:27:22,725][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39150] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50095
[2024-02-27 11:27:44,130][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39200] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50123
[2024-02-27 11:27:44,130][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39200] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50160
[2024-02-27 11:28:04,879][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39250] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.74462
[2024-02-27 11:28:04,879][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39250] - train_accuracy: 0.83874 - val_accuracy: 0.57140 - train_loss: 1.10074 - val_loss: 1.71486 - loss: 0.50116
[2024-02-27 11:28:46,608][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39300] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50186
[2024-02-27 11:28:46,608][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39300] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50070
[2024-02-27 11:29:07,186][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39350] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50071
[2024-02-27 11:29:07,186][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39350] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50098
[2024-02-27 11:29:28,215][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39400] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.60536
[2024-02-27 11:29:28,215][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39400] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50124
[2024-02-27 11:29:48,915][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39450] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50149
[2024-02-27 11:29:48,915][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39450] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50079
[2024-02-27 11:30:09,775][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39500] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50082
[2024-02-27 11:30:09,775][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39500] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50109
[2024-02-27 11:30:30,477][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39550] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50077
[2024-02-27 11:30:30,477][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39550] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50111
[2024-02-27 11:30:51,068][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39600] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50483
[2024-02-27 11:30:51,068][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39600] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50099
[2024-02-27 11:31:11,589][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39650] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 1.14653
[2024-02-27 11:31:11,590][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39650] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50100
[2024-02-27 11:31:32,315][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39700] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50118
[2024-02-27 11:31:32,315][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39700] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50085
[2024-02-27 11:31:53,412][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39750] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50111
[2024-02-27 11:31:53,412][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39750] - train_accuracy: 0.90087 - val_accuracy: 0.62220 - train_loss: 0.97076 - val_loss: 1.56424 - loss: 0.50108
[2024-02-27 11:32:35,477][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39800] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50134
[2024-02-27 11:32:35,477][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39800] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50118
[2024-02-27 11:32:55,593][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39850] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50420
[2024-02-27 11:32:55,593][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39850] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50418
[2024-02-27 11:33:15,394][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39900] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50088
[2024-02-27 11:33:15,394][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39900] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50066
[2024-02-27 11:33:35,451][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39950] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 1.85590
[2024-02-27 11:33:35,452][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39950] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50088
[2024-02-27 11:33:56,692][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40000] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50075
[2024-02-27 11:33:56,691][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40000] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50143
[2024-02-27 11:34:17,509][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40050] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50095
[2024-02-27 11:34:17,509][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40050] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50368
[2024-02-27 11:34:38,857][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40100] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50884
[2024-02-27 11:34:38,857][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40100] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50082
[2024-02-27 11:34:59,010][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40150] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50126
[2024-02-27 11:34:59,010][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40150] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.73595
[2024-02-27 11:35:20,814][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40200] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50077
[2024-02-27 11:35:20,814][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40200] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 1.86499
[2024-02-27 11:35:41,045][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40250] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50064
[2024-02-27 11:35:41,045][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40250] - train_accuracy: 0.78713 - val_accuracy: 0.52280 - train_loss: 1.15783 - val_loss: 1.92624 - loss: 0.50071
[2024-02-27 11:36:23,281][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40300] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.53894
[2024-02-27 11:36:23,281][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40300] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50070
[2024-02-27 11:36:43,842][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40350] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50090
[2024-02-27 11:36:43,843][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40350] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50081
[2024-02-27 11:37:04,952][PyLogger][INFO]: Rank[0]: Epoch[417/500], iter[40400] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50233
[2024-02-27 11:37:04,952][PyLogger][INFO]: Rank[1]: Epoch[417/500], iter[40400] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50098
[2024-02-27 11:37:26,358][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40450] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50065
[2024-02-27 11:37:26,358][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40450] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50668
[2024-02-27 11:37:46,470][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40500] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50067
[2024-02-27 11:37:46,470][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40500] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50058
[2024-02-27 11:38:07,550][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40550] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50081
[2024-02-27 11:38:07,550][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40550] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50077
[2024-02-27 11:38:28,144][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40600] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50087
[2024-02-27 11:38:28,144][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40600] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50075
[2024-02-27 11:38:49,189][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40650] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50205
[2024-02-27 11:38:49,189][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40650] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50083
[2024-02-27 11:39:09,277][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40700] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50123
[2024-02-27 11:39:09,277][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40700] - train_accuracy: 0.87889 - val_accuracy: 0.56410 - train_loss: 0.94530 - val_loss: 1.89113 - loss: 0.50079
[2024-02-27 11:39:50,856][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40750] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50066
[2024-02-27 11:39:50,856][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40750] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50078
[2024-02-27 11:40:10,831][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40800] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50172
[2024-02-27 11:40:10,831][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40800] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.51491
[2024-02-27 11:40:32,017][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40850] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50160
[2024-02-27 11:40:32,017][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40850] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50084
[2024-02-27 11:40:52,661][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40900] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50052
[2024-02-27 11:40:52,661][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40900] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 1.86907
[2024-02-27 11:41:14,248][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[40950] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.51134
[2024-02-27 11:41:14,248][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[40950] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50218
[2024-02-27 11:41:34,081][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[41000] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50264
[2024-02-27 11:41:34,081][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[41000] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.51448
[2024-02-27 11:41:55,286][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41050] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50065
[2024-02-27 11:41:55,286][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41050] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50071
[2024-02-27 11:42:15,329][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41100] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50359
[2024-02-27 11:42:15,329][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41100] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.54675
[2024-02-27 11:42:37,821][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41150] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50063
[2024-02-27 11:42:37,821][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41150] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.50079
[2024-02-27 11:42:58,342][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41200] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.52644
[2024-02-27 11:42:58,342][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41200] - train_accuracy: 0.89818 - val_accuracy: 0.59120 - train_loss: 0.89688 - val_loss: 1.73253 - loss: 0.71318
[2024-02-27 11:43:40,289][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41250] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50064
[2024-02-27 11:43:40,289][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41250] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50184
[2024-02-27 11:44:00,396][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41300] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50089
[2024-02-27 11:44:00,396][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41300] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50081
[2024-02-27 11:44:22,317][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41350] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50123
[2024-02-27 11:44:22,317][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41350] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50059
[2024-02-27 11:44:42,847][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41400] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.54639
[2024-02-27 11:44:42,847][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41400] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50063
[2024-02-27 11:45:03,878][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41450] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.51044
[2024-02-27 11:45:03,879][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41450] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50062
[2024-02-27 11:45:24,461][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41500] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50062
[2024-02-27 11:45:24,461][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41500] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50126
[2024-02-27 11:45:44,967][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41550] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.67611
[2024-02-27 11:45:44,967][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41550] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50072
[2024-02-27 11:46:05,049][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41600] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 1.15450
[2024-02-27 11:46:05,049][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41600] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50151
[2024-02-27 11:46:27,084][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41650] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50061
[2024-02-27 11:46:27,084][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41650] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50068
[2024-02-27 11:46:48,034][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41700] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50094
[2024-02-27 11:46:48,034][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41700] - train_accuracy: 0.92081 - val_accuracy: 0.55390 - train_loss: 0.80851 - val_loss: 2.01056 - loss: 0.50068
[2024-02-27 11:47:30,956][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41750] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50064
[2024-02-27 11:47:30,956][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41750] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50062
[2024-02-27 11:47:51,989][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41800] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50106
[2024-02-27 11:47:51,989][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41800] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50074
[2024-02-27 11:48:13,201][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41850] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50179
[2024-02-27 11:48:13,201][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41850] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50056
[2024-02-27 11:48:34,496][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41900] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50057
[2024-02-27 11:48:34,496][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41900] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50062
[2024-02-27 11:48:55,823][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[41950] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50080
[2024-02-27 11:48:55,823][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[41950] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50109
[2024-02-27 11:49:16,028][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[42000] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50063
[2024-02-27 11:49:16,028][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[42000] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50067
[2024-02-27 11:49:36,585][PyLogger][INFO]: Rank[1]: Epoch[434/500], iter[42050] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50542
[2024-02-27 11:49:36,585][PyLogger][INFO]: Rank[0]: Epoch[434/500], iter[42050] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 1.86946
[2024-02-27 11:49:57,583][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42100] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.55145
[2024-02-27 11:49:57,583][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42100] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50058
[2024-02-27 11:50:17,894][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42150] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50422
[2024-02-27 11:50:17,894][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42150] - train_accuracy: 0.74420 - val_accuracy: 0.52160 - train_loss: 1.27328 - val_loss: 1.75469 - loss: 0.50255
[2024-02-27 11:50:59,977][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42200] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50063
[2024-02-27 11:50:59,977][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42200] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50077
[2024-02-27 11:51:20,632][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42250] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.69101
[2024-02-27 11:51:20,632][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42250] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50068
[2024-02-27 11:51:40,610][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42300] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50134
[2024-02-27 11:51:40,610][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42300] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50058
[2024-02-27 11:52:01,699][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42350] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50051
[2024-02-27 11:52:01,699][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42350] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50061
[2024-02-27 11:52:22,377][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42400] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50095
[2024-02-27 11:52:22,378][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42400] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50051
[2024-02-27 11:52:41,946][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42450] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50053
[2024-02-27 11:52:41,946][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42450] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50189
[2024-02-27 11:53:03,283][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42500] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50071
[2024-02-27 11:53:03,283][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42500] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50052
[2024-02-27 11:53:24,820][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42550] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50063
[2024-02-27 11:53:24,820][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42550] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50061
[2024-02-27 11:53:47,187][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42600] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50063
[2024-02-27 11:53:47,187][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42600] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.54315
[2024-02-27 11:54:07,919][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42650] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.51552
[2024-02-27 11:54:07,919][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42650] - train_accuracy: 0.92351 - val_accuracy: 0.63660 - train_loss: 0.81416 - val_loss: 1.63283 - loss: 0.50072
[2024-02-27 11:54:49,352][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42700] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50071
[2024-02-27 11:54:49,353][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42700] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50104
[2024-02-27 11:55:09,539][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42750] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50049
[2024-02-27 11:55:09,539][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42750] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50078
[2024-02-27 11:55:30,129][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42800] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.67090
[2024-02-27 11:55:30,129][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42800] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50830
[2024-02-27 11:55:49,688][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42850] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50969
[2024-02-27 11:55:49,688][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42850] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50065
[2024-02-27 11:56:10,875][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42900] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.51665
[2024-02-27 11:56:10,875][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42900] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50061
[2024-02-27 11:56:31,088][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42950] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.73105
[2024-02-27 11:56:31,088][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42950] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50085
[2024-02-27 11:56:51,904][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43000] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50056
[2024-02-27 11:56:51,904][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43000] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50061
[2024-02-27 11:57:12,090][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43050] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.53673
[2024-02-27 11:57:12,090][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43050] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.54538
[2024-02-27 11:57:33,644][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43100] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50057
[2024-02-27 11:57:33,644][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43100] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50567
[2024-02-27 11:57:54,196][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43150] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50056
[2024-02-27 11:57:54,196][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43150] - train_accuracy: 0.92262 - val_accuracy: 0.64910 - train_loss: 0.82336 - val_loss: 1.53581 - loss: 0.50076
[2024-02-27 11:58:35,168][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43200] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50052
[2024-02-27 11:58:35,168][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43200] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.52012
[2024-02-27 11:58:56,045][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43250] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50082
[2024-02-27 11:58:56,045][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43250] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50063
[2024-02-27 11:59:18,197][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43300] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50129
[2024-02-27 11:59:18,197][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43300] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50063
[2024-02-27 11:59:39,224][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43350] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 1.77219
[2024-02-27 11:59:39,224][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43350] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50076
[2024-02-27 12:00:01,280][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43400] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50351
[2024-02-27 12:00:01,281][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43400] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50052
[2024-02-27 12:00:22,023][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43450] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50054
[2024-02-27 12:00:22,024][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43450] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50076
[2024-02-27 12:00:44,189][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43500] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.68376
[2024-02-27 12:00:44,189][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43500] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50056
[2024-02-27 12:01:05,433][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43550] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50101
[2024-02-27 12:01:05,433][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43550] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50056
[2024-02-27 12:01:26,818][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43600] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50055
[2024-02-27 12:01:26,818][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43600] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50069
[2024-02-27 12:01:47,746][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43650] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50059
[2024-02-27 12:01:47,746][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43650] - train_accuracy: 0.89133 - val_accuracy: 0.62420 - train_loss: 0.92667 - val_loss: 1.56208 - loss: 0.50060
[2024-02-27 12:02:29,763][PyLogger][INFO]: Rank[0]: Epoch[451/500], iter[43700] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50062
[2024-02-27 12:02:29,763][PyLogger][INFO]: Rank[1]: Epoch[451/500], iter[43700] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50079
[2024-02-27 12:02:51,102][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43750] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50054
[2024-02-27 12:02:51,102][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43750] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50064
[2024-02-27 12:03:11,567][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43800] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50111
[2024-02-27 12:03:11,567][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43800] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50053
[2024-02-27 12:03:32,471][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43850] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50098
[2024-02-27 12:03:32,471][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43850] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50212
[2024-02-27 12:03:52,659][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43900] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50066
[2024-02-27 12:03:52,659][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43900] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50086
[2024-02-27 12:04:13,182][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[43950] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50061
[2024-02-27 12:04:13,182][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[43950] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50071
[2024-02-27 12:04:33,407][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[44000] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50307
[2024-02-27 12:04:33,407][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[44000] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50057
[2024-02-27 12:04:53,987][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44050] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 1.85147
[2024-02-27 12:04:53,987][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44050] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 1.02623
[2024-02-27 12:05:15,185][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44100] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50352
[2024-02-27 12:05:15,185][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44100] - train_accuracy: 0.88207 - val_accuracy: 0.65460 - train_loss: 0.99846 - val_loss: 1.69421 - loss: 0.50072
[2024-02-27 12:05:57,717][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44150] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50105
[2024-02-27 12:05:57,717][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44150] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50055
[2024-02-27 12:06:18,327][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44200] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50092
[2024-02-27 12:06:18,327][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44200] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50056
[2024-02-27 12:06:40,409][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44250] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50340
[2024-02-27 12:06:40,409][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44250] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50057
[2024-02-27 12:07:01,965][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44300] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 1.84862
[2024-02-27 12:07:01,965][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44300] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50056
[2024-02-27 12:07:23,000][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44350] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.51333
[2024-02-27 12:07:23,000][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44350] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50057
[2024-02-27 12:07:42,599][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44400] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50057
[2024-02-27 12:07:42,599][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44400] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50051
[2024-02-27 12:08:03,702][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44450] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50050
[2024-02-27 12:08:03,702][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44450] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 1.86257
[2024-02-27 12:08:23,572][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44500] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50058
[2024-02-27 12:08:23,572][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44500] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 1.81456
[2024-02-27 12:08:45,285][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44550] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 1.84121
[2024-02-27 12:08:45,285][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44550] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50098
[2024-02-27 12:09:05,618][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44600] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50062
[2024-02-27 12:09:05,618][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44600] - train_accuracy: 0.89499 - val_accuracy: 0.62180 - train_loss: 0.88999 - val_loss: 1.65781 - loss: 0.50062
[2024-02-27 12:09:48,319][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44650] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50063
[2024-02-27 12:09:48,319][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44650] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50054
[2024-02-27 12:10:08,480][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44700] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50702
[2024-02-27 12:10:08,480][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44700] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50072
[2024-02-27 12:10:30,492][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44750] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50075
[2024-02-27 12:10:30,492][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44750] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50078
[2024-02-27 12:10:50,408][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44800] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50368
[2024-02-27 12:10:50,408][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44800] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50067
[2024-02-27 12:11:11,457][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44850] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50117
[2024-02-27 12:11:11,457][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44850] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50058
[2024-02-27 12:11:32,783][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44900] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50082
[2024-02-27 12:11:32,783][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44900] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50076
[2024-02-27 12:11:54,638][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[44950] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50053
[2024-02-27 12:11:54,638][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[44950] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50057
[2024-02-27 12:12:15,090][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[45000] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 1.06702
[2024-02-27 12:12:15,090][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[45000] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50062
[2024-02-27 12:12:36,065][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45050] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50053
[2024-02-27 12:12:36,065][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45050] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50058
[2024-02-27 12:12:55,893][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45100] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.50056
[2024-02-27 12:12:55,893][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45100] - train_accuracy: 0.85005 - val_accuracy: 0.58780 - train_loss: 1.01031 - val_loss: 1.71718 - loss: 0.71358
[2024-02-27 12:13:38,261][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45150] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50793
[2024-02-27 12:13:38,261][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45150] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50060
[2024-02-27 12:13:58,625][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45200] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50051
[2024-02-27 12:13:58,626][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45200] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50085
[2024-02-27 12:14:20,025][PyLogger][INFO]: Rank[1]: Epoch[467/500], iter[45250] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50052
[2024-02-27 12:14:20,025][PyLogger][INFO]: Rank[0]: Epoch[467/500], iter[45250] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.52588
[2024-02-27 12:14:41,361][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45300] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50059
[2024-02-27 12:14:41,361][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45300] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50237
[2024-02-27 12:15:02,046][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45350] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 1.78776
[2024-02-27 12:15:02,046][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45350] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50074
[2024-02-27 12:15:22,976][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45400] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50075
[2024-02-27 12:15:22,976][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45400] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50056
[2024-02-27 12:15:43,601][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45450] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50679
[2024-02-27 12:15:43,601][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45450] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50057
[2024-02-27 12:16:04,660][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45500] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.51710
[2024-02-27 12:16:04,660][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45500] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50058
[2024-02-27 12:16:25,325][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45550] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50088
[2024-02-27 12:16:25,325][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45550] - train_accuracy: 0.91988 - val_accuracy: 0.58450 - train_loss: 0.86511 - val_loss: 1.69704 - loss: 0.50087
[2024-02-27 12:17:07,660][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45600] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50109
[2024-02-27 12:17:07,660][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45600] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50055
[2024-02-27 12:17:28,773][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45650] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50049
[2024-02-27 12:17:28,773][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45650] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50059
[2024-02-27 12:17:49,896][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45700] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 1.80827
[2024-02-27 12:17:49,896][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45700] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50119
[2024-02-27 12:18:09,742][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45750] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.64103
[2024-02-27 12:18:09,742][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45750] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50106
[2024-02-27 12:18:31,247][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45800] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.69868
[2024-02-27 12:18:31,247][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45800] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50061
[2024-02-27 12:18:51,383][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45850] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50067
[2024-02-27 12:18:51,383][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45850] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50068
[2024-02-27 12:19:11,655][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45900] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.53498
[2024-02-27 12:19:11,655][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45900] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50071
[2024-02-27 12:19:33,007][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45950] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50976
[2024-02-27 12:19:33,007][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45950] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 1.83871
[2024-02-27 12:19:54,034][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46000] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50061
[2024-02-27 12:19:54,034][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46000] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50091
[2024-02-27 12:20:14,634][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46050] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50087
[2024-02-27 12:20:14,634][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46050] - train_accuracy: 0.71358 - val_accuracy: 0.53940 - train_loss: 1.37284 - val_loss: 1.70052 - loss: 0.50081
[2024-02-27 12:20:55,542][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46100] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50062
[2024-02-27 12:20:55,542][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46100] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50192
[2024-02-27 12:21:14,061][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46150] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50347
[2024-02-27 12:21:14,061][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46150] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50065
[2024-02-27 12:21:34,883][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46200] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50081
[2024-02-27 12:21:34,883][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46200] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50462
[2024-02-27 12:21:56,405][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46250] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50055
[2024-02-27 12:21:56,405][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46250] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.51687
[2024-02-27 12:22:18,613][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46300] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.53039
[2024-02-27 12:22:18,613][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46300] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50052
[2024-02-27 12:22:39,605][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46350] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50074
[2024-02-27 12:22:39,605][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46350] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50056
[2024-02-27 12:23:01,221][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46400] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50059
[2024-02-27 12:23:01,221][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46400] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.53290
[2024-02-27 12:23:22,161][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46450] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50122
[2024-02-27 12:23:22,161][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46450] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.57784
[2024-02-27 12:23:43,612][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46500] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50087
[2024-02-27 12:23:43,612][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46500] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50058
[2024-02-27 12:24:05,205][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46550] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 1.80588
[2024-02-27 12:24:05,205][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46550] - train_accuracy: 0.70063 - val_accuracy: 0.53700 - train_loss: 1.35580 - val_loss: 1.71017 - loss: 0.50052
[2024-02-27 12:24:46,958][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46600] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50086
[2024-02-27 12:24:46,958][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46600] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50070
[2024-02-27 12:25:08,082][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46650] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50743
[2024-02-27 12:25:08,082][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46650] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 1.06246
[2024-02-27 12:25:29,030][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46700] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50064
[2024-02-27 12:25:29,030][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46700] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50791
[2024-02-27 12:25:50,022][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46750] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50068
[2024-02-27 12:25:50,022][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46750] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50076
[2024-02-27 12:26:11,820][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46800] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50071
[2024-02-27 12:26:11,820][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46800] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50063
[2024-02-27 12:26:32,429][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46850] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50060
[2024-02-27 12:26:32,429][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46850] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50077
[2024-02-27 12:26:53,280][PyLogger][INFO]: Rank[0]: Epoch[484/500], iter[46900] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50049
[2024-02-27 12:26:53,280][PyLogger][INFO]: Rank[1]: Epoch[484/500], iter[46900] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.60059
[2024-02-27 12:27:14,919][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[46950] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.52398
[2024-02-27 12:27:14,919][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[46950] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50051
[2024-02-27 12:27:35,465][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[47000] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 1.86544
[2024-02-27 12:27:35,465][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[47000] - train_accuracy: 0.87333 - val_accuracy: 0.58570 - train_loss: 0.98778 - val_loss: 1.67577 - loss: 0.50056
[2024-02-27 12:28:17,963][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47050] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.54702
[2024-02-27 12:28:17,963][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47050] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50061
[2024-02-27 12:28:38,936][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47100] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50055
[2024-02-27 12:28:38,936][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47100] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50060
[2024-02-27 12:29:01,054][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47150] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50094
[2024-02-27 12:29:01,054][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47150] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 1.10130
[2024-02-27 12:29:21,738][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47200] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50054
[2024-02-27 12:29:21,738][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47200] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50053
[2024-02-27 12:29:42,415][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47250] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50065
[2024-02-27 12:29:42,415][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47250] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50081
[2024-02-27 12:30:02,113][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47300] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50055
[2024-02-27 12:30:02,113][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47300] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50076
[2024-02-27 12:30:23,593][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47350] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50065
[2024-02-27 12:30:23,593][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47350] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50056
[2024-02-27 12:30:44,696][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47400] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 1.88438
[2024-02-27 12:30:44,696][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47400] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50051
[2024-02-27 12:31:06,302][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47450] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50071
[2024-02-27 12:31:06,302][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47450] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50054
[2024-02-27 12:31:27,671][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47500] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50958
[2024-02-27 12:31:27,671][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47500] - train_accuracy: 0.91549 - val_accuracy: 0.60010 - train_loss: 0.83091 - val_loss: 1.71689 - loss: 0.50058
[2024-02-27 12:32:10,163][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47550] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50066
[2024-02-27 12:32:10,163][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47550] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50049
[2024-02-27 12:32:31,739][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47600] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50073
[2024-02-27 12:32:31,739][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47600] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50058
[2024-02-27 12:32:52,210][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47650] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50816
[2024-02-27 12:32:52,210][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47650] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50071
[2024-02-27 12:33:12,482][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47700] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.65769
[2024-02-27 12:33:12,482][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47700] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50066
[2024-02-27 12:33:34,165][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47750] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50081
[2024-02-27 12:33:34,165][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47750] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50309
[2024-02-27 12:33:54,695][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47800] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50087
[2024-02-27 12:33:54,695][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47800] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50084
[2024-02-27 12:34:16,618][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47850] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50089
[2024-02-27 12:34:16,618][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47850] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50061
[2024-02-27 12:34:37,513][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47900] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50062
[2024-02-27 12:34:37,513][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47900] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50048
[2024-02-27 12:34:58,710][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[47950] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50057
[2024-02-27 12:34:58,710][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[47950] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50155
[2024-02-27 12:35:18,024][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[48000] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50064
[2024-02-27 12:35:18,024][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[48000] - train_accuracy: 0.83175 - val_accuracy: 0.48430 - train_loss: 1.05763 - val_loss: 2.04833 - loss: 0.50080
[2024-02-27 12:35:59,071][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48050] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50069
[2024-02-27 12:35:59,071][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48050] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50058
[2024-02-27 12:36:19,529][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48100] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50070
[2024-02-27 12:36:19,529][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48100] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50052
[2024-02-27 12:36:41,188][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48150] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.53499
[2024-02-27 12:36:41,188][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48150] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50076
[2024-02-27 12:37:02,006][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48200] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50054
[2024-02-27 12:37:02,006][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48200] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50051
[2024-02-27 12:37:23,449][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48250] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50067
[2024-02-27 12:37:23,449][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48250] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50059
[2024-02-27 12:37:43,904][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48300] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50059
[2024-02-27 12:37:43,904][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48300] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.53301
[2024-02-27 12:38:04,462][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48350] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50142
[2024-02-27 12:38:04,462][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48350] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50058
[2024-02-27 12:38:24,474][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48400] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.62937
[2024-02-27 12:38:24,474][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48400] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 1.07118
[2024-02-27 12:38:46,694][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48450] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.50052
[2024-02-27 12:38:46,694][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48450] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 1.03629
[2024-02-27 12:39:06,584][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48500] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.54916
[2024-02-27 12:39:06,584][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48500] - train_accuracy: 0.91134 - val_accuracy: 0.60030 - train_loss: 0.85843 - val_loss: 1.67292 - loss: 0.53225
Files already downloaded and verified
Files already downloaded and verified
2024-02-27 12:39:30,015 ignite.distributed.launcher.Parallel INFO: End of run
2024-02-27 12:39:35,650 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:39:35,650 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:39:35,650 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d6811463e0>' in 2 processes
2024-02-27 12:39:45,548 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:39:45,970 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14745d4085c0>}
[2024-02-27 12:39:47,400][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:39:47,400][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:39:47,400][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:39:47,400][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:39:47,401][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:39:47,401][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:39:47,401][PyLogger][INFO]: World size: 2
[2024-02-27 12:39:47,401][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:39:47,401][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:39:47,401][PyLogger][INFO]: World size: 2
[2024-02-27 12:39:50,876][PyLogger][INFO]: Rank[0]: val_accuracy: 0.15400
[2024-02-27 12:39:50,876][PyLogger][INFO]: Rank[1]: val_accuracy: 0.15400
2024-02-27 12:39:52,282 ignite.distributed.launcher.Parallel INFO: End of run
new_size=2 done.
2024-02-27 12:39:57,631 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:39:57,631 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:39:57,631 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1519734da3e0>' in 2 processes
2024-02-27 12:40:06,848 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:40:07,263 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145bf735acc0>}
[2024-02-27 12:40:07,379][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:40:07,379][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:40:07,380][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:07,380][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:40:07,381][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:40:07,381][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:07,381][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:07,384][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:07,384][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:07,384][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:10,849][PyLogger][INFO]: Rank[0]: val_accuracy: 0.30180
[2024-02-27 12:40:10,849][PyLogger][INFO]: Rank[1]: val_accuracy: 0.30180
2024-02-27 12:40:12,275 ignite.distributed.launcher.Parallel INFO: End of run
new_size=3 done.
2024-02-27 12:40:17,129 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:40:17,129 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:40:17,129 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x153e052de3e0>' in 2 processes
2024-02-27 12:40:25,932 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:40:26,359 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d8742096a0>}
[2024-02-27 12:40:26,472][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:40:26,472][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:40:26,472][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:26,473][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:40:26,474][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:40:26,474][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:26,474][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:26,475][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:26,475][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:26,475][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:29,884][PyLogger][INFO]: Rank[1]: val_accuracy: 0.34270
[2024-02-27 12:40:29,884][PyLogger][INFO]: Rank[0]: val_accuracy: 0.34270
2024-02-27 12:40:31,295 ignite.distributed.launcher.Parallel INFO: End of run
new_size=4 done.
2024-02-27 12:40:35,459 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:40:35,459 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:40:35,459 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15334671e3e0>' in 2 processes
2024-02-27 12:40:44,430 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:40:44,862 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x146902394680>}
[2024-02-27 12:40:44,987][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:44,987][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:44,987][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:44,990][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:40:44,990][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:40:44,990][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:40:44,990][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:40:44,992][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:40:44,992][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:40:44,992][PyLogger][INFO]: World size: 2
[2024-02-27 12:40:48,558][PyLogger][INFO]: Rank[1]: val_accuracy: 0.46440
[2024-02-27 12:40:48,558][PyLogger][INFO]: Rank[0]: val_accuracy: 0.46440
2024-02-27 12:40:50,033 ignite.distributed.launcher.Parallel INFO: End of run
new_size=5 done.
2024-02-27 12:40:55,199 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:40:55,200 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:40:55,200 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1506a2cd63e0>' in 2 processes
2024-02-27 12:41:04,708 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:41:05,131 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14584e934200>}
[2024-02-27 12:41:05,245][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:05,246][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:05,246][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:05,251][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:41:05,251][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:41:05,251][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:05,251][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:41:05,252][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:41:05,252][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:05,252][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:08,848][PyLogger][INFO]: Rank[1]: val_accuracy: 0.50240
[2024-02-27 12:41:08,848][PyLogger][INFO]: Rank[0]: val_accuracy: 0.50240
2024-02-27 12:41:10,281 ignite.distributed.launcher.Parallel INFO: End of run
new_size=6 done.
2024-02-27 12:41:15,822 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:41:15,822 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:41:15,822 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152336b8e3e0>' in 2 processes
2024-02-27 12:41:26,009 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:41:26,415 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ff70078500>}
[2024-02-27 12:41:26,531][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:26,531][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:26,531][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:26,533][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:41:26,533][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:41:26,533][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:26,533][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:41:26,534][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:41:26,534][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:26,534][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:30,089][PyLogger][INFO]: Rank[1]: val_accuracy: 0.53170
[2024-02-27 12:41:30,089][PyLogger][INFO]: Rank[0]: val_accuracy: 0.53170
2024-02-27 12:41:31,545 ignite.distributed.launcher.Parallel INFO: End of run
new_size=7 done.
2024-02-27 12:41:36,583 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:41:36,583 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:41:36,583 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x147fa85523e0>' in 2 processes
2024-02-27 12:41:46,150 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:41:46,559 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154bf4dd5b80>}
[2024-02-27 12:41:46,673][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:41:46,673][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:41:46,673][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:46,673][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:41:46,674][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:41:46,674][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:46,674][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:46,675][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:41:46,675][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:41:46,675][PyLogger][INFO]: World size: 2
[2024-02-27 12:41:50,257][PyLogger][INFO]: Rank[1]: val_accuracy: 0.54230
[2024-02-27 12:41:50,257][PyLogger][INFO]: Rank[0]: val_accuracy: 0.54230
2024-02-27 12:41:51,293 ignite.distributed.launcher.Parallel INFO: End of run
new_size=8 done.
2024-02-27 12:41:56,472 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:41:56,472 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:41:56,472 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1522021a63e0>' in 2 processes
2024-02-27 12:42:05,465 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:42:05,889 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x152e1a7f68a0>}
[2024-02-27 12:42:06,000][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:42:06,000][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:42:06,000][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:06,000][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:42:06,001][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:42:06,001][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:06,001][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:06,001][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:06,002][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:06,002][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:09,778][PyLogger][INFO]: Rank[0]: val_accuracy: 0.56110
[2024-02-27 12:42:09,778][PyLogger][INFO]: Rank[1]: val_accuracy: 0.56110
2024-02-27 12:42:10,818 ignite.distributed.launcher.Parallel INFO: End of run
new_size=9 done.
2024-02-27 12:42:16,416 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:42:16,416 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:42:16,416 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14b1084e63e0>' in 2 processes
2024-02-27 12:42:25,977 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:42:26,372 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ae0b929ac0>}
[2024-02-27 12:42:26,484][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:42:26,484][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:42:26,484][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:26,484][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:42:26,485][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:42:26,485][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:26,485][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:26,490][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:26,490][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:26,491][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:30,175][PyLogger][INFO]: Rank[0]: val_accuracy: 0.57340
[2024-02-27 12:42:30,175][PyLogger][INFO]: Rank[1]: val_accuracy: 0.57340
2024-02-27 12:42:31,628 ignite.distributed.launcher.Parallel INFO: End of run
new_size=10 done.
2024-02-27 12:42:36,072 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:42:36,072 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:42:36,072 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1485cf2863e0>' in 2 processes
2024-02-27 12:42:43,851 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:42:44,273 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15380c9ace30>}
[2024-02-27 12:42:44,387][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:42:44,387][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:42:44,387][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:44,387][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:42:44,388][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:42:44,389][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:44,389][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:44,394][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:42:44,394][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:42:44,394][PyLogger][INFO]: World size: 2
[2024-02-27 12:42:48,141][PyLogger][INFO]: Rank[0]: val_accuracy: 0.58530
[2024-02-27 12:42:48,141][PyLogger][INFO]: Rank[1]: val_accuracy: 0.58530
2024-02-27 12:42:49,582 ignite.distributed.launcher.Parallel INFO: End of run
new_size=11 done.
2024-02-27 12:42:54,795 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:42:54,796 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:42:54,796 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14a93045e3e0>' in 2 processes
2024-02-27 12:43:05,216 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:43:05,648 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b4927e88f0>}
[2024-02-27 12:43:05,764][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:05,764][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:05,764][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:05,767][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:43:05,767][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:43:05,767][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:05,767][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:43:05,769][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:43:05,769][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:05,769][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:09,478][PyLogger][INFO]: Rank[0]: val_accuracy: 0.59140
[2024-02-27 12:43:09,478][PyLogger][INFO]: Rank[1]: val_accuracy: 0.59140
2024-02-27 12:43:10,937 ignite.distributed.launcher.Parallel INFO: End of run
new_size=12 done.
2024-02-27 12:43:16,853 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:43:16,853 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:43:16,853 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146fdb83e3e0>' in 2 processes
2024-02-27 12:43:27,662 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:43:28,076 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14affff4cb90>}
[2024-02-27 12:43:28,188][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:28,189][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:28,189][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:28,193][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:43:28,193][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:43:28,193][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:28,193][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:43:28,194][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:43:28,194][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:28,194][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:32,037][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60010
[2024-02-27 12:43:32,037][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60010
2024-02-27 12:43:33,499 ignite.distributed.launcher.Parallel INFO: End of run
new_size=13 done.
2024-02-27 12:43:38,525 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:43:38,525 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:43:38,525 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14a2d5ab23e0>' in 2 processes
2024-02-27 12:43:48,614 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:43:49,033 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15176e0b5a60>}
[2024-02-27 12:43:49,149][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:43:49,149][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:43:49,149][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:49,149][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:43:49,150][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:43:49,150][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:49,150][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:49,153][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:43:49,153][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:43:49,153][PyLogger][INFO]: World size: 2
[2024-02-27 12:43:53,040][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60690
[2024-02-27 12:43:53,040][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60690
2024-02-27 12:43:54,108 ignite.distributed.launcher.Parallel INFO: End of run
new_size=14 done.
2024-02-27 12:43:59,460 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:43:59,460 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:43:59,460 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f1d93be3e0>' in 2 processes
2024-02-27 12:44:08,736 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:44:09,152 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149bf61ec2c0>}
[2024-02-27 12:44:09,265][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:09,266][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:09,266][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:09,270][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:44:09,270][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:44:09,270][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:09,270][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:44:09,272][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:44:09,272][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:09,272][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:13,189][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60830
[2024-02-27 12:44:13,189][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60830
2024-02-27 12:44:14,223 ignite.distributed.launcher.Parallel INFO: End of run
new_size=15 done.
2024-02-27 12:44:19,864 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:44:19,864 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:44:19,864 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d69c0d23e0>' in 2 processes
2024-02-27 12:44:29,609 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:44:30,004 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1526759dce00>}
[2024-02-27 12:44:30,121][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:44:30,121][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:44:30,121][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:30,121][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:44:30,122][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:44:30,122][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:30,122][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:30,123][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:30,123][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:30,123][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:34,029][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61150
[2024-02-27 12:44:34,029][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61150
2024-02-27 12:44:35,481 ignite.distributed.launcher.Parallel INFO: End of run
new_size=16 done.
2024-02-27 12:44:39,941 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:44:39,941 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:44:39,941 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146a106d63e0>' in 2 processes
2024-02-27 12:44:50,240 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:44:50,649 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151b7a65c440>}
[2024-02-27 12:44:50,763][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:44:50,764][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:44:50,764][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:50,764][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:44:50,766][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:44:50,766][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:50,766][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:50,773][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:44:50,774][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:44:50,774][PyLogger][INFO]: World size: 2
[2024-02-27 12:44:54,746][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60970
[2024-02-27 12:44:54,746][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60970
2024-02-27 12:44:56,195 ignite.distributed.launcher.Parallel INFO: End of run
new_size=17 done.
2024-02-27 12:45:01,116 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:45:01,116 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:45:01,116 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14fff406e3e0>' in 2 processes
2024-02-27 12:45:11,036 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:45:11,475 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14e0b79dce60>}
[2024-02-27 12:45:11,587][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:45:11,587][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:45:11,587][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:11,587][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:45:11,588][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:45:11,588][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:11,588][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:11,590][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:11,591][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:11,591][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:15,706][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61110
[2024-02-27 12:45:15,706][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61110
2024-02-27 12:45:17,164 ignite.distributed.launcher.Parallel INFO: End of run
new_size=18 done.
2024-02-27 12:45:22,517 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:45:22,517 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:45:22,517 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f4bf89a3e0>' in 2 processes
2024-02-27 12:45:32,325 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:45:32,718 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148fe90d8e60>}
[2024-02-27 12:45:32,833][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:32,833][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:32,833][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:32,835][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:45:32,835][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:45:32,835][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:32,835][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:45:32,836][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:45:32,836][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:32,836][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:36,892][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61160
[2024-02-27 12:45:36,892][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61160
2024-02-27 12:45:38,349 ignite.distributed.launcher.Parallel INFO: End of run
new_size=19 done.
2024-02-27 12:45:43,424 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:45:43,424 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:45:43,424 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154a559363e0>' in 2 processes
2024-02-27 12:45:52,526 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:45:52,932 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1499834ace00>}
[2024-02-27 12:45:53,047][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:53,047][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:53,048][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:53,050][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:45:53,050][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:45:53,050][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:45:53,050][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:45:53,052][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:45:53,052][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:45:53,052][PyLogger][INFO]: World size: 2
[2024-02-27 12:45:57,263][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61340
[2024-02-27 12:45:57,263][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61340
2024-02-27 12:45:58,305 ignite.distributed.launcher.Parallel INFO: End of run
new_size=20 done.
2024-02-27 12:46:03,130 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:46:03,130 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:46:03,130 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1516791ea3e0>' in 2 processes
2024-02-27 12:46:12,063 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:46:12,486 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x152ecdd0ed20>}
[2024-02-27 12:46:12,599][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:46:12,599][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:46:12,599][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:12,599][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:46:12,600][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:46:12,600][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:12,600][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:12,604][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:12,604][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:12,604][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:16,853][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61250
[2024-02-27 12:46:16,853][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61250
2024-02-27 12:46:18,321 ignite.distributed.launcher.Parallel INFO: End of run
new_size=21 done.
2024-02-27 12:46:24,180 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:46:24,180 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:46:24,180 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154453d423e0>' in 2 processes
2024-02-27 12:46:34,355 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:46:34,760 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d330733740>}
[2024-02-27 12:46:34,875][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:46:34,876][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:46:34,876][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:34,876][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:46:34,877][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:46:34,877][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:34,877][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:34,878][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:34,878][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:34,878][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:39,146][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61230
[2024-02-27 12:46:39,146][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61230
2024-02-27 12:46:40,641 ignite.distributed.launcher.Parallel INFO: End of run
new_size=22 done.
2024-02-27 12:46:45,794 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:46:45,794 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:46:45,794 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1533722523e0>' in 2 processes
2024-02-27 12:46:54,573 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:46:54,991 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1519d6b9aba0>}
[2024-02-27 12:46:55,110][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:46:55,111][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:46:55,111][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:55,111][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:46:55,113][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:46:55,113][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:55,113][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:55,113][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:46:55,113][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:46:55,113][PyLogger][INFO]: World size: 2
[2024-02-27 12:46:59,529][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61070
[2024-02-27 12:46:59,529][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61070
2024-02-27 12:47:01,001 ignite.distributed.launcher.Parallel INFO: End of run
new_size=23 done.
2024-02-27 12:47:05,864 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:47:05,864 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:47:05,864 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f12c1763e0>' in 2 processes
2024-02-27 12:47:14,902 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:47:15,338 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148c3eea8380>}
[2024-02-27 12:47:15,453][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:47:15,453][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:47:15,453][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:15,453][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:47:15,454][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:47:15,455][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:15,455][PyLogger][INFO]: World size: 2
[2024-02-27 12:47:15,463][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:15,463][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:15,463][PyLogger][INFO]: World size: 2
[2024-02-27 12:47:19,861][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60940
[2024-02-27 12:47:19,861][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60940
2024-02-27 12:47:20,914 ignite.distributed.launcher.Parallel INFO: End of run
new_size=24 done.
2024-02-27 12:47:26,075 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:47:26,075 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:47:26,075 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c8952563e0>' in 2 processes
2024-02-27 12:47:34,983 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:47:35,393 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14e211768dd0>}
[2024-02-27 12:47:35,510][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:35,510][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:35,510][PyLogger][INFO]: World size: 2
[2024-02-27 12:47:35,511][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:47:35,511][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:47:35,511][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:35,511][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:47:35,512][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:47:35,512][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:35,513][PyLogger][INFO]: World size: 2
[2024-02-27 12:47:40,081][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60310
[2024-02-27 12:47:40,081][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60310
2024-02-27 12:47:41,182 ignite.distributed.launcher.Parallel INFO: End of run
new_size=25 done.
2024-02-27 12:47:45,485 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:47:45,485 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:47:45,485 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e2fee0a3e0>' in 2 processes
2024-02-27 12:47:55,351 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:47:55,797 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x147f589fae10>}
[2024-02-27 12:47:55,915][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:47:55,915][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:47:55,915][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:55,915][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:47:55,916][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:47:55,916][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:55,916][PyLogger][INFO]: World size: 2
[2024-02-27 12:47:55,917][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:47:55,917][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:47:55,917][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:00,600][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
[2024-02-27 12:48:00,600][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
2024-02-27 12:48:02,104 ignite.distributed.launcher.Parallel INFO: End of run
new_size=26 done.
2024-02-27 12:48:07,030 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:48:07,030 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:48:07,030 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1462410523e0>' in 2 processes
2024-02-27 12:48:16,261 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:48:16,682 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14dc3d35c680>}
[2024-02-27 12:48:16,801][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:16,801][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:16,801][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:16,803][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:48:16,803][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:48:16,803][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:16,803][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:48:16,804][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:48:16,804][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:16,804][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:21,584][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60210
[2024-02-27 12:48:21,584][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60210
2024-02-27 12:48:23,073 ignite.distributed.launcher.Parallel INFO: End of run
new_size=27 done.
2024-02-27 12:48:28,467 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:48:28,467 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:48:28,467 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152db183a3e0>' in 2 processes
2024-02-27 12:48:37,435 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:48:37,852 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f0dc8eaf30>}
[2024-02-27 12:48:37,966][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:37,966][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:37,966][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:37,975][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:48:37,975][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:48:37,975][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:37,975][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:48:37,976][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:48:37,976][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:37,976][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:42,756][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60140
[2024-02-27 12:48:42,756][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60140
2024-02-27 12:48:44,243 ignite.distributed.launcher.Parallel INFO: End of run
new_size=28 done.
2024-02-27 12:48:48,954 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:48:48,954 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:48:48,954 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f72213e3e0>' in 2 processes
2024-02-27 12:48:58,599 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:48:59,040 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f690d2d940>}
[2024-02-27 12:48:59,154][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:48:59,154][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:48:59,154][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:59,154][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:48:59,155][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:48:59,156][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:59,156][PyLogger][INFO]: World size: 2
[2024-02-27 12:48:59,166][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:48:59,166][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:48:59,166][PyLogger][INFO]: World size: 2
[2024-02-27 12:49:04,081][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60140
[2024-02-27 12:49:04,081][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60140
2024-02-27 12:49:05,618 ignite.distributed.launcher.Parallel INFO: End of run
new_size=29 done.
2024-02-27 12:49:10,297 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:49:10,297 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:49:10,297 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e7d0ade3e0>' in 2 processes
2024-02-27 12:49:20,003 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:49:20,421 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14843c9f4b90>}
[2024-02-27 12:49:20,536][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:49:20,536][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:49:20,536][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:49:20,536][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:49:20,537][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:49:20,537][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:49:20,537][PyLogger][INFO]: World size: 2
[2024-02-27 12:49:20,542][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:49:20,542][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:49:20,542][PyLogger][INFO]: World size: 2
[2024-02-27 12:49:25,510][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
[2024-02-27 12:49:25,510][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
2024-02-27 12:49:26,600 ignite.distributed.launcher.Parallel INFO: End of run
new_size=30 done.
2024-02-27 12:49:31,437 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:49:31,437 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:49:31,437 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14cb30c023e0>' in 2 processes
2024-02-27 12:49:40,558 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:49:40,989 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x153251ea04a0>}
[2024-02-27 12:49:41,106][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:49:41,107][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:49:41,107][PyLogger][INFO]: World size: 2
[2024-02-27 12:49:41,108][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:49:41,108][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:49:41,108][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:49:41,108][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:49:41,109][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:49:41,109][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:49:41,109][PyLogger][INFO]: World size: 2
[2024-02-27 12:49:46,386][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60240
[2024-02-27 12:49:46,386][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60240
2024-02-27 12:49:47,495 ignite.distributed.launcher.Parallel INFO: End of run
new_size=31 done.
2024-02-27 12:49:51,989 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:49:51,989 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:49:51,989 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150c1db9a3e0>' in 2 processes
2024-02-27 12:50:00,678 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:50:01,091 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ba23784b30>}
[2024-02-27 12:50:01,201][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:01,201][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:01,201][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:01,204][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:50:01,204][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:50:01,204][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:01,204][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:50:01,205][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:50:01,205][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:01,205][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:06,493][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
[2024-02-27 12:50:06,493][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
2024-02-27 12:50:07,978 ignite.distributed.launcher.Parallel INFO: End of run
new_size=32 done.
2024-02-27 12:50:12,368 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:50:12,368 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:50:12,368 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d8987e63e0>' in 2 processes
2024-02-27 12:50:22,154 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:50:22,612 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151527008380>}
[2024-02-27 12:50:22,727][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:22,727][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:22,727][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:22,730][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:50:22,730][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:50:22,730][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:22,730][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:50:22,731][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:50:22,731][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:22,731][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:28,054][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
[2024-02-27 12:50:28,054][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
2024-02-27 12:50:29,562 ignite.distributed.launcher.Parallel INFO: End of run
new_size=33 done.
2024-02-27 12:50:34,984 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:50:34,984 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:50:34,984 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x145babe8a3e0>' in 2 processes
2024-02-27 12:50:43,973 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:50:44,393 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14acb63bacc0>}
[2024-02-27 12:50:44,505][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:50:44,505][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:50:44,505][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:44,505][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:50:44,506][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:50:44,506][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:44,506][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:44,507][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:50:44,507][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:50:44,507][PyLogger][INFO]: World size: 2
[2024-02-27 12:50:49,769][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
[2024-02-27 12:50:49,769][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
2024-02-27 12:50:51,284 ignite.distributed.launcher.Parallel INFO: End of run
new_size=34 done.
2024-02-27 12:50:55,830 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:50:55,830 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:50:55,830 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14954f38e3e0>' in 2 processes
2024-02-27 12:51:04,253 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:51:04,669 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15047561c680>}
[2024-02-27 12:51:04,781][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:51:04,781][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:51:04,781][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:51:04,781][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:51:04,782][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:51:04,782][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:51:04,782][PyLogger][INFO]: World size: 2
[2024-02-27 12:51:04,785][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:51:04,786][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:51:04,786][PyLogger][INFO]: World size: 2
[2024-02-27 12:51:09,994][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
[2024-02-27 12:51:09,994][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
2024-02-27 12:51:11,494 ignite.distributed.launcher.Parallel INFO: End of run
new_size=35 done.
2024-02-27 12:51:16,117 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:51:16,117 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:51:16,117 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x153eff7723e0>' in 2 processes
2024-02-27 12:51:24,128 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:51:24,559 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1550edbd1760>}
[2024-02-27 12:51:24,671][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:51:24,672][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:51:24,672][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:51:24,672][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:51:24,673][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:51:24,673][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:51:24,673][PyLogger][INFO]: World size: 2
[2024-02-27 12:51:24,677][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:51:24,677][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:51:24,677][PyLogger][INFO]: World size: 2
[2024-02-27 12:51:29,952][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60220
[2024-02-27 12:51:29,952][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60220
2024-02-27 12:51:31,448 ignite.distributed.launcher.Parallel INFO: End of run
new_size=36 done.
