SLURM_JOB_ID: 55705875
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: dct_cifar10_sgl
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r23g39
SLURM_JOB_CPUS_PER_NODE: 18
SLURM_JOB_GPUS: 0,1
Date: Tue Feb 27 12:55:08 CET 2024
Walltime: 00-12:00:00
========================================================================
2024-02-27 12:55:14,558 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 12:55:14,558 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 12:55:14,558 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x150d95c593a0>' in 2 processes
2024-02-27 12:55:24,821 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 12:55:25,651 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145a20b8d100>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
2024-02-27 12:55:25,995 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145a2091dcd0>}
[2024-02-27 12:55:25,999][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 12:55:26,000][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:55:26,000][PyLogger][INFO]: World size: 2
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-27 12:55:26,009][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 12:55:26,009][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 12:55:26,009][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 12:55:26,009][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 12:55:26,010][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 12:55:26,010][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 12:55:26,010][PyLogger][INFO]: World size: 2
[2024-02-27 12:55:54,782][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 3.15946
[2024-02-27 12:55:54,782][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 3.14407
[2024-02-27 12:56:21,667][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.30689
[2024-02-27 12:56:21,667][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.33013
[2024-02-27 12:56:48,103][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.25666
[2024-02-27 12:56:48,103][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.30891
[2024-02-27 12:57:15,075][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.15190
[2024-02-27 12:57:15,076][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.09937
[2024-02-27 12:57:41,726][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 1.97083
[2024-02-27 12:57:41,726][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.05602
[2024-02-27 12:58:08,678][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.01384
[2024-02-27 12:58:08,678][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 1.92084
[2024-02-27 12:58:35,119][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 1.94640
[2024-02-27 12:58:35,119][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 1.83249
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-27 12:59:01,982][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 1.71413
[2024-02-27 12:59:01,982][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 1.85599
[2024-02-27 12:59:28,370][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 1.78249
[2024-02-27 12:59:28,370][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 1.67552
[2024-02-27 13:00:23,055][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.71040
[2024-02-27 13:00:23,055][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.71035
[2024-02-27 13:00:49,530][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.69367
[2024-02-27 13:00:49,530][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.72287
[2024-02-27 13:01:16,499][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.63930
[2024-02-27 13:01:16,499][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.79287
[2024-02-27 13:01:42,996][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.67530
[2024-02-27 13:01:42,996][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.62806
[2024-02-27 13:02:09,942][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.58028
[2024-02-27 13:02:09,942][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.56392
[2024-02-27 13:02:36,497][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.49286
[2024-02-27 13:02:36,497][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.56947
[2024-02-27 13:03:03,577][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.55679
[2024-02-27 13:03:03,577][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.58523
[2024-02-27 13:03:30,094][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.57463
[2024-02-27 13:03:30,094][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.66401
[2024-02-27 13:03:57,067][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.56227
[2024-02-27 13:03:57,067][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.59561
[2024-02-27 13:04:23,575][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.57222
[2024-02-27 13:04:23,575][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.41519 - val_accuracy: 0.43010 - train_loss: 1.74815 - val_loss: 1.72421 - loss: 1.52932
[2024-02-27 13:05:18,621][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.49502
[2024-02-27 13:05:18,621][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.65344
[2024-02-27 13:05:45,012][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.50032
[2024-02-27 13:05:45,012][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.46247
[2024-02-27 13:06:12,254][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.42175
[2024-02-27 13:06:12,254][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.50469
[2024-02-27 13:06:38,760][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.42813
[2024-02-27 13:06:38,760][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.43413
[2024-02-27 13:07:05,597][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.48477
[2024-02-27 13:07:05,597][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.44426
[2024-02-27 13:07:32,146][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.45022
[2024-02-27 13:07:32,146][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.51745
[2024-02-27 13:07:59,002][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.38970
[2024-02-27 13:07:59,003][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.48091
[2024-02-27 13:08:25,418][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.42099
[2024-02-27 13:08:25,418][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.33368
[2024-02-27 13:08:52,449][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.46230
[2024-02-27 13:08:52,449][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.47856
[2024-02-27 13:09:18,966][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.46821
[2024-02-27 13:09:18,966][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.49120 - val_accuracy: 0.48230 - train_loss: 1.58830 - val_loss: 1.60000 - loss: 1.35061
[2024-02-27 13:10:13,579][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.36037
[2024-02-27 13:10:13,579][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.45710
[2024-02-27 13:10:40,086][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.39928
[2024-02-27 13:10:40,086][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.37929
[2024-02-27 13:11:06,914][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.40503
[2024-02-27 13:11:06,914][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.36821
[2024-02-27 13:11:33,814][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.42720
[2024-02-27 13:11:33,814][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.38112
[2024-02-27 13:12:00,467][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.33260
[2024-02-27 13:12:00,467][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.38342
[2024-02-27 13:12:27,353][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.35100
[2024-02-27 13:12:27,353][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.45543
[2024-02-27 13:12:53,701][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.32431
[2024-02-27 13:12:53,701][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.38677
[2024-02-27 13:13:20,635][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.37806
[2024-02-27 13:13:20,634][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.30423
[2024-02-27 13:13:46,957][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.38348
[2024-02-27 13:13:46,957][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.56856 - val_accuracy: 0.56850 - train_loss: 1.43916 - val_loss: 1.43202 - loss: 1.37526
[2024-02-27 13:14:41,508][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.25761
[2024-02-27 13:14:41,508][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.28353
[2024-02-27 13:15:07,949][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.24231
[2024-02-27 13:15:07,949][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.29887
[2024-02-27 13:15:34,829][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.33195
[2024-02-27 13:15:34,829][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.34778
[2024-02-27 13:16:01,214][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.29635
[2024-02-27 13:16:01,214][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.34851
[2024-02-27 13:16:28,036][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.43228
[2024-02-27 13:16:28,036][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.29339
[2024-02-27 13:16:54,532][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.27968
[2024-02-27 13:16:54,532][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.31019
[2024-02-27 13:17:21,541][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.36113
[2024-02-27 13:17:21,541][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.33477
[2024-02-27 13:17:47,960][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.32955
[2024-02-27 13:17:47,960][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.26087
[2024-02-27 13:18:14,859][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.30556
[2024-02-27 13:18:14,859][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.21520
[2024-02-27 13:18:41,211][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.30432
[2024-02-27 13:18:41,211][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.59222 - val_accuracy: 0.58870 - train_loss: 1.40044 - val_loss: 1.41241 - loss: 1.32393
[2024-02-27 13:19:35,836][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.30335
[2024-02-27 13:19:35,836][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.21536
[2024-02-27 13:20:02,257][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.22065
[2024-02-27 13:20:02,257][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.22786
[2024-02-27 13:20:29,056][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.14201
[2024-02-27 13:20:29,056][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.26076
[2024-02-27 13:20:55,535][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.17932
[2024-02-27 13:20:55,535][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.21513
[2024-02-27 13:21:22,542][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.17257
[2024-02-27 13:21:22,542][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.24954
[2024-02-27 13:21:49,101][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.27498
[2024-02-27 13:21:49,101][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.19060
[2024-02-27 13:22:16,026][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.19415
[2024-02-27 13:22:16,027][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.22167
[2024-02-27 13:22:42,426][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.28937
[2024-02-27 13:22:42,426][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.23228
[2024-02-27 13:23:09,189][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.16569
[2024-02-27 13:23:09,189][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.24202
[2024-02-27 13:23:35,599][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.17479
[2024-02-27 13:23:35,599][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.64457 - val_accuracy: 0.63050 - train_loss: 1.27940 - val_loss: 1.30463 - loss: 1.19958
[2024-02-27 13:24:30,048][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.29474
[2024-02-27 13:24:30,048][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.22320
[2024-02-27 13:24:56,415][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.11654
[2024-02-27 13:24:56,415][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.15134
[2024-02-27 13:25:23,093][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.20195
[2024-02-27 13:25:23,093][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.22633
[2024-02-27 13:25:49,416][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.13640
[2024-02-27 13:25:49,416][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.19008
[2024-02-27 13:26:16,150][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.16847
[2024-02-27 13:26:16,150][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.17949
[2024-02-27 13:26:42,585][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.13304
[2024-02-27 13:26:42,586][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.18614
[2024-02-27 13:27:09,314][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.10222
[2024-02-27 13:27:09,314][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.16882
[2024-02-27 13:27:36,074][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.18130
[2024-02-27 13:27:36,074][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.13759
[2024-02-27 13:28:02,389][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.20066
[2024-02-27 13:28:02,390][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.51152 - val_accuracy: 0.50310 - train_loss: 1.61720 - val_loss: 1.64248 - loss: 1.10734
[2024-02-27 13:28:56,819][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.17011
[2024-02-27 13:28:56,819][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.08612
[2024-02-27 13:29:23,270][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.07076
[2024-02-27 13:29:23,270][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.14258
[2024-02-27 13:29:50,069][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.16590
[2024-02-27 13:29:50,069][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.17405
[2024-02-27 13:30:16,392][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.09748
[2024-02-27 13:30:16,392][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.18768
[2024-02-27 13:30:43,209][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.09902
[2024-02-27 13:30:43,209][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.10222
[2024-02-27 13:31:09,528][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.15726
[2024-02-27 13:31:09,528][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.02799
[2024-02-27 13:31:36,516][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.06080
[2024-02-27 13:31:36,516][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.11592
[2024-02-27 13:32:02,732][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.16986
[2024-02-27 13:32:02,732][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.15810
[2024-02-27 13:32:29,491][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.06703
[2024-02-27 13:32:29,490][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.09672
[2024-02-27 13:32:55,855][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.17962
[2024-02-27 13:32:55,856][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.67508 - val_accuracy: 0.64930 - train_loss: 1.22164 - val_loss: 1.27702 - loss: 1.10866
[2024-02-27 13:33:50,044][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.08699
[2024-02-27 13:33:50,044][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07756
[2024-02-27 13:34:16,467][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.09581
[2024-02-27 13:34:16,467][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.08483
[2024-02-27 13:34:43,180][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07065
[2024-02-27 13:34:43,180][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07005
[2024-02-27 13:35:09,525][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.02068
[2024-02-27 13:35:09,525][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.10260
[2024-02-27 13:35:36,278][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 0.99641
[2024-02-27 13:35:36,278][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.05849
[2024-02-27 13:36:02,688][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.04620
[2024-02-27 13:36:02,688][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07273
[2024-02-27 13:36:29,477][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.02119
[2024-02-27 13:36:29,477][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.05023
[2024-02-27 13:36:55,778][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 0.99867
[2024-02-27 13:36:55,778][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.00797
[2024-02-27 13:37:22,496][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.02028
[2024-02-27 13:37:22,496][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 0.96915
[2024-02-27 13:37:48,848][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07166
[2024-02-27 13:37:48,848][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.66316 - val_accuracy: 0.63320 - train_loss: 1.24949 - val_loss: 1.33805 - loss: 1.07827
[2024-02-27 13:38:43,014][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.04745
[2024-02-27 13:38:43,014][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.02004
[2024-02-27 13:39:09,307][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.00314
[2024-02-27 13:39:09,307][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.06410
[2024-02-27 13:39:36,078][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.94069
[2024-02-27 13:39:36,078][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.98275
[2024-02-27 13:40:02,346][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.99384
[2024-02-27 13:40:02,346][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.01931
[2024-02-27 13:40:29,152][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.01280
[2024-02-27 13:40:29,152][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.00125
[2024-02-27 13:40:55,455][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.01935
[2024-02-27 13:40:55,455][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.10873
[2024-02-27 13:41:22,292][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.00715
[2024-02-27 13:41:22,292][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.99283
[2024-02-27 13:41:48,621][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.03916
[2024-02-27 13:41:48,621][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.01183
[2024-02-27 13:42:15,371][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.03342
[2024-02-27 13:42:15,371][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.98892
[2024-02-27 13:42:41,658][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 0.98944
[2024-02-27 13:42:41,658][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.66807 - val_accuracy: 0.63090 - train_loss: 1.23561 - val_loss: 1.35204 - loss: 1.06083
[2024-02-27 13:43:35,886][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.88444
[2024-02-27 13:43:35,887][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.92867
[2024-02-27 13:44:02,644][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.93735
[2024-02-27 13:44:02,644][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.92702
[2024-02-27 13:44:29,029][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 1.00611
[2024-02-27 13:44:29,029][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.92208
[2024-02-27 13:44:55,768][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.91376
[2024-02-27 13:44:55,768][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.93070
[2024-02-27 13:45:21,978][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.99756
[2024-02-27 13:45:21,979][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.94931
[2024-02-27 13:45:48,769][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.95124
[2024-02-27 13:45:48,769][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.88265
[2024-02-27 13:46:15,057][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 1.04917
[2024-02-27 13:46:15,057][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.92418
[2024-02-27 13:46:41,927][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.92988
[2024-02-27 13:46:41,927][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.89538
[2024-02-27 13:47:08,162][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.97448
[2024-02-27 13:47:08,162][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.74092 - val_accuracy: 0.66630 - train_loss: 1.06861 - val_loss: 1.27043 - loss: 0.93452
[2024-02-27 13:48:02,528][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.84108
[2024-02-27 13:48:02,528][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.90581
[2024-02-27 13:48:28,767][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.92015
[2024-02-27 13:48:28,767][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.88908
[2024-02-27 13:48:55,435][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.92980
[2024-02-27 13:48:55,435][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.92602
[2024-02-27 13:49:21,750][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.89066
[2024-02-27 13:49:21,750][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.94466
[2024-02-27 13:49:48,804][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.88826
[2024-02-27 13:49:48,805][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.82453
[2024-02-27 13:50:15,102][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.92206
[2024-02-27 13:50:15,102][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.86139
[2024-02-27 13:50:41,943][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.88173
[2024-02-27 13:50:41,943][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.85282
[2024-02-27 13:51:08,339][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.89564
[2024-02-27 13:51:08,339][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.77283
[2024-02-27 13:51:35,152][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.92624
[2024-02-27 13:51:35,152][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.82817
[2024-02-27 13:52:01,547][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.87376
[2024-02-27 13:52:01,547][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.69771 - val_accuracy: 0.63320 - train_loss: 1.17882 - val_loss: 1.37771 - loss: 0.94005
[2024-02-27 13:52:55,853][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.82972
[2024-02-27 13:52:55,853][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.76222
[2024-02-27 13:53:22,109][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.93610
[2024-02-27 13:53:22,109][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.78970
[2024-02-27 13:53:48,849][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.80664
[2024-02-27 13:53:48,849][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.84393
[2024-02-27 13:54:15,198][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.85824
[2024-02-27 13:54:15,198][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.81805
[2024-02-27 13:54:42,093][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.79913
[2024-02-27 13:54:42,093][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.84212
[2024-02-27 13:55:08,336][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.85074
[2024-02-27 13:55:08,336][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.87090
[2024-02-27 13:55:35,082][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.80267
[2024-02-27 13:55:35,082][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.79121
[2024-02-27 13:56:01,265][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.86078
[2024-02-27 13:56:01,265][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.86049
[2024-02-27 13:56:27,970][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.76614
[2024-02-27 13:56:27,970][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.79999
[2024-02-27 13:56:54,216][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.88922
[2024-02-27 13:56:54,216][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.78655 - val_accuracy: 0.65710 - train_loss: 0.97980 - val_loss: 1.32517 - loss: 0.78842
[2024-02-27 13:57:48,235][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.78517
[2024-02-27 13:57:48,235][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.78452
[2024-02-27 13:58:14,425][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.85753
[2024-02-27 13:58:14,425][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.82870
[2024-02-27 13:58:41,229][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.76406
[2024-02-27 13:58:41,229][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.78283
[2024-02-27 13:59:07,935][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.74198
[2024-02-27 13:59:07,935][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.77625
[2024-02-27 13:59:34,168][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.76005
[2024-02-27 13:59:34,168][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.75540
[2024-02-27 14:00:00,937][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.76158
[2024-02-27 14:00:00,937][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.76750
[2024-02-27 14:00:27,173][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.72090
[2024-02-27 14:00:27,173][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.77815
[2024-02-27 14:00:53,704][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.71829
[2024-02-27 14:00:53,705][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.69936
[2024-02-27 14:01:19,879][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.76477
[2024-02-27 14:01:19,878][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.84307 - val_accuracy: 0.68450 - train_loss: 0.86897 - val_loss: 1.27869 - loss: 0.74355
[2024-02-27 14:02:13,950][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.70721
[2024-02-27 14:02:13,950][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.70629
[2024-02-27 14:02:40,167][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.69165
[2024-02-27 14:02:40,167][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.71452
[2024-02-27 14:03:06,804][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.73629
[2024-02-27 14:03:06,804][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.69703
[2024-02-27 14:03:33,061][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.73213
[2024-02-27 14:03:33,061][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.73291
[2024-02-27 14:03:59,718][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.69115
[2024-02-27 14:03:59,718][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.69232
[2024-02-27 14:04:26,058][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.79534
[2024-02-27 14:04:26,058][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.74133
[2024-02-27 14:04:52,788][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.71935
[2024-02-27 14:04:52,788][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.68170
[2024-02-27 14:05:18,978][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.71356
[2024-02-27 14:05:18,977][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.68748
[2024-02-27 14:05:45,728][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.66600
[2024-02-27 14:05:45,728][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.68656
[2024-02-27 14:06:11,946][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.68619
[2024-02-27 14:06:11,946][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.80181 - val_accuracy: 0.65940 - train_loss: 0.95015 - val_loss: 1.36661 - loss: 0.70084
[2024-02-27 14:07:06,294][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.74440
[2024-02-27 14:07:06,294][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.71115
[2024-02-27 14:07:32,452][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.63203
[2024-02-27 14:07:32,452][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.67565
[2024-02-27 14:07:59,056][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.67161
[2024-02-27 14:07:59,056][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.66422
[2024-02-27 14:08:25,259][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.76415
[2024-02-27 14:08:25,259][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.69164
[2024-02-27 14:08:52,031][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.70019
[2024-02-27 14:08:52,031][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.69391
[2024-02-27 14:09:18,292][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.66259
[2024-02-27 14:09:18,292][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.69937
[2024-02-27 14:09:45,143][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.65813
[2024-02-27 14:09:45,143][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.67410
[2024-02-27 14:10:11,385][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.69973
[2024-02-27 14:10:11,385][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.64328
[2024-02-27 14:10:37,959][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.68624
[2024-02-27 14:10:37,959][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.65602
[2024-02-27 14:11:04,077][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.66443
[2024-02-27 14:11:04,077][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.85118 - val_accuracy: 0.66140 - train_loss: 0.84355 - val_loss: 1.38209 - loss: 0.64674
[2024-02-27 14:11:58,173][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.68457
[2024-02-27 14:11:58,173][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.64519
[2024-02-27 14:12:24,447][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65004
[2024-02-27 14:12:24,447][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.62809
[2024-02-27 14:12:51,212][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.69445
[2024-02-27 14:12:51,212][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.63419
[2024-02-27 14:13:17,405][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.68011
[2024-02-27 14:13:17,405][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65515
[2024-02-27 14:13:44,179][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.63983
[2024-02-27 14:13:44,179][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65552
[2024-02-27 14:14:10,336][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.63856
[2024-02-27 14:14:10,336][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65878
[2024-02-27 14:14:37,663][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.67705
[2024-02-27 14:14:37,663][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.64282
[2024-02-27 14:15:04,379][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65417
[2024-02-27 14:15:04,379][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.62458
[2024-02-27 14:15:30,525][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.65498
[2024-02-27 14:15:30,525][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.88724 - val_accuracy: 0.66780 - train_loss: 0.75514 - val_loss: 1.35461 - loss: 0.66559
[2024-02-27 14:16:24,537][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.60495
[2024-02-27 14:16:24,537][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.63198
[2024-02-27 14:16:50,701][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.63905
[2024-02-27 14:16:50,701][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.64728
[2024-02-27 14:17:17,438][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.62270
[2024-02-27 14:17:17,438][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.60857
[2024-02-27 14:17:43,622][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.64895
[2024-02-27 14:17:43,622][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.66214
[2024-02-27 14:18:10,275][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.58753
[2024-02-27 14:18:10,275][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.63159
[2024-02-27 14:18:36,499][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.61224
[2024-02-27 14:18:36,499][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.64635
[2024-02-27 14:19:03,144][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.66677
[2024-02-27 14:19:03,144][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.63248
[2024-02-27 14:19:29,351][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.69098
[2024-02-27 14:19:29,351][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.64415
[2024-02-27 14:19:56,009][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.61973
[2024-02-27 14:19:56,009][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.59249
[2024-02-27 14:20:22,259][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.64641
[2024-02-27 14:20:22,260][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.91978 - val_accuracy: 0.68480 - train_loss: 0.68674 - val_loss: 1.34170 - loss: 0.61075
[2024-02-27 14:21:16,334][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.63897
[2024-02-27 14:21:16,334][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.59111
[2024-02-27 14:21:42,581][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.62104
[2024-02-27 14:21:42,581][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.64490
[2024-02-27 14:22:09,284][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.63619
[2024-02-27 14:22:09,284][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.65376
[2024-02-27 14:22:35,650][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.63447
[2024-02-27 14:22:35,650][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.62482
[2024-02-27 14:23:02,577][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.63479
[2024-02-27 14:23:02,577][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.61384
[2024-02-27 14:23:28,611][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.61440
[2024-02-27 14:23:28,611][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.59891
[2024-02-27 14:23:55,486][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.59446
[2024-02-27 14:23:55,486][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.58846
[2024-02-27 14:24:21,641][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.65055
[2024-02-27 14:24:21,641][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.59877
[2024-02-27 14:24:48,601][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.66323
[2024-02-27 14:24:48,601][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.61679
[2024-02-27 14:25:14,872][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.60078
[2024-02-27 14:25:14,873][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.93569 - val_accuracy: 0.68470 - train_loss: 0.65508 - val_loss: 1.34388 - loss: 0.61480
[2024-02-27 14:26:09,110][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.63980
[2024-02-27 14:26:09,110][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58804
[2024-02-27 14:26:35,303][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.62755
[2024-02-27 14:26:35,303][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.63541
[2024-02-27 14:27:02,411][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.60544
[2024-02-27 14:27:02,411][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.57986
[2024-02-27 14:27:28,634][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.57504
[2024-02-27 14:27:28,634][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.62964
[2024-02-27 14:27:55,360][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58181
[2024-02-27 14:27:55,360][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.61483
[2024-02-27 14:28:21,510][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.60985
[2024-02-27 14:28:21,510][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58522
[2024-02-27 14:28:48,250][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58342
[2024-02-27 14:28:48,250][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.64613
[2024-02-27 14:29:14,515][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.60617
[2024-02-27 14:29:14,515][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.57976
[2024-02-27 14:29:41,136][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58236
[2024-02-27 14:29:41,137][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.55888
[2024-02-27 14:30:07,391][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58520
[2024-02-27 14:30:07,391][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.94092 - val_accuracy: 0.68060 - train_loss: 0.64122 - val_loss: 1.35429 - loss: 0.58387
[2024-02-27 14:31:01,279][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.62373
[2024-02-27 14:31:01,279][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.57387
[2024-02-27 14:31:27,931][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.62306
[2024-02-27 14:31:27,931][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.57390
[2024-02-27 14:31:54,131][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.60035
[2024-02-27 14:31:54,131][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.60055
[2024-02-27 14:32:20,963][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.56696
[2024-02-27 14:32:20,963][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.56060
[2024-02-27 14:32:47,124][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.58317
[2024-02-27 14:32:47,124][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.60386
[2024-02-27 14:33:13,760][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.58583
[2024-02-27 14:33:13,761][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.56130
[2024-02-27 14:33:40,022][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.60190
[2024-02-27 14:33:40,022][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.58897
[2024-02-27 14:34:06,720][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.57757
[2024-02-27 14:34:06,721][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.55796
[2024-02-27 14:34:32,882][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.61562
[2024-02-27 14:34:32,882][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.94668 - val_accuracy: 0.68380 - train_loss: 0.62911 - val_loss: 1.37676 - loss: 0.60897
[2024-02-27 14:35:27,079][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.58110
[2024-02-27 14:35:27,079][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.56286
[2024-02-27 14:35:53,376][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.55913
[2024-02-27 14:35:53,376][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.55777
[2024-02-27 14:36:20,127][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.59967
[2024-02-27 14:36:20,127][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.59034
[2024-02-27 14:36:46,314][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57645
[2024-02-27 14:36:46,315][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57258
[2024-02-27 14:37:12,860][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57940
[2024-02-27 14:37:12,860][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.59690
[2024-02-27 14:37:39,074][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.60400
[2024-02-27 14:37:39,075][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.59547
[2024-02-27 14:38:05,527][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.56346
[2024-02-27 14:38:05,527][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57472
[2024-02-27 14:38:31,678][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.62061
[2024-02-27 14:38:31,678][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.56287
[2024-02-27 14:38:58,339][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.55518
[2024-02-27 14:38:58,339][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57634
[2024-02-27 14:39:24,505][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57120
[2024-02-27 14:39:24,505][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.94501 - val_accuracy: 0.67940 - train_loss: 0.63409 - val_loss: 1.38727 - loss: 0.57892
[2024-02-27 14:40:18,539][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.55374
[2024-02-27 14:40:18,539][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.56999
[2024-02-27 14:40:44,725][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.54917
[2024-02-27 14:40:44,725][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.57059
[2024-02-27 14:41:11,470][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.59140
[2024-02-27 14:41:11,470][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.59642
[2024-02-27 14:41:37,600][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.59140
[2024-02-27 14:41:37,600][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.58561
[2024-02-27 14:42:04,166][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.59240
[2024-02-27 14:42:04,166][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.57049
[2024-02-27 14:42:30,421][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.57820
[2024-02-27 14:42:30,421][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.55909
[2024-02-27 14:42:57,082][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.58171
[2024-02-27 14:42:57,082][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.58332
[2024-02-27 14:43:23,174][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.54488
[2024-02-27 14:43:23,174][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.55987
[2024-02-27 14:43:49,803][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.60050
[2024-02-27 14:43:49,803][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.59322
[2024-02-27 14:44:16,003][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.54997
[2024-02-27 14:44:16,003][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.93957 - val_accuracy: 0.66640 - train_loss: 0.64027 - val_loss: 1.38967 - loss: 0.53968
[2024-02-27 14:45:09,861][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.59555
[2024-02-27 14:45:09,861][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.58095
[2024-02-27 14:45:36,198][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.56791
[2024-02-27 14:45:36,198][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.54756
[2024-02-27 14:46:02,873][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.56602
[2024-02-27 14:46:02,873][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.58598
[2024-02-27 14:46:29,588][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.56487
[2024-02-27 14:46:29,588][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.53870
[2024-02-27 14:46:55,771][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.58271
[2024-02-27 14:46:55,771][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.55003
[2024-02-27 14:47:22,359][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.57186
[2024-02-27 14:47:22,359][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.53502
[2024-02-27 14:47:48,636][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.58852
[2024-02-27 14:47:48,636][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.59509
[2024-02-27 14:48:15,335][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.57682
[2024-02-27 14:48:15,335][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.55838
[2024-02-27 14:48:41,588][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.58060
[2024-02-27 14:48:41,588][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.96490 - val_accuracy: 0.69580 - train_loss: 0.58680 - val_loss: 1.34986 - loss: 0.54839
[2024-02-27 14:49:35,651][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.55897
[2024-02-27 14:49:35,651][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.59690
[2024-02-27 14:50:01,870][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.55273
[2024-02-27 14:50:01,870][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.59431
[2024-02-27 14:50:28,417][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.53703
[2024-02-27 14:50:28,417][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.56699
[2024-02-27 14:50:54,546][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.55415
[2024-02-27 14:50:54,546][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.56299
[2024-02-27 14:51:21,146][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.55327
[2024-02-27 14:51:21,146][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.57914
[2024-02-27 14:51:47,389][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.57519
[2024-02-27 14:51:47,389][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.54277
[2024-02-27 14:52:13,918][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.57143
[2024-02-27 14:52:13,919][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.53508
[2024-02-27 14:52:40,160][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.54604
[2024-02-27 14:52:40,160][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.54973
[2024-02-27 14:53:06,876][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.53415
[2024-02-27 14:53:06,876][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.57038
[2024-02-27 14:53:33,102][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.53186
[2024-02-27 14:53:33,102][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.94940 - val_accuracy: 0.68120 - train_loss: 0.61929 - val_loss: 1.38047 - loss: 0.58299
[2024-02-27 14:54:27,087][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.58553
[2024-02-27 14:54:27,087][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54896
[2024-02-27 14:54:53,307][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.58404
[2024-02-27 14:54:53,307][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.55066
[2024-02-27 14:55:20,035][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.55593
[2024-02-27 14:55:20,036][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.53829
[2024-02-27 14:55:46,179][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.58738
[2024-02-27 14:55:46,179][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54659
[2024-02-27 14:56:12,822][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54528
[2024-02-27 14:56:12,822][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.55482
[2024-02-27 14:56:39,041][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.53324
[2024-02-27 14:56:39,041][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54482
[2024-02-27 14:57:05,691][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.55198
[2024-02-27 14:57:05,691][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.57464
[2024-02-27 14:57:31,830][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54469
[2024-02-27 14:57:31,830][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54981
[2024-02-27 14:57:58,480][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.54541
[2024-02-27 14:57:58,479][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.56630
[2024-02-27 14:58:24,606][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.56946
[2024-02-27 14:58:24,606][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.96347 - val_accuracy: 0.68050 - train_loss: 0.58841 - val_loss: 1.39917 - loss: 0.58109
[2024-02-27 14:59:18,678][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.53938
[2024-02-27 14:59:18,678][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.57993
[2024-02-27 14:59:45,004][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.58464
[2024-02-27 14:59:45,004][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54670
[2024-02-27 15:00:11,659][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.53758
[2024-02-27 15:00:11,659][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54278
[2024-02-27 15:00:37,823][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54993
[2024-02-27 15:00:37,823][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.56053
[2024-02-27 15:01:04,708][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.57187
[2024-02-27 15:01:04,708][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54378
[2024-02-27 15:01:30,891][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54135
[2024-02-27 15:01:30,891][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.59923
[2024-02-27 15:01:57,537][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.53596
[2024-02-27 15:01:57,537][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.53410
[2024-02-27 15:02:24,136][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.52158
[2024-02-27 15:02:24,136][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.54635
[2024-02-27 15:02:50,363][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.58523
[2024-02-27 15:02:50,363][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.94179 - val_accuracy: 0.66130 - train_loss: 0.64104 - val_loss: 1.50306 - loss: 0.57931
[2024-02-27 15:03:44,241][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.54975
[2024-02-27 15:03:44,241][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.54422
[2024-02-27 15:04:10,362][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.57314
[2024-02-27 15:04:10,362][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.56826
[2024-02-27 15:04:37,002][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.53722
[2024-02-27 15:04:37,002][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.54341
[2024-02-27 15:05:03,246][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.58350
[2024-02-27 15:05:03,246][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.56166
[2024-02-27 15:05:29,885][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.57461
[2024-02-27 15:05:29,885][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.57867
[2024-02-27 15:05:55,955][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.54162
[2024-02-27 15:05:55,955][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.53896
[2024-02-27 15:06:22,653][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.56907
[2024-02-27 15:06:22,653][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.52678
[2024-02-27 15:06:48,806][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.54416
[2024-02-27 15:06:48,806][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.57848
[2024-02-27 15:07:15,393][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.53666
[2024-02-27 15:07:15,393][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.52748
[2024-02-27 15:07:41,396][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.55080
[2024-02-27 15:07:41,396][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.95242 - val_accuracy: 0.68570 - train_loss: 0.61274 - val_loss: 1.40682 - loss: 0.55593
[2024-02-27 15:08:35,342][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.52493
[2024-02-27 15:08:35,342][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.56280
[2024-02-27 15:09:01,481][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.55514
[2024-02-27 15:09:01,481][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.55469
[2024-02-27 15:09:28,310][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.52500
[2024-02-27 15:09:28,310][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.54530
[2024-02-27 15:09:54,440][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.52395
[2024-02-27 15:09:54,440][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.57970
[2024-02-27 15:10:21,117][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.56290
[2024-02-27 15:10:21,117][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.55825
[2024-02-27 15:10:47,386][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.53039
[2024-02-27 15:10:47,386][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.57224
[2024-02-27 15:11:14,115][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.54777
[2024-02-27 15:11:14,115][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.53726
[2024-02-27 15:11:40,290][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.53934
[2024-02-27 15:11:40,290][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.51981
[2024-02-27 15:12:06,901][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.56281
[2024-02-27 15:12:06,901][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.54545
[2024-02-27 15:12:33,074][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.55784
[2024-02-27 15:12:33,074][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.97461 - val_accuracy: 0.68260 - train_loss: 0.56452 - val_loss: 1.39390 - loss: 0.52514
[2024-02-27 15:13:26,958][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54808
[2024-02-27 15:13:26,958][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53996
[2024-02-27 15:13:53,068][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.57083
[2024-02-27 15:13:53,068][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54736
[2024-02-27 15:14:19,810][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53914
[2024-02-27 15:14:19,810][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53505
[2024-02-27 15:14:46,035][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.56595
[2024-02-27 15:14:46,035][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54039
[2024-02-27 15:15:12,716][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53132
[2024-02-27 15:15:12,716][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53203
[2024-02-27 15:15:38,879][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.52992
[2024-02-27 15:15:38,879][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53298
[2024-02-27 15:16:05,599][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.55324
[2024-02-27 15:16:05,599][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54371
[2024-02-27 15:16:31,734][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.56494
[2024-02-27 15:16:31,734][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54596
[2024-02-27 15:16:58,453][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.57827
[2024-02-27 15:16:58,453][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53712
[2024-02-27 15:17:24,636][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.54616
[2024-02-27 15:17:24,636][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.97344 - val_accuracy: 0.68140 - train_loss: 0.56365 - val_loss: 1.40197 - loss: 0.53861
[2024-02-27 15:18:18,856][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.54007
[2024-02-27 15:18:18,856][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.54544
[2024-02-27 15:18:45,616][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53111
[2024-02-27 15:18:45,616][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.55490
[2024-02-27 15:19:11,889][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.55735
[2024-02-27 15:19:11,889][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.55586
[2024-02-27 15:19:38,660][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53552
[2024-02-27 15:19:38,660][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.51794
[2024-02-27 15:20:04,805][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53742
[2024-02-27 15:20:04,805][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.55129
[2024-02-27 15:20:31,435][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.52496
[2024-02-27 15:20:31,435][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.52727
[2024-02-27 15:20:57,490][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53257
[2024-02-27 15:20:57,490][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53854
[2024-02-27 15:21:24,232][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.56699
[2024-02-27 15:21:24,232][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.52650
[2024-02-27 15:21:50,344][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.57295
[2024-02-27 15:21:50,344][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.92471 - val_accuracy: 0.66730 - train_loss: 0.68115 - val_loss: 1.47569 - loss: 0.53773
[2024-02-27 15:22:44,252][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.55898
[2024-02-27 15:22:44,252][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.54971
[2024-02-27 15:23:10,400][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.55504
[2024-02-27 15:23:10,400][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.58159
[2024-02-27 15:23:36,975][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.55315
[2024-02-27 15:23:36,975][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.54876
[2024-02-27 15:24:03,274][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.56331
[2024-02-27 15:24:03,274][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53107
[2024-02-27 15:24:29,913][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.54756
[2024-02-27 15:24:29,913][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.52595
[2024-02-27 15:24:56,043][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53931
[2024-02-27 15:24:56,043][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.52591
[2024-02-27 15:25:22,700][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53278
[2024-02-27 15:25:22,700][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.54870
[2024-02-27 15:25:48,842][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53728
[2024-02-27 15:25:48,842][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.56400
[2024-02-27 15:26:15,658][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.52328
[2024-02-27 15:26:15,658][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.52011
[2024-02-27 15:26:42,003][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53932
[2024-02-27 15:26:42,003][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.94982 - val_accuracy: 0.66750 - train_loss: 0.62073 - val_loss: 1.46215 - loss: 0.53872
[2024-02-27 15:27:36,017][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.51529
[2024-02-27 15:27:36,017][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.52576
[2024-02-27 15:28:02,151][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.54551
[2024-02-27 15:28:02,151][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.52625
[2024-02-27 15:28:28,796][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.53142
[2024-02-27 15:28:28,796][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.53528
[2024-02-27 15:28:55,067][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.56522
[2024-02-27 15:28:55,067][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.55689
[2024-02-27 15:29:21,780][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.55980
[2024-02-27 15:29:21,780][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.53974
[2024-02-27 15:29:47,975][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.54687
[2024-02-27 15:29:47,975][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.55213
[2024-02-27 15:30:14,544][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.51868
[2024-02-27 15:30:14,544][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.53648
[2024-02-27 15:30:40,715][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.56311
[2024-02-27 15:30:40,715][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.54988
[2024-02-27 15:31:07,503][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.54747
[2024-02-27 15:31:07,503][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.55572
[2024-02-27 15:31:33,749][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.57220
[2024-02-27 15:31:33,749][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.97765 - val_accuracy: 0.68620 - train_loss: 0.55433 - val_loss: 1.39904 - loss: 0.55791
[2024-02-27 15:32:27,527][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.53359
[2024-02-27 15:32:27,527][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.54314
[2024-02-27 15:32:53,873][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.54567
[2024-02-27 15:32:53,873][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.52614
[2024-02-27 15:33:20,561][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.53769
[2024-02-27 15:33:20,561][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.52058
[2024-02-27 15:33:47,137][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.51904
[2024-02-27 15:33:47,137][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.51104
[2024-02-27 15:34:13,347][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.54187
[2024-02-27 15:34:13,347][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.53642
[2024-02-27 15:34:40,026][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.54242
[2024-02-27 15:34:40,026][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.54066
[2024-02-27 15:35:06,232][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.55068
[2024-02-27 15:35:06,232][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.55855
[2024-02-27 15:35:32,973][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.51316
[2024-02-27 15:35:32,973][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.51498
[2024-02-27 15:35:59,171][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.52816
[2024-02-27 15:35:59,171][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.95981 - val_accuracy: 0.67890 - train_loss: 0.59425 - val_loss: 1.42967 - loss: 0.53504
[2024-02-27 15:36:53,004][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53923
[2024-02-27 15:36:53,004][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.54449
[2024-02-27 15:37:19,134][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53897
[2024-02-27 15:37:19,134][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52747
[2024-02-27 15:37:45,797][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53833
[2024-02-27 15:37:45,797][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52858
[2024-02-27 15:38:11,974][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53222
[2024-02-27 15:38:11,974][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.54076
[2024-02-27 15:38:38,559][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53108
[2024-02-27 15:38:38,559][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.55158
[2024-02-27 15:39:04,733][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53619
[2024-02-27 15:39:04,733][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.54214
[2024-02-27 15:39:31,372][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52884
[2024-02-27 15:39:31,372][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52264
[2024-02-27 15:39:57,651][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53229
[2024-02-27 15:39:57,652][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53675
[2024-02-27 15:40:24,307][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52187
[2024-02-27 15:40:24,307][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.52846
[2024-02-27 15:40:50,426][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.54027
[2024-02-27 15:40:50,426][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.97829 - val_accuracy: 0.68770 - train_loss: 0.55395 - val_loss: 1.39466 - loss: 0.53697
[2024-02-27 15:41:44,385][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52396
[2024-02-27 15:41:44,385][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.53694
[2024-02-27 15:42:10,480][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.55729
[2024-02-27 15:42:10,480][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.53163
[2024-02-27 15:42:37,137][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.56614
[2024-02-27 15:42:37,137][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.55213
[2024-02-27 15:43:03,191][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.54458
[2024-02-27 15:43:03,191][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52919
[2024-02-27 15:43:30,112][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.56968
[2024-02-27 15:43:30,113][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52931
[2024-02-27 15:43:56,313][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.55170
[2024-02-27 15:43:56,313][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.54678
[2024-02-27 15:44:22,929][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.51816
[2024-02-27 15:44:22,929][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.54701
[2024-02-27 15:44:49,072][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52298
[2024-02-27 15:44:49,072][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.53018
[2024-02-27 15:45:15,683][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52459
[2024-02-27 15:45:15,683][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.52875
[2024-02-27 15:45:41,923][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.54906
[2024-02-27 15:45:41,923][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.98651 - val_accuracy: 0.68980 - train_loss: 0.53606 - val_loss: 1.36936 - loss: 0.53874
[2024-02-27 15:46:35,945][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.54887
[2024-02-27 15:46:35,945][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.54054
[2024-02-27 15:47:02,058][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.52161
[2024-02-27 15:47:02,058][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.54375
[2024-02-27 15:47:28,562][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53453
[2024-02-27 15:47:28,563][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.55241
[2024-02-27 15:47:54,617][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53127
[2024-02-27 15:47:54,618][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.55059
[2024-02-27 15:48:21,390][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53121
[2024-02-27 15:48:21,390][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.51777
[2024-02-27 15:48:47,594][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53003
[2024-02-27 15:48:47,594][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53983
[2024-02-27 15:49:14,229][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.55024
[2024-02-27 15:49:14,229][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.52759
[2024-02-27 15:49:41,012][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.51361
[2024-02-27 15:49:41,012][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.51584
[2024-02-27 15:50:07,283][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.53294
[2024-02-27 15:50:07,283][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.97610 - val_accuracy: 0.68670 - train_loss: 0.55846 - val_loss: 1.39044 - loss: 0.54099
[2024-02-27 15:51:01,100][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.55127
[2024-02-27 15:51:01,100][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.54204
[2024-02-27 15:51:27,135][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53720
[2024-02-27 15:51:27,135][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52674
[2024-02-27 15:51:53,797][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53231
[2024-02-27 15:51:53,797][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52774
[2024-02-27 15:52:19,944][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.54513
[2024-02-27 15:52:19,944][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53177
[2024-02-27 15:52:46,629][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.56313
[2024-02-27 15:52:46,629][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52742
[2024-02-27 15:53:12,832][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52051
[2024-02-27 15:53:12,832][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.51769
[2024-02-27 15:53:39,549][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53763
[2024-02-27 15:53:39,549][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53490
[2024-02-27 15:54:05,715][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.53963
[2024-02-27 15:54:05,716][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52237
[2024-02-27 15:54:32,329][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.56371
[2024-02-27 15:54:32,329][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.54877
[2024-02-27 15:54:58,549][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.54057
[2024-02-27 15:54:58,549][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.96505 - val_accuracy: 0.68710 - train_loss: 0.58261 - val_loss: 1.39300 - loss: 0.52632
[2024-02-27 15:55:52,416][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52437
[2024-02-27 15:55:52,416][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53101
[2024-02-27 15:56:18,581][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52262
[2024-02-27 15:56:18,581][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52684
[2024-02-27 15:56:45,269][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.54262
[2024-02-27 15:56:45,269][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53773
[2024-02-27 15:57:11,428][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.54343
[2024-02-27 15:57:11,428][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.55805
[2024-02-27 15:57:38,095][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.57239
[2024-02-27 15:57:38,095][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52043
[2024-02-27 15:58:04,431][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.51419
[2024-02-27 15:58:04,431][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52129
[2024-02-27 15:58:31,187][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.51823
[2024-02-27 15:58:31,187][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53050
[2024-02-27 15:58:57,306][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53550
[2024-02-27 15:58:57,306][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53628
[2024-02-27 15:59:24,169][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.51913
[2024-02-27 15:59:24,169][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.53941
[2024-02-27 15:59:50,508][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.52828
[2024-02-27 15:59:50,508][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.97290 - val_accuracy: 0.69030 - train_loss: 0.56615 - val_loss: 1.39584 - loss: 0.54967
[2024-02-27 16:00:44,340][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52880
[2024-02-27 16:00:44,340][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.51355
[2024-02-27 16:01:10,438][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52190
[2024-02-27 16:01:10,438][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.51653
[2024-02-27 16:01:37,202][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.51638
[2024-02-27 16:01:37,202][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.51464
[2024-02-27 16:02:03,402][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.53159
[2024-02-27 16:02:03,402][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.54542
[2024-02-27 16:02:29,948][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.53178
[2024-02-27 16:02:29,948][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.53013
[2024-02-27 16:02:56,096][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.51909
[2024-02-27 16:02:56,096][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52861
[2024-02-27 16:03:22,650][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52559
[2024-02-27 16:03:22,650][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.56023
[2024-02-27 16:03:48,938][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52467
[2024-02-27 16:03:48,938][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.52972
[2024-02-27 16:04:15,505][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.55757
[2024-02-27 16:04:15,505][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.55012
[2024-02-27 16:04:41,687][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.54125
[2024-02-27 16:04:41,687][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.98715 - val_accuracy: 0.69430 - train_loss: 0.53383 - val_loss: 1.36836 - loss: 0.53243
[2024-02-27 16:05:35,728][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52003
[2024-02-27 16:05:35,728][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51798
[2024-02-27 16:06:02,405][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51604
[2024-02-27 16:06:02,406][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.53741
[2024-02-27 16:06:28,632][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52789
[2024-02-27 16:06:28,632][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52743
[2024-02-27 16:06:55,429][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51850
[2024-02-27 16:06:55,429][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51267
[2024-02-27 16:07:21,573][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52613
[2024-02-27 16:07:21,573][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52997
[2024-02-27 16:07:48,406][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51059
[2024-02-27 16:07:48,407][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52534
[2024-02-27 16:08:14,553][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.53689
[2024-02-27 16:08:14,554][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52262
[2024-02-27 16:08:41,258][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.51722
[2024-02-27 16:08:41,258][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.52158
[2024-02-27 16:09:07,491][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.53020
[2024-02-27 16:09:07,491][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.97394 - val_accuracy: 0.68540 - train_loss: 0.56156 - val_loss: 1.41016 - loss: 0.53535
[2024-02-27 16:10:01,492][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53176
[2024-02-27 16:10:01,492][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.52177
[2024-02-27 16:10:27,623][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.51567
[2024-02-27 16:10:27,623][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.57089
[2024-02-27 16:10:54,345][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.52855
[2024-02-27 16:10:54,345][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.51884
[2024-02-27 16:11:20,529][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53986
[2024-02-27 16:11:20,529][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.50730
[2024-02-27 16:11:47,469][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.50728
[2024-02-27 16:11:47,469][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53750
[2024-02-27 16:12:13,725][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.52894
[2024-02-27 16:12:13,725][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53219
[2024-02-27 16:12:40,536][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.52631
[2024-02-27 16:12:40,536][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53565
[2024-02-27 16:13:06,742][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.51956
[2024-02-27 16:13:06,742][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.53969
[2024-02-27 16:13:33,401][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.54142
[2024-02-27 16:13:33,401][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.52584
[2024-02-27 16:13:59,620][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.55879
[2024-02-27 16:13:59,620][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.98321 - val_accuracy: 0.68290 - train_loss: 0.54123 - val_loss: 1.43766 - loss: 0.55371
[2024-02-27 16:14:53,584][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.54625
[2024-02-27 16:14:53,584][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52648
[2024-02-27 16:15:19,830][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52899
[2024-02-27 16:15:19,830][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52167
[2024-02-27 16:15:46,518][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52547
[2024-02-27 16:15:46,518][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52590
[2024-02-27 16:16:12,710][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51283
[2024-02-27 16:16:12,710][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51811
[2024-02-27 16:16:39,431][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52588
[2024-02-27 16:16:39,431][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52323
[2024-02-27 16:17:05,876][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.53064
[2024-02-27 16:17:05,877][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52560
[2024-02-27 16:17:32,597][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51289
[2024-02-27 16:17:32,597][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52511
[2024-02-27 16:17:58,793][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.52052
[2024-02-27 16:17:58,793][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.53284
[2024-02-27 16:18:25,460][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51065
[2024-02-27 16:18:25,460][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.54507
[2024-02-27 16:18:51,541][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51842
[2024-02-27 16:18:51,541][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.98146 - val_accuracy: 0.69140 - train_loss: 0.54452 - val_loss: 1.41252 - loss: 0.51319
[2024-02-27 16:19:45,694][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.53533
[2024-02-27 16:19:45,694][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51924
[2024-02-27 16:20:11,789][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.52314
[2024-02-27 16:20:11,789][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51934
[2024-02-27 16:20:38,395][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51435
[2024-02-27 16:20:38,395][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51341
[2024-02-27 16:21:05,413][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51289
[2024-02-27 16:21:05,413][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51252
[2024-02-27 16:21:31,637][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51433
[2024-02-27 16:21:31,638][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.52951
[2024-02-27 16:21:58,384][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51590
[2024-02-27 16:21:58,384][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51572
[2024-02-27 16:22:24,576][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.53110
[2024-02-27 16:22:24,576][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.52494
[2024-02-27 16:22:51,298][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.52257
[2024-02-27 16:22:51,298][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51019
[2024-02-27 16:23:17,471][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51480
[2024-02-27 16:23:17,471][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.96664 - val_accuracy: 0.66560 - train_loss: 0.57857 - val_loss: 1.47748 - loss: 0.51347
[2024-02-27 16:24:11,319][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52689
[2024-02-27 16:24:11,319][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.51798
[2024-02-27 16:24:37,480][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.51043
[2024-02-27 16:24:37,480][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.51531
[2024-02-27 16:25:04,574][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50990
[2024-02-27 16:25:04,574][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.53009
[2024-02-27 16:25:30,663][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50825
[2024-02-27 16:25:30,663][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52088
[2024-02-27 16:25:57,295][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52173
[2024-02-27 16:25:57,295][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50889
[2024-02-27 16:26:23,338][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52785
[2024-02-27 16:26:23,338][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52086
[2024-02-27 16:26:49,926][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50903
[2024-02-27 16:26:49,926][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.51477
[2024-02-27 16:27:16,228][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52588
[2024-02-27 16:27:16,228][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.56099
[2024-02-27 16:27:42,826][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.51126
[2024-02-27 16:27:42,826][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50894
[2024-02-27 16:28:09,174][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.52398
[2024-02-27 16:28:09,174][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.97759 - val_accuracy: 0.67180 - train_loss: 0.55342 - val_loss: 1.42940 - loss: 0.50839
[2024-02-27 16:29:03,215][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51699
[2024-02-27 16:29:03,215][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.54726
[2024-02-27 16:29:29,495][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.53732
[2024-02-27 16:29:29,495][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52643
[2024-02-27 16:29:56,165][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51362
[2024-02-27 16:29:56,165][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52561
[2024-02-27 16:30:22,375][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.50762
[2024-02-27 16:30:22,375][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51900
[2024-02-27 16:30:49,049][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52609
[2024-02-27 16:30:49,049][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52431
[2024-02-27 16:31:15,277][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51047
[2024-02-27 16:31:15,277][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51735
[2024-02-27 16:31:41,946][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52152
[2024-02-27 16:31:41,946][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51859
[2024-02-27 16:32:08,255][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.51021
[2024-02-27 16:32:08,255][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.53204
[2024-02-27 16:32:35,026][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52725
[2024-02-27 16:32:35,026][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52991
[2024-02-27 16:33:01,235][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52283
[2024-02-27 16:33:01,235][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.98800 - val_accuracy: 0.69010 - train_loss: 0.53069 - val_loss: 1.39903 - loss: 0.52100
[2024-02-27 16:33:55,225][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.53264
[2024-02-27 16:33:55,225][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52203
[2024-02-27 16:34:21,257][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52669
[2024-02-27 16:34:21,257][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.55828
[2024-02-27 16:34:47,936][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51262
[2024-02-27 16:34:47,936][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51428
[2024-02-27 16:35:14,204][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51580
[2024-02-27 16:35:14,204][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52079
[2024-02-27 16:35:40,767][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.53348
[2024-02-27 16:35:40,768][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.53829
[2024-02-27 16:36:06,995][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52826
[2024-02-27 16:36:06,995][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51521
[2024-02-27 16:36:33,742][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52341
[2024-02-27 16:36:33,742][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51195
[2024-02-27 16:37:00,530][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51455
[2024-02-27 16:37:00,530][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.51194
[2024-02-27 16:37:26,597][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.50982
[2024-02-27 16:37:26,597][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.98315 - val_accuracy: 0.67810 - train_loss: 0.54261 - val_loss: 1.43020 - loss: 0.52359
[2024-02-27 16:38:20,788][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51094
[2024-02-27 16:38:20,788][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51806
[2024-02-27 16:38:46,910][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51199
[2024-02-27 16:38:46,910][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.52588
[2024-02-27 16:39:13,586][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.52769
[2024-02-27 16:39:13,587][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51828
[2024-02-27 16:39:39,761][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.55336
[2024-02-27 16:39:39,761][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51495
[2024-02-27 16:40:06,419][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.52288
[2024-02-27 16:40:06,419][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51237
[2024-02-27 16:40:32,489][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51123
[2024-02-27 16:40:32,490][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51840
[2024-02-27 16:40:59,007][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.52337
[2024-02-27 16:40:59,007][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51838
[2024-02-27 16:41:25,225][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.53143
[2024-02-27 16:41:25,225][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.54710
[2024-02-27 16:41:52,042][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51201
[2024-02-27 16:41:52,042][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51435
[2024-02-27 16:42:18,240][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51236
[2024-02-27 16:42:18,240][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.97902 - val_accuracy: 0.67830 - train_loss: 0.55076 - val_loss: 1.43515 - loss: 0.51646
[2024-02-27 16:43:12,158][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.53658
[2024-02-27 16:43:12,158][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52038
[2024-02-27 16:43:38,402][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51272
[2024-02-27 16:43:38,402][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52104
[2024-02-27 16:44:05,019][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.50755
[2024-02-27 16:44:05,020][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51815
[2024-02-27 16:44:31,258][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52251
[2024-02-27 16:44:31,258][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.53056
[2024-02-27 16:44:58,262][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51628
[2024-02-27 16:44:58,262][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51003
[2024-02-27 16:45:24,441][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51957
[2024-02-27 16:45:24,441][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51881
[2024-02-27 16:45:51,094][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.50807
[2024-02-27 16:45:51,095][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52487
[2024-02-27 16:46:17,327][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.50768
[2024-02-27 16:46:17,327][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52982
[2024-02-27 16:46:44,083][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52179
[2024-02-27 16:46:44,083][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.51687
[2024-02-27 16:47:10,236][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.53552
[2024-02-27 16:47:10,236][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.98931 - val_accuracy: 0.68990 - train_loss: 0.52699 - val_loss: 1.41000 - loss: 0.52028
[2024-02-27 16:48:04,143][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51381
[2024-02-27 16:48:04,143][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50448
[2024-02-27 16:48:30,357][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50735
[2024-02-27 16:48:30,357][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51216
[2024-02-27 16:48:56,995][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51965
[2024-02-27 16:48:56,995][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50783
[2024-02-27 16:49:23,230][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50319
[2024-02-27 16:49:23,230][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51019
[2024-02-27 16:49:49,945][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51295
[2024-02-27 16:49:49,945][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50494
[2024-02-27 16:50:16,155][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50973
[2024-02-27 16:50:16,154][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51666
[2024-02-27 16:50:42,938][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51887
[2024-02-27 16:50:42,938][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51675
[2024-02-27 16:51:09,200][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.51317
[2024-02-27 16:51:09,200][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50434
[2024-02-27 16:51:35,985][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.52368
[2024-02-27 16:51:35,986][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50886
[2024-02-27 16:52:02,189][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.52339
[2024-02-27 16:52:02,189][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.98999 - val_accuracy: 0.68970 - train_loss: 0.52522 - val_loss: 1.39970 - loss: 0.50612
[2024-02-27 16:52:56,106][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51582
[2024-02-27 16:52:56,106][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51313
[2024-02-27 16:53:22,729][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51036
[2024-02-27 16:53:22,729][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51608
[2024-02-27 16:53:48,817][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51670
[2024-02-27 16:53:48,817][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51277
[2024-02-27 16:54:15,449][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.50883
[2024-02-27 16:54:15,449][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.50570
[2024-02-27 16:54:41,570][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51081
[2024-02-27 16:54:41,570][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.50755
[2024-02-27 16:55:08,106][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51840
[2024-02-27 16:55:08,107][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51635
[2024-02-27 16:55:34,337][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.50846
[2024-02-27 16:55:34,337][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51764
[2024-02-27 16:56:00,917][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.52651
[2024-02-27 16:56:00,917][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.52333
[2024-02-27 16:56:27,167][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.50938
[2024-02-27 16:56:27,167][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.97711 - val_accuracy: 0.68270 - train_loss: 0.55436 - val_loss: 1.41515 - loss: 0.51453
[2024-02-27 16:57:21,152][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.53102
[2024-02-27 16:57:21,152][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50705
[2024-02-27 16:57:47,356][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51692
[2024-02-27 16:57:47,356][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50665
[2024-02-27 16:58:13,893][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51696
[2024-02-27 16:58:13,893][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.53105
[2024-02-27 16:58:40,086][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50945
[2024-02-27 16:58:40,086][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.52121
[2024-02-27 16:59:06,851][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51974
[2024-02-27 16:59:06,851][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50619
[2024-02-27 16:59:33,048][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50877
[2024-02-27 16:59:33,048][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.55139
[2024-02-27 16:59:59,591][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.53838
[2024-02-27 16:59:59,591][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51065
[2024-02-27 17:00:25,735][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51977
[2024-02-27 17:00:25,735][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50489
[2024-02-27 17:00:52,363][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.51168
[2024-02-27 17:00:52,363][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.50611
[2024-02-27 17:01:18,679][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.53089
[2024-02-27 17:01:18,679][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.98947 - val_accuracy: 0.69880 - train_loss: 0.52677 - val_loss: 1.38036 - loss: 0.52885
[2024-02-27 17:02:12,792][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.50807
[2024-02-27 17:02:12,792][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51240
[2024-02-27 17:02:39,086][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51809
[2024-02-27 17:02:39,086][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.50572
[2024-02-27 17:03:05,590][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.50456
[2024-02-27 17:03:05,590][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51156
[2024-02-27 17:03:31,882][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51234
[2024-02-27 17:03:31,882][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.52069
[2024-02-27 17:03:58,452][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51120
[2024-02-27 17:03:58,452][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51321
[2024-02-27 17:04:24,624][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51892
[2024-02-27 17:04:24,624][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51633
[2024-02-27 17:04:51,400][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.52697
[2024-02-27 17:04:51,400][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.52397
[2024-02-27 17:05:17,528][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51192
[2024-02-27 17:05:17,528][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.52581
[2024-02-27 17:05:44,106][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51071
[2024-02-27 17:05:44,106][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.52623
[2024-02-27 17:06:10,352][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51144
[2024-02-27 17:06:10,352][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.99205 - val_accuracy: 0.69140 - train_loss: 0.52024 - val_loss: 1.39482 - loss: 0.51256
[2024-02-27 17:07:04,325][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50851
[2024-02-27 17:07:04,325][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.51511
[2024-02-27 17:07:30,445][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50586
[2024-02-27 17:07:30,445][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50689
[2024-02-27 17:07:57,115][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50475
[2024-02-27 17:07:57,115][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.51401
[2024-02-27 17:08:23,771][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50741
[2024-02-27 17:08:23,771][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.51771
[2024-02-27 17:08:50,029][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50841
[2024-02-27 17:08:50,029][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50863
[2024-02-27 17:09:16,708][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.51980
[2024-02-27 17:09:16,708][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50414
[2024-02-27 17:09:42,969][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50892
[2024-02-27 17:09:42,969][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50614
[2024-02-27 17:10:09,606][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.51066
[2024-02-27 17:10:09,606][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50290
[2024-02-27 17:10:35,792][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.50685
[2024-02-27 17:10:35,792][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.99176 - val_accuracy: 0.69930 - train_loss: 0.52072 - val_loss: 1.38844 - loss: 0.53338
[2024-02-27 17:11:29,838][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51291
[2024-02-27 17:11:29,839][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50467
[2024-02-27 17:11:56,094][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51399
[2024-02-27 17:11:56,094][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51024
[2024-02-27 17:12:22,742][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51438
[2024-02-27 17:12:22,742][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51655
[2024-02-27 17:12:48,972][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50440
[2024-02-27 17:12:48,972][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51818
[2024-02-27 17:13:15,502][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51089
[2024-02-27 17:13:15,502][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50510
[2024-02-27 17:13:41,709][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50300
[2024-02-27 17:13:41,709][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51370
[2024-02-27 17:14:08,334][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50361
[2024-02-27 17:14:08,334][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50640
[2024-02-27 17:14:34,507][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.51093
[2024-02-27 17:14:34,507][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50364
[2024-02-27 17:15:01,064][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50353
[2024-02-27 17:15:01,064][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50676
[2024-02-27 17:15:27,259][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50537
[2024-02-27 17:15:27,259][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.99013 - val_accuracy: 0.68360 - train_loss: 0.52547 - val_loss: 1.41181 - loss: 0.50314
[2024-02-27 17:16:21,196][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50462
[2024-02-27 17:16:21,196][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50774
[2024-02-27 17:16:47,513][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50536
[2024-02-27 17:16:47,513][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51369
[2024-02-27 17:17:14,406][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51149
[2024-02-27 17:17:14,406][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50937
[2024-02-27 17:17:40,603][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51999
[2024-02-27 17:17:40,603][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51354
[2024-02-27 17:18:07,269][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50704
[2024-02-27 17:18:07,269][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51391
[2024-02-27 17:18:33,535][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50905
[2024-02-27 17:18:33,535][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51369
[2024-02-27 17:19:00,229][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.52278
[2024-02-27 17:19:00,229][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50715
[2024-02-27 17:19:26,410][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51301
[2024-02-27 17:19:26,410][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50454
[2024-02-27 17:19:53,050][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50883
[2024-02-27 17:19:53,050][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.51344
[2024-02-27 17:20:19,296][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.50571
[2024-02-27 17:20:19,296][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.99334 - val_accuracy: 0.69860 - train_loss: 0.51750 - val_loss: 1.38718 - loss: 0.52187
[2024-02-27 17:21:13,409][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50337
[2024-02-27 17:21:13,409][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.51008
[2024-02-27 17:21:39,533][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50944
[2024-02-27 17:21:39,533][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.51822
[2024-02-27 17:22:06,169][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50500
[2024-02-27 17:22:06,169][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50523
[2024-02-27 17:22:32,317][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.52139
[2024-02-27 17:22:32,317][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50318
[2024-02-27 17:22:59,208][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50937
[2024-02-27 17:22:59,208][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50847
[2024-02-27 17:23:25,415][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.51395
[2024-02-27 17:23:25,415][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50435
[2024-02-27 17:23:52,046][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.51040
[2024-02-27 17:23:52,046][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.51130
[2024-02-27 17:24:18,687][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50677
[2024-02-27 17:24:18,687][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50541
[2024-02-27 17:24:44,949][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50393
[2024-02-27 17:24:44,949][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.99597 - val_accuracy: 0.70170 - train_loss: 0.51115 - val_loss: 1.37549 - loss: 0.50593
[2024-02-27 17:25:39,104][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50215
[2024-02-27 17:25:39,104][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50278
[2024-02-27 17:26:05,211][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.51006
[2024-02-27 17:26:05,211][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50229
[2024-02-27 17:26:31,754][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50374
[2024-02-27 17:26:31,754][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50453
[2024-02-27 17:26:57,932][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50671
[2024-02-27 17:26:57,932][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50215
[2024-02-27 17:27:24,604][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50333
[2024-02-27 17:27:24,604][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50458
[2024-02-27 17:27:50,962][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50187
[2024-02-27 17:27:50,963][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50999
[2024-02-27 17:28:17,497][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50413
[2024-02-27 17:28:17,497][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50412
[2024-02-27 17:28:43,776][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50223
[2024-02-27 17:28:43,776][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50297
[2024-02-27 17:29:10,625][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50399
[2024-02-27 17:29:10,625][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50262
[2024-02-27 17:29:36,819][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50663
[2024-02-27 17:29:36,819][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.99680 - val_accuracy: 0.70230 - train_loss: 0.50925 - val_loss: 1.37529 - loss: 0.50468
[2024-02-27 17:30:30,933][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50243
[2024-02-27 17:30:30,933][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.51178
[2024-02-27 17:30:57,220][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50323
[2024-02-27 17:30:57,220][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50341
[2024-02-27 17:31:23,821][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50603
[2024-02-27 17:31:23,821][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50381
[2024-02-27 17:31:50,075][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50568
[2024-02-27 17:31:50,075][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50340
[2024-02-27 17:32:16,764][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50889
[2024-02-27 17:32:16,764][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50420
[2024-02-27 17:32:42,920][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50551
[2024-02-27 17:32:42,920][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50552
[2024-02-27 17:33:09,508][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50683
[2024-02-27 17:33:09,508][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50166
[2024-02-27 17:33:35,649][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50673
[2024-02-27 17:33:35,650][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50831
[2024-02-27 17:34:02,275][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50328
[2024-02-27 17:34:02,275][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50145
[2024-02-27 17:34:28,380][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50479
[2024-02-27 17:34:28,379][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.99640 - val_accuracy: 0.69990 - train_loss: 0.50973 - val_loss: 1.38017 - loss: 0.50157
[2024-02-27 17:35:22,509][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50322
[2024-02-27 17:35:22,509][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50368
[2024-02-27 17:35:48,719][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50736
[2024-02-27 17:35:48,719][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50965
[2024-02-27 17:36:15,324][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50259
[2024-02-27 17:36:15,324][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50392
[2024-02-27 17:36:41,435][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50155
[2024-02-27 17:36:41,435][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50610
[2024-02-27 17:37:08,057][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.51014
[2024-02-27 17:37:08,057][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50298
[2024-02-27 17:37:34,287][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.51021
[2024-02-27 17:37:34,287][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50491
[2024-02-27 17:38:00,931][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50491
[2024-02-27 17:38:00,931][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50381
[2024-02-27 17:38:27,294][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50304
[2024-02-27 17:38:27,294][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50466
[2024-02-27 17:38:53,866][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50209
[2024-02-27 17:38:53,866][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50655
[2024-02-27 17:39:20,072][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50309
[2024-02-27 17:39:20,072][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.99791 - val_accuracy: 0.70460 - train_loss: 0.50692 - val_loss: 1.36478 - loss: 0.50640
[2024-02-27 17:40:14,084][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50688
[2024-02-27 17:40:14,084][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50226
[2024-02-27 17:40:40,763][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50248
[2024-02-27 17:40:40,763][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50198
[2024-02-27 17:41:06,951][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50536
[2024-02-27 17:41:06,951][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50390
[2024-02-27 17:41:33,662][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50199
[2024-02-27 17:41:33,662][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50527
[2024-02-27 17:41:59,797][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50164
[2024-02-27 17:41:59,797][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50142
[2024-02-27 17:42:26,422][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50352
[2024-02-27 17:42:26,422][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50446
[2024-02-27 17:42:52,631][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50277
[2024-02-27 17:42:52,631][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50221
[2024-02-27 17:43:19,248][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50168
[2024-02-27 17:43:19,248][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50132
[2024-02-27 17:43:45,667][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50159
[2024-02-27 17:43:45,667][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.99799 - val_accuracy: 0.70480 - train_loss: 0.50625 - val_loss: 1.36401 - loss: 0.50145
[2024-02-27 17:44:39,833][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50166
[2024-02-27 17:44:39,833][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50097
[2024-02-27 17:45:06,085][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50105
[2024-02-27 17:45:06,085][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50162
[2024-02-27 17:45:32,774][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.51232
[2024-02-27 17:45:32,774][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50205
[2024-02-27 17:45:58,994][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50260
[2024-02-27 17:45:58,995][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50181
[2024-02-27 17:46:25,503][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50264
[2024-02-27 17:46:25,503][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.53282
[2024-02-27 17:46:51,698][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50104
[2024-02-27 17:46:51,698][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50163
[2024-02-27 17:47:18,270][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50368
[2024-02-27 17:47:18,270][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50218
[2024-02-27 17:47:44,479][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50282
[2024-02-27 17:47:44,479][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50562
[2024-02-27 17:48:11,044][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50213
[2024-02-27 17:48:11,044][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50131
[2024-02-27 17:48:37,287][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50125
[2024-02-27 17:48:37,287][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.99897 - val_accuracy: 0.71270 - train_loss: 0.50361 - val_loss: 1.34443 - loss: 0.50184
[2024-02-27 17:49:31,235][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50302
[2024-02-27 17:49:31,235][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50132
[2024-02-27 17:49:57,572][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50110
[2024-02-27 17:49:57,572][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50205
[2024-02-27 17:50:24,260][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50098
[2024-02-27 17:50:24,260][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50107
[2024-02-27 17:50:50,413][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50111
[2024-02-27 17:50:50,413][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50274
[2024-02-27 17:51:17,043][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50211
[2024-02-27 17:51:17,043][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50147
[2024-02-27 17:51:43,186][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50565
[2024-02-27 17:51:43,186][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50084
[2024-02-27 17:52:09,726][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50202
[2024-02-27 17:52:09,726][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50189
[2024-02-27 17:52:35,943][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50076
[2024-02-27 17:52:35,943][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50178
[2024-02-27 17:53:02,592][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50156
[2024-02-27 17:53:02,592][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50300
[2024-02-27 17:53:28,688][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50218
[2024-02-27 17:53:28,688][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.99915 - val_accuracy: 0.71520 - train_loss: 0.50320 - val_loss: 1.33732 - loss: 0.50168
[2024-02-27 17:54:22,513][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50113
[2024-02-27 17:54:22,513][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50174
[2024-02-27 17:54:48,666][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50096
[2024-02-27 17:54:48,666][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50091
[2024-02-27 17:55:15,254][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50153
[2024-02-27 17:55:15,254][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50961
[2024-02-27 17:55:42,092][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50139
[2024-02-27 17:55:42,092][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50203
[2024-02-27 17:56:08,302][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50346
[2024-02-27 17:56:08,302][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50123
[2024-02-27 17:56:35,058][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50092
[2024-02-27 17:56:35,058][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50148
[2024-02-27 17:57:01,247][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50243
[2024-02-27 17:57:01,247][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50175
[2024-02-27 17:57:27,982][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50817
[2024-02-27 17:57:27,982][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50113
[2024-02-27 17:57:54,225][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50107
[2024-02-27 17:57:54,225][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.99952 - val_accuracy: 0.71550 - train_loss: 0.50201 - val_loss: 1.33298 - loss: 0.50096
[2024-02-27 17:58:48,302][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50130
[2024-02-27 17:58:48,302][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50109
[2024-02-27 17:59:14,481][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50079
[2024-02-27 17:59:14,481][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50753
[2024-02-27 17:59:41,140][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50103
[2024-02-27 17:59:41,140][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50113
[2024-02-27 18:00:07,363][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50098
[2024-02-27 18:00:07,363][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50237
[2024-02-27 18:00:33,922][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50085
[2024-02-27 18:00:33,922][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50286
[2024-02-27 18:01:00,082][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50132
[2024-02-27 18:01:00,082][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50233
[2024-02-27 18:01:26,588][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50173
[2024-02-27 18:01:26,588][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50075
[2024-02-27 18:01:52,782][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50298
[2024-02-27 18:01:52,782][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50070
[2024-02-27 18:02:19,417][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50150
[2024-02-27 18:02:19,417][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50061
[2024-02-27 18:02:45,649][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50100
[2024-02-27 18:02:45,649][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.99976 - val_accuracy: 0.71520 - train_loss: 0.50149 - val_loss: 1.32607 - loss: 0.50119
[2024-02-27 18:03:39,726][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50083
[2024-02-27 18:03:39,726][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50175
[2024-02-27 18:04:05,910][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50107
[2024-02-27 18:04:05,910][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50074
[2024-02-27 18:04:32,469][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50060
[2024-02-27 18:04:32,469][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50095
[2024-02-27 18:04:58,592][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50087
[2024-02-27 18:04:58,592][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50141
[2024-02-27 18:05:25,276][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50084
[2024-02-27 18:05:25,276][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50077
[2024-02-27 18:05:51,449][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50070
[2024-02-27 18:05:51,449][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50100
[2024-02-27 18:06:18,030][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50072
[2024-02-27 18:06:18,030][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50098
[2024-02-27 18:06:44,162][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50260
[2024-02-27 18:06:44,162][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50083
[2024-02-27 18:07:11,051][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50076
[2024-02-27 18:07:11,051][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50117
[2024-02-27 18:07:37,265][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50098
[2024-02-27 18:07:37,265][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.99980 - val_accuracy: 0.71650 - train_loss: 0.50111 - val_loss: 1.32571 - loss: 0.50436
[2024-02-27 18:08:31,347][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50144
[2024-02-27 18:08:31,347][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50108
[2024-02-27 18:08:57,557][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50083
[2024-02-27 18:08:57,557][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50073
[2024-02-27 18:09:24,158][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50088
[2024-02-27 18:09:24,158][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50116
[2024-02-27 18:09:50,357][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50090
[2024-02-27 18:09:50,357][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50102
[2024-02-27 18:10:16,950][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50070
[2024-02-27 18:10:16,950][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50102
[2024-02-27 18:10:43,100][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50134
[2024-02-27 18:10:43,100][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50078
[2024-02-27 18:11:09,824][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50083
[2024-02-27 18:11:09,824][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50066
[2024-02-27 18:11:36,508][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50106
[2024-02-27 18:11:36,508][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50108
[2024-02-27 18:12:02,617][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50091
[2024-02-27 18:12:02,617][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.99996 - val_accuracy: 0.71570 - train_loss: 0.50072 - val_loss: 1.32060 - loss: 0.50197
[2024-02-27 18:12:56,701][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50094
[2024-02-27 18:12:56,701][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50105
[2024-02-27 18:13:22,810][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50228
[2024-02-27 18:13:22,810][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50063
[2024-02-27 18:13:49,799][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50058
[2024-02-27 18:13:49,799][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50070
[2024-02-27 18:14:15,949][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50085
[2024-02-27 18:14:15,949][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50082
[2024-02-27 18:14:42,881][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50112
[2024-02-27 18:14:42,881][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50057
[2024-02-27 18:15:09,141][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50064
[2024-02-27 18:15:09,141][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50065
[2024-02-27 18:15:35,916][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50055
[2024-02-27 18:15:35,917][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50063
[2024-02-27 18:16:02,074][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50085
[2024-02-27 18:16:02,075][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50079
[2024-02-27 18:16:29,268][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50065
[2024-02-27 18:16:29,268][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50098
[2024-02-27 18:16:55,460][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50060
[2024-02-27 18:16:55,460][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.99998 - val_accuracy: 0.71880 - train_loss: 0.50072 - val_loss: 1.31644 - loss: 0.50230
[2024-02-27 18:17:49,362][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50077
[2024-02-27 18:17:49,362][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50083
[2024-02-27 18:18:15,600][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50073
[2024-02-27 18:18:15,600][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50083
[2024-02-27 18:18:42,316][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50076
[2024-02-27 18:18:42,316][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50064
[2024-02-27 18:19:08,552][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50050
[2024-02-27 18:19:08,552][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50094
[2024-02-27 18:19:35,098][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50107
[2024-02-27 18:19:35,098][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50074
[2024-02-27 18:20:01,333][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50064
[2024-02-27 18:20:01,333][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50090
[2024-02-27 18:20:28,095][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50209
[2024-02-27 18:20:28,095][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50062
[2024-02-27 18:20:54,200][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50079
[2024-02-27 18:20:54,200][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50071
[2024-02-27 18:21:20,792][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50078
[2024-02-27 18:21:20,792][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50103
[2024-02-27 18:21:46,939][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50088
[2024-02-27 18:21:46,939][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.99996 - val_accuracy: 0.71870 - train_loss: 0.50067 - val_loss: 1.31870 - loss: 0.50099
[2024-02-27 18:22:41,016][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50069
[2024-02-27 18:22:41,016][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50072
[2024-02-27 18:23:07,216][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50068
[2024-02-27 18:23:07,216][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50088
[2024-02-27 18:23:33,858][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50063
[2024-02-27 18:23:33,858][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50064
[2024-02-27 18:24:00,090][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50155
[2024-02-27 18:24:00,090][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50074
[2024-02-27 18:24:26,833][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50111
[2024-02-27 18:24:26,833][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50063
[2024-02-27 18:24:53,070][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50079
[2024-02-27 18:24:53,071][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50067
[2024-02-27 18:25:19,653][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50057
[2024-02-27 18:25:19,653][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50059
[2024-02-27 18:25:45,825][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50071
[2024-02-27 18:25:45,825][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50056
[2024-02-27 18:26:12,576][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50051
[2024-02-27 18:26:12,576][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50067
[2024-02-27 18:26:38,850][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50057
[2024-02-27 18:26:38,850][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 1.00000 - val_accuracy: 0.71900 - train_loss: 0.50064 - val_loss: 1.32119 - loss: 0.50058
[2024-02-27 18:27:32,849][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50065
[2024-02-27 18:27:32,849][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50056
[2024-02-27 18:27:59,510][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50107
[2024-02-27 18:27:59,510][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50052
[2024-02-27 18:28:25,667][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50065
[2024-02-27 18:28:25,667][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50089
[2024-02-27 18:28:52,580][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50053
[2024-02-27 18:28:52,580][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50071
[2024-02-27 18:29:18,803][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50069
[2024-02-27 18:29:18,803][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50059
[2024-02-27 18:29:45,387][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50059
[2024-02-27 18:29:45,387][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50076
[2024-02-27 18:30:11,492][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50229
[2024-02-27 18:30:11,492][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50072
[2024-02-27 18:30:38,075][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50071
[2024-02-27 18:30:38,075][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50054
[2024-02-27 18:31:04,200][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50067
[2024-02-27 18:31:04,200][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.99998 - val_accuracy: 0.71870 - train_loss: 0.50058 - val_loss: 1.30913 - loss: 0.50140
[2024-02-27 18:31:58,176][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50055
[2024-02-27 18:31:58,176][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50062
[2024-02-27 18:32:24,409][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50060
[2024-02-27 18:32:24,409][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50070
[2024-02-27 18:32:51,824][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50053
[2024-02-27 18:32:51,824][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50219
[2024-02-27 18:33:18,020][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34600] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50058
[2024-02-27 18:33:18,020][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34600] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50073
[2024-02-27 18:33:44,537][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34650] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50061
[2024-02-27 18:33:44,537][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34650] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50063
[2024-02-27 18:34:10,760][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34700] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50070
[2024-02-27 18:34:10,760][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34700] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50057
[2024-02-27 18:34:37,566][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34750] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50141
[2024-02-27 18:34:37,566][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34750] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50066
[2024-02-27 18:35:03,667][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34800] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50059
[2024-02-27 18:35:03,667][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34800] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50048
[2024-02-27 18:35:30,323][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34850] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50066
[2024-02-27 18:35:30,323][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34850] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50083
[2024-02-27 18:35:56,567][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34900] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50066
[2024-02-27 18:35:56,567][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34900] - train_accuracy: 0.99998 - val_accuracy: 0.72190 - train_loss: 0.50049 - val_loss: 1.30129 - loss: 0.50061
[2024-02-27 18:36:50,391][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[34950] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50072
[2024-02-27 18:36:50,391][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[34950] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50056
[2024-02-27 18:37:16,645][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[35000] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50046
[2024-02-27 18:37:16,645][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[35000] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50063
[2024-02-27 18:37:43,325][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35050] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50069
[2024-02-27 18:37:43,325][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35050] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50056
[2024-02-27 18:38:09,515][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35100] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50049
[2024-02-27 18:38:09,515][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35100] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50058
[2024-02-27 18:38:36,165][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35150] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50057
[2024-02-27 18:38:36,165][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35150] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50052
[2024-02-27 18:39:02,518][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35200] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50047
[2024-02-27 18:39:02,518][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35200] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50060
[2024-02-27 18:39:29,299][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35250] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50056
[2024-02-27 18:39:29,299][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35250] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50075
[2024-02-27 18:39:55,502][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35300] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50066
[2024-02-27 18:39:55,502][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35300] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50052
[2024-02-27 18:40:22,273][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35350] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50067
[2024-02-27 18:40:22,273][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35350] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50059
[2024-02-27 18:40:48,551][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35400] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50052
[2024-02-27 18:40:48,551][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35400] - train_accuracy: 1.00000 - val_accuracy: 0.72270 - train_loss: 0.50052 - val_loss: 1.30056 - loss: 0.50271
[2024-02-27 18:41:42,900][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35450] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50180
[2024-02-27 18:41:42,900][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35450] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50056
[2024-02-27 18:42:09,150][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35500] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50047
[2024-02-27 18:42:09,150][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35500] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50068
[2024-02-27 18:42:35,721][PyLogger][INFO]: Rank[1]: Epoch[367/500], iter[35550] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50055
[2024-02-27 18:42:35,721][PyLogger][INFO]: Rank[0]: Epoch[367/500], iter[35550] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50089
[2024-02-27 18:43:02,435][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35600] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50299
[2024-02-27 18:43:02,435][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35600] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50050
[2024-02-27 18:43:28,599][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35650] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50053
[2024-02-27 18:43:28,599][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35650] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50055
[2024-02-27 18:43:55,339][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35700] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50067
[2024-02-27 18:43:55,339][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35700] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50052
[2024-02-27 18:44:21,569][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35750] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50048
[2024-02-27 18:44:21,569][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35750] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50053
[2024-02-27 18:44:48,053][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35800] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50053
[2024-02-27 18:44:48,053][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35800] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50072
[2024-02-27 18:45:14,260][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35850] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50065
[2024-02-27 18:45:14,260][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35850] - train_accuracy: 0.99998 - val_accuracy: 0.72030 - train_loss: 0.50048 - val_loss: 1.29878 - loss: 0.50057
[2024-02-27 18:46:08,313][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35900] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50059
[2024-02-27 18:46:08,313][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35900] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50062
[2024-02-27 18:46:34,668][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35950] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50108
[2024-02-27 18:46:34,668][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35950] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50059
[2024-02-27 18:47:01,292][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36000] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50062
[2024-02-27 18:47:01,292][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36000] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50053
[2024-02-27 18:47:27,497][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36050] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50055
[2024-02-27 18:47:27,496][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36050] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50047
[2024-02-27 18:47:54,175][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36100] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50044
[2024-02-27 18:47:54,175][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36100] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50050
[2024-02-27 18:48:20,450][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36150] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50062
[2024-02-27 18:48:20,450][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36150] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50055
[2024-02-27 18:48:47,062][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36200] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50058
[2024-02-27 18:48:47,062][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36200] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50051
[2024-02-27 18:49:13,268][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36250] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50056
[2024-02-27 18:49:13,268][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36250] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50052
[2024-02-27 18:49:39,857][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36300] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50072
[2024-02-27 18:49:39,858][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36300] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50047
[2024-02-27 18:50:06,021][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36350] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50049
[2024-02-27 18:50:06,021][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36350] - train_accuracy: 1.00000 - val_accuracy: 0.71980 - train_loss: 0.50045 - val_loss: 1.29524 - loss: 0.50053
[2024-02-27 18:51:00,072][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36400] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50053
[2024-02-27 18:51:00,073][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36400] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50064
[2024-02-27 18:51:26,195][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36450] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50048
[2024-02-27 18:51:26,195][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36450] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50056
[2024-02-27 18:51:52,714][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36500] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50058
[2024-02-27 18:51:52,714][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36500] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50053
[2024-02-27 18:52:19,014][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36550] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50058
[2024-02-27 18:52:19,014][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36550] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50054
[2024-02-27 18:52:45,633][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36600] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50050
[2024-02-27 18:52:45,633][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36600] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50048
[2024-02-27 18:53:11,843][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36650] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50056
[2024-02-27 18:53:11,843][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36650] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50048
[2024-02-27 18:53:38,411][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36700] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50064
[2024-02-27 18:53:38,411][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36700] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50051
[2024-02-27 18:54:04,594][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36750] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50056
[2024-02-27 18:54:04,594][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36750] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50044
[2024-02-27 18:54:31,295][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36800] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50059
[2024-02-27 18:54:31,295][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36800] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50054
[2024-02-27 18:54:57,493][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36850] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50053
[2024-02-27 18:54:57,493][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36850] - train_accuracy: 1.00000 - val_accuracy: 0.72290 - train_loss: 0.50043 - val_loss: 1.29245 - loss: 0.50055
[2024-02-27 18:55:51,480][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36900] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50074
[2024-02-27 18:55:51,480][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36900] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50048
[2024-02-27 18:56:17,654][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36950] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50051
[2024-02-27 18:56:17,654][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36950] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50045
[2024-02-27 18:56:44,295][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37000] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50052
[2024-02-27 18:56:44,295][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37000] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50046
[2024-02-27 18:57:10,401][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37050] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50061
[2024-02-27 18:57:10,401][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37050] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50090
[2024-02-27 18:57:37,071][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37100] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50046
[2024-02-27 18:57:37,071][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37100] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50057
[2024-02-27 18:58:03,228][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37150] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50054
[2024-02-27 18:58:03,228][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37150] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50048
[2024-02-27 18:58:29,872][PyLogger][INFO]: Rank[0]: Epoch[384/500], iter[37200] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50044
[2024-02-27 18:58:29,872][PyLogger][INFO]: Rank[1]: Epoch[384/500], iter[37200] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50064
[2024-02-27 18:58:56,550][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37250] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50054
[2024-02-27 18:58:56,550][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37250] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50061
[2024-02-27 18:59:22,859][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37300] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50047
[2024-02-27 18:59:22,859][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37300] - train_accuracy: 1.00000 - val_accuracy: 0.72360 - train_loss: 0.50042 - val_loss: 1.28879 - loss: 0.50046
[2024-02-27 19:00:16,954][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37350] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50045
[2024-02-27 19:00:16,954][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37350] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50047
[2024-02-27 19:00:43,137][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37400] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50103
[2024-02-27 19:00:43,137][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37400] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50065
[2024-02-27 19:01:09,725][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37450] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50053
[2024-02-27 19:01:09,726][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37450] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50052
[2024-02-27 19:01:36,020][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37500] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50054
[2024-02-27 19:01:36,020][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37500] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50068
[2024-02-27 19:02:02,671][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37550] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50050
[2024-02-27 19:02:02,671][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37550] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50054
[2024-02-27 19:02:28,872][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37600] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50048
[2024-02-27 19:02:28,872][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37600] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50045
[2024-02-27 19:02:55,609][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37650] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50050
[2024-02-27 19:02:55,609][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37650] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50053
[2024-02-27 19:03:21,741][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37700] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50047
[2024-02-27 19:03:21,741][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37700] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50058
[2024-02-27 19:03:48,352][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37750] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50055
[2024-02-27 19:03:48,352][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37750] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50058
[2024-02-27 19:04:14,538][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37800] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50043
[2024-02-27 19:04:14,539][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37800] - train_accuracy: 1.00000 - val_accuracy: 0.72220 - train_loss: 0.50042 - val_loss: 1.28999 - loss: 0.50057
[2024-02-27 19:05:08,425][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37850] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50051
[2024-02-27 19:05:08,425][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37850] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50069
[2024-02-27 19:05:34,820][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37900] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50051
[2024-02-27 19:05:34,820][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37900] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50054
[2024-02-27 19:06:01,688][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[37950] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50049
[2024-02-27 19:06:01,688][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[37950] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50055
[2024-02-27 19:06:27,836][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[38000] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50058
[2024-02-27 19:06:27,836][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[38000] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50054
[2024-02-27 19:06:54,675][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38050] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50074
[2024-02-27 19:06:54,675][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38050] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50046
[2024-02-27 19:07:20,845][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38100] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50055
[2024-02-27 19:07:20,845][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38100] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50058
[2024-02-27 19:07:47,596][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38150] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50052
[2024-02-27 19:07:47,596][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38150] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50048
[2024-02-27 19:08:13,825][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38200] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50050
[2024-02-27 19:08:13,825][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38200] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50058
[2024-02-27 19:08:40,475][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38250] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50065
[2024-02-27 19:08:40,475][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38250] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50060
[2024-02-27 19:09:06,615][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38300] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50044
[2024-02-27 19:09:06,615][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38300] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50041 - val_loss: 1.28732 - loss: 0.50055
[2024-02-27 19:10:00,710][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38350] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50047
[2024-02-27 19:10:00,710][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38350] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50062
[2024-02-27 19:10:26,881][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38400] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50046
[2024-02-27 19:10:26,881][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38400] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50047
[2024-02-27 19:10:53,502][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38450] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50046
[2024-02-27 19:10:53,502][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38450] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50046
[2024-02-27 19:11:19,684][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38500] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50048
[2024-02-27 19:11:19,684][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38500] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50062
[2024-02-27 19:11:46,429][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38550] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50053
[2024-02-27 19:11:46,429][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38550] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50056
[2024-02-27 19:12:12,715][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38600] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50114
[2024-02-27 19:12:12,715][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38600] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50045
[2024-02-27 19:12:39,348][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38650] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50047
[2024-02-27 19:12:39,348][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38650] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50090
[2024-02-27 19:13:05,484][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38700] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50051
[2024-02-27 19:13:05,484][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38700] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50076
[2024-02-27 19:13:32,045][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38750] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50054
[2024-02-27 19:13:32,045][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38750] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50047
[2024-02-27 19:13:58,277][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38800] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50054
[2024-02-27 19:13:58,277][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38800] - train_accuracy: 1.00000 - val_accuracy: 0.72200 - train_loss: 0.50040 - val_loss: 1.28521 - loss: 0.50047
[2024-02-27 19:14:52,390][PyLogger][INFO]: Rank[0]: Epoch[401/500], iter[38850] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50048
[2024-02-27 19:14:52,390][PyLogger][INFO]: Rank[1]: Epoch[401/500], iter[38850] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50048
[2024-02-27 19:15:19,049][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38900] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50044
[2024-02-27 19:15:19,049][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38900] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50046
[2024-02-27 19:15:45,297][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38950] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50055
[2024-02-27 19:15:45,297][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38950] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50050
[2024-02-27 19:16:12,053][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39000] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50055
[2024-02-27 19:16:12,053][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39000] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50043
[2024-02-27 19:16:38,300][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39050] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50045
[2024-02-27 19:16:38,300][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39050] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50056
[2024-02-27 19:17:05,249][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39100] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50044
[2024-02-27 19:17:05,249][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39100] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50048
[2024-02-27 19:17:31,511][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39150] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50064
[2024-02-27 19:17:31,511][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39150] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50061
[2024-02-27 19:17:58,197][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39200] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50041
[2024-02-27 19:17:58,197][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39200] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50043
[2024-02-27 19:18:24,502][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39250] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50054
[2024-02-27 19:18:24,502][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39250] - train_accuracy: 1.00000 - val_accuracy: 0.72450 - train_loss: 0.50039 - val_loss: 1.28397 - loss: 0.50044
[2024-02-27 19:19:18,441][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39300] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50047
[2024-02-27 19:19:18,441][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39300] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50055
[2024-02-27 19:19:44,637][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39350] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50049
[2024-02-27 19:19:44,637][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39350] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50049
[2024-02-27 19:20:11,332][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39400] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50046
[2024-02-27 19:20:11,333][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39400] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50063
[2024-02-27 19:20:37,597][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39450] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50052
[2024-02-27 19:20:37,597][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39450] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50046
[2024-02-27 19:21:04,179][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39500] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50051
[2024-02-27 19:21:04,179][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39500] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50047
[2024-02-27 19:21:30,434][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39550] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50062
[2024-02-27 19:21:30,434][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39550] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50043
[2024-02-27 19:21:57,080][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39600] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50047
[2024-02-27 19:21:57,080][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39600] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50050
[2024-02-27 19:22:23,332][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39650] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50044
[2024-02-27 19:22:23,332][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39650] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50048
[2024-02-27 19:22:50,081][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39700] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50048
[2024-02-27 19:22:50,081][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39700] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50046
[2024-02-27 19:23:16,364][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39750] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50044
[2024-02-27 19:23:16,364][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39750] - train_accuracy: 1.00000 - val_accuracy: 0.72670 - train_loss: 0.50039 - val_loss: 1.28239 - loss: 0.50056
[2024-02-27 19:24:10,516][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50054
[2024-02-27 19:24:10,516][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50060
[2024-02-27 19:24:36,747][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50049
[2024-02-27 19:24:36,747][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50050
[2024-02-27 19:25:03,299][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50044
[2024-02-27 19:25:03,299][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50071
[2024-02-27 19:25:29,558][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50053
[2024-02-27 19:25:29,558][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50049
[2024-02-27 19:25:56,203][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50046
[2024-02-27 19:25:56,203][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50044
[2024-02-27 19:26:22,363][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40050] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50080
[2024-02-27 19:26:22,363][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40050] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50045
[2024-02-27 19:26:49,147][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40100] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50050
[2024-02-27 19:26:49,147][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40100] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50049
[2024-02-27 19:27:15,431][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40150] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50042
[2024-02-27 19:27:15,431][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40150] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50042
[2024-02-27 19:27:42,129][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40200] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50055
[2024-02-27 19:27:42,129][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40200] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50047
[2024-02-27 19:28:08,329][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40250] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50049
[2024-02-27 19:28:08,329][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40250] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50040 - val_loss: 1.28137 - loss: 0.50051
[2024-02-27 19:29:02,341][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40300] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50061
[2024-02-27 19:29:02,341][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40300] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50045
[2024-02-27 19:29:28,585][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40350] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50061
[2024-02-27 19:29:28,585][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40350] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50046
[2024-02-27 19:29:55,287][PyLogger][INFO]: Rank[1]: Epoch[417/500], iter[40400] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50065
[2024-02-27 19:29:55,287][PyLogger][INFO]: Rank[0]: Epoch[417/500], iter[40400] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50048
[2024-02-27 19:30:22,049][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40450] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50050
[2024-02-27 19:30:22,049][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40450] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50057
[2024-02-27 19:30:48,292][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40500] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50044
[2024-02-27 19:30:48,292][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40500] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50043
[2024-02-27 19:31:14,890][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40550] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50043
[2024-02-27 19:31:14,890][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40550] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50048
[2024-02-27 19:31:41,140][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40600] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50047
[2024-02-27 19:31:41,140][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40600] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50052
[2024-02-27 19:32:07,842][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40650] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50047
[2024-02-27 19:32:07,842][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40650] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50048
[2024-02-27 19:32:34,034][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40700] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50047
[2024-02-27 19:32:34,034][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40700] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28134 - loss: 0.50043
[2024-02-27 19:33:27,974][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40750] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50044
[2024-02-27 19:33:27,974][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40750] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50048
[2024-02-27 19:33:54,225][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40800] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50043
[2024-02-27 19:33:54,225][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40800] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50062
[2024-02-27 19:34:20,871][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40850] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50047
[2024-02-27 19:34:20,871][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40850] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50052
[2024-02-27 19:34:47,264][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40900] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50049
[2024-02-27 19:34:47,264][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40900] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50043
[2024-02-27 19:35:13,975][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[40950] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50059
[2024-02-27 19:35:13,975][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[40950] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50046
[2024-02-27 19:35:40,164][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[41000] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50048
[2024-02-27 19:35:40,165][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[41000] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50042
[2024-02-27 19:36:06,872][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41050] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50048
[2024-02-27 19:36:06,872][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41050] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50050
[2024-02-27 19:36:33,207][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41100] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50045
[2024-02-27 19:36:33,207][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41100] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50048
[2024-02-27 19:36:59,852][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41150] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50068
[2024-02-27 19:36:59,852][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41150] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50046
[2024-02-27 19:37:26,114][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41200] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50051
[2024-02-27 19:37:26,115][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41200] - train_accuracy: 1.00000 - val_accuracy: 0.72540 - train_loss: 0.50038 - val_loss: 1.28150 - loss: 0.50049
[2024-02-27 19:38:20,172][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41250] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50045
[2024-02-27 19:38:20,172][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41250] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50051
[2024-02-27 19:38:46,456][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41300] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50056
[2024-02-27 19:38:46,457][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41300] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50044
[2024-02-27 19:39:13,208][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41350] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50053
[2024-02-27 19:39:13,208][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41350] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50050
[2024-02-27 19:39:39,434][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41400] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50057
[2024-02-27 19:39:39,434][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41400] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50061
[2024-02-27 19:40:06,270][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41450] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50042
[2024-02-27 19:40:06,270][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41450] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50048
[2024-02-27 19:40:32,568][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41500] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50053
[2024-02-27 19:40:32,568][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41500] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50047
[2024-02-27 19:40:59,171][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41550] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50044
[2024-02-27 19:40:59,172][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41550] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50051
[2024-02-27 19:41:25,398][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41600] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50049
[2024-02-27 19:41:25,398][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41600] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50047
[2024-02-27 19:41:52,075][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41650] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50055
[2024-02-27 19:41:52,075][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41650] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50046
[2024-02-27 19:42:18,325][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41700] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50051
[2024-02-27 19:42:18,325][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41700] - train_accuracy: 1.00000 - val_accuracy: 0.72460 - train_loss: 0.50038 - val_loss: 1.28090 - loss: 0.50051
[2024-02-27 19:43:12,321][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41750] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50044
[2024-02-27 19:43:12,321][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41750] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50048
[2024-02-27 19:43:38,516][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41800] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50054
[2024-02-27 19:43:38,516][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41800] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50042
[2024-02-27 19:44:05,273][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41850] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50048
[2024-02-27 19:44:05,273][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41850] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50048
[2024-02-27 19:44:31,489][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41900] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50050
[2024-02-27 19:44:31,489][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41900] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50042
[2024-02-27 19:44:58,346][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[41950] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50045
[2024-02-27 19:44:58,346][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[41950] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50070
[2024-02-27 19:45:24,568][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[42000] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50048
[2024-02-27 19:45:24,568][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[42000] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50053
[2024-02-27 19:45:51,239][PyLogger][INFO]: Rank[0]: Epoch[434/500], iter[42050] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50043
[2024-02-27 19:45:51,239][PyLogger][INFO]: Rank[1]: Epoch[434/500], iter[42050] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50044
[2024-02-27 19:46:17,800][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42100] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50045
[2024-02-27 19:46:17,800][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42100] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50047
[2024-02-27 19:46:43,950][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42150] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50046
[2024-02-27 19:46:43,950][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42150] - train_accuracy: 1.00000 - val_accuracy: 0.72590 - train_loss: 0.50038 - val_loss: 1.28205 - loss: 0.50052
[2024-02-27 19:47:37,862][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42200] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50043
[2024-02-27 19:47:37,862][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42200] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50048
[2024-02-27 19:48:04,042][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42250] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50044
[2024-02-27 19:48:04,042][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42250] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50067
[2024-02-27 19:48:30,783][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42300] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50048
[2024-02-27 19:48:30,783][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42300] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50097
[2024-02-27 19:48:56,880][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42350] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50056
[2024-02-27 19:48:56,880][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42350] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50047
[2024-02-27 19:49:23,560][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42400] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50042
[2024-02-27 19:49:23,560][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42400] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50050
[2024-02-27 19:49:49,804][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42450] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50046
[2024-02-27 19:49:49,804][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42450] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50048
[2024-02-27 19:50:16,509][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42500] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50044
[2024-02-27 19:50:16,509][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42500] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50059
[2024-02-27 19:50:42,771][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42550] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50046
[2024-02-27 19:50:42,771][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42550] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50055
[2024-02-27 19:51:09,371][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42600] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50052
[2024-02-27 19:51:09,371][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42600] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50050
[2024-02-27 19:51:35,495][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42650] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50094
[2024-02-27 19:51:35,496][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42650] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50038 - val_loss: 1.28046 - loss: 0.50043
[2024-02-27 19:52:29,293][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42700] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50074
[2024-02-27 19:52:29,293][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42700] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50044
[2024-02-27 19:52:55,565][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42750] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50051
[2024-02-27 19:52:55,565][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42750] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50047
[2024-02-27 19:53:22,131][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42800] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50051
[2024-02-27 19:53:22,131][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42800] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50064
[2024-02-27 19:53:48,330][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42850] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50063
[2024-02-27 19:53:48,331][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42850] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50044
[2024-02-27 19:54:14,887][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42900] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50047
[2024-02-27 19:54:14,887][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42900] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50053
[2024-02-27 19:54:41,115][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42950] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50048
[2024-02-27 19:54:41,115][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42950] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50052
[2024-02-27 19:55:07,638][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43000] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50050
[2024-02-27 19:55:07,638][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43000] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50048
[2024-02-27 19:55:34,014][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43050] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50048
[2024-02-27 19:55:34,014][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43050] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50047
[2024-02-27 19:56:00,603][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43100] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50053
[2024-02-27 19:56:00,603][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43100] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50045
[2024-02-27 19:56:26,863][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43150] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50049
[2024-02-27 19:56:26,863][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43150] - train_accuracy: 1.00000 - val_accuracy: 0.72430 - train_loss: 0.50038 - val_loss: 1.28002 - loss: 0.50051
[2024-02-27 19:57:20,824][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43200] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50043
[2024-02-27 19:57:20,824][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43200] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50044
[2024-02-27 19:57:46,999][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43250] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50062
[2024-02-27 19:57:46,999][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43250] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50050
[2024-02-27 19:58:13,657][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43300] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50044
[2024-02-27 19:58:13,657][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43300] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50049
[2024-02-27 19:58:39,712][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43350] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50051
[2024-02-27 19:58:39,712][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43350] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50048
[2024-02-27 19:59:06,404][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43400] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50045
[2024-02-27 19:59:06,404][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43400] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50051
[2024-02-27 19:59:32,468][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43450] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50059
[2024-02-27 19:59:32,469][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43450] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50047
[2024-02-27 19:59:59,203][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43500] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50046
[2024-02-27 19:59:59,203][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43500] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50043
[2024-02-27 20:00:25,323][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43550] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50046
[2024-02-27 20:00:25,323][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43550] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50069
[2024-02-27 20:00:52,094][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43600] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50044
[2024-02-27 20:00:52,094][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43600] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50050
[2024-02-27 20:01:18,150][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43650] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50044
[2024-02-27 20:01:18,150][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43650] - train_accuracy: 1.00000 - val_accuracy: 0.72710 - train_loss: 0.50037 - val_loss: 1.27848 - loss: 0.50044
[2024-02-27 20:02:11,906][PyLogger][INFO]: Rank[0]: Epoch[451/500], iter[43700] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50047
[2024-02-27 20:02:11,906][PyLogger][INFO]: Rank[1]: Epoch[451/500], iter[43700] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50070
[2024-02-27 20:02:38,578][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43750] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50046
[2024-02-27 20:02:38,578][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43750] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50051
[2024-02-27 20:03:04,736][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43800] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50045
[2024-02-27 20:03:04,736][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43800] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50043
[2024-02-27 20:03:31,400][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43850] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50044
[2024-02-27 20:03:31,400][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43850] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50049
[2024-02-27 20:03:57,595][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43900] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50045
[2024-02-27 20:03:57,595][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43900] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50048
[2024-02-27 20:04:24,096][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[43950] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50048
[2024-02-27 20:04:24,096][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[43950] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50052
[2024-02-27 20:04:50,229][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[44000] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50050
[2024-02-27 20:04:50,229][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[44000] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50064
[2024-02-27 20:05:16,959][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44050] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50047
[2024-02-27 20:05:16,959][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44050] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50050
[2024-02-27 20:05:43,164][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44100] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50050
[2024-02-27 20:05:43,164][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44100] - train_accuracy: 1.00000 - val_accuracy: 0.72570 - train_loss: 0.50037 - val_loss: 1.27949 - loss: 0.50041
[2024-02-27 20:06:37,114][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44150] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50065
[2024-02-27 20:06:37,114][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44150] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50047
[2024-02-27 20:07:03,394][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44200] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50065
[2024-02-27 20:07:03,394][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44200] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50044
[2024-02-27 20:07:30,057][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44250] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50048
[2024-02-27 20:07:30,057][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44250] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50048
[2024-02-27 20:07:56,242][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44300] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50082
[2024-02-27 20:07:56,242][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44300] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50050
[2024-02-27 20:08:22,843][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44350] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50050
[2024-02-27 20:08:22,843][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44350] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50064
[2024-02-27 20:08:48,971][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44400] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50045
[2024-02-27 20:08:48,972][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44400] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50041
[2024-02-27 20:09:15,832][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44450] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50046
[2024-02-27 20:09:15,832][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44450] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50044
[2024-02-27 20:09:41,960][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44500] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50055
[2024-02-27 20:09:41,960][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44500] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50058
[2024-02-27 20:10:08,702][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44550] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50043
[2024-02-27 20:10:08,702][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44550] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50049
[2024-02-27 20:10:34,963][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44600] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50061
[2024-02-27 20:10:34,963][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44600] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27960 - loss: 0.50043
[2024-02-27 20:11:28,948][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44650] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50050
[2024-02-27 20:11:28,948][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44650] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50049
[2024-02-27 20:11:55,147][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44700] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50049
[2024-02-27 20:11:55,147][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44700] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50044
[2024-02-27 20:12:21,713][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44750] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50048
[2024-02-27 20:12:21,713][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44750] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50054
[2024-02-27 20:12:47,836][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50065
[2024-02-27 20:12:47,836][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50041
[2024-02-27 20:13:14,404][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50048
[2024-02-27 20:13:14,404][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50047
[2024-02-27 20:13:40,608][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50041
[2024-02-27 20:13:40,608][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50045
[2024-02-27 20:14:07,338][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[44950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50053
[2024-02-27 20:14:07,338][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[44950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50065
[2024-02-27 20:14:33,602][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[45000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50058
[2024-02-27 20:14:33,602][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[45000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50052
[2024-02-27 20:15:00,230][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45050] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50045
[2024-02-27 20:15:00,230][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45050] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50043
[2024-02-27 20:15:26,399][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45100] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50046
[2024-02-27 20:15:26,399][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45100] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27842 - loss: 0.50042
[2024-02-27 20:16:20,486][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45150] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50050
[2024-02-27 20:16:20,486][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45150] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50048
[2024-02-27 20:16:46,704][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45200] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50044
[2024-02-27 20:16:46,704][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45200] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50052
[2024-02-27 20:17:13,277][PyLogger][INFO]: Rank[0]: Epoch[467/500], iter[45250] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50045
[2024-02-27 20:17:13,277][PyLogger][INFO]: Rank[1]: Epoch[467/500], iter[45250] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50042
[2024-02-27 20:17:39,883][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45300] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50052
[2024-02-27 20:17:39,883][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45300] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50049
[2024-02-27 20:18:06,109][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45350] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50057
[2024-02-27 20:18:06,109][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45350] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50042
[2024-02-27 20:18:32,766][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45400] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50043
[2024-02-27 20:18:32,766][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45400] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50044
[2024-02-27 20:18:59,080][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45450] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50047
[2024-02-27 20:18:59,080][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45450] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50056
[2024-02-27 20:19:25,716][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45500] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50055
[2024-02-27 20:19:25,716][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45500] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50042
[2024-02-27 20:19:51,983][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45550] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50048
[2024-02-27 20:19:51,983][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45550] - train_accuracy: 1.00000 - val_accuracy: 0.72650 - train_loss: 0.50037 - val_loss: 1.27913 - loss: 0.50043
[2024-02-27 20:20:46,027][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45600] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50068
[2024-02-27 20:20:46,027][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45600] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50041
[2024-02-27 20:21:12,313][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45650] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50049
[2024-02-27 20:21:12,313][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45650] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50045
[2024-02-27 20:21:39,073][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45700] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50052
[2024-02-27 20:21:39,073][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45700] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50061
[2024-02-27 20:22:05,246][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45750] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50046
[2024-02-27 20:22:05,246][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45750] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50044
[2024-02-27 20:22:31,920][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45800] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50047
[2024-02-27 20:22:31,920][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45800] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50045
[2024-02-27 20:22:58,140][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45850] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50044
[2024-02-27 20:22:58,140][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45850] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50045
[2024-02-27 20:23:24,798][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45900] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50049
[2024-02-27 20:23:24,798][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45900] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50060
[2024-02-27 20:23:50,881][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45950] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50054
[2024-02-27 20:23:50,881][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45950] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50042
[2024-02-27 20:24:17,528][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46000] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50060
[2024-02-27 20:24:17,528][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46000] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50058
[2024-02-27 20:24:43,670][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46050] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50049
[2024-02-27 20:24:43,670][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46050] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27908 - loss: 0.50051
[2024-02-27 20:25:37,691][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46100] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50050
[2024-02-27 20:25:37,691][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46100] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50043
[2024-02-27 20:26:03,871][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46150] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50049
[2024-02-27 20:26:03,871][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46150] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50046
[2024-02-27 20:26:30,496][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46200] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50051
[2024-02-27 20:26:30,496][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46200] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50043
[2024-02-27 20:26:56,665][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46250] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50050
[2024-02-27 20:26:56,665][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46250] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50044
[2024-02-27 20:27:23,290][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46300] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50042
[2024-02-27 20:27:23,290][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46300] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50051
[2024-02-27 20:27:49,415][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46350] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50052
[2024-02-27 20:27:49,415][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46350] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50052
[2024-02-27 20:28:15,935][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46400] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50048
[2024-02-27 20:28:15,935][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46400] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50042
[2024-02-27 20:28:42,138][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46450] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50052
[2024-02-27 20:28:42,138][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46450] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50050
[2024-02-27 20:29:08,687][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46500] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50047
[2024-02-27 20:29:08,687][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46500] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50049
[2024-02-27 20:29:34,919][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46550] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50063
[2024-02-27 20:29:34,919][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46550] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.28049 - loss: 0.50044
[2024-02-27 20:30:28,736][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46600] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50050
[2024-02-27 20:30:28,736][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46600] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50055
[2024-02-27 20:30:54,942][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46650] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50042
[2024-02-27 20:30:54,942][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46650] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50049
[2024-02-27 20:31:21,668][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46700] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50045
[2024-02-27 20:31:21,668][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46700] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50041
[2024-02-27 20:31:47,847][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46750] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50047
[2024-02-27 20:31:47,847][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46750] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50106
[2024-02-27 20:32:14,479][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50053
[2024-02-27 20:32:14,479][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46800] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50045
[2024-02-27 20:32:40,651][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50047
[2024-02-27 20:32:40,651][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46850] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50044
[2024-02-27 20:33:07,313][PyLogger][INFO]: Rank[1]: Epoch[484/500], iter[46900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50044
[2024-02-27 20:33:07,313][PyLogger][INFO]: Rank[0]: Epoch[484/500], iter[46900] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50041
[2024-02-27 20:33:34,024][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[46950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50046
[2024-02-27 20:33:34,024][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[46950] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50055
[2024-02-27 20:34:00,123][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[47000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50059
[2024-02-27 20:34:00,123][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[47000] - train_accuracy: 1.00000 - val_accuracy: 0.72550 - train_loss: 0.50037 - val_loss: 1.27936 - loss: 0.50057
[2024-02-27 20:34:54,288][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47050] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50047
[2024-02-27 20:34:54,288][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47050] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50046
[2024-02-27 20:35:20,450][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47100] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50054
[2024-02-27 20:35:20,450][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47100] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50041
[2024-02-27 20:35:47,068][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47150] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50038
[2024-02-27 20:35:47,069][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47150] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50043
[2024-02-27 20:36:13,223][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47200] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50053
[2024-02-27 20:36:13,223][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47200] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50049
[2024-02-27 20:36:40,069][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47250] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50041
[2024-02-27 20:36:40,069][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47250] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50048
[2024-02-27 20:37:06,243][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47300] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50049
[2024-02-27 20:37:06,243][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47300] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50048
[2024-02-27 20:37:32,886][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47350] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50069
[2024-02-27 20:37:32,886][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47350] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50047
[2024-02-27 20:37:59,047][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47400] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50053
[2024-02-27 20:37:59,048][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47400] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50046
[2024-02-27 20:38:25,667][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47450] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50063
[2024-02-27 20:38:25,667][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47450] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50046
[2024-02-27 20:38:51,811][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47500] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50051
[2024-02-27 20:38:51,811][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47500] - train_accuracy: 1.00000 - val_accuracy: 0.72560 - train_loss: 0.50038 - val_loss: 1.27805 - loss: 0.50051
[2024-02-27 20:39:45,724][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47550] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50045
[2024-02-27 20:39:45,724][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47550] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50046
[2024-02-27 20:40:11,968][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47600] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50043
[2024-02-27 20:40:11,968][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47600] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50047
[2024-02-27 20:40:38,545][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47650] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50048
[2024-02-27 20:40:38,545][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47650] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50046
[2024-02-27 20:41:04,692][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47700] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50054
[2024-02-27 20:41:04,692][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47700] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50042
[2024-02-27 20:41:31,366][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47750] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50054
[2024-02-27 20:41:31,366][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47750] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50049
[2024-02-27 20:41:57,608][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47800] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50063
[2024-02-27 20:41:57,608][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47800] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50056
[2024-02-27 20:42:24,250][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47850] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50048
[2024-02-27 20:42:24,250][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47850] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50049
[2024-02-27 20:42:50,410][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47900] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50056
[2024-02-27 20:42:50,410][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47900] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50042
[2024-02-27 20:43:17,091][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[47950] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50054
[2024-02-27 20:43:17,091][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[47950] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50047
[2024-02-27 20:43:43,349][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[48000] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50063
[2024-02-27 20:43:43,349][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[48000] - train_accuracy: 1.00000 - val_accuracy: 0.72640 - train_loss: 0.50037 - val_loss: 1.27831 - loss: 0.50042
[2024-02-27 20:44:37,461][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48050] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50063
[2024-02-27 20:44:37,461][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48050] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50045
[2024-02-27 20:45:03,645][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48100] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50046
[2024-02-27 20:45:03,645][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48100] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50045
[2024-02-27 20:45:30,361][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48150] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50048
[2024-02-27 20:45:30,361][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48150] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50054
[2024-02-27 20:45:56,456][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48200] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50053
[2024-02-27 20:45:56,456][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48200] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50047
[2024-02-27 20:46:23,063][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48250] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50044
[2024-02-27 20:46:23,064][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48250] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50052
[2024-02-27 20:46:49,306][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48300] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50046
[2024-02-27 20:46:49,306][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48300] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50045
[2024-02-27 20:47:15,817][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48350] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50047
[2024-02-27 20:47:15,817][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48350] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50047
[2024-02-27 20:47:42,141][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48400] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50053
[2024-02-27 20:47:42,141][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48400] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50053
[2024-02-27 20:48:08,718][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48450] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50047
[2024-02-27 20:48:08,718][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48450] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50046
[2024-02-27 20:48:34,821][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48500] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50049
[2024-02-27 20:48:34,821][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48500] - train_accuracy: 1.00000 - val_accuracy: 0.72580 - train_loss: 0.50037 - val_loss: 1.27776 - loss: 0.50046
Files already downloaded and verified
Files already downloaded and verified
2024-02-27 20:49:03,764 ignite.distributed.launcher.Parallel INFO: End of run
2024-02-27 20:49:08,563 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:49:08,563 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:49:08,563 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1506b51ea3e0>' in 2 processes
2024-02-27 20:49:15,969 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:49:16,393 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a4f5839940>}
[2024-02-27 20:49:16,999][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:16,999][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:16,999][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:17,000][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:49:17,000][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:49:17,000][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:17,000][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:49:17,001][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:49:17,001][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:17,001][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:20,388][PyLogger][INFO]: Rank[0]: val_accuracy: 0.14580
[2024-02-27 20:49:20,388][PyLogger][INFO]: Rank[1]: val_accuracy: 0.14580
2024-02-27 20:49:21,822 ignite.distributed.launcher.Parallel INFO: End of run
new_size=2 done.
2024-02-27 20:49:25,682 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:49:25,683 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:49:25,683 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1543f66663e0>' in 2 processes
2024-02-27 20:49:33,737 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:49:34,155 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b19c894200>}
[2024-02-27 20:49:34,269][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:49:34,269][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:49:34,269][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:34,269][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:49:34,270][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:49:34,270][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:34,270][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:34,272][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:34,272][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:34,272][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:37,656][PyLogger][INFO]: Rank[1]: val_accuracy: 0.24890
[2024-02-27 20:49:37,656][PyLogger][INFO]: Rank[0]: val_accuracy: 0.24890
2024-02-27 20:49:39,122 ignite.distributed.launcher.Parallel INFO: End of run
new_size=3 done.
2024-02-27 20:49:43,134 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:49:43,134 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:49:43,134 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c7629a23e0>' in 2 processes
2024-02-27 20:49:50,558 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:49:50,958 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151ed1528380>}
[2024-02-27 20:49:51,073][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:51,073][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:51,073][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:51,078][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:49:51,078][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:49:51,078][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:49:51,078][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:49:51,079][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:49:51,079][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:49:51,079][PyLogger][INFO]: World size: 2
[2024-02-27 20:49:54,456][PyLogger][INFO]: Rank[1]: val_accuracy: 0.26200
[2024-02-27 20:49:54,456][PyLogger][INFO]: Rank[0]: val_accuracy: 0.26200
2024-02-27 20:49:55,481 ignite.distributed.launcher.Parallel INFO: End of run
new_size=4 done.
2024-02-27 20:49:59,223 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:49:59,223 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:49:59,223 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1529a62863e0>' in 2 processes
2024-02-27 20:50:07,399 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:50:07,797 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1531dd8b0ec0>}
[2024-02-27 20:50:07,917][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:50:07,917][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:50:07,917][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:07,917][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:50:07,918][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:50:07,918][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:07,918][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:07,919][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:07,920][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:07,920][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:11,550][PyLogger][INFO]: Rank[0]: val_accuracy: 0.26430
[2024-02-27 20:50:11,550][PyLogger][INFO]: Rank[1]: val_accuracy: 0.26430
2024-02-27 20:50:13,104 ignite.distributed.launcher.Parallel INFO: End of run
new_size=5 done.
2024-02-27 20:50:17,374 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:50:17,374 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:50:17,374 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14faf15fa3e0>' in 2 processes
2024-02-27 20:50:24,526 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:50:24,941 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1457d2278380>}
[2024-02-27 20:50:25,054][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:25,054][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:25,054][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:25,061][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:50:25,061][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:50:25,061][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:25,061][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:50:25,062][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:50:25,062][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:25,062][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:28,691][PyLogger][INFO]: Rank[1]: val_accuracy: 0.26330
[2024-02-27 20:50:28,691][PyLogger][INFO]: Rank[0]: val_accuracy: 0.26330
2024-02-27 20:50:30,111 ignite.distributed.launcher.Parallel INFO: End of run
new_size=6 done.
2024-02-27 20:50:33,833 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:50:33,833 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:50:33,833 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1511c255e3e0>' in 2 processes
2024-02-27 20:50:42,573 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:50:42,978 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a841ffc2f0>}
[2024-02-27 20:50:43,092][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:50:43,092][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:50:43,092][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:43,092][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:50:43,093][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:50:43,093][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:43,093][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:43,100][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:50:43,100][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:50:43,101][PyLogger][INFO]: World size: 2
[2024-02-27 20:50:46,717][PyLogger][INFO]: Rank[1]: val_accuracy: 0.25440
[2024-02-27 20:50:46,717][PyLogger][INFO]: Rank[0]: val_accuracy: 0.25440
2024-02-27 20:50:48,201 ignite.distributed.launcher.Parallel INFO: End of run
new_size=7 done.
2024-02-27 20:50:51,884 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:50:51,884 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:50:51,884 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14cc2cbca3e0>' in 2 processes
2024-02-27 20:50:59,946 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:51:00,352 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15405df38dd0>}
[2024-02-27 20:51:00,465][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:00,465][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:00,465][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:00,470][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:51:00,470][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:51:00,470][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:00,470][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:51:00,471][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:51:00,471][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:00,471][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:04,003][PyLogger][INFO]: Rank[0]: val_accuracy: 0.25820
[2024-02-27 20:51:04,003][PyLogger][INFO]: Rank[1]: val_accuracy: 0.25820
2024-02-27 20:51:05,473 ignite.distributed.launcher.Parallel INFO: End of run
new_size=8 done.
2024-02-27 20:51:09,223 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:51:09,223 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:51:09,223 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146f4925a3e0>' in 2 processes
2024-02-27 20:51:16,333 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:51:16,727 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14957ea0c8f0>}
[2024-02-27 20:51:16,838][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:16,838][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:16,838][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:16,843][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:51:16,843][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:51:16,843][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:16,843][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:51:16,844][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:51:16,844][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:16,844][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:20,531][PyLogger][INFO]: Rank[0]: val_accuracy: 0.47060
[2024-02-27 20:51:20,531][PyLogger][INFO]: Rank[1]: val_accuracy: 0.47060
2024-02-27 20:51:21,950 ignite.distributed.launcher.Parallel INFO: End of run
new_size=9 done.
2024-02-27 20:51:26,245 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:51:26,245 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:51:26,245 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154b5d98e3e0>' in 2 processes
2024-02-27 20:51:33,645 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:51:34,071 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x150d30dfc470>}
[2024-02-27 20:51:34,183][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:51:34,183][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:51:34,183][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:34,183][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:51:34,184][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:51:34,184][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:34,184][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:34,189][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:34,190][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:34,190][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:37,871][PyLogger][INFO]: Rank[0]: val_accuracy: 0.47820
[2024-02-27 20:51:37,871][PyLogger][INFO]: Rank[1]: val_accuracy: 0.47820
2024-02-27 20:51:39,277 ignite.distributed.launcher.Parallel INFO: End of run
new_size=10 done.
2024-02-27 20:51:43,020 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:51:43,020 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:51:43,020 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152b7550e3e0>' in 2 processes
2024-02-27 20:51:50,192 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:51:50,582 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ba4ea741a0>}
[2024-02-27 20:51:50,695][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:50,695][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:50,695][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:50,696][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:51:50,696][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:51:50,696][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:51:50,696][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:51:50,697][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:51:50,697][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:51:50,697][PyLogger][INFO]: World size: 2
[2024-02-27 20:51:54,336][PyLogger][INFO]: Rank[1]: val_accuracy: 0.48400
[2024-02-27 20:51:54,337][PyLogger][INFO]: Rank[0]: val_accuracy: 0.48400
2024-02-27 20:51:55,753 ignite.distributed.launcher.Parallel INFO: End of run
new_size=11 done.
2024-02-27 20:51:59,472 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:51:59,472 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:51:59,472 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152cca86a3e0>' in 2 processes
2024-02-27 20:52:06,528 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:52:06,937 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14adc416c680>}
[2024-02-27 20:52:07,053][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:52:07,053][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:52:07,053][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:07,053][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:52:07,054][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:52:07,054][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:07,054][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:07,055][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:07,055][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:07,055][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:10,787][PyLogger][INFO]: Rank[1]: val_accuracy: 0.48640
[2024-02-27 20:52:10,787][PyLogger][INFO]: Rank[0]: val_accuracy: 0.48640
2024-02-27 20:52:12,214 ignite.distributed.launcher.Parallel INFO: End of run
new_size=12 done.
2024-02-27 20:52:15,988 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:52:15,988 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:52:15,988 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e352b3a3e0>' in 2 processes
2024-02-27 20:52:23,026 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:52:23,439 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x147e1207ce00>}
[2024-02-27 20:52:23,554][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:23,554][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:23,554][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:23,559][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:52:23,559][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:52:23,559][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:23,559][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:52:23,560][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:52:23,560][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:23,560][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:27,320][PyLogger][INFO]: Rank[1]: val_accuracy: 0.52310
[2024-02-27 20:52:27,320][PyLogger][INFO]: Rank[0]: val_accuracy: 0.52310
2024-02-27 20:52:28,734 ignite.distributed.launcher.Parallel INFO: End of run
new_size=13 done.
2024-02-27 20:52:32,968 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:52:32,968 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:52:32,968 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14cf103963e0>' in 2 processes
2024-02-27 20:52:41,261 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:52:41,662 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x150b82a7f080>}
[2024-02-27 20:52:41,780][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:52:41,780][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:52:41,780][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:41,780][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:52:41,781][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:52:41,781][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:41,781][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:41,783][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:41,783][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:41,783][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:45,577][PyLogger][INFO]: Rank[1]: val_accuracy: 0.53570
[2024-02-27 20:52:45,577][PyLogger][INFO]: Rank[0]: val_accuracy: 0.53570
2024-02-27 20:52:47,048 ignite.distributed.launcher.Parallel INFO: End of run
new_size=14 done.
2024-02-27 20:52:50,775 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:52:50,775 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:52:50,775 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x147fea6e63e0>' in 2 processes
2024-02-27 20:52:58,742 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:52:59,155 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1489edeece90>}
[2024-02-27 20:52:59,271][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:59,271][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:59,271][PyLogger][INFO]: World size: 2
[2024-02-27 20:52:59,274][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:52:59,274][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:52:59,274][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:52:59,274][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:52:59,275][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:52:59,275][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:52:59,275][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:03,055][PyLogger][INFO]: Rank[1]: val_accuracy: 0.54490
[2024-02-27 20:53:03,055][PyLogger][INFO]: Rank[0]: val_accuracy: 0.54490
2024-02-27 20:53:04,547 ignite.distributed.launcher.Parallel INFO: End of run
new_size=15 done.
2024-02-27 20:53:08,572 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:53:08,572 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:53:08,572 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x155050c323e0>' in 2 processes
2024-02-27 20:53:15,677 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:53:16,072 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15222e224440>}
[2024-02-27 20:53:16,186][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:53:16,187][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:53:16,187][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:16,187][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:53:16,188][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:53:16,188][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:16,188][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:16,192][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:16,192][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:16,192][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:20,104][PyLogger][INFO]: Rank[1]: val_accuracy: 0.54970
[2024-02-27 20:53:20,104][PyLogger][INFO]: Rank[0]: val_accuracy: 0.54970
2024-02-27 20:53:21,537 ignite.distributed.launcher.Parallel INFO: End of run
new_size=16 done.
2024-02-27 20:53:25,268 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:53:25,268 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:53:25,268 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c6b674a3e0>' in 2 processes
2024-02-27 20:53:32,490 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:53:32,885 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1536d7e58b00>}
[2024-02-27 20:53:33,004][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:33,004][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:33,004][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:33,005][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:53:33,005][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:53:33,005][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:33,005][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:53:33,006][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:53:33,006][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:33,006][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:37,140][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61400
[2024-02-27 20:53:37,140][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61400
2024-02-27 20:53:38,609 ignite.distributed.launcher.Parallel INFO: End of run
new_size=17 done.
2024-02-27 20:53:42,920 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:53:42,920 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:53:42,920 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1529a099a3e0>' in 2 processes
2024-02-27 20:53:50,196 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:53:50,601 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14bd8b6b8080>}
[2024-02-27 20:53:50,715][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:50,715][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:50,715][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:50,718][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:53:50,718][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:53:50,718][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:53:50,718][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:53:50,719][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:53:50,719][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:53:50,719][PyLogger][INFO]: World size: 2
[2024-02-27 20:53:54,792][PyLogger][INFO]: Rank[0]: val_accuracy: 0.62290
[2024-02-27 20:53:54,792][PyLogger][INFO]: Rank[1]: val_accuracy: 0.62290
2024-02-27 20:53:56,237 ignite.distributed.launcher.Parallel INFO: End of run
new_size=18 done.
2024-02-27 20:54:00,086 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:54:00,086 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:54:00,086 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x148df511e3e0>' in 2 processes
2024-02-27 20:54:07,794 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:54:08,193 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f696d20c80>}
[2024-02-27 20:54:08,306][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:08,306][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:08,306][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:08,310][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:54:08,310][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:54:08,310][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:08,310][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:54:08,311][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:54:08,311][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:08,311][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:12,569][PyLogger][INFO]: Rank[1]: val_accuracy: 0.63610
[2024-02-27 20:54:12,569][PyLogger][INFO]: Rank[0]: val_accuracy: 0.63610
2024-02-27 20:54:14,042 ignite.distributed.launcher.Parallel INFO: End of run
new_size=19 done.
2024-02-27 20:54:17,860 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:54:17,861 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:54:17,861 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146d527ae3e0>' in 2 processes
2024-02-27 20:54:26,068 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:54:26,487 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149d5d2170b0>}
[2024-02-27 20:54:26,602][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:54:26,602][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:54:26,602][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:26,602][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:54:26,603][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:54:26,603][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:26,603][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:26,607][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:26,607][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:26,607][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:30,695][PyLogger][INFO]: Rank[0]: val_accuracy: 0.64370
[2024-02-27 20:54:30,695][PyLogger][INFO]: Rank[1]: val_accuracy: 0.64370
2024-02-27 20:54:32,171 ignite.distributed.launcher.Parallel INFO: End of run
new_size=20 done.
2024-02-27 20:54:36,000 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:54:36,000 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:54:36,001 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1517840b63e0>' in 2 processes
2024-02-27 20:54:44,272 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:54:44,664 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14fc23688770>}
[2024-02-27 20:54:44,781][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:44,781][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:44,781][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:44,784][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:54:44,784][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:54:44,784][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:54:44,784][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:54:44,785][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:54:44,785][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:54:44,785][PyLogger][INFO]: World size: 2
[2024-02-27 20:54:49,093][PyLogger][INFO]: Rank[0]: val_accuracy: 0.65820
[2024-02-27 20:54:49,093][PyLogger][INFO]: Rank[1]: val_accuracy: 0.65820
2024-02-27 20:54:50,619 ignite.distributed.launcher.Parallel INFO: End of run
new_size=21 done.
2024-02-27 20:54:54,888 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:54:54,888 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:54:54,888 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1493f21263e0>' in 2 processes
2024-02-27 20:55:02,218 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:55:02,621 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d4dcbc0b00>}
[2024-02-27 20:55:02,734][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:02,734][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:02,734][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:02,740][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:55:02,740][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:55:02,740][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:02,740][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:55:02,741][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:55:02,741][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:02,741][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:07,098][PyLogger][INFO]: Rank[0]: val_accuracy: 0.66070
[2024-02-27 20:55:07,098][PyLogger][INFO]: Rank[1]: val_accuracy: 0.66070
2024-02-27 20:55:08,576 ignite.distributed.launcher.Parallel INFO: End of run
new_size=22 done.
2024-02-27 20:55:12,405 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:55:12,405 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:55:12,405 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15360f7c23e0>' in 2 processes
2024-02-27 20:55:19,921 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:55:20,315 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14782323c9b0>}
[2024-02-27 20:55:20,433][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:55:20,433][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:55:20,433][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:20,434][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:55:20,434][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:55:20,435][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:20,435][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:20,437][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:20,437][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:20,437][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:24,849][PyLogger][INFO]: Rank[1]: val_accuracy: 0.67530
[2024-02-27 20:55:24,849][PyLogger][INFO]: Rank[0]: val_accuracy: 0.67530
2024-02-27 20:55:26,305 ignite.distributed.launcher.Parallel INFO: End of run
new_size=23 done.
2024-02-27 20:55:30,104 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:55:30,104 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:55:30,104 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15144fc4a3e0>' in 2 processes
2024-02-27 20:55:38,408 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:55:38,805 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1509c137f680>}
[2024-02-27 20:55:38,923][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:55:38,923][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:55:38,923][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:38,923][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:55:38,924][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:55:38,924][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:38,924][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:38,924][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:38,924][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:38,924][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:43,293][PyLogger][INFO]: Rank[0]: val_accuracy: 0.67940
[2024-02-27 20:55:43,294][PyLogger][INFO]: Rank[1]: val_accuracy: 0.67940
2024-02-27 20:55:44,811 ignite.distributed.launcher.Parallel INFO: End of run
new_size=24 done.
2024-02-27 20:55:48,738 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:55:48,738 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:55:48,738 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1493601c63e0>' in 2 processes
2024-02-27 20:55:57,127 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:55:57,524 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14c91eca5c40>}
[2024-02-27 20:55:57,642][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:57,642][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:57,642][PyLogger][INFO]: World size: 2
[2024-02-27 20:55:57,643][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:55:57,643][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:55:57,643][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:55:57,644][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:55:57,644][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:55:57,644][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:55:57,644][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:02,243][PyLogger][INFO]: Rank[0]: val_accuracy: 0.67660
[2024-02-27 20:56:02,243][PyLogger][INFO]: Rank[1]: val_accuracy: 0.67660
2024-02-27 20:56:03,365 ignite.distributed.launcher.Parallel INFO: End of run
new_size=25 done.
2024-02-27 20:56:07,657 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:56:07,658 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:56:07,658 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x147e957f23e0>' in 2 processes
2024-02-27 20:56:15,929 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:56:16,348 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d93b9d0950>}
[2024-02-27 20:56:16,463][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:56:16,463][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:56:16,463][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:16,463][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:56:16,464][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:16,464][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:16,464][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:16,464][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:56:16,465][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:16,465][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:21,102][PyLogger][INFO]: Rank[0]: val_accuracy: 0.67610
[2024-02-27 20:56:21,102][PyLogger][INFO]: Rank[1]: val_accuracy: 0.67610
2024-02-27 20:56:22,219 ignite.distributed.launcher.Parallel INFO: End of run
new_size=26 done.
2024-02-27 20:56:25,998 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:56:25,998 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:56:25,998 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14a49d7263e0>' in 2 processes
2024-02-27 20:56:34,183 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:56:34,574 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145683b40cb0>}
[2024-02-27 20:56:34,693][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:56:34,693][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:56:34,693][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:34,693][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:56:34,694][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:34,694][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:34,694][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:34,694][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:56:34,694][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:34,694][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:39,428][PyLogger][INFO]: Rank[1]: val_accuracy: 0.70410
[2024-02-27 20:56:39,428][PyLogger][INFO]: Rank[0]: val_accuracy: 0.70410
2024-02-27 20:56:40,962 ignite.distributed.launcher.Parallel INFO: End of run
new_size=27 done.
2024-02-27 20:56:44,763 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:56:44,764 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:56:44,764 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x145e12e423e0>' in 2 processes
2024-02-27 20:56:51,940 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:56:52,333 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154a2e608260>}
[2024-02-27 20:56:52,450][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:56:52,450][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:56:52,450][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:52,450][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:56:52,451][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:56:52,451][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:52,451][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:52,451][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:56:52,451][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:56:52,451][PyLogger][INFO]: World size: 2
[2024-02-27 20:56:57,192][PyLogger][INFO]: Rank[1]: val_accuracy: 0.70770
[2024-02-27 20:56:57,192][PyLogger][INFO]: Rank[0]: val_accuracy: 0.70770
2024-02-27 20:56:58,681 ignite.distributed.launcher.Parallel INFO: End of run
new_size=28 done.
2024-02-27 20:57:02,431 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:57:02,431 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:57:02,431 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14f61fefa3e0>' in 2 processes
2024-02-27 20:57:10,808 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:57:11,202 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x146632767740>}
[2024-02-27 20:57:11,321][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:11,321][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:11,321][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:11,323][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:57:11,323][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:57:11,323][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:11,323][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:57:11,324][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:57:11,324][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:11,324][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:16,258][PyLogger][INFO]: Rank[0]: val_accuracy: 0.68900
[2024-02-27 20:57:16,259][PyLogger][INFO]: Rank[1]: val_accuracy: 0.68900
2024-02-27 20:57:17,789 ignite.distributed.launcher.Parallel INFO: End of run
new_size=29 done.
2024-02-27 20:57:21,971 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:57:21,971 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:57:21,971 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1495921063e0>' in 2 processes
2024-02-27 20:57:30,198 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:57:30,598 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14931dd901a0>}
[2024-02-27 20:57:30,717][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:30,717][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:30,717][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:30,718][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:57:30,718][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:57:30,718][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:30,718][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:57:30,719][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:57:30,719][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:30,719][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:35,691][PyLogger][INFO]: Rank[0]: val_accuracy: 0.70010
[2024-02-27 20:57:35,691][PyLogger][INFO]: Rank[1]: val_accuracy: 0.70010
2024-02-27 20:57:37,219 ignite.distributed.launcher.Parallel INFO: End of run
new_size=30 done.
2024-02-27 20:57:41,080 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:57:41,080 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:57:41,080 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152e792223e0>' in 2 processes
2024-02-27 20:57:49,270 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:57:49,681 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151c65a64e00>}
[2024-02-27 20:57:49,797][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:49,798][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:49,798][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:49,800][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:57:49,800][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:57:49,800][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:57:49,800][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:57:49,801][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:57:49,801][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:57:49,801][PyLogger][INFO]: World size: 2
[2024-02-27 20:57:54,958][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72380
[2024-02-27 20:57:54,958][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72380
2024-02-27 20:57:56,525 ignite.distributed.launcher.Parallel INFO: End of run
new_size=31 done.
2024-02-27 20:58:00,310 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:58:00,310 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:58:00,310 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1540cbf663e0>' in 2 processes
2024-02-27 20:58:07,357 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:58:07,753 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14595b67cce0>}
[2024-02-27 20:58:07,868][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:07,869][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:07,869][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:07,872][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:58:07,872][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:58:07,872][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:07,872][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:58:07,873][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:58:07,873][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:07,873][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:13,196][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72640
[2024-02-27 20:58:13,196][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72640
2024-02-27 20:58:14,717 ignite.distributed.launcher.Parallel INFO: End of run
new_size=32 done.
2024-02-27 20:58:18,532 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:58:18,532 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:58:18,532 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152e461863e0>' in 2 processes
2024-02-27 20:58:25,950 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:58:26,350 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x147b71a982c0>}
[2024-02-27 20:58:26,465][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:58:26,465][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:58:26,465][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:26,465][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:58:26,466][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:58:26,466][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:26,466][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:26,470][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:26,470][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:26,470][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:31,681][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72640
[2024-02-27 20:58:31,681][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72640
2024-02-27 20:58:33,205 ignite.distributed.launcher.Parallel INFO: End of run
new_size=33 done.
2024-02-27 20:58:36,991 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:58:36,991 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:58:36,991 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x148f17cda3e0>' in 2 processes
2024-02-27 20:58:44,214 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:58:44,634 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15195f550080>}
[2024-02-27 20:58:44,747][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:58:44,747][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:58:44,747][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:44,747][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:58:44,748][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:58:44,748][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:44,748][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:44,752][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:58:44,752][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:58:44,752][PyLogger][INFO]: World size: 2
[2024-02-27 20:58:49,958][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72640
[2024-02-27 20:58:49,958][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72640
2024-02-27 20:58:51,469 ignite.distributed.launcher.Parallel INFO: End of run
new_size=34 done.
2024-02-27 20:58:55,317 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:58:55,317 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:58:55,317 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x154a4fe463e0>' in 2 processes
2024-02-27 20:59:02,623 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:59:03,152 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ae717ece00>}
[2024-02-27 20:59:03,277][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:59:03,277][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:59:03,277][PyLogger][INFO]: World size: 2
[2024-02-27 20:59:03,291][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:59:03,291][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:59:03,291][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:59:03,291][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:59:03,292][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:59:03,292][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:59:03,292][PyLogger][INFO]: World size: 2
[2024-02-27 20:59:08,508][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72640
[2024-02-27 20:59:08,508][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72640
2024-02-27 20:59:10,063 ignite.distributed.launcher.Parallel INFO: End of run
new_size=35 done.
2024-02-27 20:59:13,839 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-27 20:59:13,839 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-27 20:59:13,839 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d61d3ca3e0>' in 2 processes
2024-02-27 20:59:20,983 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-27 20:59:21,385 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x151640a7ef00>}
[2024-02-27 20:59:21,502][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-27 20:59:21,502][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-27 20:59:21,502][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-27 20:59:21,502][PyLogger][INFO]: CUDA version: 12.1
[2024-02-27 20:59:21,503][PyLogger][INFO]: CUDNN version: 8902
[2024-02-27 20:59:21,503][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:59:21,503][PyLogger][INFO]: World size: 2
[2024-02-27 20:59:21,504][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-27 20:59:21,504][PyLogger][INFO]: Distributed backend: nccl
[2024-02-27 20:59:21,504][PyLogger][INFO]: World size: 2
[2024-02-27 20:59:26,801][PyLogger][INFO]: Rank[0]: val_accuracy: 0.72640
[2024-02-27 20:59:26,801][PyLogger][INFO]: Rank[1]: val_accuracy: 0.72640
2024-02-27 20:59:28,315 ignite.distributed.launcher.Parallel INFO: End of run
new_size=36 done.
