SLURM_JOB_ID: 55705870
SLURM_JOB_USER: vsc33647
SLURM_JOB_ACCOUNT: lp_inspiremed
SLURM_JOB_NAME: interpolate_cifar10_com
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r22g39
SLURM_JOB_CPUS_PER_NODE: 18
SLURM_JOB_GPUS: 2,3
Date: Mon Feb 26 17:35:56 CET 2024
Walltime: 00-12:00:00
========================================================================
2024-02-26 17:36:01,245 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 17:36:01,248 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 17:36:01,248 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x1476e61193a0>' in 2 processes
2024-02-26 17:36:09,248 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 17:36:10,093 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 256, 'num_workers': 0, 'pin_memory': True, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x145452886120>}
2024-02-26 17:36:10,447 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1454528e9910>}
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[2024-02-26 17:36:10,454][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 17:36:10,454][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 17:36:10,454][PyLogger][INFO]: World size: 2
[2024-02-26 17:36:10,457][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 17:36:10,457][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 17:36:10,458][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 17:36:10,458][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 17:36:10,459][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 17:36:10,459][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 17:36:10,459][PyLogger][INFO]: World size: 2
[2024-02-26 17:36:32,896][PyLogger][INFO]: Rank[1]: Epoch[1/500], iter[50] -  - loss: 4.00187
[2024-02-26 17:36:32,896][PyLogger][INFO]: Rank[0]: Epoch[1/500], iter[50] -  - loss: 2.37760
[2024-02-26 17:36:53,843][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[100] -  - loss: 2.71455
[2024-02-26 17:36:53,843][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[100] -  - loss: 2.49956
[2024-02-26 17:37:14,638][PyLogger][INFO]: Rank[1]: Epoch[2/500], iter[150] -  - loss: 2.44591
[2024-02-26 17:37:14,638][PyLogger][INFO]: Rank[0]: Epoch[2/500], iter[150] -  - loss: 2.31910
[2024-02-26 17:37:35,648][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[200] -  - loss: 2.23821
[2024-02-26 17:37:35,648][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[200] -  - loss: 2.25693
[2024-02-26 17:37:57,460][PyLogger][INFO]: Rank[1]: Epoch[3/500], iter[250] -  - loss: 2.35255
[2024-02-26 17:37:57,460][PyLogger][INFO]: Rank[0]: Epoch[3/500], iter[250] -  - loss: 2.28291
[2024-02-26 17:38:17,613][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[300] -  - loss: 2.30777
[2024-02-26 17:38:17,613][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[300] -  - loss: 2.17680
[2024-02-26 17:38:38,434][PyLogger][INFO]: Rank[1]: Epoch[4/500], iter[350] -  - loss: 2.20888
[2024-02-26 17:38:38,434][PyLogger][INFO]: Rank[0]: Epoch[4/500], iter[350] -  - loss: 2.07638
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/data/leuven/336/vsc33647/miniconda3/envs/deepenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-02-26 17:38:58,282][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[400] -  - loss: 2.10669
[2024-02-26 17:38:58,282][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[400] -  - loss: 2.04752
[2024-02-26 17:39:18,964][PyLogger][INFO]: Rank[1]: Epoch[5/500], iter[450] -  - loss: 2.28673
[2024-02-26 17:39:18,965][PyLogger][INFO]: Rank[0]: Epoch[5/500], iter[450] -  - loss: 2.18011
[2024-02-26 17:40:00,184][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[500] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.13691
[2024-02-26 17:40:00,184][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[500] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.02707
[2024-02-26 17:40:21,513][PyLogger][INFO]: Rank[1]: Epoch[6/500], iter[550] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.03713
[2024-02-26 17:40:21,513][PyLogger][INFO]: Rank[0]: Epoch[6/500], iter[550] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.03693
[2024-02-26 17:40:42,589][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[600] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.01055
[2024-02-26 17:40:42,589][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[600] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.05122
[2024-02-26 17:41:04,138][PyLogger][INFO]: Rank[1]: Epoch[7/500], iter[650] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.11436
[2024-02-26 17:41:04,138][PyLogger][INFO]: Rank[0]: Epoch[7/500], iter[650] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.98161
[2024-02-26 17:41:25,027][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[700] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.12262
[2024-02-26 17:41:25,027][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[700] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.94586
[2024-02-26 17:41:45,970][PyLogger][INFO]: Rank[1]: Epoch[8/500], iter[750] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.93787
[2024-02-26 17:41:45,971][PyLogger][INFO]: Rank[0]: Epoch[8/500], iter[750] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.84124
[2024-02-26 17:42:07,146][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[800] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.88412
[2024-02-26 17:42:07,146][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[800] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.88729
[2024-02-26 17:42:27,481][PyLogger][INFO]: Rank[0]: Epoch[9/500], iter[850] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 2.24542
[2024-02-26 17:42:27,481][PyLogger][INFO]: Rank[1]: Epoch[9/500], iter[850] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.81177
[2024-02-26 17:42:48,878][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[900] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.89419
[2024-02-26 17:42:48,878][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[900] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.89349
[2024-02-26 17:43:09,087][PyLogger][INFO]: Rank[1]: Epoch[10/500], iter[950] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.88291
[2024-02-26 17:43:09,087][PyLogger][INFO]: Rank[0]: Epoch[10/500], iter[950] - train_accuracy: 0.17214 - val_accuracy: 0.16310 - train_loss: 2.39454 - val_loss: 2.36173 - loss: 1.87385
[2024-02-26 17:43:52,393][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1000] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.98305
[2024-02-26 17:43:52,394][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1000] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.73804
[2024-02-26 17:44:12,511][PyLogger][INFO]: Rank[0]: Epoch[11/500], iter[1050] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.93809
[2024-02-26 17:44:12,511][PyLogger][INFO]: Rank[1]: Epoch[11/500], iter[1050] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.67205
[2024-02-26 17:44:33,299][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1100] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.69463
[2024-02-26 17:44:33,300][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1100] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.76221
[2024-02-26 17:44:53,753][PyLogger][INFO]: Rank[1]: Epoch[12/500], iter[1150] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.70009
[2024-02-26 17:44:53,753][PyLogger][INFO]: Rank[0]: Epoch[12/500], iter[1150] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.68516
[2024-02-26 17:45:14,672][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1200] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.81289
[2024-02-26 17:45:14,672][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1200] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.73765
[2024-02-26 17:45:35,190][PyLogger][INFO]: Rank[1]: Epoch[13/500], iter[1250] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.78082
[2024-02-26 17:45:35,190][PyLogger][INFO]: Rank[0]: Epoch[13/500], iter[1250] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.76737
[2024-02-26 17:45:55,171][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1300] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.66874
[2024-02-26 17:45:55,171][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1300] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.64353
[2024-02-26 17:46:15,824][PyLogger][INFO]: Rank[1]: Epoch[14/500], iter[1350] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.61287
[2024-02-26 17:46:15,824][PyLogger][INFO]: Rank[0]: Epoch[14/500], iter[1350] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.64003
[2024-02-26 17:46:36,940][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1400] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.69934
[2024-02-26 17:46:36,940][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1400] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.74461
[2024-02-26 17:46:57,915][PyLogger][INFO]: Rank[1]: Epoch[15/500], iter[1450] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.80673
[2024-02-26 17:46:57,915][PyLogger][INFO]: Rank[0]: Epoch[15/500], iter[1450] - train_accuracy: 0.24656 - val_accuracy: 0.26060 - train_loss: 2.19851 - val_loss: 2.16286 - loss: 1.60119
[2024-02-26 17:47:40,416][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1500] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.55608
[2024-02-26 17:47:40,416][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1500] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.57466
[2024-02-26 17:48:01,689][PyLogger][INFO]: Rank[0]: Epoch[16/500], iter[1550] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 2.17890
[2024-02-26 17:48:01,689][PyLogger][INFO]: Rank[1]: Epoch[16/500], iter[1550] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.67548
[2024-02-26 17:48:23,922][PyLogger][INFO]: Rank[1]: Epoch[17/500], iter[1600] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.58639
[2024-02-26 17:48:23,923][PyLogger][INFO]: Rank[0]: Epoch[17/500], iter[1600] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.60352
[2024-02-26 17:48:45,320][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1650] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.52961
[2024-02-26 17:48:45,320][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1650] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.64503
[2024-02-26 17:49:05,272][PyLogger][INFO]: Rank[0]: Epoch[18/500], iter[1700] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.65684
[2024-02-26 17:49:05,272][PyLogger][INFO]: Rank[1]: Epoch[18/500], iter[1700] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.70721
[2024-02-26 17:49:26,155][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1750] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.79077
[2024-02-26 17:49:26,155][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1750] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.46766
[2024-02-26 17:49:46,453][PyLogger][INFO]: Rank[1]: Epoch[19/500], iter[1800] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 2.13695
[2024-02-26 17:49:46,453][PyLogger][INFO]: Rank[0]: Epoch[19/500], iter[1800] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.72040
[2024-02-26 17:50:07,656][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1850] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.54904
[2024-02-26 17:50:07,656][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1850] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.55433
[2024-02-26 17:50:27,996][PyLogger][INFO]: Rank[1]: Epoch[20/500], iter[1900] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.50538
[2024-02-26 17:50:27,996][PyLogger][INFO]: Rank[0]: Epoch[20/500], iter[1900] - train_accuracy: 0.30680 - val_accuracy: 0.31900 - train_loss: 2.05561 - val_loss: 2.08367 - loss: 1.41792
[2024-02-26 17:51:10,048][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[1950] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.42941
[2024-02-26 17:51:10,048][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[1950] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.43122
[2024-02-26 17:51:30,474][PyLogger][INFO]: Rank[0]: Epoch[21/500], iter[2000] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.39880
[2024-02-26 17:51:30,474][PyLogger][INFO]: Rank[1]: Epoch[21/500], iter[2000] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.46244
[2024-02-26 17:51:51,432][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2050] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.93951
[2024-02-26 17:51:51,432][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2050] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.47283
[2024-02-26 17:52:13,193][PyLogger][INFO]: Rank[0]: Epoch[22/500], iter[2100] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.35312
[2024-02-26 17:52:13,193][PyLogger][INFO]: Rank[1]: Epoch[22/500], iter[2100] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.44985
[2024-02-26 17:52:34,855][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2150] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.36290
[2024-02-26 17:52:34,855][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2150] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.43066
[2024-02-26 17:52:56,622][PyLogger][INFO]: Rank[0]: Epoch[23/500], iter[2200] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.78930
[2024-02-26 17:52:56,622][PyLogger][INFO]: Rank[1]: Epoch[23/500], iter[2200] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.36742
[2024-02-26 17:53:18,280][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2250] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.86848
[2024-02-26 17:53:18,281][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2250] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.32010
[2024-02-26 17:53:38,243][PyLogger][INFO]: Rank[1]: Epoch[24/500], iter[2300] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.64939
[2024-02-26 17:53:38,244][PyLogger][INFO]: Rank[0]: Epoch[24/500], iter[2300] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.34602
[2024-02-26 17:53:59,095][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2350] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.48928
[2024-02-26 17:53:59,095][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2350] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.31231
[2024-02-26 17:54:19,270][PyLogger][INFO]: Rank[0]: Epoch[25/500], iter[2400] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.34225
[2024-02-26 17:54:19,270][PyLogger][INFO]: Rank[1]: Epoch[25/500], iter[2400] - train_accuracy: 0.37748 - val_accuracy: 0.38610 - train_loss: 1.87977 - val_loss: 1.84048 - loss: 1.58348
[2024-02-26 17:55:01,178][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2450] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.33993
[2024-02-26 17:55:01,178][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2450] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.26184
[2024-02-26 17:55:22,173][PyLogger][INFO]: Rank[1]: Epoch[26/500], iter[2500] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.29516
[2024-02-26 17:55:22,173][PyLogger][INFO]: Rank[0]: Epoch[26/500], iter[2500] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.26438
[2024-02-26 17:55:42,988][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2550] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.60273
[2024-02-26 17:55:42,988][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2550] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.88143
[2024-02-26 17:56:04,031][PyLogger][INFO]: Rank[1]: Epoch[27/500], iter[2600] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 2.04515
[2024-02-26 17:56:04,031][PyLogger][INFO]: Rank[0]: Epoch[27/500], iter[2600] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.20837
[2024-02-26 17:56:24,797][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2650] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.24650
[2024-02-26 17:56:24,797][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2650] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.38834
[2024-02-26 17:56:45,983][PyLogger][INFO]: Rank[1]: Epoch[28/500], iter[2700] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.51226
[2024-02-26 17:56:45,983][PyLogger][INFO]: Rank[0]: Epoch[28/500], iter[2700] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.18890
[2024-02-26 17:57:06,226][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2750] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 2.04301
[2024-02-26 17:57:06,226][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2750] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.30545
[2024-02-26 17:57:27,045][PyLogger][INFO]: Rank[1]: Epoch[29/500], iter[2800] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.45761
[2024-02-26 17:57:27,045][PyLogger][INFO]: Rank[0]: Epoch[29/500], iter[2800] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.28686
[2024-02-26 17:57:48,243][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2850] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.98505
[2024-02-26 17:57:48,243][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2850] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.35496
[2024-02-26 17:58:08,668][PyLogger][INFO]: Rank[1]: Epoch[30/500], iter[2900] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.35004
[2024-02-26 17:58:08,669][PyLogger][INFO]: Rank[0]: Epoch[30/500], iter[2900] - train_accuracy: 0.46100 - val_accuracy: 0.46620 - train_loss: 1.69113 - val_loss: 1.67802 - loss: 1.18855
[2024-02-26 17:58:51,475][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[2950] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.24523
[2024-02-26 17:58:51,475][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[2950] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.38920
[2024-02-26 17:59:11,455][PyLogger][INFO]: Rank[0]: Epoch[31/500], iter[3000] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.22494
[2024-02-26 17:59:11,455][PyLogger][INFO]: Rank[1]: Epoch[31/500], iter[3000] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.59405
[2024-02-26 17:59:33,406][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3050] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.04987
[2024-02-26 17:59:33,406][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3050] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.33354
[2024-02-26 17:59:53,433][PyLogger][INFO]: Rank[0]: Epoch[32/500], iter[3100] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.59198
[2024-02-26 17:59:53,433][PyLogger][INFO]: Rank[1]: Epoch[32/500], iter[3100] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.27823
[2024-02-26 18:00:14,367][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3150] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.13195
[2024-02-26 18:00:14,367][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3150] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.22600
[2024-02-26 18:00:34,915][PyLogger][INFO]: Rank[0]: Epoch[33/500], iter[3200] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.94907
[2024-02-26 18:00:34,915][PyLogger][INFO]: Rank[1]: Epoch[33/500], iter[3200] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.16385
[2024-02-26 18:00:56,676][PyLogger][INFO]: Rank[1]: Epoch[34/500], iter[3250] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.10774
[2024-02-26 18:00:56,676][PyLogger][INFO]: Rank[0]: Epoch[34/500], iter[3250] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.08569
[2024-02-26 18:01:17,699][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3300] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.22784
[2024-02-26 18:01:17,699][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3300] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.06588
[2024-02-26 18:01:38,319][PyLogger][INFO]: Rank[1]: Epoch[35/500], iter[3350] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.05771
[2024-02-26 18:01:38,319][PyLogger][INFO]: Rank[0]: Epoch[35/500], iter[3350] - train_accuracy: 0.46448 - val_accuracy: 0.46010 - train_loss: 1.70126 - val_loss: 1.74016 - loss: 1.15634
[2024-02-26 18:02:20,059][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3400] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.16269
[2024-02-26 18:02:20,060][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3400] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.07121
[2024-02-26 18:02:41,089][PyLogger][INFO]: Rank[0]: Epoch[36/500], iter[3450] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.89457
[2024-02-26 18:02:41,089][PyLogger][INFO]: Rank[1]: Epoch[36/500], iter[3450] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.46751
[2024-02-26 18:03:02,826][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3500] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.14889
[2024-02-26 18:03:02,826][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3500] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.22171
[2024-02-26 18:03:22,941][PyLogger][INFO]: Rank[0]: Epoch[37/500], iter[3550] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.69587
[2024-02-26 18:03:22,941][PyLogger][INFO]: Rank[1]: Epoch[37/500], iter[3550] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.27779
[2024-02-26 18:03:43,608][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3600] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.04032
[2024-02-26 18:03:43,608][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3600] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.37084
[2024-02-26 18:04:03,753][PyLogger][INFO]: Rank[0]: Epoch[38/500], iter[3650] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.06267
[2024-02-26 18:04:03,753][PyLogger][INFO]: Rank[1]: Epoch[38/500], iter[3650] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 0.97682
[2024-02-26 18:04:24,977][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3700] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.81419
[2024-02-26 18:04:24,977][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3700] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.00143
[2024-02-26 18:04:45,575][PyLogger][INFO]: Rank[0]: Epoch[39/500], iter[3750] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.08543
[2024-02-26 18:04:45,575][PyLogger][INFO]: Rank[1]: Epoch[39/500], iter[3750] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.96311
[2024-02-26 18:05:06,587][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3800] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.09180
[2024-02-26 18:05:06,587][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3800] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.19071
[2024-02-26 18:05:26,543][PyLogger][INFO]: Rank[0]: Epoch[40/500], iter[3850] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 1.11926
[2024-02-26 18:05:26,543][PyLogger][INFO]: Rank[1]: Epoch[40/500], iter[3850] - train_accuracy: 0.48335 - val_accuracy: 0.54670 - train_loss: 1.79990 - val_loss: 1.64092 - loss: 2.03039
[2024-02-26 18:06:08,016][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3900] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.18247
[2024-02-26 18:06:08,016][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3900] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.94573
[2024-02-26 18:06:28,128][PyLogger][INFO]: Rank[1]: Epoch[41/500], iter[3950] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.74610
[2024-02-26 18:06:28,128][PyLogger][INFO]: Rank[0]: Epoch[41/500], iter[3950] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.25921
[2024-02-26 18:06:49,034][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4000] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.86755
[2024-02-26 18:06:49,034][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4000] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.00045
[2024-02-26 18:07:10,521][PyLogger][INFO]: Rank[1]: Epoch[42/500], iter[4050] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.27470
[2024-02-26 18:07:10,522][PyLogger][INFO]: Rank[0]: Epoch[42/500], iter[4050] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.96745
[2024-02-26 18:07:31,110][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4100] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.24110
[2024-02-26 18:07:31,110][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4100] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.08703
[2024-02-26 18:07:51,259][PyLogger][INFO]: Rank[1]: Epoch[43/500], iter[4150] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.98672
[2024-02-26 18:07:51,259][PyLogger][INFO]: Rank[0]: Epoch[43/500], iter[4150] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.96813
[2024-02-26 18:08:12,545][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4200] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.96313
[2024-02-26 18:08:12,545][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4200] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.94390
[2024-02-26 18:08:33,856][PyLogger][INFO]: Rank[1]: Epoch[44/500], iter[4250] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.97789
[2024-02-26 18:08:33,856][PyLogger][INFO]: Rank[0]: Epoch[44/500], iter[4250] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.84293
[2024-02-26 18:08:54,828][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4300] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.89850
[2024-02-26 18:08:54,828][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4300] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 1.03230
[2024-02-26 18:09:14,864][PyLogger][INFO]: Rank[1]: Epoch[45/500], iter[4350] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.86529
[2024-02-26 18:09:14,864][PyLogger][INFO]: Rank[0]: Epoch[45/500], iter[4350] - train_accuracy: 0.58880 - val_accuracy: 0.55280 - train_loss: 1.46792 - val_loss: 1.52253 - loss: 0.90869
[2024-02-26 18:09:56,439][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4400] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.93843
[2024-02-26 18:09:56,439][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4400] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.86112
[2024-02-26 18:10:16,971][PyLogger][INFO]: Rank[0]: Epoch[46/500], iter[4450] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.67173
[2024-02-26 18:10:16,971][PyLogger][INFO]: Rank[1]: Epoch[46/500], iter[4450] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.93124
[2024-02-26 18:10:37,717][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4500] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.53091
[2024-02-26 18:10:37,717][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4500] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.97249
[2024-02-26 18:10:58,432][PyLogger][INFO]: Rank[0]: Epoch[47/500], iter[4550] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.02207
[2024-02-26 18:10:58,432][PyLogger][INFO]: Rank[1]: Epoch[47/500], iter[4550] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.02715
[2024-02-26 18:11:19,228][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4600] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.50744
[2024-02-26 18:11:19,228][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4600] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.96679
[2024-02-26 18:11:40,392][PyLogger][INFO]: Rank[0]: Epoch[48/500], iter[4650] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.40415
[2024-02-26 18:11:40,392][PyLogger][INFO]: Rank[1]: Epoch[48/500], iter[4650] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.07189
[2024-02-26 18:12:01,934][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4700] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.86702
[2024-02-26 18:12:01,934][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4700] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.98770
[2024-02-26 18:12:23,046][PyLogger][INFO]: Rank[1]: Epoch[49/500], iter[4750] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.85708
[2024-02-26 18:12:23,046][PyLogger][INFO]: Rank[0]: Epoch[49/500], iter[4750] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.90370
[2024-02-26 18:12:44,073][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4800] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.71948
[2024-02-26 18:12:44,073][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4800] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 1.35449
[2024-02-26 18:13:04,952][PyLogger][INFO]: Rank[1]: Epoch[50/500], iter[4850] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.90654
[2024-02-26 18:13:04,952][PyLogger][INFO]: Rank[0]: Epoch[50/500], iter[4850] - train_accuracy: 0.57867 - val_accuracy: 0.59330 - train_loss: 1.46095 - val_loss: 1.44192 - loss: 0.81762
[2024-02-26 18:13:46,578][PyLogger][INFO]: Rank[1]: Epoch[51/500], iter[4900] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.87936
[2024-02-26 18:13:46,578][PyLogger][INFO]: Rank[0]: Epoch[51/500], iter[4900] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.81761
[2024-02-26 18:14:07,454][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[4950] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.88757
[2024-02-26 18:14:07,454][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[4950] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.90130
[2024-02-26 18:14:27,994][PyLogger][INFO]: Rank[1]: Epoch[52/500], iter[5000] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.89895
[2024-02-26 18:14:27,994][PyLogger][INFO]: Rank[0]: Epoch[52/500], iter[5000] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.88297
[2024-02-26 18:14:49,978][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5050] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.83653
[2024-02-26 18:14:49,978][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5050] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 1.08263
[2024-02-26 18:15:10,646][PyLogger][INFO]: Rank[0]: Epoch[53/500], iter[5100] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.88968
[2024-02-26 18:15:10,646][PyLogger][INFO]: Rank[1]: Epoch[53/500], iter[5100] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.90658
[2024-02-26 18:15:31,676][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5150] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.85081
[2024-02-26 18:15:31,676][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5150] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 1.34735
[2024-02-26 18:15:52,224][PyLogger][INFO]: Rank[0]: Epoch[54/500], iter[5200] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 1.29204
[2024-02-26 18:15:52,224][PyLogger][INFO]: Rank[1]: Epoch[54/500], iter[5200] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.96479
[2024-02-26 18:16:15,394][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5250] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.85035
[2024-02-26 18:16:15,394][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5250] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 0.94055
[2024-02-26 18:16:36,478][PyLogger][INFO]: Rank[0]: Epoch[55/500], iter[5300] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 2.03259
[2024-02-26 18:16:36,478][PyLogger][INFO]: Rank[1]: Epoch[55/500], iter[5300] - train_accuracy: 0.62351 - val_accuracy: 0.63720 - train_loss: 1.35765 - val_loss: 1.35905 - loss: 1.00074
[2024-02-26 18:17:21,235][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5350] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.91384
[2024-02-26 18:17:21,235][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5350] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.84343
[2024-02-26 18:17:40,917][PyLogger][INFO]: Rank[1]: Epoch[56/500], iter[5400] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.89453
[2024-02-26 18:17:40,917][PyLogger][INFO]: Rank[0]: Epoch[56/500], iter[5400] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.19593
[2024-02-26 18:18:02,278][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5450] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.91193
[2024-02-26 18:18:02,278][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5450] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.97265
[2024-02-26 18:18:23,902][PyLogger][INFO]: Rank[1]: Epoch[57/500], iter[5500] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.15737
[2024-02-26 18:18:23,902][PyLogger][INFO]: Rank[0]: Epoch[57/500], iter[5500] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.85899
[2024-02-26 18:18:45,252][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5550] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.85432
[2024-02-26 18:18:45,252][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5550] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.84139
[2024-02-26 18:19:06,051][PyLogger][INFO]: Rank[1]: Epoch[58/500], iter[5600] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.59593
[2024-02-26 18:19:06,051][PyLogger][INFO]: Rank[0]: Epoch[58/500], iter[5600] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.15216
[2024-02-26 18:19:26,780][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5650] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.14422
[2024-02-26 18:19:26,780][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5650] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.31642
[2024-02-26 18:19:46,666][PyLogger][INFO]: Rank[1]: Epoch[59/500], iter[5700] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.09094
[2024-02-26 18:19:46,666][PyLogger][INFO]: Rank[0]: Epoch[59/500], iter[5700] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.40804
[2024-02-26 18:20:09,101][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5750] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.88211
[2024-02-26 18:20:09,101][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5750] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 0.75455
[2024-02-26 18:20:30,180][PyLogger][INFO]: Rank[1]: Epoch[60/500], iter[5800] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.60785
[2024-02-26 18:20:30,180][PyLogger][INFO]: Rank[0]: Epoch[60/500], iter[5800] - train_accuracy: 0.63944 - val_accuracy: 0.60680 - train_loss: 1.36996 - val_loss: 1.42725 - loss: 1.44383
[2024-02-26 18:21:11,856][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5850] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.79313
[2024-02-26 18:21:11,856][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5850] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.77579
[2024-02-26 18:21:32,411][PyLogger][INFO]: Rank[0]: Epoch[61/500], iter[5900] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.89288
[2024-02-26 18:21:32,411][PyLogger][INFO]: Rank[1]: Epoch[61/500], iter[5900] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.97540
[2024-02-26 18:21:53,383][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[5950] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.88888
[2024-02-26 18:21:53,383][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[5950] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.03389
[2024-02-26 18:22:13,918][PyLogger][INFO]: Rank[0]: Epoch[62/500], iter[6000] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.72947
[2024-02-26 18:22:13,918][PyLogger][INFO]: Rank[1]: Epoch[62/500], iter[6000] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.28913
[2024-02-26 18:22:35,163][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6050] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.59658
[2024-02-26 18:22:35,163][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6050] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.47135
[2024-02-26 18:22:56,294][PyLogger][INFO]: Rank[0]: Epoch[63/500], iter[6100] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.80507
[2024-02-26 18:22:56,294][PyLogger][INFO]: Rank[1]: Epoch[63/500], iter[6100] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.57770
[2024-02-26 18:23:17,030][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6150] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 2.06198
[2024-02-26 18:23:17,030][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6150] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.85592
[2024-02-26 18:23:37,413][PyLogger][INFO]: Rank[0]: Epoch[64/500], iter[6200] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.80820
[2024-02-26 18:23:37,413][PyLogger][INFO]: Rank[1]: Epoch[64/500], iter[6200] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.63514
[2024-02-26 18:23:58,695][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6250] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 1.23524
[2024-02-26 18:23:58,695][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6250] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.98420
[2024-02-26 18:24:19,054][PyLogger][INFO]: Rank[0]: Epoch[65/500], iter[6300] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.85514
[2024-02-26 18:24:19,054][PyLogger][INFO]: Rank[1]: Epoch[65/500], iter[6300] - train_accuracy: 0.67713 - val_accuracy: 0.74130 - train_loss: 1.26762 - val_loss: 1.14902 - loss: 0.84513
[2024-02-26 18:24:59,404][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6350] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.89220
[2024-02-26 18:24:59,404][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6350] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.09200
[2024-02-26 18:25:20,403][PyLogger][INFO]: Rank[1]: Epoch[66/500], iter[6400] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.85547
[2024-02-26 18:25:20,403][PyLogger][INFO]: Rank[0]: Epoch[66/500], iter[6400] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.78401
[2024-02-26 18:25:41,159][PyLogger][INFO]: Rank[0]: Epoch[67/500], iter[6450] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.86049
[2024-02-26 18:25:41,159][PyLogger][INFO]: Rank[1]: Epoch[67/500], iter[6450] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.27043
[2024-02-26 18:26:02,210][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6500] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.78765
[2024-02-26 18:26:02,210][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6500] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.76527
[2024-02-26 18:26:23,200][PyLogger][INFO]: Rank[0]: Epoch[68/500], iter[6550] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.37401
[2024-02-26 18:26:23,200][PyLogger][INFO]: Rank[1]: Epoch[68/500], iter[6550] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.85918
[2024-02-26 18:26:44,280][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6600] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.82683
[2024-02-26 18:26:44,280][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6600] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.82780
[2024-02-26 18:27:04,257][PyLogger][INFO]: Rank[0]: Epoch[69/500], iter[6650] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.02178
[2024-02-26 18:27:04,257][PyLogger][INFO]: Rank[1]: Epoch[69/500], iter[6650] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.36537
[2024-02-26 18:27:25,102][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6700] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.85757
[2024-02-26 18:27:25,102][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6700] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.77053
[2024-02-26 18:27:46,339][PyLogger][INFO]: Rank[0]: Epoch[70/500], iter[6750] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 1.90333
[2024-02-26 18:27:46,340][PyLogger][INFO]: Rank[1]: Epoch[70/500], iter[6750] - train_accuracy: 0.65756 - val_accuracy: 0.69090 - train_loss: 1.37101 - val_loss: 1.33062 - loss: 0.86428
[2024-02-26 18:28:28,261][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6800] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.18563
[2024-02-26 18:28:28,261][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6800] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.80082
[2024-02-26 18:28:48,854][PyLogger][INFO]: Rank[1]: Epoch[71/500], iter[6850] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.75456
[2024-02-26 18:28:48,854][PyLogger][INFO]: Rank[0]: Epoch[71/500], iter[6850] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.12834
[2024-02-26 18:29:09,413][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6900] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.03552
[2024-02-26 18:29:09,413][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6900] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.79654
[2024-02-26 18:29:30,294][PyLogger][INFO]: Rank[1]: Epoch[72/500], iter[6950] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.76583
[2024-02-26 18:29:30,294][PyLogger][INFO]: Rank[0]: Epoch[72/500], iter[6950] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.98713
[2024-02-26 18:29:51,222][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7000] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.88648
[2024-02-26 18:29:51,222][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7000] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.77265
[2024-02-26 18:30:10,494][PyLogger][INFO]: Rank[1]: Epoch[73/500], iter[7050] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.77290
[2024-02-26 18:30:10,494][PyLogger][INFO]: Rank[0]: Epoch[73/500], iter[7050] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.76011
[2024-02-26 18:30:31,077][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7100] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.91375
[2024-02-26 18:30:31,077][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7100] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.78458
[2024-02-26 18:30:52,188][PyLogger][INFO]: Rank[1]: Epoch[74/500], iter[7150] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.57476
[2024-02-26 18:30:52,188][PyLogger][INFO]: Rank[0]: Epoch[74/500], iter[7150] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.15389
[2024-02-26 18:31:13,581][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7200] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 1.29933
[2024-02-26 18:31:13,581][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7200] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.85109
[2024-02-26 18:31:33,827][PyLogger][INFO]: Rank[1]: Epoch[75/500], iter[7250] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.74839
[2024-02-26 18:31:33,827][PyLogger][INFO]: Rank[0]: Epoch[75/500], iter[7250] - train_accuracy: 0.68017 - val_accuracy: 0.66450 - train_loss: 1.28354 - val_loss: 1.32525 - loss: 0.80447
[2024-02-26 18:32:15,438][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7300] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.78604
[2024-02-26 18:32:15,438][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7300] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.80797
[2024-02-26 18:32:36,237][PyLogger][INFO]: Rank[0]: Epoch[76/500], iter[7350] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 1.15964
[2024-02-26 18:32:36,237][PyLogger][INFO]: Rank[1]: Epoch[76/500], iter[7350] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.67996
[2024-02-26 18:32:57,323][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7400] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.75868
[2024-02-26 18:32:57,323][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7400] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.78356
[2024-02-26 18:33:17,455][PyLogger][INFO]: Rank[1]: Epoch[77/500], iter[7450] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 1.36117
[2024-02-26 18:33:17,455][PyLogger][INFO]: Rank[0]: Epoch[77/500], iter[7450] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.91014
[2024-02-26 18:33:38,090][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7500] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.79344
[2024-02-26 18:33:38,090][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7500] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 1.54249
[2024-02-26 18:33:58,322][PyLogger][INFO]: Rank[1]: Epoch[78/500], iter[7550] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.90243
[2024-02-26 18:33:58,322][PyLogger][INFO]: Rank[0]: Epoch[78/500], iter[7550] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.71891
[2024-02-26 18:34:19,870][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7600] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.78193
[2024-02-26 18:34:19,870][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7600] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.74929
[2024-02-26 18:34:40,890][PyLogger][INFO]: Rank[1]: Epoch[79/500], iter[7650] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.75360
[2024-02-26 18:34:40,890][PyLogger][INFO]: Rank[0]: Epoch[79/500], iter[7650] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.69434
[2024-02-26 18:35:02,123][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7700] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.76385
[2024-02-26 18:35:02,123][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7700] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 1.41912
[2024-02-26 18:35:23,238][PyLogger][INFO]: Rank[1]: Epoch[80/500], iter[7750] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 0.71393
[2024-02-26 18:35:23,238][PyLogger][INFO]: Rank[0]: Epoch[80/500], iter[7750] - train_accuracy: 0.59307 - val_accuracy: 0.61600 - train_loss: 1.73656 - val_loss: 1.60207 - loss: 2.02424
[2024-02-26 18:36:04,189][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7800] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.82985
[2024-02-26 18:36:04,189][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7800] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.03836
[2024-02-26 18:36:25,398][PyLogger][INFO]: Rank[0]: Epoch[81/500], iter[7850] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.26265
[2024-02-26 18:36:25,398][PyLogger][INFO]: Rank[1]: Epoch[81/500], iter[7850] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.78181
[2024-02-26 18:36:45,886][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7900] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.73419
[2024-02-26 18:36:45,886][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7900] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.74247
[2024-02-26 18:37:06,528][PyLogger][INFO]: Rank[0]: Epoch[82/500], iter[7950] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.95292
[2024-02-26 18:37:06,528][PyLogger][INFO]: Rank[1]: Epoch[82/500], iter[7950] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.80538
[2024-02-26 18:37:27,098][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8000] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 2.08728
[2024-02-26 18:37:27,098][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8000] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.80802
[2024-02-26 18:37:47,164][PyLogger][INFO]: Rank[1]: Epoch[83/500], iter[8050] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.80286
[2024-02-26 18:37:47,164][PyLogger][INFO]: Rank[0]: Epoch[83/500], iter[8050] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.72145
[2024-02-26 18:38:08,233][PyLogger][INFO]: Rank[0]: Epoch[84/500], iter[8100] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.97516
[2024-02-26 18:38:08,233][PyLogger][INFO]: Rank[1]: Epoch[84/500], iter[8100] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.59149
[2024-02-26 18:38:29,340][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8150] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.74010
[2024-02-26 18:38:29,341][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8150] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 0.76273
[2024-02-26 18:38:50,018][PyLogger][INFO]: Rank[0]: Epoch[85/500], iter[8200] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 2.10677
[2024-02-26 18:38:50,018][PyLogger][INFO]: Rank[1]: Epoch[85/500], iter[8200] - train_accuracy: 0.68577 - val_accuracy: 0.68070 - train_loss: 1.27443 - val_loss: 1.26452 - loss: 1.18154
[2024-02-26 18:39:30,534][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8250] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.83067
[2024-02-26 18:39:30,534][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8250] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.73215
[2024-02-26 18:39:50,053][PyLogger][INFO]: Rank[0]: Epoch[86/500], iter[8300] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.84339
[2024-02-26 18:39:50,053][PyLogger][INFO]: Rank[1]: Epoch[86/500], iter[8300] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.74486
[2024-02-26 18:40:11,984][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8350] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.86490
[2024-02-26 18:40:11,984][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8350] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.74542
[2024-02-26 18:40:32,633][PyLogger][INFO]: Rank[1]: Epoch[87/500], iter[8400] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.84955
[2024-02-26 18:40:32,633][PyLogger][INFO]: Rank[0]: Epoch[87/500], iter[8400] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.72682
[2024-02-26 18:40:53,719][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8450] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.70873
[2024-02-26 18:40:53,719][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8450] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 1.94997
[2024-02-26 18:41:15,414][PyLogger][INFO]: Rank[0]: Epoch[88/500], iter[8500] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.70554
[2024-02-26 18:41:15,414][PyLogger][INFO]: Rank[1]: Epoch[88/500], iter[8500] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.73742
[2024-02-26 18:41:37,046][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8550] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.85213
[2024-02-26 18:41:37,046][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8550] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.92408
[2024-02-26 18:41:56,951][PyLogger][INFO]: Rank[1]: Epoch[89/500], iter[8600] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.79241
[2024-02-26 18:41:56,951][PyLogger][INFO]: Rank[0]: Epoch[89/500], iter[8600] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.88060
[2024-02-26 18:42:18,062][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8650] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.92922
[2024-02-26 18:42:18,062][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8650] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 1.00250
[2024-02-26 18:42:38,871][PyLogger][INFO]: Rank[1]: Epoch[90/500], iter[8700] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 0.75879
[2024-02-26 18:42:38,871][PyLogger][INFO]: Rank[0]: Epoch[90/500], iter[8700] - train_accuracy: 0.69757 - val_accuracy: 0.75200 - train_loss: 1.29675 - val_loss: 1.15199 - loss: 2.13732
[2024-02-26 18:43:19,800][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8750] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.81032
[2024-02-26 18:43:19,800][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8750] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.72994
[2024-02-26 18:43:40,514][PyLogger][INFO]: Rank[0]: Epoch[91/500], iter[8800] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.28887
[2024-02-26 18:43:40,514][PyLogger][INFO]: Rank[1]: Epoch[91/500], iter[8800] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.00044
[2024-02-26 18:44:01,252][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8850] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.46160
[2024-02-26 18:44:01,252][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8850] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.74120
[2024-02-26 18:44:22,119][PyLogger][INFO]: Rank[0]: Epoch[92/500], iter[8900] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.48883
[2024-02-26 18:44:22,119][PyLogger][INFO]: Rank[1]: Epoch[92/500], iter[8900] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.87126
[2024-02-26 18:44:42,827][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[8950] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.70087
[2024-02-26 18:44:42,827][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[8950] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.82058
[2024-02-26 18:45:02,559][PyLogger][INFO]: Rank[0]: Epoch[93/500], iter[9000] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.68294
[2024-02-26 18:45:02,559][PyLogger][INFO]: Rank[1]: Epoch[93/500], iter[9000] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.75475
[2024-02-26 18:45:23,842][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9050] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.73567
[2024-02-26 18:45:23,842][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9050] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.83925
[2024-02-26 18:45:43,343][PyLogger][INFO]: Rank[0]: Epoch[94/500], iter[9100] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.75397
[2024-02-26 18:45:43,343][PyLogger][INFO]: Rank[1]: Epoch[94/500], iter[9100] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.73174
[2024-02-26 18:46:03,747][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9150] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.76085
[2024-02-26 18:46:03,747][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9150] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 0.74424
[2024-02-26 18:46:23,456][PyLogger][INFO]: Rank[1]: Epoch[95/500], iter[9200] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 2.06800
[2024-02-26 18:46:23,456][PyLogger][INFO]: Rank[0]: Epoch[95/500], iter[9200] - train_accuracy: 0.70981 - val_accuracy: 0.68860 - train_loss: 1.24433 - val_loss: 1.27461 - loss: 1.40654
[2024-02-26 18:47:07,357][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9250] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.66254
[2024-02-26 18:47:07,357][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9250] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.69585
[2024-02-26 18:47:27,485][PyLogger][INFO]: Rank[1]: Epoch[96/500], iter[9300] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 1.82660
[2024-02-26 18:47:27,485][PyLogger][INFO]: Rank[0]: Epoch[96/500], iter[9300] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 1.38545
[2024-02-26 18:47:48,194][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9350] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.91971
[2024-02-26 18:47:48,194][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9350] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.83971
[2024-02-26 18:48:09,198][PyLogger][INFO]: Rank[0]: Epoch[97/500], iter[9400] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.68074
[2024-02-26 18:48:09,198][PyLogger][INFO]: Rank[1]: Epoch[97/500], iter[9400] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.70406
[2024-02-26 18:48:30,375][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9450] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 2.09216
[2024-02-26 18:48:30,375][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9450] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.87464
[2024-02-26 18:48:50,764][PyLogger][INFO]: Rank[0]: Epoch[98/500], iter[9500] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.92316
[2024-02-26 18:48:50,764][PyLogger][INFO]: Rank[1]: Epoch[98/500], iter[9500] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 1.15142
[2024-02-26 18:49:11,448][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9550] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 1.29916
[2024-02-26 18:49:11,448][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9550] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.76652
[2024-02-26 18:49:31,746][PyLogger][INFO]: Rank[1]: Epoch[99/500], iter[9600] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.68369
[2024-02-26 18:49:31,746][PyLogger][INFO]: Rank[0]: Epoch[99/500], iter[9600] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.69623
[2024-02-26 18:49:53,200][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9650] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.68635
[2024-02-26 18:49:53,200][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9650] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 1.37378
[2024-02-26 18:50:14,020][PyLogger][INFO]: Rank[0]: Epoch[100/500], iter[9700] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.72737
[2024-02-26 18:50:14,020][PyLogger][INFO]: Rank[1]: Epoch[100/500], iter[9700] - train_accuracy: 0.73667 - val_accuracy: 0.73970 - train_loss: 1.19650 - val_loss: 1.18885 - loss: 0.69401
[2024-02-26 18:50:56,102][PyLogger][INFO]: Rank[0]: Epoch[101/500], iter[9750] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 1.73365
[2024-02-26 18:50:56,102][PyLogger][INFO]: Rank[1]: Epoch[101/500], iter[9750] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 1.11353
[2024-02-26 18:51:16,778][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9800] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.77393
[2024-02-26 18:51:16,778][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9800] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.81967
[2024-02-26 18:51:36,993][PyLogger][INFO]: Rank[1]: Epoch[102/500], iter[9850] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.74037
[2024-02-26 18:51:36,993][PyLogger][INFO]: Rank[0]: Epoch[102/500], iter[9850] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.75504
[2024-02-26 18:51:57,206][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9900] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.75565
[2024-02-26 18:51:57,206][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9900] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.77156
[2024-02-26 18:52:17,560][PyLogger][INFO]: Rank[1]: Epoch[103/500], iter[9950] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 1.11896
[2024-02-26 18:52:17,560][PyLogger][INFO]: Rank[0]: Epoch[103/500], iter[9950] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.88345
[2024-02-26 18:52:37,955][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10000] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.71484
[2024-02-26 18:52:37,955][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10000] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.72946
[2024-02-26 18:52:57,740][PyLogger][INFO]: Rank[0]: Epoch[104/500], iter[10050] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.88476
[2024-02-26 18:52:57,740][PyLogger][INFO]: Rank[1]: Epoch[104/500], iter[10050] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.80980
[2024-02-26 18:53:18,655][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10100] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.74090
[2024-02-26 18:53:18,655][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10100] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.70022
[2024-02-26 18:53:38,683][PyLogger][INFO]: Rank[0]: Epoch[105/500], iter[10150] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.79244
[2024-02-26 18:53:38,683][PyLogger][INFO]: Rank[1]: Epoch[105/500], iter[10150] - train_accuracy: 0.65971 - val_accuracy: 0.69790 - train_loss: 1.35658 - val_loss: 1.27316 - loss: 0.72315
[2024-02-26 18:54:20,719][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10200] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.69339
[2024-02-26 18:54:20,720][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10200] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.65507
[2024-02-26 18:54:42,438][PyLogger][INFO]: Rank[1]: Epoch[106/500], iter[10250] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.75245
[2024-02-26 18:54:42,438][PyLogger][INFO]: Rank[0]: Epoch[106/500], iter[10250] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.17028
[2024-02-26 18:55:03,269][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10300] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.77036
[2024-02-26 18:55:03,269][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10300] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.89312
[2024-02-26 18:55:24,120][PyLogger][INFO]: Rank[1]: Epoch[107/500], iter[10350] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.42087
[2024-02-26 18:55:24,120][PyLogger][INFO]: Rank[0]: Epoch[107/500], iter[10350] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.67019
[2024-02-26 18:55:45,283][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10400] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.16208
[2024-02-26 18:55:45,283][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10400] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.91047
[2024-02-26 18:56:05,262][PyLogger][INFO]: Rank[1]: Epoch[108/500], iter[10450] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.84625
[2024-02-26 18:56:05,262][PyLogger][INFO]: Rank[0]: Epoch[108/500], iter[10450] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.76611
[2024-02-26 18:56:25,602][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10500] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.98532
[2024-02-26 18:56:25,602][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10500] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.15294
[2024-02-26 18:56:46,184][PyLogger][INFO]: Rank[1]: Epoch[109/500], iter[10550] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.70286
[2024-02-26 18:56:46,184][PyLogger][INFO]: Rank[0]: Epoch[109/500], iter[10550] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.99101
[2024-02-26 18:57:06,450][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10600] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.72634
[2024-02-26 18:57:06,450][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10600] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 0.70977
[2024-02-26 18:57:27,433][PyLogger][INFO]: Rank[1]: Epoch[110/500], iter[10650] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.63708
[2024-02-26 18:57:27,433][PyLogger][INFO]: Rank[0]: Epoch[110/500], iter[10650] - train_accuracy: 0.73522 - val_accuracy: 0.75090 - train_loss: 1.17224 - val_loss: 1.13559 - loss: 1.79945
[2024-02-26 18:58:07,782][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10700] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.98538
[2024-02-26 18:58:07,782][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10700] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 2.03991
[2024-02-26 18:58:28,367][PyLogger][INFO]: Rank[0]: Epoch[111/500], iter[10750] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.69294
[2024-02-26 18:58:28,367][PyLogger][INFO]: Rank[1]: Epoch[111/500], iter[10750] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.67587
[2024-02-26 18:58:49,715][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10800] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.63529
[2024-02-26 18:58:49,715][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10800] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 1.02162
[2024-02-26 18:59:09,757][PyLogger][INFO]: Rank[0]: Epoch[112/500], iter[10850] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 1.13654
[2024-02-26 18:59:09,757][PyLogger][INFO]: Rank[1]: Epoch[112/500], iter[10850] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.75582
[2024-02-26 18:59:30,933][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10900] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 1.03693
[2024-02-26 18:59:30,934][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10900] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.65251
[2024-02-26 18:59:51,581][PyLogger][INFO]: Rank[0]: Epoch[113/500], iter[10950] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.63632
[2024-02-26 18:59:51,581][PyLogger][INFO]: Rank[1]: Epoch[113/500], iter[10950] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.71762
[2024-02-26 19:00:12,216][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11000] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.68185
[2024-02-26 19:00:12,216][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11000] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.83629
[2024-02-26 19:00:32,427][PyLogger][INFO]: Rank[0]: Epoch[114/500], iter[11050] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.68277
[2024-02-26 19:00:32,427][PyLogger][INFO]: Rank[1]: Epoch[114/500], iter[11050] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.75495
[2024-02-26 19:00:54,593][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11100] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.77967
[2024-02-26 19:00:54,593][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11100] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.67851
[2024-02-26 19:01:15,203][PyLogger][INFO]: Rank[0]: Epoch[115/500], iter[11150] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 0.75371
[2024-02-26 19:01:15,203][PyLogger][INFO]: Rank[1]: Epoch[115/500], iter[11150] - train_accuracy: 0.74257 - val_accuracy: 0.70480 - train_loss: 1.12903 - val_loss: 1.24770 - loss: 1.29840
[2024-02-26 19:01:56,474][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11200] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 1.43537
[2024-02-26 19:01:56,474][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11200] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.70678
[2024-02-26 19:02:17,184][PyLogger][INFO]: Rank[1]: Epoch[116/500], iter[11250] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.98259
[2024-02-26 19:02:17,184][PyLogger][INFO]: Rank[0]: Epoch[116/500], iter[11250] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.94415
[2024-02-26 19:02:38,399][PyLogger][INFO]: Rank[0]: Epoch[117/500], iter[11300] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.78988
[2024-02-26 19:02:38,399][PyLogger][INFO]: Rank[1]: Epoch[117/500], iter[11300] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.95989
[2024-02-26 19:02:58,980][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11350] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.70566
[2024-02-26 19:02:58,980][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11350] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 1.37294
[2024-02-26 19:03:18,572][PyLogger][INFO]: Rank[0]: Epoch[118/500], iter[11400] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.72092
[2024-02-26 19:03:18,572][PyLogger][INFO]: Rank[1]: Epoch[118/500], iter[11400] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.73660
[2024-02-26 19:03:39,233][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11450] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.63132
[2024-02-26 19:03:39,233][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11450] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.78249
[2024-02-26 19:03:59,935][PyLogger][INFO]: Rank[0]: Epoch[119/500], iter[11500] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.71497
[2024-02-26 19:03:59,935][PyLogger][INFO]: Rank[1]: Epoch[119/500], iter[11500] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.63125
[2024-02-26 19:04:21,330][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11550] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 1.17841
[2024-02-26 19:04:21,330][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11550] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.71152
[2024-02-26 19:04:41,485][PyLogger][INFO]: Rank[0]: Epoch[120/500], iter[11600] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.99613
[2024-02-26 19:04:41,485][PyLogger][INFO]: Rank[1]: Epoch[120/500], iter[11600] - train_accuracy: 0.71627 - val_accuracy: 0.74280 - train_loss: 1.20092 - val_loss: 1.17450 - loss: 0.75375
[2024-02-26 19:05:23,179][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11650] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.68731
[2024-02-26 19:05:23,179][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11650] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 1.93072
[2024-02-26 19:05:43,975][PyLogger][INFO]: Rank[1]: Epoch[121/500], iter[11700] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 1.08913
[2024-02-26 19:05:43,975][PyLogger][INFO]: Rank[0]: Epoch[121/500], iter[11700] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.70734
[2024-02-26 19:06:04,744][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11750] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.81292
[2024-02-26 19:06:04,744][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11750] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.66044
[2024-02-26 19:06:25,128][PyLogger][INFO]: Rank[0]: Epoch[122/500], iter[11800] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.85365
[2024-02-26 19:06:25,128][PyLogger][INFO]: Rank[1]: Epoch[122/500], iter[11800] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.63765
[2024-02-26 19:06:45,566][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11850] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.97289
[2024-02-26 19:06:45,566][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11850] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 1.85883
[2024-02-26 19:07:05,437][PyLogger][INFO]: Rank[0]: Epoch[123/500], iter[11900] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.62399
[2024-02-26 19:07:05,437][PyLogger][INFO]: Rank[1]: Epoch[123/500], iter[11900] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.61234
[2024-02-26 19:07:26,448][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[11950] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.86324
[2024-02-26 19:07:26,448][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[11950] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.67271
[2024-02-26 19:07:46,729][PyLogger][INFO]: Rank[0]: Epoch[124/500], iter[12000] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.61799
[2024-02-26 19:07:46,729][PyLogger][INFO]: Rank[1]: Epoch[124/500], iter[12000] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.66751
[2024-02-26 19:08:07,072][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12050] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.66632
[2024-02-26 19:08:07,072][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12050] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.68574
[2024-02-26 19:08:27,350][PyLogger][INFO]: Rank[0]: Epoch[125/500], iter[12100] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.64852
[2024-02-26 19:08:27,350][PyLogger][INFO]: Rank[1]: Epoch[125/500], iter[12100] - train_accuracy: 0.69559 - val_accuracy: 0.65610 - train_loss: 1.25372 - val_loss: 1.34854 - loss: 0.87904
[2024-02-26 19:09:09,832][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12150] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 2.01958
[2024-02-26 19:09:09,832][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12150] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.67101
[2024-02-26 19:09:30,764][PyLogger][INFO]: Rank[1]: Epoch[126/500], iter[12200] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.64827
[2024-02-26 19:09:30,764][PyLogger][INFO]: Rank[0]: Epoch[126/500], iter[12200] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.66335
[2024-02-26 19:09:52,178][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12250] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.61442
[2024-02-26 19:09:52,178][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12250] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.62792
[2024-02-26 19:10:11,825][PyLogger][INFO]: Rank[1]: Epoch[127/500], iter[12300] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.78724
[2024-02-26 19:10:11,826][PyLogger][INFO]: Rank[0]: Epoch[127/500], iter[12300] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.70029
[2024-02-26 19:10:31,979][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12350] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 2.00942
[2024-02-26 19:10:31,979][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12350] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.75840
[2024-02-26 19:10:52,173][PyLogger][INFO]: Rank[0]: Epoch[128/500], iter[12400] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.82025
[2024-02-26 19:10:52,173][PyLogger][INFO]: Rank[1]: Epoch[128/500], iter[12400] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.66085
[2024-02-26 19:11:11,753][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12450] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.66092
[2024-02-26 19:11:11,753][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12450] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.63939
[2024-02-26 19:11:32,056][PyLogger][INFO]: Rank[0]: Epoch[129/500], iter[12500] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 1.43365
[2024-02-26 19:11:32,056][PyLogger][INFO]: Rank[1]: Epoch[129/500], iter[12500] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.86226
[2024-02-26 19:11:53,580][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12550] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.69571
[2024-02-26 19:11:53,580][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12550] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.66249
[2024-02-26 19:12:13,306][PyLogger][INFO]: Rank[0]: Epoch[130/500], iter[12600] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.66128
[2024-02-26 19:12:13,306][PyLogger][INFO]: Rank[1]: Epoch[130/500], iter[12600] - train_accuracy: 0.71007 - val_accuracy: 0.66760 - train_loss: 1.19544 - val_loss: 1.30658 - loss: 0.68777
[2024-02-26 19:12:54,734][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12650] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.68765
[2024-02-26 19:12:54,734][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12650] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.63258
[2024-02-26 19:13:14,785][PyLogger][INFO]: Rank[1]: Epoch[131/500], iter[12700] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.94983
[2024-02-26 19:13:14,785][PyLogger][INFO]: Rank[0]: Epoch[131/500], iter[12700] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 1.05329
[2024-02-26 19:13:34,709][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12750] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.74267
[2024-02-26 19:13:34,709][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12750] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 1.23167
[2024-02-26 19:13:54,574][PyLogger][INFO]: Rank[1]: Epoch[132/500], iter[12800] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.75580
[2024-02-26 19:13:54,573][PyLogger][INFO]: Rank[0]: Epoch[132/500], iter[12800] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.88605
[2024-02-26 19:14:15,898][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12850] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.68529
[2024-02-26 19:14:15,898][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12850] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.67545
[2024-02-26 19:14:36,927][PyLogger][INFO]: Rank[1]: Epoch[133/500], iter[12900] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 1.41456
[2024-02-26 19:14:36,927][PyLogger][INFO]: Rank[0]: Epoch[133/500], iter[12900] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.67014
[2024-02-26 19:14:58,702][PyLogger][INFO]: Rank[0]: Epoch[134/500], iter[12950] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.60242
[2024-02-26 19:14:58,702][PyLogger][INFO]: Rank[1]: Epoch[134/500], iter[12950] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.65176
[2024-02-26 19:15:18,874][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13000] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.63271
[2024-02-26 19:15:18,875][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13000] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.61576
[2024-02-26 19:15:39,443][PyLogger][INFO]: Rank[0]: Epoch[135/500], iter[13050] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 1.42001
[2024-02-26 19:15:39,443][PyLogger][INFO]: Rank[1]: Epoch[135/500], iter[13050] - train_accuracy: 0.73768 - val_accuracy: 0.74010 - train_loss: 1.19626 - val_loss: 1.20558 - loss: 0.70792
[2024-02-26 19:16:21,259][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13100] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 1.08983
[2024-02-26 19:16:21,259][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13100] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.67374
[2024-02-26 19:16:41,390][PyLogger][INFO]: Rank[1]: Epoch[136/500], iter[13150] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 1.33598
[2024-02-26 19:16:41,390][PyLogger][INFO]: Rank[0]: Epoch[136/500], iter[13150] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.68746
[2024-02-26 19:17:01,385][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13200] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.94015
[2024-02-26 19:17:01,385][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13200] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.98385
[2024-02-26 19:17:22,383][PyLogger][INFO]: Rank[1]: Epoch[137/500], iter[13250] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.59429
[2024-02-26 19:17:22,383][PyLogger][INFO]: Rank[0]: Epoch[137/500], iter[13250] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 1.18822
[2024-02-26 19:17:42,876][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13300] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 1.26858
[2024-02-26 19:17:42,876][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13300] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.76343
[2024-02-26 19:18:03,357][PyLogger][INFO]: Rank[1]: Epoch[138/500], iter[13350] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.84376
[2024-02-26 19:18:03,357][PyLogger][INFO]: Rank[0]: Epoch[138/500], iter[13350] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.64753
[2024-02-26 19:18:24,589][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13400] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.62678
[2024-02-26 19:18:24,589][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13400] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.65326
[2024-02-26 19:18:45,294][PyLogger][INFO]: Rank[0]: Epoch[139/500], iter[13450] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.72567
[2024-02-26 19:18:45,294][PyLogger][INFO]: Rank[1]: Epoch[139/500], iter[13450] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.63182
[2024-02-26 19:19:07,692][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13500] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.62080
[2024-02-26 19:19:07,692][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13500] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 1.27291
[2024-02-26 19:19:28,149][PyLogger][INFO]: Rank[0]: Epoch[140/500], iter[13550] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.61245
[2024-02-26 19:19:28,149][PyLogger][INFO]: Rank[1]: Epoch[140/500], iter[13550] - train_accuracy: 0.73522 - val_accuracy: 0.77300 - train_loss: 1.18112 - val_loss: 1.09400 - loss: 0.61975
[2024-02-26 19:20:09,159][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13600] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.61340
[2024-02-26 19:20:09,159][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13600] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.68745
[2024-02-26 19:20:29,474][PyLogger][INFO]: Rank[1]: Epoch[141/500], iter[13650] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 1.39326
[2024-02-26 19:20:29,474][PyLogger][INFO]: Rank[0]: Epoch[141/500], iter[13650] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.68171
[2024-02-26 19:20:50,396][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13700] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.87934
[2024-02-26 19:20:50,396][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13700] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.60516
[2024-02-26 19:21:10,447][PyLogger][INFO]: Rank[0]: Epoch[142/500], iter[13750] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 1.38890
[2024-02-26 19:21:10,447][PyLogger][INFO]: Rank[1]: Epoch[142/500], iter[13750] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.74376
[2024-02-26 19:21:32,833][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13800] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.60642
[2024-02-26 19:21:32,833][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13800] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.62941
[2024-02-26 19:21:53,027][PyLogger][INFO]: Rank[0]: Epoch[143/500], iter[13850] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 1.33670
[2024-02-26 19:21:53,028][PyLogger][INFO]: Rank[1]: Epoch[143/500], iter[13850] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.89417
[2024-02-26 19:22:13,997][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13900] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.64725
[2024-02-26 19:22:13,997][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13900] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.67994
[2024-02-26 19:22:34,696][PyLogger][INFO]: Rank[0]: Epoch[144/500], iter[13950] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 1.15225
[2024-02-26 19:22:34,696][PyLogger][INFO]: Rank[1]: Epoch[144/500], iter[13950] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.67948
[2024-02-26 19:22:55,569][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14000] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.89660
[2024-02-26 19:22:55,569][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14000] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.60951
[2024-02-26 19:23:16,206][PyLogger][INFO]: Rank[1]: Epoch[145/500], iter[14050] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.68694
[2024-02-26 19:23:16,206][PyLogger][INFO]: Rank[0]: Epoch[145/500], iter[14050] - train_accuracy: 0.66404 - val_accuracy: 0.68600 - train_loss: 1.37655 - val_loss: 1.31893 - loss: 0.61629
[2024-02-26 19:23:57,926][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14100] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 2.06336
[2024-02-26 19:23:57,927][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14100] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 1.42434
[2024-02-26 19:24:18,285][PyLogger][INFO]: Rank[1]: Epoch[146/500], iter[14150] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.92024
[2024-02-26 19:24:18,286][PyLogger][INFO]: Rank[0]: Epoch[146/500], iter[14150] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.67501
[2024-02-26 19:24:38,685][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14200] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 1.29734
[2024-02-26 19:24:38,685][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14200] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.66677
[2024-02-26 19:24:59,415][PyLogger][INFO]: Rank[1]: Epoch[147/500], iter[14250] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.65710
[2024-02-26 19:24:59,415][PyLogger][INFO]: Rank[0]: Epoch[147/500], iter[14250] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.61105
[2024-02-26 19:25:19,925][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14300] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.75466
[2024-02-26 19:25:19,925][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14300] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.60427
[2024-02-26 19:25:40,722][PyLogger][INFO]: Rank[0]: Epoch[148/500], iter[14350] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.63514
[2024-02-26 19:25:40,722][PyLogger][INFO]: Rank[1]: Epoch[148/500], iter[14350] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.63188
[2024-02-26 19:26:01,177][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14400] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.60382
[2024-02-26 19:26:01,177][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14400] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.63683
[2024-02-26 19:26:21,381][PyLogger][INFO]: Rank[0]: Epoch[149/500], iter[14450] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 1.35955
[2024-02-26 19:26:21,381][PyLogger][INFO]: Rank[1]: Epoch[149/500], iter[14450] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.63408
[2024-02-26 19:26:42,667][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14500] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.65418
[2024-02-26 19:26:42,667][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14500] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.68149
[2024-02-26 19:27:03,538][PyLogger][INFO]: Rank[0]: Epoch[150/500], iter[14550] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 1.17115
[2024-02-26 19:27:03,538][PyLogger][INFO]: Rank[1]: Epoch[150/500], iter[14550] - train_accuracy: 0.70824 - val_accuracy: 0.72550 - train_loss: 1.30772 - val_loss: 1.27199 - loss: 0.72302
[2024-02-26 19:27:45,974][PyLogger][INFO]: Rank[0]: Epoch[151/500], iter[14600] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.21262
[2024-02-26 19:27:45,974][PyLogger][INFO]: Rank[1]: Epoch[151/500], iter[14600] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.61008
[2024-02-26 19:28:07,354][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14650] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.60295
[2024-02-26 19:28:07,354][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14650] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.61375
[2024-02-26 19:28:28,746][PyLogger][INFO]: Rank[1]: Epoch[152/500], iter[14700] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.44482
[2024-02-26 19:28:28,746][PyLogger][INFO]: Rank[0]: Epoch[152/500], iter[14700] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.62534
[2024-02-26 19:28:50,092][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14750] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.24964
[2024-02-26 19:28:50,092][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14750] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.71809
[2024-02-26 19:29:09,746][PyLogger][INFO]: Rank[0]: Epoch[153/500], iter[14800] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.61625
[2024-02-26 19:29:09,746][PyLogger][INFO]: Rank[1]: Epoch[153/500], iter[14800] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.61242
[2024-02-26 19:29:30,275][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14850] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.65577
[2024-02-26 19:29:30,275][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14850] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.65840
[2024-02-26 19:29:50,695][PyLogger][INFO]: Rank[0]: Epoch[154/500], iter[14900] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.64050
[2024-02-26 19:29:50,695][PyLogger][INFO]: Rank[1]: Epoch[154/500], iter[14900] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 0.74667
[2024-02-26 19:30:12,335][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[14950] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 2.14219
[2024-02-26 19:30:12,335][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[14950] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.90343
[2024-02-26 19:30:33,113][PyLogger][INFO]: Rank[0]: Epoch[155/500], iter[15000] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.87711
[2024-02-26 19:30:33,113][PyLogger][INFO]: Rank[1]: Epoch[155/500], iter[15000] - train_accuracy: 0.75753 - val_accuracy: 0.77390 - train_loss: 1.16684 - val_loss: 1.15201 - loss: 1.86330
[2024-02-26 19:31:15,317][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15050] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.92650
[2024-02-26 19:31:15,317][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15050] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.71163
[2024-02-26 19:31:36,081][PyLogger][INFO]: Rank[1]: Epoch[156/500], iter[15100] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.92240
[2024-02-26 19:31:36,081][PyLogger][INFO]: Rank[0]: Epoch[156/500], iter[15100] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.70089
[2024-02-26 19:31:56,651][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15150] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.81819
[2024-02-26 19:31:56,651][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15150] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.81383
[2024-02-26 19:32:16,936][PyLogger][INFO]: Rank[1]: Epoch[157/500], iter[15200] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.64210
[2024-02-26 19:32:16,936][PyLogger][INFO]: Rank[0]: Epoch[157/500], iter[15200] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.70464
[2024-02-26 19:32:37,422][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15250] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.64643
[2024-02-26 19:32:37,422][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15250] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 2.08203
[2024-02-26 19:32:58,143][PyLogger][INFO]: Rank[1]: Epoch[158/500], iter[15300] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.67982
[2024-02-26 19:32:58,143][PyLogger][INFO]: Rank[0]: Epoch[158/500], iter[15300] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.50357
[2024-02-26 19:33:18,992][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15350] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.71803
[2024-02-26 19:33:18,992][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15350] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.47864
[2024-02-26 19:33:39,603][PyLogger][INFO]: Rank[1]: Epoch[159/500], iter[15400] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.83915
[2024-02-26 19:33:39,603][PyLogger][INFO]: Rank[0]: Epoch[159/500], iter[15400] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.51078
[2024-02-26 19:34:01,280][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15450] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.59456
[2024-02-26 19:34:01,280][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15450] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.37169
[2024-02-26 19:34:20,982][PyLogger][INFO]: Rank[1]: Epoch[160/500], iter[15500] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.47884
[2024-02-26 19:34:20,982][PyLogger][INFO]: Rank[0]: Epoch[160/500], iter[15500] - train_accuracy: 0.25288 - val_accuracy: 0.22100 - train_loss: 2.08821 - val_loss: 2.15006 - loss: 1.41542
[2024-02-26 19:35:02,958][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15550] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.86410
[2024-02-26 19:35:02,958][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15550] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 2.04350
[2024-02-26 19:35:22,631][PyLogger][INFO]: Rank[0]: Epoch[161/500], iter[15600] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.53249
[2024-02-26 19:35:22,631][PyLogger][INFO]: Rank[1]: Epoch[161/500], iter[15600] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.37738
[2024-02-26 19:35:43,716][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15650] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.85708
[2024-02-26 19:35:43,716][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15650] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.52135
[2024-02-26 19:36:03,954][PyLogger][INFO]: Rank[1]: Epoch[162/500], iter[15700] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.27313
[2024-02-26 19:36:03,954][PyLogger][INFO]: Rank[0]: Epoch[162/500], iter[15700] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.29910
[2024-02-26 19:36:25,445][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15750] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.94562
[2024-02-26 19:36:25,445][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15750] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.25089
[2024-02-26 19:36:45,533][PyLogger][INFO]: Rank[0]: Epoch[163/500], iter[15800] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.32363
[2024-02-26 19:36:45,533][PyLogger][INFO]: Rank[1]: Epoch[163/500], iter[15800] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.70944
[2024-02-26 19:37:07,061][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15850] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.11953
[2024-02-26 19:37:07,061][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15850] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.23262
[2024-02-26 19:37:27,887][PyLogger][INFO]: Rank[0]: Epoch[164/500], iter[15900] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.98960
[2024-02-26 19:37:27,887][PyLogger][INFO]: Rank[1]: Epoch[164/500], iter[15900] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.10685
[2024-02-26 19:37:49,001][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[15950] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.89368
[2024-02-26 19:37:49,001][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[15950] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 2.05238
[2024-02-26 19:38:10,193][PyLogger][INFO]: Rank[0]: Epoch[165/500], iter[16000] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.10768
[2024-02-26 19:38:10,194][PyLogger][INFO]: Rank[1]: Epoch[165/500], iter[16000] - train_accuracy: 0.42280 - val_accuracy: 0.42110 - train_loss: 1.74526 - val_loss: 1.75137 - loss: 1.99362
[2024-02-26 19:38:51,912][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16050] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 2.00098
[2024-02-26 19:38:51,912][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16050] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.41563
[2024-02-26 19:39:12,506][PyLogger][INFO]: Rank[1]: Epoch[166/500], iter[16100] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.24370
[2024-02-26 19:39:12,506][PyLogger][INFO]: Rank[0]: Epoch[166/500], iter[16100] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.15995
[2024-02-26 19:39:34,402][PyLogger][INFO]: Rank[0]: Epoch[167/500], iter[16150] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.40437
[2024-02-26 19:39:34,402][PyLogger][INFO]: Rank[1]: Epoch[167/500], iter[16150] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.13017
[2024-02-26 19:39:54,949][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16200] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.06214
[2024-02-26 19:39:54,949][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16200] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.94698
[2024-02-26 19:40:15,413][PyLogger][INFO]: Rank[0]: Epoch[168/500], iter[16250] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.36481
[2024-02-26 19:40:15,413][PyLogger][INFO]: Rank[1]: Epoch[168/500], iter[16250] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 0.97308
[2024-02-26 19:40:35,410][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16300] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.02460
[2024-02-26 19:40:35,410][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16300] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.02494
[2024-02-26 19:40:56,029][PyLogger][INFO]: Rank[1]: Epoch[169/500], iter[16350] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.58997
[2024-02-26 19:40:56,029][PyLogger][INFO]: Rank[0]: Epoch[169/500], iter[16350] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.36100
[2024-02-26 19:41:17,615][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16400] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.72713
[2024-02-26 19:41:17,615][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16400] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.12123
[2024-02-26 19:41:37,592][PyLogger][INFO]: Rank[0]: Epoch[170/500], iter[16450] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 0.99576
[2024-02-26 19:41:37,592][PyLogger][INFO]: Rank[1]: Epoch[170/500], iter[16450] - train_accuracy: 0.49511 - val_accuracy: 0.53440 - train_loss: 1.61633 - val_loss: 1.52534 - loss: 1.48140
[2024-02-26 19:42:20,755][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16500] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.91911
[2024-02-26 19:42:20,755][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16500] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.67717
[2024-02-26 19:42:41,759][PyLogger][INFO]: Rank[0]: Epoch[171/500], iter[16550] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.97188
[2024-02-26 19:42:41,759][PyLogger][INFO]: Rank[1]: Epoch[171/500], iter[16550] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.86391
[2024-02-26 19:43:03,661][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16600] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.90987
[2024-02-26 19:43:03,661][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16600] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.88087
[2024-02-26 19:43:24,618][PyLogger][INFO]: Rank[0]: Epoch[172/500], iter[16650] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.42682
[2024-02-26 19:43:24,619][PyLogger][INFO]: Rank[1]: Epoch[172/500], iter[16650] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.15791
[2024-02-26 19:43:45,571][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16700] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.07927
[2024-02-26 19:43:45,571][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16700] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.39404
[2024-02-26 19:44:05,922][PyLogger][INFO]: Rank[1]: Epoch[173/500], iter[16750] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 1.92001
[2024-02-26 19:44:05,922][PyLogger][INFO]: Rank[0]: Epoch[173/500], iter[16750] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.93332
[2024-02-26 19:44:26,532][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16800] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.98493
[2024-02-26 19:44:26,532][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16800] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.92679
[2024-02-26 19:44:47,210][PyLogger][INFO]: Rank[0]: Epoch[174/500], iter[16850] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.94118
[2024-02-26 19:44:47,210][PyLogger][INFO]: Rank[1]: Epoch[174/500], iter[16850] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.81120
[2024-02-26 19:45:07,765][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16900] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 2.12413
[2024-02-26 19:45:07,765][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16900] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.90349
[2024-02-26 19:45:28,681][PyLogger][INFO]: Rank[0]: Epoch[175/500], iter[16950] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.98703
[2024-02-26 19:45:28,681][PyLogger][INFO]: Rank[1]: Epoch[175/500], iter[16950] - train_accuracy: 0.60184 - val_accuracy: 0.61630 - train_loss: 1.41199 - val_loss: 1.38108 - loss: 0.96041
[2024-02-26 19:46:09,390][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17000] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.84060
[2024-02-26 19:46:09,390][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17000] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.80988
[2024-02-26 19:46:30,193][PyLogger][INFO]: Rank[0]: Epoch[176/500], iter[17050] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.97027
[2024-02-26 19:46:30,193][PyLogger][INFO]: Rank[1]: Epoch[176/500], iter[17050] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.86025
[2024-02-26 19:46:50,301][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17100] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.96611
[2024-02-26 19:46:50,301][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17100] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.90406
[2024-02-26 19:47:10,804][PyLogger][INFO]: Rank[1]: Epoch[177/500], iter[17150] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 1.31720
[2024-02-26 19:47:10,804][PyLogger][INFO]: Rank[0]: Epoch[177/500], iter[17150] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.97794
[2024-02-26 19:47:31,485][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17200] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.88179
[2024-02-26 19:47:31,485][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17200] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 1.24392
[2024-02-26 19:47:52,336][PyLogger][INFO]: Rank[1]: Epoch[178/500], iter[17250] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 1.01821
[2024-02-26 19:47:52,337][PyLogger][INFO]: Rank[0]: Epoch[178/500], iter[17250] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.79954
[2024-02-26 19:48:13,683][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17300] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.75978
[2024-02-26 19:48:13,683][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17300] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.75349
[2024-02-26 19:48:33,781][PyLogger][INFO]: Rank[1]: Epoch[179/500], iter[17350] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 1.68928
[2024-02-26 19:48:33,781][PyLogger][INFO]: Rank[0]: Epoch[179/500], iter[17350] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.93478
[2024-02-26 19:48:54,300][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17400] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 1.47409
[2024-02-26 19:48:54,301][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17400] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.87752
[2024-02-26 19:49:13,997][PyLogger][INFO]: Rank[0]: Epoch[180/500], iter[17450] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.93250
[2024-02-26 19:49:13,997][PyLogger][INFO]: Rank[1]: Epoch[180/500], iter[17450] - train_accuracy: 0.58163 - val_accuracy: 0.61460 - train_loss: 1.50431 - val_loss: 1.40359 - loss: 0.95521
[2024-02-26 19:49:56,286][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17500] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.78042
[2024-02-26 19:49:56,286][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17500] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.91303
[2024-02-26 19:50:17,639][PyLogger][INFO]: Rank[0]: Epoch[181/500], iter[17550] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.77640
[2024-02-26 19:50:17,639][PyLogger][INFO]: Rank[1]: Epoch[181/500], iter[17550] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.76916
[2024-02-26 19:50:38,326][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17600] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.22597
[2024-02-26 19:50:38,326][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17600] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.78599
[2024-02-26 19:50:57,440][PyLogger][INFO]: Rank[0]: Epoch[182/500], iter[17650] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.90101
[2024-02-26 19:50:57,440][PyLogger][INFO]: Rank[1]: Epoch[182/500], iter[17650] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.81375
[2024-02-26 19:51:18,830][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17700] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.87380
[2024-02-26 19:51:18,830][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17700] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.75551
[2024-02-26 19:51:39,522][PyLogger][INFO]: Rank[0]: Epoch[183/500], iter[17750] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.62836
[2024-02-26 19:51:39,522][PyLogger][INFO]: Rank[1]: Epoch[183/500], iter[17750] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.79542
[2024-02-26 19:51:59,985][PyLogger][INFO]: Rank[0]: Epoch[184/500], iter[17800] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.02950
[2024-02-26 19:51:59,985][PyLogger][INFO]: Rank[1]: Epoch[184/500], iter[17800] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.00866
[2024-02-26 19:52:20,656][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17850] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.14435
[2024-02-26 19:52:20,656][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17850] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.84117
[2024-02-26 19:52:41,803][PyLogger][INFO]: Rank[1]: Epoch[185/500], iter[17900] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 1.04496
[2024-02-26 19:52:41,803][PyLogger][INFO]: Rank[0]: Epoch[185/500], iter[17900] - train_accuracy: 0.67983 - val_accuracy: 0.74520 - train_loss: 1.25765 - val_loss: 1.13605 - loss: 0.71123
[2024-02-26 19:53:23,205][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[17950] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 2.00294
[2024-02-26 19:53:23,205][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[17950] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.79251
[2024-02-26 19:53:43,015][PyLogger][INFO]: Rank[1]: Epoch[186/500], iter[18000] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.75893
[2024-02-26 19:53:43,015][PyLogger][INFO]: Rank[0]: Epoch[186/500], iter[18000] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.82281
[2024-02-26 19:54:03,810][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18050] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.80835
[2024-02-26 19:54:03,810][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18050] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.28272
[2024-02-26 19:54:24,460][PyLogger][INFO]: Rank[1]: Epoch[187/500], iter[18100] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.52694
[2024-02-26 19:54:24,460][PyLogger][INFO]: Rank[0]: Epoch[187/500], iter[18100] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.81625
[2024-02-26 19:54:45,997][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18150] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.42450
[2024-02-26 19:54:45,997][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18150] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.71241
[2024-02-26 19:55:06,126][PyLogger][INFO]: Rank[1]: Epoch[188/500], iter[18200] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.59275
[2024-02-26 19:55:06,126][PyLogger][INFO]: Rank[0]: Epoch[188/500], iter[18200] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.77703
[2024-02-26 19:55:27,324][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18250] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.13885
[2024-02-26 19:55:27,324][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18250] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.71888
[2024-02-26 19:55:47,526][PyLogger][INFO]: Rank[1]: Epoch[189/500], iter[18300] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.87296
[2024-02-26 19:55:47,526][PyLogger][INFO]: Rank[0]: Epoch[189/500], iter[18300] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.77836
[2024-02-26 19:56:08,252][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18350] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.82376
[2024-02-26 19:56:08,252][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18350] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.06405
[2024-02-26 19:56:27,371][PyLogger][INFO]: Rank[1]: Epoch[190/500], iter[18400] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 0.79081
[2024-02-26 19:56:27,371][PyLogger][INFO]: Rank[0]: Epoch[190/500], iter[18400] - train_accuracy: 0.64558 - val_accuracy: 0.61170 - train_loss: 1.39665 - val_loss: 1.48229 - loss: 1.49382
[2024-02-26 19:57:08,136][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18450] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.00880
[2024-02-26 19:57:08,136][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18450] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.74213
[2024-02-26 19:57:29,143][PyLogger][INFO]: Rank[0]: Epoch[191/500], iter[18500] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.71937
[2024-02-26 19:57:29,143][PyLogger][INFO]: Rank[1]: Epoch[191/500], iter[18500] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.77787
[2024-02-26 19:57:50,186][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18550] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.82478
[2024-02-26 19:57:50,186][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18550] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.40006
[2024-02-26 19:58:10,876][PyLogger][INFO]: Rank[1]: Epoch[192/500], iter[18600] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.74534
[2024-02-26 19:58:10,876][PyLogger][INFO]: Rank[0]: Epoch[192/500], iter[18600] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.10802
[2024-02-26 19:58:32,541][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18650] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.11267
[2024-02-26 19:58:32,541][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18650] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.89298
[2024-02-26 19:58:53,251][PyLogger][INFO]: Rank[1]: Epoch[193/500], iter[18700] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.99514
[2024-02-26 19:58:53,251][PyLogger][INFO]: Rank[0]: Epoch[193/500], iter[18700] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.09059
[2024-02-26 19:59:14,227][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18750] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.69055
[2024-02-26 19:59:14,227][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18750] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.82360
[2024-02-26 19:59:35,031][PyLogger][INFO]: Rank[1]: Epoch[194/500], iter[18800] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.83385
[2024-02-26 19:59:35,031][PyLogger][INFO]: Rank[0]: Epoch[194/500], iter[18800] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.70525
[2024-02-26 19:59:55,104][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18850] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.38742
[2024-02-26 19:59:55,104][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18850] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.07782
[2024-02-26 20:00:15,408][PyLogger][INFO]: Rank[1]: Epoch[195/500], iter[18900] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 0.79429
[2024-02-26 20:00:15,408][PyLogger][INFO]: Rank[0]: Epoch[195/500], iter[18900] - train_accuracy: 0.65329 - val_accuracy: 0.69080 - train_loss: 1.37067 - val_loss: 1.27922 - loss: 1.24894
[2024-02-26 20:00:57,585][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[18950] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.78268
[2024-02-26 20:00:57,585][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[18950] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.68225
[2024-02-26 20:01:17,912][PyLogger][INFO]: Rank[0]: Epoch[196/500], iter[19000] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.80579
[2024-02-26 20:01:17,912][PyLogger][INFO]: Rank[1]: Epoch[196/500], iter[19000] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.99807
[2024-02-26 20:01:39,405][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19050] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.12840
[2024-02-26 20:01:39,405][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19050] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.11065
[2024-02-26 20:02:00,442][PyLogger][INFO]: Rank[0]: Epoch[197/500], iter[19100] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.74671
[2024-02-26 20:02:00,442][PyLogger][INFO]: Rank[1]: Epoch[197/500], iter[19100] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.39459
[2024-02-26 20:02:21,742][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19150] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.80627
[2024-02-26 20:02:21,742][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19150] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.71151
[2024-02-26 20:02:42,325][PyLogger][INFO]: Rank[0]: Epoch[198/500], iter[19200] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.92150
[2024-02-26 20:02:42,325][PyLogger][INFO]: Rank[1]: Epoch[198/500], iter[19200] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.73737
[2024-02-26 20:03:03,466][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19250] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.66851
[2024-02-26 20:03:03,466][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19250] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.59954
[2024-02-26 20:03:23,724][PyLogger][INFO]: Rank[0]: Epoch[199/500], iter[19300] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.43313
[2024-02-26 20:03:23,724][PyLogger][INFO]: Rank[1]: Epoch[199/500], iter[19300] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.90449
[2024-02-26 20:03:44,933][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19350] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.02528
[2024-02-26 20:03:44,933][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19350] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 1.25340
[2024-02-26 20:04:04,915][PyLogger][INFO]: Rank[1]: Epoch[200/500], iter[19400] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.85650
[2024-02-26 20:04:04,915][PyLogger][INFO]: Rank[0]: Epoch[200/500], iter[19400] - train_accuracy: 0.68210 - val_accuracy: 0.70320 - train_loss: 1.31237 - val_loss: 1.29927 - loss: 0.63183
[2024-02-26 20:04:46,595][PyLogger][INFO]: Rank[0]: Epoch[201/500], iter[19450] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.72568
[2024-02-26 20:04:46,595][PyLogger][INFO]: Rank[1]: Epoch[201/500], iter[19450] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.72456
[2024-02-26 20:05:08,655][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19500] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.73186
[2024-02-26 20:05:08,655][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19500] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 2.04900
[2024-02-26 20:05:29,384][PyLogger][INFO]: Rank[1]: Epoch[202/500], iter[19550] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.76042
[2024-02-26 20:05:29,384][PyLogger][INFO]: Rank[0]: Epoch[202/500], iter[19550] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.99406
[2024-02-26 20:05:49,976][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19600] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 2.08708
[2024-02-26 20:05:49,976][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19600] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.67002
[2024-02-26 20:06:10,102][PyLogger][INFO]: Rank[1]: Epoch[203/500], iter[19650] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 1.26925
[2024-02-26 20:06:10,102][PyLogger][INFO]: Rank[0]: Epoch[203/500], iter[19650] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 1.64576
[2024-02-26 20:06:32,220][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19700] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.90322
[2024-02-26 20:06:32,220][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19700] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.65431
[2024-02-26 20:06:52,761][PyLogger][INFO]: Rank[1]: Epoch[204/500], iter[19750] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.64682
[2024-02-26 20:06:52,761][PyLogger][INFO]: Rank[0]: Epoch[204/500], iter[19750] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 1.14234
[2024-02-26 20:07:13,106][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19800] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.66349
[2024-02-26 20:07:13,106][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19800] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 0.81265
[2024-02-26 20:07:32,774][PyLogger][INFO]: Rank[0]: Epoch[205/500], iter[19850] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 1.57398
[2024-02-26 20:07:32,774][PyLogger][INFO]: Rank[1]: Epoch[205/500], iter[19850] - train_accuracy: 0.70157 - val_accuracy: 0.60350 - train_loss: 1.24466 - val_loss: 1.43263 - loss: 1.37918
[2024-02-26 20:08:13,592][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19900] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.71033
[2024-02-26 20:08:13,592][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19900] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.68764
[2024-02-26 20:08:34,865][PyLogger][INFO]: Rank[1]: Epoch[206/500], iter[19950] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 2.09909
[2024-02-26 20:08:34,865][PyLogger][INFO]: Rank[0]: Epoch[206/500], iter[19950] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.73319
[2024-02-26 20:08:56,174][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20000] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.08038
[2024-02-26 20:08:56,174][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20000] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.70209
[2024-02-26 20:09:16,931][PyLogger][INFO]: Rank[0]: Epoch[207/500], iter[20050] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.70019
[2024-02-26 20:09:16,931][PyLogger][INFO]: Rank[1]: Epoch[207/500], iter[20050] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.82429
[2024-02-26 20:09:37,940][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20100] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.66314
[2024-02-26 20:09:37,940][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20100] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.97283
[2024-02-26 20:09:57,075][PyLogger][INFO]: Rank[0]: Epoch[208/500], iter[20150] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.69632
[2024-02-26 20:09:57,075][PyLogger][INFO]: Rank[1]: Epoch[208/500], iter[20150] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.69447
[2024-02-26 20:10:17,661][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20200] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.45391
[2024-02-26 20:10:17,661][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20200] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.21077
[2024-02-26 20:10:38,137][PyLogger][INFO]: Rank[0]: Epoch[209/500], iter[20250] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.30110
[2024-02-26 20:10:38,137][PyLogger][INFO]: Rank[1]: Epoch[209/500], iter[20250] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.66365
[2024-02-26 20:10:58,526][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20300] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.76316
[2024-02-26 20:10:58,526][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20300] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.88779
[2024-02-26 20:11:19,039][PyLogger][INFO]: Rank[1]: Epoch[210/500], iter[20350] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 1.34676
[2024-02-26 20:11:19,039][PyLogger][INFO]: Rank[0]: Epoch[210/500], iter[20350] - train_accuracy: 0.68110 - val_accuracy: 0.66880 - train_loss: 1.30836 - val_loss: 1.35359 - loss: 0.74407
[2024-02-26 20:12:00,763][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20400] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.68840
[2024-02-26 20:12:00,763][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20400] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.40167
[2024-02-26 20:12:22,001][PyLogger][INFO]: Rank[0]: Epoch[211/500], iter[20450] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 2.07337
[2024-02-26 20:12:22,001][PyLogger][INFO]: Rank[1]: Epoch[211/500], iter[20450] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.63068
[2024-02-26 20:12:43,038][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20500] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.79353
[2024-02-26 20:12:43,038][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20500] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.00607
[2024-02-26 20:13:03,655][PyLogger][INFO]: Rank[0]: Epoch[212/500], iter[20550] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.55346
[2024-02-26 20:13:03,655][PyLogger][INFO]: Rank[1]: Epoch[212/500], iter[20550] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.16945
[2024-02-26 20:13:24,037][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20600] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.81418
[2024-02-26 20:13:24,037][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20600] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.91785
[2024-02-26 20:13:44,164][PyLogger][INFO]: Rank[0]: Epoch[213/500], iter[20650] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 1.76067
[2024-02-26 20:13:44,164][PyLogger][INFO]: Rank[1]: Epoch[213/500], iter[20650] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.69912
[2024-02-26 20:14:04,220][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20700] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.78076
[2024-02-26 20:14:04,220][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20700] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.66609
[2024-02-26 20:14:24,423][PyLogger][INFO]: Rank[0]: Epoch[214/500], iter[20750] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.64052
[2024-02-26 20:14:24,423][PyLogger][INFO]: Rank[1]: Epoch[214/500], iter[20750] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.70609
[2024-02-26 20:14:45,586][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20800] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 2.00719
[2024-02-26 20:14:45,586][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20800] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.82049
[2024-02-26 20:15:06,522][PyLogger][INFO]: Rank[1]: Epoch[215/500], iter[20850] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.98812
[2024-02-26 20:15:06,522][PyLogger][INFO]: Rank[0]: Epoch[215/500], iter[20850] - train_accuracy: 0.70443 - val_accuracy: 0.66800 - train_loss: 1.22377 - val_loss: 1.27710 - loss: 0.71052
[2024-02-26 20:15:47,135][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20900] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.69500
[2024-02-26 20:15:47,135][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20900] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.92764
[2024-02-26 20:16:08,495][PyLogger][INFO]: Rank[0]: Epoch[216/500], iter[20950] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.71620
[2024-02-26 20:16:08,495][PyLogger][INFO]: Rank[1]: Epoch[216/500], iter[20950] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.63531
[2024-02-26 20:16:28,847][PyLogger][INFO]: Rank[1]: Epoch[217/500], iter[21000] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 1.88994
[2024-02-26 20:16:28,847][PyLogger][INFO]: Rank[0]: Epoch[217/500], iter[21000] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.71730
[2024-02-26 20:16:49,450][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21050] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.72563
[2024-02-26 20:16:49,450][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21050] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 2.08469
[2024-02-26 20:17:09,929][PyLogger][INFO]: Rank[1]: Epoch[218/500], iter[21100] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 1.73490
[2024-02-26 20:17:09,929][PyLogger][INFO]: Rank[0]: Epoch[218/500], iter[21100] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.83117
[2024-02-26 20:17:30,028][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21150] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.71450
[2024-02-26 20:17:30,028][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21150] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.61775
[2024-02-26 20:17:50,357][PyLogger][INFO]: Rank[1]: Epoch[219/500], iter[21200] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.66496
[2024-02-26 20:17:50,357][PyLogger][INFO]: Rank[0]: Epoch[219/500], iter[21200] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 1.82032
[2024-02-26 20:18:10,986][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21250] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 1.71962
[2024-02-26 20:18:10,986][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21250] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.63079
[2024-02-26 20:18:31,026][PyLogger][INFO]: Rank[1]: Epoch[220/500], iter[21300] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 1.61745
[2024-02-26 20:18:31,026][PyLogger][INFO]: Rank[0]: Epoch[220/500], iter[21300] - train_accuracy: 0.60130 - val_accuracy: 0.58860 - train_loss: 1.49578 - val_loss: 1.52220 - loss: 0.86677
[2024-02-26 20:19:13,436][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21350] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 1.55877
[2024-02-26 20:19:13,436][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21350] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.61777
[2024-02-26 20:19:33,477][PyLogger][INFO]: Rank[1]: Epoch[221/500], iter[21400] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.77499
[2024-02-26 20:19:33,477][PyLogger][INFO]: Rank[0]: Epoch[221/500], iter[21400] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.63973
[2024-02-26 20:19:54,184][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21450] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.63680
[2024-02-26 20:19:54,184][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21450] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 1.66882
[2024-02-26 20:20:14,184][PyLogger][INFO]: Rank[0]: Epoch[222/500], iter[21500] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.73853
[2024-02-26 20:20:14,184][PyLogger][INFO]: Rank[1]: Epoch[222/500], iter[21500] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.66082
[2024-02-26 20:20:33,995][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21550] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.73778
[2024-02-26 20:20:33,995][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21550] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.70925
[2024-02-26 20:20:53,618][PyLogger][INFO]: Rank[1]: Epoch[223/500], iter[21600] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 1.75391
[2024-02-26 20:20:53,619][PyLogger][INFO]: Rank[0]: Epoch[223/500], iter[21600] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.66516
[2024-02-26 20:21:14,534][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21650] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 1.09699
[2024-02-26 20:21:14,534][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21650] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.62705
[2024-02-26 20:21:35,370][PyLogger][INFO]: Rank[1]: Epoch[224/500], iter[21700] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.62766
[2024-02-26 20:21:35,370][PyLogger][INFO]: Rank[0]: Epoch[224/500], iter[21700] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.59656
[2024-02-26 20:21:55,982][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21750] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.67815
[2024-02-26 20:21:55,982][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21750] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 1.88520
[2024-02-26 20:22:15,964][PyLogger][INFO]: Rank[1]: Epoch[225/500], iter[21800] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.64641
[2024-02-26 20:22:15,964][PyLogger][INFO]: Rank[0]: Epoch[225/500], iter[21800] - train_accuracy: 0.69310 - val_accuracy: 0.75210 - train_loss: 1.27370 - val_loss: 1.16547 - loss: 0.73703
[2024-02-26 20:22:56,329][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21850] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 1.05327
[2024-02-26 20:22:56,329][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21850] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.67453
[2024-02-26 20:23:16,328][PyLogger][INFO]: Rank[0]: Epoch[226/500], iter[21900] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.79643
[2024-02-26 20:23:16,328][PyLogger][INFO]: Rank[1]: Epoch[226/500], iter[21900] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.85784
[2024-02-26 20:23:36,776][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[21950] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.71515
[2024-02-26 20:23:36,776][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[21950] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.61329
[2024-02-26 20:23:58,255][PyLogger][INFO]: Rank[0]: Epoch[227/500], iter[22000] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.95335
[2024-02-26 20:23:58,255][PyLogger][INFO]: Rank[1]: Epoch[227/500], iter[22000] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.58633
[2024-02-26 20:24:18,942][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22050] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.71892
[2024-02-26 20:24:18,942][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22050] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.60883
[2024-02-26 20:24:40,211][PyLogger][INFO]: Rank[0]: Epoch[228/500], iter[22100] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.67659
[2024-02-26 20:24:40,211][PyLogger][INFO]: Rank[1]: Epoch[228/500], iter[22100] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.64369
[2024-02-26 20:25:00,938][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22150] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.73158
[2024-02-26 20:25:00,938][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22150] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.63675
[2024-02-26 20:25:20,794][PyLogger][INFO]: Rank[1]: Epoch[229/500], iter[22200] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.60545
[2024-02-26 20:25:20,794][PyLogger][INFO]: Rank[0]: Epoch[229/500], iter[22200] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 1.02292
[2024-02-26 20:25:41,827][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22250] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.99988
[2024-02-26 20:25:41,827][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22250] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.57894
[2024-02-26 20:26:02,953][PyLogger][INFO]: Rank[0]: Epoch[230/500], iter[22300] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.76337
[2024-02-26 20:26:02,953][PyLogger][INFO]: Rank[1]: Epoch[230/500], iter[22300] - train_accuracy: 0.71142 - val_accuracy: 0.73670 - train_loss: 1.27317 - val_loss: 1.22296 - loss: 0.62945
[2024-02-26 20:26:44,780][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22350] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.84461
[2024-02-26 20:26:44,780][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22350] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.65407
[2024-02-26 20:27:05,812][PyLogger][INFO]: Rank[1]: Epoch[231/500], iter[22400] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.73469
[2024-02-26 20:27:05,813][PyLogger][INFO]: Rank[0]: Epoch[231/500], iter[22400] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.67880
[2024-02-26 20:27:26,311][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22450] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 1.26334
[2024-02-26 20:27:26,311][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22450] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.58833
[2024-02-26 20:27:46,892][PyLogger][INFO]: Rank[0]: Epoch[232/500], iter[22500] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.61688
[2024-02-26 20:27:46,892][PyLogger][INFO]: Rank[1]: Epoch[232/500], iter[22500] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.94079
[2024-02-26 20:28:07,865][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22550] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.76201
[2024-02-26 20:28:07,865][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22550] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.70063
[2024-02-26 20:28:28,742][PyLogger][INFO]: Rank[0]: Epoch[233/500], iter[22600] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.62467
[2024-02-26 20:28:28,743][PyLogger][INFO]: Rank[1]: Epoch[233/500], iter[22600] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.65094
[2024-02-26 20:28:48,351][PyLogger][INFO]: Rank[1]: Epoch[234/500], iter[22650] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.62254
[2024-02-26 20:28:48,351][PyLogger][INFO]: Rank[0]: Epoch[234/500], iter[22650] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 1.05456
[2024-02-26 20:29:09,496][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22700] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.65150
[2024-02-26 20:29:09,496][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22700] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 2.03735
[2024-02-26 20:29:29,452][PyLogger][INFO]: Rank[1]: Epoch[235/500], iter[22750] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.70817
[2024-02-26 20:29:29,452][PyLogger][INFO]: Rank[0]: Epoch[235/500], iter[22750] - train_accuracy: 0.76313 - val_accuracy: 0.72070 - train_loss: 1.11330 - val_loss: 1.20735 - loss: 0.63334
[2024-02-26 20:30:10,182][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22800] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.04487
[2024-02-26 20:30:10,182][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22800] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.61682
[2024-02-26 20:30:31,304][PyLogger][INFO]: Rank[1]: Epoch[236/500], iter[22850] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.71996
[2024-02-26 20:30:31,304][PyLogger][INFO]: Rank[0]: Epoch[236/500], iter[22850] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.62840
[2024-02-26 20:30:52,809][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22900] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.63031
[2024-02-26 20:30:52,809][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22900] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.59523
[2024-02-26 20:31:13,472][PyLogger][INFO]: Rank[1]: Epoch[237/500], iter[22950] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.93421
[2024-02-26 20:31:13,472][PyLogger][INFO]: Rank[0]: Epoch[237/500], iter[22950] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.53850
[2024-02-26 20:31:33,205][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23000] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.60107
[2024-02-26 20:31:33,205][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23000] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.74377
[2024-02-26 20:31:52,877][PyLogger][INFO]: Rank[1]: Epoch[238/500], iter[23050] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.47570
[2024-02-26 20:31:52,877][PyLogger][INFO]: Rank[0]: Epoch[238/500], iter[23050] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.62049
[2024-02-26 20:32:13,113][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23100] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.67210
[2024-02-26 20:32:13,113][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23100] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.60524
[2024-02-26 20:32:34,530][PyLogger][INFO]: Rank[1]: Epoch[239/500], iter[23150] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.65999
[2024-02-26 20:32:34,530][PyLogger][INFO]: Rank[0]: Epoch[239/500], iter[23150] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.59613
[2024-02-26 20:32:55,490][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23200] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.65597
[2024-02-26 20:32:55,490][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23200] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.59187
[2024-02-26 20:33:15,503][PyLogger][INFO]: Rank[1]: Epoch[240/500], iter[23250] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 1.02652
[2024-02-26 20:33:15,503][PyLogger][INFO]: Rank[0]: Epoch[240/500], iter[23250] - train_accuracy: 0.66052 - val_accuracy: 0.68170 - train_loss: 1.36231 - val_loss: 1.34100 - loss: 0.57939
[2024-02-26 20:33:57,887][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23300] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.83496
[2024-02-26 20:33:57,887][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23300] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.60649
[2024-02-26 20:34:19,246][PyLogger][INFO]: Rank[0]: Epoch[241/500], iter[23350] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.60834
[2024-02-26 20:34:19,246][PyLogger][INFO]: Rank[1]: Epoch[241/500], iter[23350] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 1.31177
[2024-02-26 20:34:39,829][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23400] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.58783
[2024-02-26 20:34:39,829][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23400] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.76002
[2024-02-26 20:35:01,596][PyLogger][INFO]: Rank[1]: Epoch[242/500], iter[23450] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.67946
[2024-02-26 20:35:01,596][PyLogger][INFO]: Rank[0]: Epoch[242/500], iter[23450] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.58611
[2024-02-26 20:35:22,213][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23500] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 1.44481
[2024-02-26 20:35:22,213][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23500] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.70093
[2024-02-26 20:35:41,849][PyLogger][INFO]: Rank[1]: Epoch[243/500], iter[23550] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.64265
[2024-02-26 20:35:41,849][PyLogger][INFO]: Rank[0]: Epoch[243/500], iter[23550] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.63962
[2024-02-26 20:36:03,155][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23600] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.61565
[2024-02-26 20:36:03,156][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23600] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.62595
[2024-02-26 20:36:23,933][PyLogger][INFO]: Rank[1]: Epoch[244/500], iter[23650] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.97981
[2024-02-26 20:36:23,933][PyLogger][INFO]: Rank[0]: Epoch[244/500], iter[23650] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.58603
[2024-02-26 20:36:45,104][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23700] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 1.02859
[2024-02-26 20:36:45,104][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23700] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.57257
[2024-02-26 20:37:05,465][PyLogger][INFO]: Rank[0]: Epoch[245/500], iter[23750] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 0.68345
[2024-02-26 20:37:05,465][PyLogger][INFO]: Rank[1]: Epoch[245/500], iter[23750] - train_accuracy: 0.70335 - val_accuracy: 0.66710 - train_loss: 1.24802 - val_loss: 1.32595 - loss: 1.83588
[2024-02-26 20:37:48,415][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23800] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.96100
[2024-02-26 20:37:48,415][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23800] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 1.28857
[2024-02-26 20:38:09,218][PyLogger][INFO]: Rank[1]: Epoch[246/500], iter[23850] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.72566
[2024-02-26 20:38:09,218][PyLogger][INFO]: Rank[0]: Epoch[246/500], iter[23850] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 1.44610
[2024-02-26 20:38:30,096][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23900] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 1.71325
[2024-02-26 20:38:30,096][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23900] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.64247
[2024-02-26 20:38:50,906][PyLogger][INFO]: Rank[1]: Epoch[247/500], iter[23950] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.58430
[2024-02-26 20:38:50,906][PyLogger][INFO]: Rank[0]: Epoch[247/500], iter[23950] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.57948
[2024-02-26 20:39:11,547][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24000] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.68440
[2024-02-26 20:39:11,547][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24000] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.58016
[2024-02-26 20:39:32,401][PyLogger][INFO]: Rank[0]: Epoch[248/500], iter[24050] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.61755
[2024-02-26 20:39:32,401][PyLogger][INFO]: Rank[1]: Epoch[248/500], iter[24050] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.99483
[2024-02-26 20:39:54,570][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24100] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.67833
[2024-02-26 20:39:54,570][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24100] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 1.44397
[2024-02-26 20:40:14,027][PyLogger][INFO]: Rank[0]: Epoch[249/500], iter[24150] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 1.37589
[2024-02-26 20:40:14,027][PyLogger][INFO]: Rank[1]: Epoch[249/500], iter[24150] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.71666
[2024-02-26 20:40:33,959][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24200] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.57524
[2024-02-26 20:40:33,959][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24200] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.63583
[2024-02-26 20:40:54,584][PyLogger][INFO]: Rank[1]: Epoch[250/500], iter[24250] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 0.58321
[2024-02-26 20:40:54,584][PyLogger][INFO]: Rank[0]: Epoch[250/500], iter[24250] - train_accuracy: 0.74875 - val_accuracy: 0.70520 - train_loss: 1.14271 - val_loss: 1.26148 - loss: 2.03258
[2024-02-26 20:41:37,986][PyLogger][INFO]: Rank[0]: Epoch[251/500], iter[24300] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.78104
[2024-02-26 20:41:37,986][PyLogger][INFO]: Rank[1]: Epoch[251/500], iter[24300] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.86082
[2024-02-26 20:41:59,158][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24350] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.59480
[2024-02-26 20:41:59,158][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24350] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.91337
[2024-02-26 20:42:20,140][PyLogger][INFO]: Rank[0]: Epoch[252/500], iter[24400] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.59658
[2024-02-26 20:42:20,140][PyLogger][INFO]: Rank[1]: Epoch[252/500], iter[24400] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.21170
[2024-02-26 20:42:41,077][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24450] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.48960
[2024-02-26 20:42:41,077][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24450] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.97512
[2024-02-26 20:43:01,578][PyLogger][INFO]: Rank[0]: Epoch[253/500], iter[24500] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.66813
[2024-02-26 20:43:01,578][PyLogger][INFO]: Rank[1]: Epoch[253/500], iter[24500] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.36535
[2024-02-26 20:43:22,940][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24550] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.59659
[2024-02-26 20:43:22,940][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24550] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.83845
[2024-02-26 20:43:43,657][PyLogger][INFO]: Rank[1]: Epoch[254/500], iter[24600] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.45790
[2024-02-26 20:43:43,657][PyLogger][INFO]: Rank[0]: Epoch[254/500], iter[24600] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 1.54966
[2024-02-26 20:44:04,705][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24650] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.60552
[2024-02-26 20:44:04,705][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24650] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.58963
[2024-02-26 20:44:24,972][PyLogger][INFO]: Rank[1]: Epoch[255/500], iter[24700] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.63256
[2024-02-26 20:44:24,972][PyLogger][INFO]: Rank[0]: Epoch[255/500], iter[24700] - train_accuracy: 0.68231 - val_accuracy: 0.63970 - train_loss: 1.29254 - val_loss: 1.38158 - loss: 0.57378
[2024-02-26 20:45:06,587][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24750] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.63361
[2024-02-26 20:45:06,587][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24750] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.56272
[2024-02-26 20:45:27,145][PyLogger][INFO]: Rank[1]: Epoch[256/500], iter[24800] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.58288
[2024-02-26 20:45:27,145][PyLogger][INFO]: Rank[0]: Epoch[256/500], iter[24800] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.58734
[2024-02-26 20:45:48,509][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24850] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.62568
[2024-02-26 20:45:48,509][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24850] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.52968
[2024-02-26 20:46:08,614][PyLogger][INFO]: Rank[1]: Epoch[257/500], iter[24900] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.63303
[2024-02-26 20:46:08,614][PyLogger][INFO]: Rank[0]: Epoch[257/500], iter[24900] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.60858
[2024-02-26 20:46:30,416][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[24950] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.66199
[2024-02-26 20:46:30,416][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[24950] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.56141
[2024-02-26 20:46:50,546][PyLogger][INFO]: Rank[1]: Epoch[258/500], iter[25000] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.99001
[2024-02-26 20:46:50,546][PyLogger][INFO]: Rank[0]: Epoch[258/500], iter[25000] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.65951
[2024-02-26 20:47:12,474][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25050] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.33364
[2024-02-26 20:47:12,475][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25050] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.66384
[2024-02-26 20:47:32,350][PyLogger][INFO]: Rank[1]: Epoch[259/500], iter[25100] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.59203
[2024-02-26 20:47:32,350][PyLogger][INFO]: Rank[0]: Epoch[259/500], iter[25100] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.28767
[2024-02-26 20:47:52,911][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25150] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.23892
[2024-02-26 20:47:52,911][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25150] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.59134
[2024-02-26 20:48:12,871][PyLogger][INFO]: Rank[0]: Epoch[260/500], iter[25200] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 1.38688
[2024-02-26 20:48:12,871][PyLogger][INFO]: Rank[1]: Epoch[260/500], iter[25200] - train_accuracy: 0.78252 - val_accuracy: 0.64190 - train_loss: 1.08312 - val_loss: 1.37368 - loss: 0.58962
[2024-02-26 20:48:54,193][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25250] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.95665
[2024-02-26 20:48:54,193][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25250] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.64106
[2024-02-26 20:49:14,603][PyLogger][INFO]: Rank[0]: Epoch[261/500], iter[25300] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 1.42641
[2024-02-26 20:49:14,603][PyLogger][INFO]: Rank[1]: Epoch[261/500], iter[25300] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.57367
[2024-02-26 20:49:34,374][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25350] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.65282
[2024-02-26 20:49:34,374][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25350] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.59635
[2024-02-26 20:49:54,974][PyLogger][INFO]: Rank[0]: Epoch[262/500], iter[25400] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 1.14597
[2024-02-26 20:49:54,974][PyLogger][INFO]: Rank[1]: Epoch[262/500], iter[25400] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 1.67710
[2024-02-26 20:50:16,159][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25450] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.63457
[2024-02-26 20:50:16,159][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25450] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.55633
[2024-02-26 20:50:36,814][PyLogger][INFO]: Rank[0]: Epoch[263/500], iter[25500] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.59717
[2024-02-26 20:50:36,814][PyLogger][INFO]: Rank[1]: Epoch[263/500], iter[25500] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.56757
[2024-02-26 20:50:57,872][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25550] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 1.27559
[2024-02-26 20:50:57,872][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25550] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.60196
[2024-02-26 20:51:18,178][PyLogger][INFO]: Rank[1]: Epoch[264/500], iter[25600] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 1.12619
[2024-02-26 20:51:18,178][PyLogger][INFO]: Rank[0]: Epoch[264/500], iter[25600] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.64968
[2024-02-26 20:51:39,976][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25650] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.59386
[2024-02-26 20:51:39,976][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25650] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.56822
[2024-02-26 20:52:00,199][PyLogger][INFO]: Rank[1]: Epoch[265/500], iter[25700] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.62565
[2024-02-26 20:52:00,198][PyLogger][INFO]: Rank[0]: Epoch[265/500], iter[25700] - train_accuracy: 0.73176 - val_accuracy: 0.64730 - train_loss: 1.17894 - val_loss: 1.35714 - loss: 0.71269
[2024-02-26 20:52:41,398][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25750] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.97229
[2024-02-26 20:52:41,398][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25750] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.52047
[2024-02-26 20:53:02,413][PyLogger][INFO]: Rank[0]: Epoch[266/500], iter[25800] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.68853
[2024-02-26 20:53:02,413][PyLogger][INFO]: Rank[1]: Epoch[266/500], iter[25800] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.86330
[2024-02-26 20:53:23,939][PyLogger][INFO]: Rank[1]: Epoch[267/500], iter[25850] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.37769
[2024-02-26 20:53:23,939][PyLogger][INFO]: Rank[0]: Epoch[267/500], iter[25850] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.73214
[2024-02-26 20:53:45,503][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25900] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.56605
[2024-02-26 20:53:45,503][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25900] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.57284
[2024-02-26 20:54:05,842][PyLogger][INFO]: Rank[1]: Epoch[268/500], iter[25950] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.85030
[2024-02-26 20:54:05,842][PyLogger][INFO]: Rank[0]: Epoch[268/500], iter[25950] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.66160
[2024-02-26 20:54:26,715][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26000] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.79048
[2024-02-26 20:54:26,715][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26000] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.39758
[2024-02-26 20:54:47,605][PyLogger][INFO]: Rank[1]: Epoch[269/500], iter[26050] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 1.42234
[2024-02-26 20:54:47,605][PyLogger][INFO]: Rank[0]: Epoch[269/500], iter[26050] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.57304
[2024-02-26 20:55:07,699][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26100] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.72902
[2024-02-26 20:55:07,699][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26100] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.60022
[2024-02-26 20:55:28,212][PyLogger][INFO]: Rank[0]: Epoch[270/500], iter[26150] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 2.00611
[2024-02-26 20:55:28,212][PyLogger][INFO]: Rank[1]: Epoch[270/500], iter[26150] - train_accuracy: 0.76142 - val_accuracy: 0.69110 - train_loss: 1.12174 - val_loss: 1.29378 - loss: 0.57690
[2024-02-26 20:56:10,620][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26200] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 1.92650
[2024-02-26 20:56:10,620][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26200] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.55481
[2024-02-26 20:56:30,742][PyLogger][INFO]: Rank[1]: Epoch[271/500], iter[26250] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 1.33485
[2024-02-26 20:56:30,742][PyLogger][INFO]: Rank[0]: Epoch[271/500], iter[26250] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.85474
[2024-02-26 20:56:52,164][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26300] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 2.09533
[2024-02-26 20:56:52,164][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26300] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.61437
[2024-02-26 20:57:12,788][PyLogger][INFO]: Rank[1]: Epoch[272/500], iter[26350] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.58892
[2024-02-26 20:57:12,788][PyLogger][INFO]: Rank[0]: Epoch[272/500], iter[26350] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.56097
[2024-02-26 20:57:34,535][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26400] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.60966
[2024-02-26 20:57:34,535][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26400] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.58459
[2024-02-26 20:57:55,423][PyLogger][INFO]: Rank[1]: Epoch[273/500], iter[26450] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 1.38005
[2024-02-26 20:57:55,423][PyLogger][INFO]: Rank[0]: Epoch[273/500], iter[26450] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.63311
[2024-02-26 20:58:16,572][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26500] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.55280
[2024-02-26 20:58:16,572][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26500] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.57669
[2024-02-26 20:58:37,284][PyLogger][INFO]: Rank[1]: Epoch[274/500], iter[26550] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 1.34369
[2024-02-26 20:58:37,284][PyLogger][INFO]: Rank[0]: Epoch[274/500], iter[26550] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.57411
[2024-02-26 20:58:57,971][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26600] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.55631
[2024-02-26 20:58:57,971][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26600] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.54556
[2024-02-26 20:59:18,819][PyLogger][INFO]: Rank[0]: Epoch[275/500], iter[26650] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.63077
[2024-02-26 20:59:18,819][PyLogger][INFO]: Rank[1]: Epoch[275/500], iter[26650] - train_accuracy: 0.77285 - val_accuracy: 0.68890 - train_loss: 1.07151 - val_loss: 1.26325 - loss: 0.56535
[2024-02-26 21:00:00,008][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26700] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 1.51841
[2024-02-26 21:00:00,008][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26700] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 1.00189
[2024-02-26 21:00:20,542][PyLogger][INFO]: Rank[0]: Epoch[276/500], iter[26750] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.57622
[2024-02-26 21:00:20,542][PyLogger][INFO]: Rank[1]: Epoch[276/500], iter[26750] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.53149
[2024-02-26 21:00:42,431][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26800] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.54875
[2024-02-26 21:00:42,431][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26800] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.56039
[2024-02-26 21:01:02,544][PyLogger][INFO]: Rank[1]: Epoch[277/500], iter[26850] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.92945
[2024-02-26 21:01:02,544][PyLogger][INFO]: Rank[0]: Epoch[277/500], iter[26850] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.57191
[2024-02-26 21:01:23,832][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26900] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.59345
[2024-02-26 21:01:23,832][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26900] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.57009
[2024-02-26 21:01:44,043][PyLogger][INFO]: Rank[1]: Epoch[278/500], iter[26950] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.67521
[2024-02-26 21:01:44,043][PyLogger][INFO]: Rank[0]: Epoch[278/500], iter[26950] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.58149
[2024-02-26 21:02:05,103][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27000] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.56455
[2024-02-26 21:02:05,103][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27000] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.91732
[2024-02-26 21:02:26,311][PyLogger][INFO]: Rank[1]: Epoch[279/500], iter[27050] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 2.04650
[2024-02-26 21:02:26,311][PyLogger][INFO]: Rank[0]: Epoch[279/500], iter[27050] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.61318
[2024-02-26 21:02:47,935][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27100] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.86705
[2024-02-26 21:02:47,935][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27100] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.55620
[2024-02-26 21:03:08,655][PyLogger][INFO]: Rank[1]: Epoch[280/500], iter[27150] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.58670
[2024-02-26 21:03:08,655][PyLogger][INFO]: Rank[0]: Epoch[280/500], iter[27150] - train_accuracy: 0.76144 - val_accuracy: 0.74360 - train_loss: 1.20060 - val_loss: 1.23288 - loss: 0.57693
[2024-02-26 21:03:49,714][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27200] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 1.33421
[2024-02-26 21:03:49,714][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27200] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.61062
[2024-02-26 21:04:10,385][PyLogger][INFO]: Rank[1]: Epoch[281/500], iter[27250] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.66436
[2024-02-26 21:04:10,385][PyLogger][INFO]: Rank[0]: Epoch[281/500], iter[27250] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.65233
[2024-02-26 21:04:30,888][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27300] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 1.01720
[2024-02-26 21:04:30,888][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27300] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.55447
[2024-02-26 21:04:51,930][PyLogger][INFO]: Rank[0]: Epoch[282/500], iter[27350] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.58882
[2024-02-26 21:04:51,930][PyLogger][INFO]: Rank[1]: Epoch[282/500], iter[27350] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.55701
[2024-02-26 21:05:13,109][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27400] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.72866
[2024-02-26 21:05:13,109][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27400] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 1.80271
[2024-02-26 21:05:32,523][PyLogger][INFO]: Rank[0]: Epoch[283/500], iter[27450] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.62480
[2024-02-26 21:05:32,523][PyLogger][INFO]: Rank[1]: Epoch[283/500], iter[27450] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.56458
[2024-02-26 21:05:53,157][PyLogger][INFO]: Rank[1]: Epoch[284/500], iter[27500] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.57628
[2024-02-26 21:05:53,157][PyLogger][INFO]: Rank[0]: Epoch[284/500], iter[27500] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.54861
[2024-02-26 21:06:14,121][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27550] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.56222
[2024-02-26 21:06:14,121][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27550] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 1.96411
[2024-02-26 21:06:34,776][PyLogger][INFO]: Rank[1]: Epoch[285/500], iter[27600] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 2.00125
[2024-02-26 21:06:34,776][PyLogger][INFO]: Rank[0]: Epoch[285/500], iter[27600] - train_accuracy: 0.73802 - val_accuracy: 0.73750 - train_loss: 1.20082 - val_loss: 1.19697 - loss: 0.54799
[2024-02-26 21:07:17,840][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27650] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.58099
[2024-02-26 21:07:17,840][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27650] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.53298
[2024-02-26 21:07:38,948][PyLogger][INFO]: Rank[0]: Epoch[286/500], iter[27700] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.55381
[2024-02-26 21:07:38,948][PyLogger][INFO]: Rank[1]: Epoch[286/500], iter[27700] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 1.35258
[2024-02-26 21:08:00,028][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27750] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.74925
[2024-02-26 21:08:00,028][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27750] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.56635
[2024-02-26 21:08:20,285][PyLogger][INFO]: Rank[1]: Epoch[287/500], iter[27800] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 2.00230
[2024-02-26 21:08:20,286][PyLogger][INFO]: Rank[0]: Epoch[287/500], iter[27800] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 1.33873
[2024-02-26 21:08:41,104][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27850] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.81265
[2024-02-26 21:08:41,105][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27850] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.54194
[2024-02-26 21:09:00,899][PyLogger][INFO]: Rank[1]: Epoch[288/500], iter[27900] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.79691
[2024-02-26 21:09:00,899][PyLogger][INFO]: Rank[0]: Epoch[288/500], iter[27900] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.59001
[2024-02-26 21:09:22,497][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[27950] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.72260
[2024-02-26 21:09:22,497][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[27950] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.65522
[2024-02-26 21:09:43,617][PyLogger][INFO]: Rank[1]: Epoch[289/500], iter[28000] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.56727
[2024-02-26 21:09:43,617][PyLogger][INFO]: Rank[0]: Epoch[289/500], iter[28000] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.56238
[2024-02-26 21:10:04,644][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28050] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 1.13580
[2024-02-26 21:10:04,644][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28050] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.93599
[2024-02-26 21:10:25,590][PyLogger][INFO]: Rank[1]: Epoch[290/500], iter[28100] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 0.61367
[2024-02-26 21:10:25,590][PyLogger][INFO]: Rank[0]: Epoch[290/500], iter[28100] - train_accuracy: 0.79416 - val_accuracy: 0.81060 - train_loss: 1.05379 - val_loss: 1.02068 - loss: 1.45651
[2024-02-26 21:11:06,978][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28150] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.64796
[2024-02-26 21:11:06,978][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28150] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 1.01122
[2024-02-26 21:11:27,262][PyLogger][INFO]: Rank[0]: Epoch[291/500], iter[28200] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.60702
[2024-02-26 21:11:27,262][PyLogger][INFO]: Rank[1]: Epoch[291/500], iter[28200] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.69321
[2024-02-26 21:11:47,985][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28250] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 1.14419
[2024-02-26 21:11:47,985][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28250] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.54651
[2024-02-26 21:12:08,251][PyLogger][INFO]: Rank[0]: Epoch[292/500], iter[28300] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.83724
[2024-02-26 21:12:08,251][PyLogger][INFO]: Rank[1]: Epoch[292/500], iter[28300] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.64140
[2024-02-26 21:12:29,020][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28350] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.59220
[2024-02-26 21:12:29,020][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28350] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.64215
[2024-02-26 21:12:48,240][PyLogger][INFO]: Rank[0]: Epoch[293/500], iter[28400] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.58308
[2024-02-26 21:12:48,240][PyLogger][INFO]: Rank[1]: Epoch[293/500], iter[28400] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.76840
[2024-02-26 21:13:10,471][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28450] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.52822
[2024-02-26 21:13:10,471][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28450] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.53763
[2024-02-26 21:13:30,650][PyLogger][INFO]: Rank[1]: Epoch[294/500], iter[28500] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.58045
[2024-02-26 21:13:30,650][PyLogger][INFO]: Rank[0]: Epoch[294/500], iter[28500] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.59235
[2024-02-26 21:13:50,955][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28550] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 1.49448
[2024-02-26 21:13:50,955][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28550] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.57470
[2024-02-26 21:14:11,469][PyLogger][INFO]: Rank[1]: Epoch[295/500], iter[28600] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.52925
[2024-02-26 21:14:11,469][PyLogger][INFO]: Rank[0]: Epoch[295/500], iter[28600] - train_accuracy: 0.77245 - val_accuracy: 0.68200 - train_loss: 1.08926 - val_loss: 1.29552 - loss: 0.58662
[2024-02-26 21:14:52,386][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28650] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.92207
[2024-02-26 21:14:52,386][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28650] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.56332
[2024-02-26 21:15:12,058][PyLogger][INFO]: Rank[1]: Epoch[296/500], iter[28700] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 2.07374
[2024-02-26 21:15:12,058][PyLogger][INFO]: Rank[0]: Epoch[296/500], iter[28700] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.55957
[2024-02-26 21:15:32,872][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28750] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.83081
[2024-02-26 21:15:32,873][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28750] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.68709
[2024-02-26 21:15:54,564][PyLogger][INFO]: Rank[1]: Epoch[297/500], iter[28800] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.71108
[2024-02-26 21:15:54,565][PyLogger][INFO]: Rank[0]: Epoch[297/500], iter[28800] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.55110
[2024-02-26 21:16:15,024][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28850] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.91884
[2024-02-26 21:16:15,024][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28850] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.34845
[2024-02-26 21:16:36,422][PyLogger][INFO]: Rank[1]: Epoch[298/500], iter[28900] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.23035
[2024-02-26 21:16:36,422][PyLogger][INFO]: Rank[0]: Epoch[298/500], iter[28900] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.55665
[2024-02-26 21:16:57,333][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[28950] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.07710
[2024-02-26 21:16:57,333][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[28950] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.08608
[2024-02-26 21:17:16,952][PyLogger][INFO]: Rank[1]: Epoch[299/500], iter[29000] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.73366
[2024-02-26 21:17:16,952][PyLogger][INFO]: Rank[0]: Epoch[299/500], iter[29000] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.11693
[2024-02-26 21:17:36,991][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29050] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 1.48146
[2024-02-26 21:17:36,991][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29050] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.58888
[2024-02-26 21:17:57,739][PyLogger][INFO]: Rank[1]: Epoch[300/500], iter[29100] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.55662
[2024-02-26 21:17:57,739][PyLogger][INFO]: Rank[0]: Epoch[300/500], iter[29100] - train_accuracy: 0.75060 - val_accuracy: 0.66710 - train_loss: 1.17657 - val_loss: 1.38660 - loss: 0.53463
[2024-02-26 21:18:40,813][PyLogger][INFO]: Rank[0]: Epoch[301/500], iter[29150] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.55843
[2024-02-26 21:18:40,813][PyLogger][INFO]: Rank[1]: Epoch[301/500], iter[29150] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.55220
[2024-02-26 21:19:00,530][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29200] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.06919
[2024-02-26 21:19:00,530][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29200] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.75060
[2024-02-26 21:19:20,391][PyLogger][INFO]: Rank[1]: Epoch[302/500], iter[29250] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.16235
[2024-02-26 21:19:20,391][PyLogger][INFO]: Rank[0]: Epoch[302/500], iter[29250] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.54592
[2024-02-26 21:19:42,078][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29300] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.52213
[2024-02-26 21:19:42,078][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29300] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.67999
[2024-02-26 21:20:02,967][PyLogger][INFO]: Rank[1]: Epoch[303/500], iter[29350] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.63512
[2024-02-26 21:20:02,967][PyLogger][INFO]: Rank[0]: Epoch[303/500], iter[29350] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.87071
[2024-02-26 21:20:23,530][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29400] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.14850
[2024-02-26 21:20:23,530][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29400] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.52887
[2024-02-26 21:20:43,816][PyLogger][INFO]: Rank[1]: Epoch[304/500], iter[29450] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.09266
[2024-02-26 21:20:43,816][PyLogger][INFO]: Rank[0]: Epoch[304/500], iter[29450] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.56820
[2024-02-26 21:21:04,829][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29500] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.82204
[2024-02-26 21:21:04,829][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29500] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 1.09229
[2024-02-26 21:21:25,196][PyLogger][INFO]: Rank[0]: Epoch[305/500], iter[29550] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.53776
[2024-02-26 21:21:25,196][PyLogger][INFO]: Rank[1]: Epoch[305/500], iter[29550] - train_accuracy: 0.71654 - val_accuracy: 0.71550 - train_loss: 1.26469 - val_loss: 1.26681 - loss: 0.53691
[2024-02-26 21:22:06,413][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29600] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.86559
[2024-02-26 21:22:06,413][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29600] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.59670
[2024-02-26 21:22:26,980][PyLogger][INFO]: Rank[0]: Epoch[306/500], iter[29650] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.79337
[2024-02-26 21:22:26,980][PyLogger][INFO]: Rank[1]: Epoch[306/500], iter[29650] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.34152
[2024-02-26 21:22:47,744][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29700] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.55515
[2024-02-26 21:22:47,744][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29700] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.54779
[2024-02-26 21:23:08,015][PyLogger][INFO]: Rank[0]: Epoch[307/500], iter[29750] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.31742
[2024-02-26 21:23:08,015][PyLogger][INFO]: Rank[1]: Epoch[307/500], iter[29750] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.54123
[2024-02-26 21:23:29,589][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29800] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.45576
[2024-02-26 21:23:29,589][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29800] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.54310
[2024-02-26 21:23:49,502][PyLogger][INFO]: Rank[1]: Epoch[308/500], iter[29850] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.14385
[2024-02-26 21:23:49,502][PyLogger][INFO]: Rank[0]: Epoch[308/500], iter[29850] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.58039
[2024-02-26 21:24:09,747][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29900] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.46328
[2024-02-26 21:24:09,747][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29900] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.56176
[2024-02-26 21:24:29,870][PyLogger][INFO]: Rank[1]: Epoch[309/500], iter[29950] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.55903
[2024-02-26 21:24:29,870][PyLogger][INFO]: Rank[0]: Epoch[309/500], iter[29950] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.61145
[2024-02-26 21:24:51,507][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30000] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.51790
[2024-02-26 21:24:51,507][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30000] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 1.82101
[2024-02-26 21:25:12,249][PyLogger][INFO]: Rank[1]: Epoch[310/500], iter[30050] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.96545
[2024-02-26 21:25:12,249][PyLogger][INFO]: Rank[0]: Epoch[310/500], iter[30050] - train_accuracy: 0.77134 - val_accuracy: 0.64150 - train_loss: 1.13083 - val_loss: 1.39615 - loss: 0.58015
[2024-02-26 21:25:54,020][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30100] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 1.79796
[2024-02-26 21:25:54,020][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30100] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.62343
[2024-02-26 21:26:14,167][PyLogger][INFO]: Rank[1]: Epoch[311/500], iter[30150] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.85235
[2024-02-26 21:26:14,167][PyLogger][INFO]: Rank[0]: Epoch[311/500], iter[30150] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.54484
[2024-02-26 21:26:34,791][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30200] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.55248
[2024-02-26 21:26:34,791][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30200] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.53085
[2024-02-26 21:26:55,951][PyLogger][INFO]: Rank[1]: Epoch[312/500], iter[30250] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.76417
[2024-02-26 21:26:55,951][PyLogger][INFO]: Rank[0]: Epoch[312/500], iter[30250] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.53327
[2024-02-26 21:27:15,495][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30300] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.75144
[2024-02-26 21:27:15,496][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30300] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.57178
[2024-02-26 21:27:36,406][PyLogger][INFO]: Rank[1]: Epoch[313/500], iter[30350] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 1.37386
[2024-02-26 21:27:36,406][PyLogger][INFO]: Rank[0]: Epoch[313/500], iter[30350] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.52634
[2024-02-26 21:27:57,757][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30400] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.58331
[2024-02-26 21:27:57,757][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30400] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.54295
[2024-02-26 21:28:17,433][PyLogger][INFO]: Rank[1]: Epoch[314/500], iter[30450] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 1.46748
[2024-02-26 21:28:17,433][PyLogger][INFO]: Rank[0]: Epoch[314/500], iter[30450] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.93269
[2024-02-26 21:28:37,659][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30500] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.76737
[2024-02-26 21:28:37,659][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30500] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.54066
[2024-02-26 21:28:57,852][PyLogger][INFO]: Rank[1]: Epoch[315/500], iter[30550] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.99409
[2024-02-26 21:28:57,852][PyLogger][INFO]: Rank[0]: Epoch[315/500], iter[30550] - train_accuracy: 0.78695 - val_accuracy: 0.77540 - train_loss: 1.05219 - val_loss: 1.08781 - loss: 0.59574
[2024-02-26 21:29:38,845][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30600] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.59185
[2024-02-26 21:29:38,845][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30600] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.58400
[2024-02-26 21:29:59,684][PyLogger][INFO]: Rank[0]: Epoch[316/500], iter[30650] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 1.30393
[2024-02-26 21:29:59,684][PyLogger][INFO]: Rank[1]: Epoch[316/500], iter[30650] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.80328
[2024-02-26 21:30:20,852][PyLogger][INFO]: Rank[1]: Epoch[317/500], iter[30700] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.60814
[2024-02-26 21:30:20,852][PyLogger][INFO]: Rank[0]: Epoch[317/500], iter[30700] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.57740
[2024-02-26 21:30:41,945][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30750] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 1.16480
[2024-02-26 21:30:41,946][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30750] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.82347
[2024-02-26 21:31:03,090][PyLogger][INFO]: Rank[0]: Epoch[318/500], iter[30800] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 2.00952
[2024-02-26 21:31:03,090][PyLogger][INFO]: Rank[1]: Epoch[318/500], iter[30800] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.55367
[2024-02-26 21:31:23,806][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30850] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.52453
[2024-02-26 21:31:23,806][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30850] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.55887
[2024-02-26 21:31:44,837][PyLogger][INFO]: Rank[1]: Epoch[319/500], iter[30900] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.53538
[2024-02-26 21:31:44,837][PyLogger][INFO]: Rank[0]: Epoch[319/500], iter[30900] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.53547
[2024-02-26 21:32:06,279][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[30950] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 2.03736
[2024-02-26 21:32:06,279][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[30950] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.54037
[2024-02-26 21:32:26,298][PyLogger][INFO]: Rank[1]: Epoch[320/500], iter[31000] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.53982
[2024-02-26 21:32:26,298][PyLogger][INFO]: Rank[0]: Epoch[320/500], iter[31000] - train_accuracy: 0.66676 - val_accuracy: 0.65640 - train_loss: 1.39767 - val_loss: 1.39335 - loss: 0.52984
[2024-02-26 21:33:07,015][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31050] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.52389
[2024-02-26 21:33:07,015][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31050] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.54329
[2024-02-26 21:33:27,150][PyLogger][INFO]: Rank[1]: Epoch[321/500], iter[31100] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.58842
[2024-02-26 21:33:27,150][PyLogger][INFO]: Rank[0]: Epoch[321/500], iter[31100] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.62397
[2024-02-26 21:33:48,072][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31150] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 1.82000
[2024-02-26 21:33:48,072][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31150] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.72908
[2024-02-26 21:34:08,712][PyLogger][INFO]: Rank[1]: Epoch[322/500], iter[31200] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 1.68710
[2024-02-26 21:34:08,712][PyLogger][INFO]: Rank[0]: Epoch[322/500], iter[31200] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 1.96268
[2024-02-26 21:34:30,241][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31250] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.52287
[2024-02-26 21:34:30,241][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31250] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.65992
[2024-02-26 21:34:49,939][PyLogger][INFO]: Rank[1]: Epoch[323/500], iter[31300] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.69646
[2024-02-26 21:34:49,939][PyLogger][INFO]: Rank[0]: Epoch[323/500], iter[31300] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 1.49673
[2024-02-26 21:35:10,370][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31350] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.53787
[2024-02-26 21:35:10,370][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31350] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.66329
[2024-02-26 21:35:31,129][PyLogger][INFO]: Rank[1]: Epoch[324/500], iter[31400] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.54896
[2024-02-26 21:35:31,129][PyLogger][INFO]: Rank[0]: Epoch[324/500], iter[31400] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.52610
[2024-02-26 21:35:51,945][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31450] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.88277
[2024-02-26 21:35:51,945][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31450] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 1.12857
[2024-02-26 21:36:12,001][PyLogger][INFO]: Rank[0]: Epoch[325/500], iter[31500] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.64525
[2024-02-26 21:36:12,001][PyLogger][INFO]: Rank[1]: Epoch[325/500], iter[31500] - train_accuracy: 0.74684 - val_accuracy: 0.78850 - train_loss: 1.16810 - val_loss: 1.09965 - loss: 0.52683
[2024-02-26 21:36:53,273][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31550] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.60876
[2024-02-26 21:36:53,273][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31550] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.56314
[2024-02-26 21:37:13,853][PyLogger][INFO]: Rank[0]: Epoch[326/500], iter[31600] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.54630
[2024-02-26 21:37:13,853][PyLogger][INFO]: Rank[1]: Epoch[326/500], iter[31600] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.54483
[2024-02-26 21:37:34,028][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31650] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.56599
[2024-02-26 21:37:34,028][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31650] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.54937
[2024-02-26 21:37:54,093][PyLogger][INFO]: Rank[0]: Epoch[327/500], iter[31700] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.56631
[2024-02-26 21:37:54,093][PyLogger][INFO]: Rank[1]: Epoch[327/500], iter[31700] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.56239
[2024-02-26 21:38:14,944][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31750] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.57766
[2024-02-26 21:38:14,944][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31750] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.51770
[2024-02-26 21:38:35,441][PyLogger][INFO]: Rank[0]: Epoch[328/500], iter[31800] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 1.93374
[2024-02-26 21:38:35,441][PyLogger][INFO]: Rank[1]: Epoch[328/500], iter[31800] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.67859
[2024-02-26 21:38:55,974][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31850] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 1.14014
[2024-02-26 21:38:55,974][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31850] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.56624
[2024-02-26 21:39:16,383][PyLogger][INFO]: Rank[1]: Epoch[329/500], iter[31900] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 1.65277
[2024-02-26 21:39:16,383][PyLogger][INFO]: Rank[0]: Epoch[329/500], iter[31900] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.55371
[2024-02-26 21:39:37,096][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[31950] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 1.76657
[2024-02-26 21:39:37,096][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[31950] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.52968
[2024-02-26 21:39:57,181][PyLogger][INFO]: Rank[1]: Epoch[330/500], iter[32000] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.53046
[2024-02-26 21:39:57,181][PyLogger][INFO]: Rank[0]: Epoch[330/500], iter[32000] - train_accuracy: 0.71305 - val_accuracy: 0.78220 - train_loss: 1.23521 - val_loss: 1.07822 - loss: 0.52316
[2024-02-26 21:40:38,491][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32050] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.70136
[2024-02-26 21:40:38,491][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32050] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.55977
[2024-02-26 21:40:58,910][PyLogger][INFO]: Rank[0]: Epoch[331/500], iter[32100] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 1.28709
[2024-02-26 21:40:58,911][PyLogger][INFO]: Rank[1]: Epoch[331/500], iter[32100] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 1.11322
[2024-02-26 21:41:20,560][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32150] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.53428
[2024-02-26 21:41:20,560][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32150] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.85365
[2024-02-26 21:41:40,766][PyLogger][INFO]: Rank[0]: Epoch[332/500], iter[32200] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.59977
[2024-02-26 21:41:40,766][PyLogger][INFO]: Rank[1]: Epoch[332/500], iter[32200] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.53127
[2024-02-26 21:42:00,839][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32250] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.58101
[2024-02-26 21:42:00,839][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32250] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.53767
[2024-02-26 21:42:21,398][PyLogger][INFO]: Rank[0]: Epoch[333/500], iter[32300] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.60434
[2024-02-26 21:42:21,398][PyLogger][INFO]: Rank[1]: Epoch[333/500], iter[32300] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.62959
[2024-02-26 21:42:42,328][PyLogger][INFO]: Rank[1]: Epoch[334/500], iter[32350] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.73500
[2024-02-26 21:42:42,329][PyLogger][INFO]: Rank[0]: Epoch[334/500], iter[32350] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.57045
[2024-02-26 21:43:02,158][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32400] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.55770
[2024-02-26 21:43:02,158][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32400] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.52259
[2024-02-26 21:43:22,744][PyLogger][INFO]: Rank[0]: Epoch[335/500], iter[32450] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.62316
[2024-02-26 21:43:22,744][PyLogger][INFO]: Rank[1]: Epoch[335/500], iter[32450] - train_accuracy: 0.79653 - val_accuracy: 0.77660 - train_loss: 1.05109 - val_loss: 1.15443 - loss: 0.88417
[2024-02-26 21:44:04,954][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32500] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.53193
[2024-02-26 21:44:04,954][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32500] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.55765
[2024-02-26 21:44:24,219][PyLogger][INFO]: Rank[0]: Epoch[336/500], iter[32550] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.85106
[2024-02-26 21:44:24,219][PyLogger][INFO]: Rank[1]: Epoch[336/500], iter[32550] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.55362
[2024-02-26 21:44:45,000][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32600] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.51707
[2024-02-26 21:44:45,000][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32600] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.53229
[2024-02-26 21:45:05,148][PyLogger][INFO]: Rank[0]: Epoch[337/500], iter[32650] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.88272
[2024-02-26 21:45:05,148][PyLogger][INFO]: Rank[1]: Epoch[337/500], iter[32650] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.54640
[2024-02-26 21:45:26,880][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32700] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.54764
[2024-02-26 21:45:26,880][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32700] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.93369
[2024-02-26 21:45:47,529][PyLogger][INFO]: Rank[1]: Epoch[338/500], iter[32750] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 1.14466
[2024-02-26 21:45:47,529][PyLogger][INFO]: Rank[0]: Epoch[338/500], iter[32750] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.58549
[2024-02-26 21:46:09,430][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32800] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.51959
[2024-02-26 21:46:09,430][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32800] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.91799
[2024-02-26 21:46:30,165][PyLogger][INFO]: Rank[1]: Epoch[339/500], iter[32850] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.92353
[2024-02-26 21:46:30,165][PyLogger][INFO]: Rank[0]: Epoch[339/500], iter[32850] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.53313
[2024-02-26 21:46:51,883][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32900] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.53138
[2024-02-26 21:46:51,883][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32900] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.51613
[2024-02-26 21:47:12,623][PyLogger][INFO]: Rank[0]: Epoch[340/500], iter[32950] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.52833
[2024-02-26 21:47:12,623][PyLogger][INFO]: Rank[1]: Epoch[340/500], iter[32950] - train_accuracy: 0.71132 - val_accuracy: 0.69290 - train_loss: 1.28520 - val_loss: 1.29885 - loss: 0.80359
[2024-02-26 21:47:53,629][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33000] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.61523
[2024-02-26 21:47:53,629][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33000] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.50778
[2024-02-26 21:48:14,294][PyLogger][INFO]: Rank[1]: Epoch[341/500], iter[33050] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.67434
[2024-02-26 21:48:14,294][PyLogger][INFO]: Rank[0]: Epoch[341/500], iter[33050] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.51531
[2024-02-26 21:48:34,719][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33100] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 1.13418
[2024-02-26 21:48:34,719][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33100] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.54199
[2024-02-26 21:48:55,177][PyLogger][INFO]: Rank[1]: Epoch[342/500], iter[33150] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.70614
[2024-02-26 21:48:55,177][PyLogger][INFO]: Rank[0]: Epoch[342/500], iter[33150] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.74057
[2024-02-26 21:49:16,453][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33200] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 1.26329
[2024-02-26 21:49:16,454][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33200] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 1.16831
[2024-02-26 21:49:36,587][PyLogger][INFO]: Rank[0]: Epoch[343/500], iter[33250] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.64453
[2024-02-26 21:49:36,587][PyLogger][INFO]: Rank[1]: Epoch[343/500], iter[33250] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.77793
[2024-02-26 21:49:58,954][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33300] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 1.29860
[2024-02-26 21:49:58,954][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33300] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.61505
[2024-02-26 21:50:20,003][PyLogger][INFO]: Rank[0]: Epoch[344/500], iter[33350] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.52710
[2024-02-26 21:50:20,003][PyLogger][INFO]: Rank[1]: Epoch[344/500], iter[33350] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.53842
[2024-02-26 21:50:40,850][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33400] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.52980
[2024-02-26 21:50:40,850][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33400] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.52642
[2024-02-26 21:51:02,332][PyLogger][INFO]: Rank[0]: Epoch[345/500], iter[33450] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 0.59886
[2024-02-26 21:51:02,332][PyLogger][INFO]: Rank[1]: Epoch[345/500], iter[33450] - train_accuracy: 0.76452 - val_accuracy: 0.68730 - train_loss: 1.20565 - val_loss: 1.35611 - loss: 2.03517
[2024-02-26 21:51:45,059][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33500] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 1.58657
[2024-02-26 21:51:45,059][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33500] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.52223
[2024-02-26 21:52:05,542][PyLogger][INFO]: Rank[0]: Epoch[346/500], iter[33550] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 1.41859
[2024-02-26 21:52:05,543][PyLogger][INFO]: Rank[1]: Epoch[346/500], iter[33550] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.53214
[2024-02-26 21:52:26,336][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33600] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.52812
[2024-02-26 21:52:26,336][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33600] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.51434
[2024-02-26 21:52:47,191][PyLogger][INFO]: Rank[0]: Epoch[347/500], iter[33650] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.50995
[2024-02-26 21:52:47,191][PyLogger][INFO]: Rank[1]: Epoch[347/500], iter[33650] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.53304
[2024-02-26 21:53:09,118][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33700] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 1.26767
[2024-02-26 21:53:09,118][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33700] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.50502
[2024-02-26 21:53:28,937][PyLogger][INFO]: Rank[0]: Epoch[348/500], iter[33750] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.53790
[2024-02-26 21:53:28,937][PyLogger][INFO]: Rank[1]: Epoch[348/500], iter[33750] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 1.27824
[2024-02-26 21:53:49,588][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33800] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.53108
[2024-02-26 21:53:49,588][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33800] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 2.03843
[2024-02-26 21:54:09,537][PyLogger][INFO]: Rank[0]: Epoch[349/500], iter[33850] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.75317
[2024-02-26 21:54:09,537][PyLogger][INFO]: Rank[1]: Epoch[349/500], iter[33850] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.51333
[2024-02-26 21:54:29,749][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33900] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 1.73922
[2024-02-26 21:54:29,749][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33900] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.70574
[2024-02-26 21:54:51,014][PyLogger][INFO]: Rank[1]: Epoch[350/500], iter[33950] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.50881
[2024-02-26 21:54:51,014][PyLogger][INFO]: Rank[0]: Epoch[350/500], iter[33950] - train_accuracy: 0.75822 - val_accuracy: 0.67810 - train_loss: 1.17452 - val_loss: 1.29709 - loss: 0.61117
[2024-02-26 21:55:32,723][PyLogger][INFO]: Rank[0]: Epoch[351/500], iter[34000] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.54466
[2024-02-26 21:55:32,723][PyLogger][INFO]: Rank[1]: Epoch[351/500], iter[34000] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 1.02846
[2024-02-26 21:55:53,158][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34050] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 1.01252
[2024-02-26 21:55:53,158][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34050] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.61617
[2024-02-26 21:56:15,147][PyLogger][INFO]: Rank[1]: Epoch[352/500], iter[34100] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 1.45383
[2024-02-26 21:56:15,147][PyLogger][INFO]: Rank[0]: Epoch[352/500], iter[34100] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.53957
[2024-02-26 21:56:35,473][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34150] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.71689
[2024-02-26 21:56:35,473][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34150] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.50991
[2024-02-26 21:56:56,182][PyLogger][INFO]: Rank[0]: Epoch[353/500], iter[34200] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.54321
[2024-02-26 21:56:56,182][PyLogger][INFO]: Rank[1]: Epoch[353/500], iter[34200] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.55895
[2024-02-26 21:57:17,498][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34250] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.57852
[2024-02-26 21:57:17,499][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34250] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.52281
[2024-02-26 21:57:37,984][PyLogger][INFO]: Rank[0]: Epoch[354/500], iter[34300] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.51823
[2024-02-26 21:57:37,984][PyLogger][INFO]: Rank[1]: Epoch[354/500], iter[34300] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 1.04472
[2024-02-26 21:57:59,263][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34350] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.51328
[2024-02-26 21:57:59,263][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34350] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.53151
[2024-02-26 21:58:20,010][PyLogger][INFO]: Rank[1]: Epoch[355/500], iter[34400] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.50744
[2024-02-26 21:58:20,010][PyLogger][INFO]: Rank[0]: Epoch[355/500], iter[34400] - train_accuracy: 0.76796 - val_accuracy: 0.73450 - train_loss: 1.12438 - val_loss: 1.17158 - loss: 0.87415
[2024-02-26 21:59:02,745][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34450] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 1.33299
[2024-02-26 21:59:02,745][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34450] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.64073
[2024-02-26 21:59:22,699][PyLogger][INFO]: Rank[1]: Epoch[356/500], iter[34500] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 1.96868
[2024-02-26 21:59:22,699][PyLogger][INFO]: Rank[0]: Epoch[356/500], iter[34500] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.54604
[2024-02-26 21:59:43,512][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34550] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 1.42887
[2024-02-26 21:59:43,512][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34550] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.69810
[2024-02-26 22:00:03,693][PyLogger][INFO]: Rank[0]: Epoch[357/500], iter[34600] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.84951
[2024-02-26 22:00:03,693][PyLogger][INFO]: Rank[1]: Epoch[357/500], iter[34600] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.51501
[2024-02-26 22:00:24,112][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34650] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.60652
[2024-02-26 22:00:24,112][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34650] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.52266
[2024-02-26 22:00:44,363][PyLogger][INFO]: Rank[0]: Epoch[358/500], iter[34700] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.86065
[2024-02-26 22:00:44,363][PyLogger][INFO]: Rank[1]: Epoch[358/500], iter[34700] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.51467
[2024-02-26 22:01:04,845][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34750] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 1.61506
[2024-02-26 22:01:04,845][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34750] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.58060
[2024-02-26 22:01:25,101][PyLogger][INFO]: Rank[0]: Epoch[359/500], iter[34800] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.52133
[2024-02-26 22:01:25,101][PyLogger][INFO]: Rank[1]: Epoch[359/500], iter[34800] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.97008
[2024-02-26 22:01:45,787][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34850] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.54613
[2024-02-26 22:01:45,787][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34850] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.53081
[2024-02-26 22:02:05,935][PyLogger][INFO]: Rank[1]: Epoch[360/500], iter[34900] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.51349
[2024-02-26 22:02:05,935][PyLogger][INFO]: Rank[0]: Epoch[360/500], iter[34900] - train_accuracy: 0.80902 - val_accuracy: 0.72560 - train_loss: 1.01505 - val_loss: 1.21220 - loss: 0.52608
[2024-02-26 22:02:47,265][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[34950] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 1.37645
[2024-02-26 22:02:47,265][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[34950] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.67914
[2024-02-26 22:03:07,708][PyLogger][INFO]: Rank[0]: Epoch[361/500], iter[35000] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 1.17085
[2024-02-26 22:03:07,708][PyLogger][INFO]: Rank[1]: Epoch[361/500], iter[35000] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 1.02529
[2024-02-26 22:03:28,538][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35050] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.56627
[2024-02-26 22:03:28,538][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35050] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.53041
[2024-02-26 22:03:50,656][PyLogger][INFO]: Rank[0]: Epoch[362/500], iter[35100] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.55295
[2024-02-26 22:03:50,656][PyLogger][INFO]: Rank[1]: Epoch[362/500], iter[35100] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.52296
[2024-02-26 22:04:10,989][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35150] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.51186
[2024-02-26 22:04:10,989][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35150] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.51728
[2024-02-26 22:04:32,330][PyLogger][INFO]: Rank[1]: Epoch[363/500], iter[35200] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.50579
[2024-02-26 22:04:32,330][PyLogger][INFO]: Rank[0]: Epoch[363/500], iter[35200] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 1.67386
[2024-02-26 22:04:53,811][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35250] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.50949
[2024-02-26 22:04:53,811][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35250] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.56368
[2024-02-26 22:05:14,705][PyLogger][INFO]: Rank[0]: Epoch[364/500], iter[35300] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 1.23853
[2024-02-26 22:05:14,705][PyLogger][INFO]: Rank[1]: Epoch[364/500], iter[35300] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.52436
[2024-02-26 22:05:35,033][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35350] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.57513
[2024-02-26 22:05:35,033][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35350] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.52120
[2024-02-26 22:05:56,057][PyLogger][INFO]: Rank[1]: Epoch[365/500], iter[35400] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.50897
[2024-02-26 22:05:56,057][PyLogger][INFO]: Rank[0]: Epoch[365/500], iter[35400] - train_accuracy: 0.74990 - val_accuracy: 0.73610 - train_loss: 1.19858 - val_loss: 1.21882 - loss: 0.79338
[2024-02-26 22:06:37,833][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35450] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.68777
[2024-02-26 22:06:37,833][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35450] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.70447
[2024-02-26 22:06:57,663][PyLogger][INFO]: Rank[1]: Epoch[366/500], iter[35500] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 2.01906
[2024-02-26 22:06:57,663][PyLogger][INFO]: Rank[0]: Epoch[366/500], iter[35500] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.50610
[2024-02-26 22:07:17,687][PyLogger][INFO]: Rank[1]: Epoch[367/500], iter[35550] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 1.17124
[2024-02-26 22:07:17,687][PyLogger][INFO]: Rank[0]: Epoch[367/500], iter[35550] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.51035
[2024-02-26 22:07:37,819][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35600] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.50358
[2024-02-26 22:07:37,819][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35600] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.51233
[2024-02-26 22:07:58,024][PyLogger][INFO]: Rank[1]: Epoch[368/500], iter[35650] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.52124
[2024-02-26 22:07:58,024][PyLogger][INFO]: Rank[0]: Epoch[368/500], iter[35650] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.50757
[2024-02-26 22:08:18,678][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35700] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.63391
[2024-02-26 22:08:18,678][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35700] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.57159
[2024-02-26 22:08:39,535][PyLogger][INFO]: Rank[1]: Epoch[369/500], iter[35750] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.61563
[2024-02-26 22:08:39,535][PyLogger][INFO]: Rank[0]: Epoch[369/500], iter[35750] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.59305
[2024-02-26 22:09:00,434][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35800] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.52844
[2024-02-26 22:09:00,434][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35800] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 1.62621
[2024-02-26 22:09:20,837][PyLogger][INFO]: Rank[0]: Epoch[370/500], iter[35850] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 1.37994
[2024-02-26 22:09:20,837][PyLogger][INFO]: Rank[1]: Epoch[370/500], iter[35850] - train_accuracy: 0.76140 - val_accuracy: 0.70470 - train_loss: 1.15221 - val_loss: 1.25336 - loss: 0.60551
[2024-02-26 22:10:02,698][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35900] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51654
[2024-02-26 22:10:02,698][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35900] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.50615
[2024-02-26 22:10:24,116][PyLogger][INFO]: Rank[0]: Epoch[371/500], iter[35950] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.55340
[2024-02-26 22:10:24,116][PyLogger][INFO]: Rank[1]: Epoch[371/500], iter[35950] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.53551
[2024-02-26 22:10:45,438][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36000] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 1.20005
[2024-02-26 22:10:45,438][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36000] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 1.37315
[2024-02-26 22:11:05,437][PyLogger][INFO]: Rank[1]: Epoch[372/500], iter[36050] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51735
[2024-02-26 22:11:05,437][PyLogger][INFO]: Rank[0]: Epoch[372/500], iter[36050] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51910
[2024-02-26 22:11:26,113][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36100] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 1.22580
[2024-02-26 22:11:26,113][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36100] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.61967
[2024-02-26 22:11:46,312][PyLogger][INFO]: Rank[1]: Epoch[373/500], iter[36150] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.50938
[2024-02-26 22:11:46,312][PyLogger][INFO]: Rank[0]: Epoch[373/500], iter[36150] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.50680
[2024-02-26 22:12:07,557][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36200] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.50480
[2024-02-26 22:12:07,557][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36200] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51918
[2024-02-26 22:12:27,477][PyLogger][INFO]: Rank[1]: Epoch[374/500], iter[36250] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51037
[2024-02-26 22:12:27,477][PyLogger][INFO]: Rank[0]: Epoch[374/500], iter[36250] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 1.98610
[2024-02-26 22:12:47,262][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36300] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.95082
[2024-02-26 22:12:47,262][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36300] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.52667
[2024-02-26 22:13:07,326][PyLogger][INFO]: Rank[0]: Epoch[375/500], iter[36350] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 1.16079
[2024-02-26 22:13:07,326][PyLogger][INFO]: Rank[1]: Epoch[375/500], iter[36350] - train_accuracy: 0.79305 - val_accuracy: 0.78490 - train_loss: 1.05237 - val_loss: 1.09106 - loss: 0.51132
[2024-02-26 22:13:49,299][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36400] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.50916
[2024-02-26 22:13:49,299][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36400] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.42946
[2024-02-26 22:14:09,389][PyLogger][INFO]: Rank[0]: Epoch[376/500], iter[36450] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.00209
[2024-02-26 22:14:09,389][PyLogger][INFO]: Rank[1]: Epoch[376/500], iter[36450] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.50787
[2024-02-26 22:14:30,162][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36500] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.63739
[2024-02-26 22:14:30,162][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36500] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.06281
[2024-02-26 22:14:50,764][PyLogger][INFO]: Rank[1]: Epoch[377/500], iter[36550] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.50797
[2024-02-26 22:14:50,764][PyLogger][INFO]: Rank[0]: Epoch[377/500], iter[36550] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.56547
[2024-02-26 22:15:11,877][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36600] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.12105
[2024-02-26 22:15:11,878][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36600] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.84128
[2024-02-26 22:15:32,451][PyLogger][INFO]: Rank[0]: Epoch[378/500], iter[36650] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.84557
[2024-02-26 22:15:32,451][PyLogger][INFO]: Rank[1]: Epoch[378/500], iter[36650] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.50631
[2024-02-26 22:15:52,355][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36700] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.22997
[2024-02-26 22:15:52,355][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36700] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.60197
[2024-02-26 22:16:13,138][PyLogger][INFO]: Rank[1]: Epoch[379/500], iter[36750] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.79352
[2024-02-26 22:16:13,138][PyLogger][INFO]: Rank[0]: Epoch[379/500], iter[36750] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.56652
[2024-02-26 22:16:32,342][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36800] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.55019
[2024-02-26 22:16:32,342][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36800] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.50819
[2024-02-26 22:16:51,743][PyLogger][INFO]: Rank[1]: Epoch[380/500], iter[36850] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 1.32568
[2024-02-26 22:16:51,743][PyLogger][INFO]: Rank[0]: Epoch[380/500], iter[36850] - train_accuracy: 0.79253 - val_accuracy: 0.72310 - train_loss: 1.08320 - val_loss: 1.19586 - loss: 0.66022
[2024-02-26 22:17:33,241][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36900] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.53885
[2024-02-26 22:17:33,241][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36900] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 2.03219
[2024-02-26 22:17:54,176][PyLogger][INFO]: Rank[1]: Epoch[381/500], iter[36950] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.53804
[2024-02-26 22:17:54,176][PyLogger][INFO]: Rank[0]: Epoch[381/500], iter[36950] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.52809
[2024-02-26 22:18:15,255][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37000] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.54011
[2024-02-26 22:18:15,255][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37000] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.51857
[2024-02-26 22:18:35,657][PyLogger][INFO]: Rank[1]: Epoch[382/500], iter[37050] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.50669
[2024-02-26 22:18:35,657][PyLogger][INFO]: Rank[0]: Epoch[382/500], iter[37050] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.52316
[2024-02-26 22:18:57,771][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37100] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.52235
[2024-02-26 22:18:57,771][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37100] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 1.68505
[2024-02-26 22:19:19,077][PyLogger][INFO]: Rank[1]: Epoch[383/500], iter[37150] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.51785
[2024-02-26 22:19:19,077][PyLogger][INFO]: Rank[0]: Epoch[383/500], iter[37150] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.52949
[2024-02-26 22:19:39,333][PyLogger][INFO]: Rank[0]: Epoch[384/500], iter[37200] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.64551
[2024-02-26 22:19:39,333][PyLogger][INFO]: Rank[1]: Epoch[384/500], iter[37200] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.51900
[2024-02-26 22:20:00,939][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37250] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 1.59520
[2024-02-26 22:20:00,939][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37250] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.94156
[2024-02-26 22:20:20,779][PyLogger][INFO]: Rank[1]: Epoch[385/500], iter[37300] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.51442
[2024-02-26 22:20:20,779][PyLogger][INFO]: Rank[0]: Epoch[385/500], iter[37300] - train_accuracy: 0.83066 - val_accuracy: 0.80330 - train_loss: 0.96818 - val_loss: 1.00868 - loss: 0.61044
[2024-02-26 22:21:02,166][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37350] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 1.10773
[2024-02-26 22:21:02,166][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37350] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.51655
[2024-02-26 22:21:23,095][PyLogger][INFO]: Rank[0]: Epoch[386/500], iter[37400] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.54828
[2024-02-26 22:21:23,095][PyLogger][INFO]: Rank[1]: Epoch[386/500], iter[37400] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.50400
[2024-02-26 22:21:44,565][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37450] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 1.51339
[2024-02-26 22:21:44,565][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37450] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.70808
[2024-02-26 22:22:04,993][PyLogger][INFO]: Rank[1]: Epoch[387/500], iter[37500] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 1.60903
[2024-02-26 22:22:04,993][PyLogger][INFO]: Rank[0]: Epoch[387/500], iter[37500] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.51926
[2024-02-26 22:22:26,360][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37550] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.52302
[2024-02-26 22:22:26,360][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37550] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.63922
[2024-02-26 22:22:46,810][PyLogger][INFO]: Rank[1]: Epoch[388/500], iter[37600] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 1.55901
[2024-02-26 22:22:46,810][PyLogger][INFO]: Rank[0]: Epoch[388/500], iter[37600] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.57510
[2024-02-26 22:23:07,904][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37650] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.50795
[2024-02-26 22:23:07,904][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37650] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.51618
[2024-02-26 22:23:28,493][PyLogger][INFO]: Rank[1]: Epoch[389/500], iter[37700] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.77935
[2024-02-26 22:23:28,493][PyLogger][INFO]: Rank[0]: Epoch[389/500], iter[37700] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.50938
[2024-02-26 22:23:49,912][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37750] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.51458
[2024-02-26 22:23:49,912][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37750] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.50937
[2024-02-26 22:24:10,335][PyLogger][INFO]: Rank[1]: Epoch[390/500], iter[37800] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 0.52255
[2024-02-26 22:24:10,335][PyLogger][INFO]: Rank[0]: Epoch[390/500], iter[37800] - train_accuracy: 0.80408 - val_accuracy: 0.75170 - train_loss: 1.01481 - val_loss: 1.13484 - loss: 1.38299
[2024-02-26 22:24:52,037][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37850] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50844
[2024-02-26 22:24:52,037][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37850] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.52273
[2024-02-26 22:25:12,611][PyLogger][INFO]: Rank[1]: Epoch[391/500], iter[37900] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 2.04510
[2024-02-26 22:25:12,611][PyLogger][INFO]: Rank[0]: Epoch[391/500], iter[37900] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 1.16555
[2024-02-26 22:25:33,244][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[37950] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.77283
[2024-02-26 22:25:33,244][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[37950] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.54767
[2024-02-26 22:25:53,675][PyLogger][INFO]: Rank[1]: Epoch[392/500], iter[38000] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.59470
[2024-02-26 22:25:53,675][PyLogger][INFO]: Rank[0]: Epoch[392/500], iter[38000] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50601
[2024-02-26 22:26:15,001][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38050] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.51093
[2024-02-26 22:26:15,001][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38050] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50643
[2024-02-26 22:26:35,316][PyLogger][INFO]: Rank[1]: Epoch[393/500], iter[38100] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.52353
[2024-02-26 22:26:35,316][PyLogger][INFO]: Rank[0]: Epoch[393/500], iter[38100] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.51197
[2024-02-26 22:26:56,532][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38150] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50321
[2024-02-26 22:26:56,532][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38150] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.51779
[2024-02-26 22:27:16,826][PyLogger][INFO]: Rank[0]: Epoch[394/500], iter[38200] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50459
[2024-02-26 22:27:16,826][PyLogger][INFO]: Rank[1]: Epoch[394/500], iter[38200] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50323
[2024-02-26 22:27:38,567][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38250] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.96254
[2024-02-26 22:27:38,567][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38250] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50572
[2024-02-26 22:27:59,026][PyLogger][INFO]: Rank[1]: Epoch[395/500], iter[38300] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.95510
[2024-02-26 22:27:59,027][PyLogger][INFO]: Rank[0]: Epoch[395/500], iter[38300] - train_accuracy: 0.83539 - val_accuracy: 0.80660 - train_loss: 0.93206 - val_loss: 1.06417 - loss: 0.50828
[2024-02-26 22:28:39,722][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38350] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.51834
[2024-02-26 22:28:39,722][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38350] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50737
[2024-02-26 22:29:00,204][PyLogger][INFO]: Rank[0]: Epoch[396/500], iter[38400] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 1.29744
[2024-02-26 22:29:00,204][PyLogger][INFO]: Rank[1]: Epoch[396/500], iter[38400] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50474
[2024-02-26 22:29:20,816][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38450] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.52044
[2024-02-26 22:29:20,816][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38450] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 1.79332
[2024-02-26 22:29:40,661][PyLogger][INFO]: Rank[1]: Epoch[397/500], iter[38500] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50542
[2024-02-26 22:29:40,661][PyLogger][INFO]: Rank[0]: Epoch[397/500], iter[38500] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50724
[2024-02-26 22:30:01,700][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38550] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 1.14353
[2024-02-26 22:30:01,700][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38550] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 1.04655
[2024-02-26 22:30:21,875][PyLogger][INFO]: Rank[0]: Epoch[398/500], iter[38600] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50498
[2024-02-26 22:30:21,875][PyLogger][INFO]: Rank[1]: Epoch[398/500], iter[38600] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50633
[2024-02-26 22:30:42,603][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38650] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.53301
[2024-02-26 22:30:42,603][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38650] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.50458
[2024-02-26 22:31:02,572][PyLogger][INFO]: Rank[0]: Epoch[399/500], iter[38700] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.53892
[2024-02-26 22:31:02,572][PyLogger][INFO]: Rank[1]: Epoch[399/500], iter[38700] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.51573
[2024-02-26 22:31:22,801][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38750] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.56275
[2024-02-26 22:31:22,801][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38750] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.51349
[2024-02-26 22:31:43,409][PyLogger][INFO]: Rank[0]: Epoch[400/500], iter[38800] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 1.55076
[2024-02-26 22:31:43,409][PyLogger][INFO]: Rank[1]: Epoch[400/500], iter[38800] - train_accuracy: 0.80171 - val_accuracy: 0.67620 - train_loss: 1.10797 - val_loss: 1.40234 - loss: 0.87703
[2024-02-26 22:32:24,596][PyLogger][INFO]: Rank[1]: Epoch[401/500], iter[38850] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.76174
[2024-02-26 22:32:24,596][PyLogger][INFO]: Rank[0]: Epoch[401/500], iter[38850] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.50327
[2024-02-26 22:32:46,819][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38900] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.50946
[2024-02-26 22:32:46,819][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38900] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.55440
[2024-02-26 22:33:06,548][PyLogger][INFO]: Rank[0]: Epoch[402/500], iter[38950] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 1.54499
[2024-02-26 22:33:06,548][PyLogger][INFO]: Rank[1]: Epoch[402/500], iter[38950] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.61214
[2024-02-26 22:33:27,485][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39000] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.51482
[2024-02-26 22:33:27,485][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39000] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.52072
[2024-02-26 22:33:48,784][PyLogger][INFO]: Rank[1]: Epoch[403/500], iter[39050] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.92325
[2024-02-26 22:33:48,784][PyLogger][INFO]: Rank[0]: Epoch[403/500], iter[39050] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.50610
[2024-02-26 22:34:09,952][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39100] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 1.94268
[2024-02-26 22:34:09,952][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39100] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.50451
[2024-02-26 22:34:30,312][PyLogger][INFO]: Rank[0]: Epoch[404/500], iter[39150] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.50303
[2024-02-26 22:34:30,312][PyLogger][INFO]: Rank[1]: Epoch[404/500], iter[39150] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.51662
[2024-02-26 22:34:51,580][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39200] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.79418
[2024-02-26 22:34:51,580][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39200] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.66344
[2024-02-26 22:35:12,109][PyLogger][INFO]: Rank[1]: Epoch[405/500], iter[39250] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 1.52143
[2024-02-26 22:35:12,110][PyLogger][INFO]: Rank[0]: Epoch[405/500], iter[39250] - train_accuracy: 0.75077 - val_accuracy: 0.68360 - train_loss: 1.21382 - val_loss: 1.33708 - loss: 0.59744
[2024-02-26 22:35:53,065][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39300] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.54654
[2024-02-26 22:35:53,066][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39300] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.50291
[2024-02-26 22:36:13,740][PyLogger][INFO]: Rank[1]: Epoch[406/500], iter[39350] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.54458
[2024-02-26 22:36:13,740][PyLogger][INFO]: Rank[0]: Epoch[406/500], iter[39350] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.51714
[2024-02-26 22:36:34,686][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39400] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 1.41610
[2024-02-26 22:36:34,686][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39400] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.65170
[2024-02-26 22:36:55,322][PyLogger][INFO]: Rank[1]: Epoch[407/500], iter[39450] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.52182
[2024-02-26 22:36:55,322][PyLogger][INFO]: Rank[0]: Epoch[407/500], iter[39450] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.50453
[2024-02-26 22:37:16,001][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39500] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.52614
[2024-02-26 22:37:16,001][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39500] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.52558
[2024-02-26 22:37:36,526][PyLogger][INFO]: Rank[0]: Epoch[408/500], iter[39550] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.61299
[2024-02-26 22:37:36,526][PyLogger][INFO]: Rank[1]: Epoch[408/500], iter[39550] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.50840
[2024-02-26 22:37:57,194][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39600] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.73701
[2024-02-26 22:37:57,194][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39600] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.51668
[2024-02-26 22:38:17,683][PyLogger][INFO]: Rank[1]: Epoch[409/500], iter[39650] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.61110
[2024-02-26 22:38:17,683][PyLogger][INFO]: Rank[0]: Epoch[409/500], iter[39650] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 1.79518
[2024-02-26 22:38:38,452][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39700] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.50317
[2024-02-26 22:38:38,452][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39700] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.61434
[2024-02-26 22:38:59,443][PyLogger][INFO]: Rank[1]: Epoch[410/500], iter[39750] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.61556
[2024-02-26 22:38:59,443][PyLogger][INFO]: Rank[0]: Epoch[410/500], iter[39750] - train_accuracy: 0.78463 - val_accuracy: 0.76750 - train_loss: 1.16051 - val_loss: 1.15534 - loss: 0.50386
[2024-02-26 22:39:41,682][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39800] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.50361
[2024-02-26 22:39:41,682][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39800] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.51878
[2024-02-26 22:40:01,844][PyLogger][INFO]: Rank[1]: Epoch[411/500], iter[39850] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.68563
[2024-02-26 22:40:01,844][PyLogger][INFO]: Rank[0]: Epoch[411/500], iter[39850] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.63179
[2024-02-26 22:40:21,224][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39900] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.56856
[2024-02-26 22:40:21,224][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39900] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.50328
[2024-02-26 22:40:41,427][PyLogger][INFO]: Rank[1]: Epoch[412/500], iter[39950] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 1.99424
[2024-02-26 22:40:41,427][PyLogger][INFO]: Rank[0]: Epoch[412/500], iter[39950] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.55585
[2024-02-26 22:41:02,265][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40000] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.73420
[2024-02-26 22:41:02,265][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40000] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.51516
[2024-02-26 22:41:22,864][PyLogger][INFO]: Rank[1]: Epoch[413/500], iter[40050] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.76250
[2024-02-26 22:41:22,864][PyLogger][INFO]: Rank[0]: Epoch[413/500], iter[40050] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.72514
[2024-02-26 22:41:43,785][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40100] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.51142
[2024-02-26 22:41:43,785][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40100] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 1.02265
[2024-02-26 22:42:03,649][PyLogger][INFO]: Rank[1]: Epoch[414/500], iter[40150] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 1.44400
[2024-02-26 22:42:03,649][PyLogger][INFO]: Rank[0]: Epoch[414/500], iter[40150] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.56981
[2024-02-26 22:42:25,266][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40200] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 2.10013
[2024-02-26 22:42:25,266][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40200] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.51409
[2024-02-26 22:42:45,286][PyLogger][INFO]: Rank[0]: Epoch[415/500], iter[40250] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.50863
[2024-02-26 22:42:45,286][PyLogger][INFO]: Rank[1]: Epoch[415/500], iter[40250] - train_accuracy: 0.81832 - val_accuracy: 0.71440 - train_loss: 0.97630 - val_loss: 1.20696 - loss: 0.50435
[2024-02-26 22:43:28,431][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40300] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50427
[2024-02-26 22:43:28,431][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40300] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 1.06347
[2024-02-26 22:43:49,257][PyLogger][INFO]: Rank[1]: Epoch[416/500], iter[40350] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.68862
[2024-02-26 22:43:49,257][PyLogger][INFO]: Rank[0]: Epoch[416/500], iter[40350] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50416
[2024-02-26 22:44:10,114][PyLogger][INFO]: Rank[0]: Epoch[417/500], iter[40400] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.77666
[2024-02-26 22:44:10,114][PyLogger][INFO]: Rank[1]: Epoch[417/500], iter[40400] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50511
[2024-02-26 22:44:31,437][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40450] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50598
[2024-02-26 22:44:31,437][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40450] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50515
[2024-02-26 22:44:51,488][PyLogger][INFO]: Rank[0]: Epoch[418/500], iter[40500] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50550
[2024-02-26 22:44:51,488][PyLogger][INFO]: Rank[1]: Epoch[418/500], iter[40500] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50183
[2024-02-26 22:45:12,083][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40550] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50145
[2024-02-26 22:45:12,083][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40550] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50832
[2024-02-26 22:45:32,551][PyLogger][INFO]: Rank[1]: Epoch[419/500], iter[40600] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.51254
[2024-02-26 22:45:32,551][PyLogger][INFO]: Rank[0]: Epoch[419/500], iter[40600] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50775
[2024-02-26 22:45:53,467][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40650] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.52662
[2024-02-26 22:45:53,467][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40650] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.50303
[2024-02-26 22:46:13,616][PyLogger][INFO]: Rank[0]: Epoch[420/500], iter[40700] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.65017
[2024-02-26 22:46:13,616][PyLogger][INFO]: Rank[1]: Epoch[420/500], iter[40700] - train_accuracy: 0.80586 - val_accuracy: 0.71070 - train_loss: 1.01236 - val_loss: 1.24503 - loss: 0.52941
[2024-02-26 22:46:54,432][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40750] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50241
[2024-02-26 22:46:54,432][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40750] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50536
[2024-02-26 22:47:14,360][PyLogger][INFO]: Rank[0]: Epoch[421/500], iter[40800] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.97067
[2024-02-26 22:47:14,361][PyLogger][INFO]: Rank[1]: Epoch[421/500], iter[40800] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50408
[2024-02-26 22:47:35,000][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40850] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50707
[2024-02-26 22:47:35,000][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40850] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50362
[2024-02-26 22:47:55,536][PyLogger][INFO]: Rank[0]: Epoch[422/500], iter[40900] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 1.99224
[2024-02-26 22:47:55,536][PyLogger][INFO]: Rank[1]: Epoch[422/500], iter[40900] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50455
[2024-02-26 22:48:17,532][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[40950] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.62511
[2024-02-26 22:48:17,532][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[40950] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.61397
[2024-02-26 22:48:37,306][PyLogger][INFO]: Rank[0]: Epoch[423/500], iter[41000] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.53366
[2024-02-26 22:48:37,306][PyLogger][INFO]: Rank[1]: Epoch[423/500], iter[41000] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.90925
[2024-02-26 22:48:58,335][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41050] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50184
[2024-02-26 22:48:58,335][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41050] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50386
[2024-02-26 22:49:18,411][PyLogger][INFO]: Rank[0]: Epoch[424/500], iter[41100] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.67085
[2024-02-26 22:49:18,411][PyLogger][INFO]: Rank[1]: Epoch[424/500], iter[41100] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 1.34656
[2024-02-26 22:49:40,452][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41150] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50326
[2024-02-26 22:49:40,452][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41150] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 0.50418
[2024-02-26 22:50:00,935][PyLogger][INFO]: Rank[0]: Epoch[425/500], iter[41200] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 1.06493
[2024-02-26 22:50:00,935][PyLogger][INFO]: Rank[1]: Epoch[425/500], iter[41200] - train_accuracy: 0.83839 - val_accuracy: 0.75150 - train_loss: 1.00040 - val_loss: 1.16238 - loss: 1.56724
[2024-02-26 22:50:42,807][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41250] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50384
[2024-02-26 22:50:42,807][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41250] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50868
[2024-02-26 22:51:02,703][PyLogger][INFO]: Rank[1]: Epoch[426/500], iter[41300] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.69448
[2024-02-26 22:51:02,704][PyLogger][INFO]: Rank[0]: Epoch[426/500], iter[41300] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.52604
[2024-02-26 22:51:24,013][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41350] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.51545
[2024-02-26 22:51:24,013][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41350] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.51211
[2024-02-26 22:51:44,370][PyLogger][INFO]: Rank[0]: Epoch[427/500], iter[41400] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 1.36072
[2024-02-26 22:51:44,370][PyLogger][INFO]: Rank[1]: Epoch[427/500], iter[41400] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50976
[2024-02-26 22:52:05,125][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41450] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.97520
[2024-02-26 22:52:05,125][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41450] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.51029
[2024-02-26 22:52:25,680][PyLogger][INFO]: Rank[0]: Epoch[428/500], iter[41500] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50243
[2024-02-26 22:52:25,680][PyLogger][INFO]: Rank[1]: Epoch[428/500], iter[41500] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50214
[2024-02-26 22:52:46,038][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41550] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 1.55633
[2024-02-26 22:52:46,038][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41550] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50156
[2024-02-26 22:53:06,167][PyLogger][INFO]: Rank[1]: Epoch[429/500], iter[41600] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 1.69539
[2024-02-26 22:53:06,167][PyLogger][INFO]: Rank[0]: Epoch[429/500], iter[41600] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.58207
[2024-02-26 22:53:28,141][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41650] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50377
[2024-02-26 22:53:28,141][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41650] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50131
[2024-02-26 22:53:48,916][PyLogger][INFO]: Rank[1]: Epoch[430/500], iter[41700] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.72282
[2024-02-26 22:53:48,916][PyLogger][INFO]: Rank[0]: Epoch[430/500], iter[41700] - train_accuracy: 0.85335 - val_accuracy: 0.70790 - train_loss: 0.91582 - val_loss: 1.23317 - loss: 0.50312
[2024-02-26 22:54:31,079][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41750] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.51229
[2024-02-26 22:54:31,079][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41750] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50182
[2024-02-26 22:54:51,924][PyLogger][INFO]: Rank[0]: Epoch[431/500], iter[41800] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.65228
[2024-02-26 22:54:51,924][PyLogger][INFO]: Rank[1]: Epoch[431/500], iter[41800] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50241
[2024-02-26 22:55:12,922][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41850] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.62674
[2024-02-26 22:55:12,922][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41850] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50133
[2024-02-26 22:55:34,140][PyLogger][INFO]: Rank[0]: Epoch[432/500], iter[41900] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50392
[2024-02-26 22:55:34,140][PyLogger][INFO]: Rank[1]: Epoch[432/500], iter[41900] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50182
[2024-02-26 22:55:55,153][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[41950] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.63542
[2024-02-26 22:55:55,153][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[41950] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.58753
[2024-02-26 22:56:15,208][PyLogger][INFO]: Rank[0]: Epoch[433/500], iter[42000] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50675
[2024-02-26 22:56:15,208][PyLogger][INFO]: Rank[1]: Epoch[433/500], iter[42000] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50174
[2024-02-26 22:56:35,605][PyLogger][INFO]: Rank[1]: Epoch[434/500], iter[42050] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.86569
[2024-02-26 22:56:35,605][PyLogger][INFO]: Rank[0]: Epoch[434/500], iter[42050] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 1.97531
[2024-02-26 22:56:56,110][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42100] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 1.29992
[2024-02-26 22:56:56,110][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42100] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.52274
[2024-02-26 22:57:16,345][PyLogger][INFO]: Rank[0]: Epoch[435/500], iter[42150] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.95797
[2024-02-26 22:57:16,345][PyLogger][INFO]: Rank[1]: Epoch[435/500], iter[42150] - train_accuracy: 0.81592 - val_accuracy: 0.72810 - train_loss: 1.06326 - val_loss: 1.21678 - loss: 0.50518
[2024-02-26 22:57:58,181][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42200] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50589
[2024-02-26 22:57:58,181][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42200] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.52467
[2024-02-26 22:58:18,865][PyLogger][INFO]: Rank[1]: Epoch[436/500], iter[42250] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.51439
[2024-02-26 22:58:18,865][PyLogger][INFO]: Rank[0]: Epoch[436/500], iter[42250] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 1.55160
[2024-02-26 22:58:38,623][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42300] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50301
[2024-02-26 22:58:38,623][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42300] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.55639
[2024-02-26 22:58:59,680][PyLogger][INFO]: Rank[1]: Epoch[437/500], iter[42350] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50518
[2024-02-26 22:58:59,680][PyLogger][INFO]: Rank[0]: Epoch[437/500], iter[42350] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50424
[2024-02-26 22:59:20,117][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42400] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.51959
[2024-02-26 22:59:20,117][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42400] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50128
[2024-02-26 22:59:39,673][PyLogger][INFO]: Rank[0]: Epoch[438/500], iter[42450] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.60996
[2024-02-26 22:59:39,673][PyLogger][INFO]: Rank[1]: Epoch[438/500], iter[42450] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50616
[2024-02-26 23:00:00,636][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42500] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50198
[2024-02-26 23:00:00,636][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42500] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50139
[2024-02-26 23:00:22,005][PyLogger][INFO]: Rank[0]: Epoch[439/500], iter[42550] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50549
[2024-02-26 23:00:22,005][PyLogger][INFO]: Rank[1]: Epoch[439/500], iter[42550] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50224
[2024-02-26 23:00:43,853][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42600] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 1.25205
[2024-02-26 23:00:43,853][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42600] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50476
[2024-02-26 23:01:04,416][PyLogger][INFO]: Rank[0]: Epoch[440/500], iter[42650] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.50900
[2024-02-26 23:01:04,416][PyLogger][INFO]: Rank[1]: Epoch[440/500], iter[42650] - train_accuracy: 0.82871 - val_accuracy: 0.77960 - train_loss: 0.98587 - val_loss: 1.16347 - loss: 0.88503
[2024-02-26 23:01:46,405][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42700] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.53316
[2024-02-26 23:01:46,405][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42700] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.53708
[2024-02-26 23:02:06,527][PyLogger][INFO]: Rank[0]: Epoch[441/500], iter[42750] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.57697
[2024-02-26 23:02:06,528][PyLogger][INFO]: Rank[1]: Epoch[441/500], iter[42750] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50842
[2024-02-26 23:02:26,768][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42800] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.96539
[2024-02-26 23:02:26,768][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42800] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 1.54794
[2024-02-26 23:02:46,258][PyLogger][INFO]: Rank[1]: Epoch[442/500], iter[42850] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50446
[2024-02-26 23:02:46,258][PyLogger][INFO]: Rank[0]: Epoch[442/500], iter[42850] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.89433
[2024-02-26 23:03:07,248][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42900] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 1.12631
[2024-02-26 23:03:07,248][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42900] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50445
[2024-02-26 23:03:27,288][PyLogger][INFO]: Rank[1]: Epoch[443/500], iter[42950] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 1.47832
[2024-02-26 23:03:27,288][PyLogger][INFO]: Rank[0]: Epoch[443/500], iter[42950] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50185
[2024-02-26 23:03:47,775][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43000] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.51032
[2024-02-26 23:03:47,775][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43000] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50195
[2024-02-26 23:04:07,821][PyLogger][INFO]: Rank[0]: Epoch[444/500], iter[43050] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 1.36039
[2024-02-26 23:04:07,821][PyLogger][INFO]: Rank[1]: Epoch[444/500], iter[43050] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 1.40660
[2024-02-26 23:04:29,049][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43100] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50643
[2024-02-26 23:04:29,049][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43100] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.81241
[2024-02-26 23:04:49,528][PyLogger][INFO]: Rank[1]: Epoch[445/500], iter[43150] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50451
[2024-02-26 23:04:49,528][PyLogger][INFO]: Rank[0]: Epoch[445/500], iter[43150] - train_accuracy: 0.84768 - val_accuracy: 0.83010 - train_loss: 0.95049 - val_loss: 1.01604 - loss: 0.50314
[2024-02-26 23:05:30,165][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43200] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50151
[2024-02-26 23:05:30,165][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43200] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 1.14043
[2024-02-26 23:05:51,078][PyLogger][INFO]: Rank[0]: Epoch[446/500], iter[43250] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.52414
[2024-02-26 23:05:51,078][PyLogger][INFO]: Rank[1]: Epoch[446/500], iter[43250] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50304
[2024-02-26 23:06:12,989][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43300] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.74045
[2024-02-26 23:06:12,989][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43300] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50148
[2024-02-26 23:06:33,892][PyLogger][INFO]: Rank[0]: Epoch[447/500], iter[43350] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.56324
[2024-02-26 23:06:33,892][PyLogger][INFO]: Rank[1]: Epoch[447/500], iter[43350] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 1.90310
[2024-02-26 23:06:55,609][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43400] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.51673
[2024-02-26 23:06:55,609][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43400] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50114
[2024-02-26 23:07:16,187][PyLogger][INFO]: Rank[1]: Epoch[448/500], iter[43450] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50299
[2024-02-26 23:07:16,187][PyLogger][INFO]: Rank[0]: Epoch[448/500], iter[43450] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50214
[2024-02-26 23:07:38,089][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43500] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 1.61422
[2024-02-26 23:07:38,089][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43500] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50140
[2024-02-26 23:07:59,292][PyLogger][INFO]: Rank[1]: Epoch[449/500], iter[43550] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.58369
[2024-02-26 23:07:59,292][PyLogger][INFO]: Rank[0]: Epoch[449/500], iter[43550] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50124
[2024-02-26 23:08:20,693][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43600] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50220
[2024-02-26 23:08:20,693][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43600] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50224
[2024-02-26 23:08:41,546][PyLogger][INFO]: Rank[1]: Epoch[450/500], iter[43650] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50155
[2024-02-26 23:08:41,546][PyLogger][INFO]: Rank[0]: Epoch[450/500], iter[43650] - train_accuracy: 0.82110 - val_accuracy: 0.79450 - train_loss: 1.04959 - val_loss: 1.06706 - loss: 0.50248
[2024-02-26 23:09:24,091][PyLogger][INFO]: Rank[1]: Epoch[451/500], iter[43700] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.51435
[2024-02-26 23:09:24,091][PyLogger][INFO]: Rank[0]: Epoch[451/500], iter[43700] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50181
[2024-02-26 23:09:45,178][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43750] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50305
[2024-02-26 23:09:45,178][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43750] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50310
[2024-02-26 23:10:05,585][PyLogger][INFO]: Rank[0]: Epoch[452/500], iter[43800] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.56611
[2024-02-26 23:10:05,586][PyLogger][INFO]: Rank[1]: Epoch[452/500], iter[43800] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.51207
[2024-02-26 23:10:26,134][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43850] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50140
[2024-02-26 23:10:26,134][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43850] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.59008
[2024-02-26 23:10:46,182][PyLogger][INFO]: Rank[0]: Epoch[453/500], iter[43900] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.53986
[2024-02-26 23:10:46,182][PyLogger][INFO]: Rank[1]: Epoch[453/500], iter[43900] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.59362
[2024-02-26 23:11:06,382][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[43950] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50399
[2024-02-26 23:11:06,383][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[43950] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.51425
[2024-02-26 23:11:26,394][PyLogger][INFO]: Rank[0]: Epoch[454/500], iter[44000] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50389
[2024-02-26 23:11:26,394][PyLogger][INFO]: Rank[1]: Epoch[454/500], iter[44000] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.81217
[2024-02-26 23:11:46,740][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44050] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 1.92070
[2024-02-26 23:11:46,740][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44050] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 1.66806
[2024-02-26 23:12:08,086][PyLogger][INFO]: Rank[1]: Epoch[455/500], iter[44100] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.89377
[2024-02-26 23:12:08,086][PyLogger][INFO]: Rank[0]: Epoch[455/500], iter[44100] - train_accuracy: 0.80940 - val_accuracy: 0.83020 - train_loss: 0.97236 - val_loss: 1.03656 - loss: 0.50519
[2024-02-26 23:12:50,526][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44150] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.52824
[2024-02-26 23:12:50,527][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44150] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50247
[2024-02-26 23:13:11,234][PyLogger][INFO]: Rank[0]: Epoch[456/500], iter[44200] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.66328
[2024-02-26 23:13:11,235][PyLogger][INFO]: Rank[1]: Epoch[456/500], iter[44200] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50145
[2024-02-26 23:13:32,883][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44250] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.83155
[2024-02-26 23:13:32,883][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44250] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50467
[2024-02-26 23:13:54,406][PyLogger][INFO]: Rank[0]: Epoch[457/500], iter[44300] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.51464
[2024-02-26 23:13:54,406][PyLogger][INFO]: Rank[1]: Epoch[457/500], iter[44300] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 1.94106
[2024-02-26 23:14:15,145][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44350] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 1.14857
[2024-02-26 23:14:15,146][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44350] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50130
[2024-02-26 23:14:34,639][PyLogger][INFO]: Rank[1]: Epoch[458/500], iter[44400] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50229
[2024-02-26 23:14:34,639][PyLogger][INFO]: Rank[0]: Epoch[458/500], iter[44400] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50109
[2024-02-26 23:14:55,722][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44450] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50228
[2024-02-26 23:14:55,722][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44450] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 2.00186
[2024-02-26 23:15:15,684][PyLogger][INFO]: Rank[0]: Epoch[459/500], iter[44500] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 1.94123
[2024-02-26 23:15:15,684][PyLogger][INFO]: Rank[1]: Epoch[459/500], iter[44500] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.51489
[2024-02-26 23:15:37,078][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44550] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.61103
[2024-02-26 23:15:37,078][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44550] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 1.96824
[2024-02-26 23:15:57,296][PyLogger][INFO]: Rank[1]: Epoch[460/500], iter[44600] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.51849
[2024-02-26 23:15:57,296][PyLogger][INFO]: Rank[0]: Epoch[460/500], iter[44600] - train_accuracy: 0.84828 - val_accuracy: 0.80640 - train_loss: 0.94846 - val_loss: 1.03306 - loss: 0.50414
[2024-02-26 23:16:40,609][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44650] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50138
[2024-02-26 23:16:40,609][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44650] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50175
[2024-02-26 23:17:00,495][PyLogger][INFO]: Rank[0]: Epoch[461/500], iter[44700] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.87874
[2024-02-26 23:17:00,495][PyLogger][INFO]: Rank[1]: Epoch[461/500], iter[44700] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.51700
[2024-02-26 23:17:22,120][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44750] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.75595
[2024-02-26 23:17:22,120][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44750] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.51774
[2024-02-26 23:17:42,013][PyLogger][INFO]: Rank[1]: Epoch[462/500], iter[44800] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.75053
[2024-02-26 23:17:42,013][PyLogger][INFO]: Rank[0]: Epoch[462/500], iter[44800] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.56888
[2024-02-26 23:18:02,737][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44850] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50187
[2024-02-26 23:18:02,737][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44850] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50235
[2024-02-26 23:18:24,319][PyLogger][INFO]: Rank[1]: Epoch[463/500], iter[44900] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50616
[2024-02-26 23:18:24,319][PyLogger][INFO]: Rank[0]: Epoch[463/500], iter[44900] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.65230
[2024-02-26 23:18:45,682][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[44950] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50186
[2024-02-26 23:18:45,682][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[44950] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50123
[2024-02-26 23:19:05,918][PyLogger][INFO]: Rank[1]: Epoch[464/500], iter[45000] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50224
[2024-02-26 23:19:05,918][PyLogger][INFO]: Rank[0]: Epoch[464/500], iter[45000] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 1.70212
[2024-02-26 23:19:26,793][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45050] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50110
[2024-02-26 23:19:26,793][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45050] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50122
[2024-02-26 23:19:46,506][PyLogger][INFO]: Rank[1]: Epoch[465/500], iter[45100] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 1.62071
[2024-02-26 23:19:46,506][PyLogger][INFO]: Rank[0]: Epoch[465/500], iter[45100] - train_accuracy: 0.81578 - val_accuracy: 0.78910 - train_loss: 0.99741 - val_loss: 1.07403 - loss: 0.50131
[2024-02-26 23:20:28,090][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45150] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.83414
[2024-02-26 23:20:28,090][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45150] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50263
[2024-02-26 23:20:48,295][PyLogger][INFO]: Rank[0]: Epoch[466/500], iter[45200] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50641
[2024-02-26 23:20:48,295][PyLogger][INFO]: Rank[1]: Epoch[466/500], iter[45200] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50390
[2024-02-26 23:21:09,641][PyLogger][INFO]: Rank[0]: Epoch[467/500], iter[45250] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 1.08686
[2024-02-26 23:21:09,641][PyLogger][INFO]: Rank[1]: Epoch[467/500], iter[45250] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50158
[2024-02-26 23:21:30,717][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45300] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.71639
[2024-02-26 23:21:30,717][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45300] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50372
[2024-02-26 23:21:51,364][PyLogger][INFO]: Rank[1]: Epoch[468/500], iter[45350] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 1.96962
[2024-02-26 23:21:51,364][PyLogger][INFO]: Rank[0]: Epoch[468/500], iter[45350] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.51106
[2024-02-26 23:22:11,970][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45400] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50424
[2024-02-26 23:22:11,970][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45400] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50201
[2024-02-26 23:22:32,671][PyLogger][INFO]: Rank[1]: Epoch[469/500], iter[45450] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 1.12168
[2024-02-26 23:22:32,671][PyLogger][INFO]: Rank[0]: Epoch[469/500], iter[45450] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50130
[2024-02-26 23:22:53,331][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45500] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 1.12867
[2024-02-26 23:22:53,331][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45500] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50255
[2024-02-26 23:23:14,021][PyLogger][INFO]: Rank[1]: Epoch[470/500], iter[45550] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.50142
[2024-02-26 23:23:14,021][PyLogger][INFO]: Rank[0]: Epoch[470/500], iter[45550] - train_accuracy: 0.85575 - val_accuracy: 0.75940 - train_loss: 0.99218 - val_loss: 1.15723 - loss: 0.56006
[2024-02-26 23:23:55,472][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45600] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50156
[2024-02-26 23:23:55,472][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45600] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.55668
[2024-02-26 23:24:16,421][PyLogger][INFO]: Rank[1]: Epoch[471/500], iter[45650] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50220
[2024-02-26 23:24:16,421][PyLogger][INFO]: Rank[0]: Epoch[471/500], iter[45650] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50171
[2024-02-26 23:24:37,327][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45700] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.66702
[2024-02-26 23:24:37,327][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45700] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 1.95947
[2024-02-26 23:24:57,292][PyLogger][INFO]: Rank[0]: Epoch[472/500], iter[45750] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 1.58781
[2024-02-26 23:24:57,293][PyLogger][INFO]: Rank[1]: Epoch[472/500], iter[45750] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.60050
[2024-02-26 23:25:18,531][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45800] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 1.54143
[2024-02-26 23:25:18,531][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45800] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50124
[2024-02-26 23:25:38,641][PyLogger][INFO]: Rank[0]: Epoch[473/500], iter[45850] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.53930
[2024-02-26 23:25:38,641][PyLogger][INFO]: Rank[1]: Epoch[473/500], iter[45850] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.59527
[2024-02-26 23:25:58,689][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45900] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 1.22922
[2024-02-26 23:25:58,689][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45900] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50346
[2024-02-26 23:26:20,120][PyLogger][INFO]: Rank[0]: Epoch[474/500], iter[45950] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 2.04919
[2024-02-26 23:26:20,120][PyLogger][INFO]: Rank[1]: Epoch[474/500], iter[45950] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 1.12819
[2024-02-26 23:26:41,108][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46000] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.53916
[2024-02-26 23:26:41,108][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46000] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50977
[2024-02-26 23:27:01,657][PyLogger][INFO]: Rank[0]: Epoch[475/500], iter[46050] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50225
[2024-02-26 23:27:01,657][PyLogger][INFO]: Rank[1]: Epoch[475/500], iter[46050] - train_accuracy: 0.75759 - val_accuracy: 0.72610 - train_loss: 1.21872 - val_loss: 1.24291 - loss: 0.50334
[2024-02-26 23:27:41,864][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46100] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.51458
[2024-02-26 23:27:41,864][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46100] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50206
[2024-02-26 23:28:00,461][PyLogger][INFO]: Rank[1]: Epoch[476/500], iter[46150] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.84903
[2024-02-26 23:28:00,461][PyLogger][INFO]: Rank[0]: Epoch[476/500], iter[46150] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50455
[2024-02-26 23:28:21,053][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46200] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 1.04486
[2024-02-26 23:28:21,053][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46200] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.60129
[2024-02-26 23:28:42,553][PyLogger][INFO]: Rank[0]: Epoch[477/500], iter[46250] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 1.27245
[2024-02-26 23:28:42,553][PyLogger][INFO]: Rank[1]: Epoch[477/500], iter[46250] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50739
[2024-02-26 23:29:04,477][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46300] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 1.21577
[2024-02-26 23:29:04,477][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46300] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50122
[2024-02-26 23:29:25,394][PyLogger][INFO]: Rank[1]: Epoch[478/500], iter[46350] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50703
[2024-02-26 23:29:25,394][PyLogger][INFO]: Rank[0]: Epoch[478/500], iter[46350] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50279
[2024-02-26 23:29:46,845][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46400] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50410
[2024-02-26 23:29:46,846][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46400] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 1.13865
[2024-02-26 23:30:07,562][PyLogger][INFO]: Rank[0]: Epoch[479/500], iter[46450] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 1.63538
[2024-02-26 23:30:07,562][PyLogger][INFO]: Rank[1]: Epoch[479/500], iter[46450] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.52738
[2024-02-26 23:30:28,834][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46500] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50131
[2024-02-26 23:30:28,835][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46500] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50175
[2024-02-26 23:30:50,297][PyLogger][INFO]: Rank[0]: Epoch[480/500], iter[46550] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 2.00502
[2024-02-26 23:30:50,297][PyLogger][INFO]: Rank[1]: Epoch[480/500], iter[46550] - train_accuracy: 0.80485 - val_accuracy: 0.76400 - train_loss: 1.05346 - val_loss: 1.13609 - loss: 0.50382
[2024-02-26 23:31:33,008][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46600] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50180
[2024-02-26 23:31:33,008][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46600] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.55477
[2024-02-26 23:31:54,182][PyLogger][INFO]: Rank[0]: Epoch[481/500], iter[46650] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 1.72027
[2024-02-26 23:31:54,182][PyLogger][INFO]: Rank[1]: Epoch[481/500], iter[46650] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.83932
[2024-02-26 23:32:14,946][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46700] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50813
[2024-02-26 23:32:14,946][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46700] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.90593
[2024-02-26 23:32:35,708][PyLogger][INFO]: Rank[1]: Epoch[482/500], iter[46750] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.52019
[2024-02-26 23:32:35,708][PyLogger][INFO]: Rank[0]: Epoch[482/500], iter[46750] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50160
[2024-02-26 23:32:57,178][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46800] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.69065
[2024-02-26 23:32:57,178][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46800] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50605
[2024-02-26 23:33:17,640][PyLogger][INFO]: Rank[0]: Epoch[483/500], iter[46850] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.65946
[2024-02-26 23:33:17,640][PyLogger][INFO]: Rank[1]: Epoch[483/500], iter[46850] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50161
[2024-02-26 23:33:38,207][PyLogger][INFO]: Rank[1]: Epoch[484/500], iter[46900] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 1.45583
[2024-02-26 23:33:38,207][PyLogger][INFO]: Rank[0]: Epoch[484/500], iter[46900] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50185
[2024-02-26 23:33:59,832][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[46950] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 1.21311
[2024-02-26 23:33:59,832][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[46950] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50121
[2024-02-26 23:34:20,245][PyLogger][INFO]: Rank[1]: Epoch[485/500], iter[47000] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 2.00659
[2024-02-26 23:34:20,245][PyLogger][INFO]: Rank[0]: Epoch[485/500], iter[47000] - train_accuracy: 0.82023 - val_accuracy: 0.73950 - train_loss: 1.06081 - val_loss: 1.21526 - loss: 0.50308
[2024-02-26 23:35:01,898][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47050] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 1.21076
[2024-02-26 23:35:01,899][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47050] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50128
[2024-02-26 23:35:22,760][PyLogger][INFO]: Rank[0]: Epoch[486/500], iter[47100] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50097
[2024-02-26 23:35:22,760][PyLogger][INFO]: Rank[1]: Epoch[486/500], iter[47100] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50521
[2024-02-26 23:35:44,661][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47150] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 1.70755
[2024-02-26 23:35:44,661][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47150] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.56889
[2024-02-26 23:36:05,040][PyLogger][INFO]: Rank[1]: Epoch[487/500], iter[47200] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50201
[2024-02-26 23:36:05,040][PyLogger][INFO]: Rank[0]: Epoch[487/500], iter[47200] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50111
[2024-02-26 23:36:25,345][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47250] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.68171
[2024-02-26 23:36:25,345][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47250] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50322
[2024-02-26 23:36:44,985][PyLogger][INFO]: Rank[0]: Epoch[488/500], iter[47300] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50590
[2024-02-26 23:36:44,985][PyLogger][INFO]: Rank[1]: Epoch[488/500], iter[47300] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.66074
[2024-02-26 23:37:06,336][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47350] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50866
[2024-02-26 23:37:06,336][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47350] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50534
[2024-02-26 23:37:27,223][PyLogger][INFO]: Rank[1]: Epoch[489/500], iter[47400] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 2.07015
[2024-02-26 23:37:27,224][PyLogger][INFO]: Rank[0]: Epoch[489/500], iter[47400] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50138
[2024-02-26 23:37:48,403][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47450] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50179
[2024-02-26 23:37:48,403][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47450] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50114
[2024-02-26 23:38:09,774][PyLogger][INFO]: Rank[1]: Epoch[490/500], iter[47500] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.84263
[2024-02-26 23:38:09,774][PyLogger][INFO]: Rank[0]: Epoch[490/500], iter[47500] - train_accuracy: 0.84590 - val_accuracy: 0.77940 - train_loss: 0.94878 - val_loss: 1.07713 - loss: 0.50171
[2024-02-26 23:38:52,075][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47550] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50284
[2024-02-26 23:38:52,075][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47550] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50214
[2024-02-26 23:39:13,397][PyLogger][INFO]: Rank[0]: Epoch[491/500], iter[47600] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50240
[2024-02-26 23:39:13,397][PyLogger][INFO]: Rank[1]: Epoch[491/500], iter[47600] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50227
[2024-02-26 23:39:33,735][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47650] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.92256
[2024-02-26 23:39:33,735][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47650] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.54475
[2024-02-26 23:39:53,973][PyLogger][INFO]: Rank[1]: Epoch[492/500], iter[47700] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 1.46755
[2024-02-26 23:39:53,973][PyLogger][INFO]: Rank[0]: Epoch[492/500], iter[47700] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.53350
[2024-02-26 23:40:15,148][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47750] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.55606
[2024-02-26 23:40:15,148][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47750] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 1.07353
[2024-02-26 23:40:35,555][PyLogger][INFO]: Rank[0]: Epoch[493/500], iter[47800] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.57203
[2024-02-26 23:40:35,555][PyLogger][INFO]: Rank[1]: Epoch[493/500], iter[47800] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.57176
[2024-02-26 23:40:57,183][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47850] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.63762
[2024-02-26 23:40:57,183][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47850] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50191
[2024-02-26 23:41:18,220][PyLogger][INFO]: Rank[0]: Epoch[494/500], iter[47900] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50156
[2024-02-26 23:41:18,221][PyLogger][INFO]: Rank[1]: Epoch[494/500], iter[47900] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50098
[2024-02-26 23:41:38,700][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[47950] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.51815
[2024-02-26 23:41:38,700][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[47950] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.50107
[2024-02-26 23:41:57,906][PyLogger][INFO]: Rank[0]: Epoch[495/500], iter[48000] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.51371
[2024-02-26 23:41:57,906][PyLogger][INFO]: Rank[1]: Epoch[495/500], iter[48000] - train_accuracy: 0.83600 - val_accuracy: 0.63820 - train_loss: 0.99718 - val_loss: 1.38303 - loss: 0.67561
[2024-02-26 23:42:39,067][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48050] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.51587
[2024-02-26 23:42:39,067][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48050] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.54473
[2024-02-26 23:42:59,436][PyLogger][INFO]: Rank[0]: Epoch[496/500], iter[48100] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.60163
[2024-02-26 23:42:59,437][PyLogger][INFO]: Rank[1]: Epoch[496/500], iter[48100] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50190
[2024-02-26 23:43:20,890][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48150] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.66264
[2024-02-26 23:43:20,890][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48150] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.32127
[2024-02-26 23:43:41,789][PyLogger][INFO]: Rank[0]: Epoch[497/500], iter[48200] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50131
[2024-02-26 23:43:41,789][PyLogger][INFO]: Rank[1]: Epoch[497/500], iter[48200] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50096
[2024-02-26 23:44:03,402][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48250] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50105
[2024-02-26 23:44:03,402][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48250] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50114
[2024-02-26 23:44:23,852][PyLogger][INFO]: Rank[1]: Epoch[498/500], iter[48300] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.32754
[2024-02-26 23:44:23,852][PyLogger][INFO]: Rank[0]: Epoch[498/500], iter[48300] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50168
[2024-02-26 23:44:44,158][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48350] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50255
[2024-02-26 23:44:44,158][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48350] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.51764
[2024-02-26 23:45:04,053][PyLogger][INFO]: Rank[0]: Epoch[499/500], iter[48400] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.52626
[2024-02-26 23:45:04,054][PyLogger][INFO]: Rank[1]: Epoch[499/500], iter[48400] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.70016
[2024-02-26 23:45:25,779][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48450] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.69024
[2024-02-26 23:45:25,779][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48450] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 0.50125
[2024-02-26 23:45:45,674][PyLogger][INFO]: Rank[1]: Epoch[500/500], iter[48500] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.19523
[2024-02-26 23:45:45,674][PyLogger][INFO]: Rank[0]: Epoch[500/500], iter[48500] - train_accuracy: 0.81947 - val_accuracy: 0.76140 - train_loss: 1.03752 - val_loss: 1.14309 - loss: 1.21817
Files already downloaded and verified
Files already downloaded and verified
2024-02-26 23:46:09,740 ignite.distributed.launcher.Parallel INFO: End of run
2024-02-26 23:46:14,466 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:46:14,466 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:46:14,466 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15269954a3e0>' in 2 processes
2024-02-26 23:46:22,689 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:46:23,099 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15215c83e810>}
[2024-02-26 23:46:24,227][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:46:24,227][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:46:24,227][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:24,227][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:46:24,228][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:46:24,228][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:24,228][PyLogger][INFO]: World size: 2
[2024-02-26 23:46:24,229][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:24,229][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:24,229][PyLogger][INFO]: World size: 2
[2024-02-26 23:46:27,666][PyLogger][INFO]: Rank[0]: val_accuracy: 0.22200
[2024-02-26 23:46:27,666][PyLogger][INFO]: Rank[1]: val_accuracy: 0.22200
2024-02-26 23:46:29,100 ignite.distributed.launcher.Parallel INFO: End of run
new_size=2 done.
2024-02-26 23:46:33,186 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:46:33,186 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:46:33,186 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e6002923e0>' in 2 processes
2024-02-26 23:46:41,881 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:46:42,290 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154a1f9f1dc0>}
[2024-02-26 23:46:42,407][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:46:42,407][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:46:42,407][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:42,407][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:46:42,408][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:46:42,408][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:42,408][PyLogger][INFO]: World size: 2
[2024-02-26 23:46:42,410][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:42,410][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:42,410][PyLogger][INFO]: World size: 2
[2024-02-26 23:46:45,776][PyLogger][INFO]: Rank[1]: val_accuracy: 0.38340
[2024-02-26 23:46:45,776][PyLogger][INFO]: Rank[0]: val_accuracy: 0.38340
2024-02-26 23:46:47,231 ignite.distributed.launcher.Parallel INFO: End of run
new_size=3 done.
2024-02-26 23:46:51,280 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:46:51,280 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:46:51,280 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d1eb4ca3e0>' in 2 processes
2024-02-26 23:46:59,214 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:46:59,637 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149f7b708920>}
[2024-02-26 23:46:59,755][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:59,755][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:59,755][PyLogger][INFO]: World size: 2
[2024-02-26 23:46:59,759][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:46:59,759][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:46:59,759][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:46:59,759][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:46:59,760][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:46:59,760][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:46:59,760][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:03,291][PyLogger][INFO]: Rank[1]: val_accuracy: 0.46230
[2024-02-26 23:47:03,291][PyLogger][INFO]: Rank[0]: val_accuracy: 0.46230
2024-02-26 23:47:04,318 ignite.distributed.launcher.Parallel INFO: End of run
new_size=4 done.
2024-02-26 23:47:07,876 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:47:07,877 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:47:07,877 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14eb371fe3e0>' in 2 processes
2024-02-26 23:47:14,769 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:47:15,164 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14a797254e00>}
[2024-02-26 23:47:15,275][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:15,275][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:15,275][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:15,282][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:47:15,282][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:47:15,282][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:15,282][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:47:15,283][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:47:15,283][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:15,283][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:18,770][PyLogger][INFO]: Rank[1]: val_accuracy: 0.53610
[2024-02-26 23:47:18,770][PyLogger][INFO]: Rank[0]: val_accuracy: 0.53610
2024-02-26 23:47:19,791 ignite.distributed.launcher.Parallel INFO: End of run
new_size=5 done.
2024-02-26 23:47:23,752 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:47:23,752 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:47:23,752 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150fb42c23e0>' in 2 processes
2024-02-26 23:47:30,745 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:47:31,152 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x146ccec04440>}
[2024-02-26 23:47:31,264][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:31,264][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:31,264][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:31,269][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:47:31,269][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:47:31,269][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:31,269][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:47:31,270][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:47:31,270][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:31,270][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:34,732][PyLogger][INFO]: Rank[0]: val_accuracy: 0.60580
[2024-02-26 23:47:34,732][PyLogger][INFO]: Rank[1]: val_accuracy: 0.60580
2024-02-26 23:47:36,139 ignite.distributed.launcher.Parallel INFO: End of run
new_size=6 done.
2024-02-26 23:47:39,685 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:47:39,685 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:47:39,685 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x152e58cf63e0>' in 2 processes
2024-02-26 23:47:46,743 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:47:47,136 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d2f6228500>}
[2024-02-26 23:47:47,248][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:47:47,248][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:47:47,248][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:47,248][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:47:47,250][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:47:47,250][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:47,250][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:47,254][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:47:47,254][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:47:47,255][PyLogger][INFO]: World size: 2
[2024-02-26 23:47:50,727][PyLogger][INFO]: Rank[0]: val_accuracy: 0.66770
[2024-02-26 23:47:50,727][PyLogger][INFO]: Rank[1]: val_accuracy: 0.66770
2024-02-26 23:47:51,724 ignite.distributed.launcher.Parallel INFO: End of run
new_size=7 done.
2024-02-26 23:47:55,296 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:47:55,296 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:47:55,296 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14cf7260e3e0>' in 2 processes
2024-02-26 23:48:03,184 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:48:03,598 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x146ec3ac16a0>}
[2024-02-26 23:48:03,709][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:03,709][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:03,709][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:03,712][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:48:03,712][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:48:03,712][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:03,712][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:48:03,713][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:48:03,713][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:03,713][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:07,203][PyLogger][INFO]: Rank[0]: val_accuracy: 0.69620
[2024-02-26 23:48:07,203][PyLogger][INFO]: Rank[1]: val_accuracy: 0.69620
2024-02-26 23:48:08,668 ignite.distributed.launcher.Parallel INFO: End of run
new_size=8 done.
2024-02-26 23:48:12,383 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:48:12,383 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:48:12,383 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14e8fa9be3e0>' in 2 processes
2024-02-26 23:48:20,109 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:48:20,516 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x152b0ed4c380>}
[2024-02-26 23:48:20,635][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:48:20,635][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:48:20,635][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:20,635][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:48:20,636][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:48:20,636][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:20,636][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:20,636][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:20,636][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:20,637][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:24,293][PyLogger][INFO]: Rank[0]: val_accuracy: 0.75460
[2024-02-26 23:48:24,293][PyLogger][INFO]: Rank[1]: val_accuracy: 0.75460
2024-02-26 23:48:25,842 ignite.distributed.launcher.Parallel INFO: End of run
new_size=9 done.
2024-02-26 23:48:29,860 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:48:29,860 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:48:29,860 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150ca2c563e0>' in 2 processes
2024-02-26 23:48:37,878 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:48:38,287 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14ffedb21a00>}
[2024-02-26 23:48:38,400][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:38,401][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:38,401][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:38,404][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:48:38,404][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:48:38,405][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:38,405][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:48:38,406][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:48:38,406][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:38,406][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:42,055][PyLogger][INFO]: Rank[0]: val_accuracy: 0.77150
[2024-02-26 23:48:42,055][PyLogger][INFO]: Rank[1]: val_accuracy: 0.77150
2024-02-26 23:48:43,513 ignite.distributed.launcher.Parallel INFO: End of run
new_size=10 done.
2024-02-26 23:48:47,120 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:48:47,120 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:48:47,120 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1552a119e3e0>' in 2 processes
2024-02-26 23:48:54,108 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:48:54,538 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1508ef439f40>}
[2024-02-26 23:48:54,652][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:48:54,652][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:48:54,652][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:54,652][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:48:54,653][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:48:54,653][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:54,653][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:54,661][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:48:54,661][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:48:54,661][PyLogger][INFO]: World size: 2
[2024-02-26 23:48:58,400][PyLogger][INFO]: Rank[0]: val_accuracy: 0.79910
[2024-02-26 23:48:58,400][PyLogger][INFO]: Rank[1]: val_accuracy: 0.79910
2024-02-26 23:48:59,425 ignite.distributed.launcher.Parallel INFO: End of run
new_size=11 done.
2024-02-26 23:49:03,074 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:49:03,074 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:49:03,074 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14d7ead963e0>' in 2 processes
2024-02-26 23:49:09,800 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:49:10,217 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x153fd83b5ac0>}
[2024-02-26 23:49:10,330][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:49:10,330][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:49:10,330][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:10,330][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:49:10,331][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:49:10,331][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:10,331][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:10,339][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:10,339][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:10,339][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:14,010][PyLogger][INFO]: Rank[0]: val_accuracy: 0.81570
[2024-02-26 23:49:14,010][PyLogger][INFO]: Rank[1]: val_accuracy: 0.81570
2024-02-26 23:49:15,031 ignite.distributed.launcher.Parallel INFO: End of run
new_size=12 done.
2024-02-26 23:49:18,730 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:49:18,730 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:49:18,730 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146e7cd563e0>' in 2 processes
2024-02-26 23:49:26,537 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:49:26,934 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1548427d0140>}
[2024-02-26 23:49:27,051][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:27,051][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:27,051][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:27,054][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:49:27,055][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:49:27,055][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:27,055][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:49:27,056][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:49:27,056][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:27,056][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:30,809][PyLogger][INFO]: Rank[0]: val_accuracy: 0.82790
[2024-02-26 23:49:30,809][PyLogger][INFO]: Rank[1]: val_accuracy: 0.82790
2024-02-26 23:49:31,880 ignite.distributed.launcher.Parallel INFO: End of run
new_size=13 done.
2024-02-26 23:49:35,836 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:49:35,836 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:49:35,836 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x149d3a9c23e0>' in 2 processes
2024-02-26 23:49:43,031 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:49:43,433 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1470b9515460>}
[2024-02-26 23:49:43,548][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:43,549][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:43,549][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:43,550][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:49:43,550][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:49:43,550][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:43,550][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:49:43,551][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:49:43,551][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:43,551][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:47,300][PyLogger][INFO]: Rank[0]: val_accuracy: 0.84060
[2024-02-26 23:49:47,300][PyLogger][INFO]: Rank[1]: val_accuracy: 0.84060
2024-02-26 23:49:48,723 ignite.distributed.launcher.Parallel INFO: End of run
new_size=14 done.
2024-02-26 23:49:52,292 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:49:52,292 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:49:52,292 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150fce26a3e0>' in 2 processes
2024-02-26 23:49:59,144 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:49:59,555 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14aff99fce30>}
[2024-02-26 23:49:59,669][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:59,669][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:59,669][PyLogger][INFO]: World size: 2
[2024-02-26 23:49:59,673][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:49:59,673][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:49:59,674][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:49:59,674][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:49:59,674][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:49:59,675][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:49:59,675][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:03,497][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85620
[2024-02-26 23:50:03,497][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85620
2024-02-26 23:50:04,911 ignite.distributed.launcher.Parallel INFO: End of run
new_size=15 done.
2024-02-26 23:50:08,408 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:50:08,408 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:50:08,408 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1494ddff23e0>' in 2 processes
2024-02-26 23:50:15,210 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:50:15,613 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14de9418d460>}
[2024-02-26 23:50:15,731][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:15,731][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:15,731][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:15,732][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:50:15,732][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:50:15,732][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:15,732][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:50:15,733][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:50:15,733][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:15,733][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:19,524][PyLogger][INFO]: Rank[0]: val_accuracy: 0.86670
[2024-02-26 23:50:19,524][PyLogger][INFO]: Rank[1]: val_accuracy: 0.86670
2024-02-26 23:50:20,942 ignite.distributed.launcher.Parallel INFO: End of run
new_size=16 done.
2024-02-26 23:50:24,591 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:50:24,591 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:50:24,591 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14dd7629e3e0>' in 2 processes
2024-02-26 23:50:31,365 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:50:31,763 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x146be7b18680>}
[2024-02-26 23:50:31,883][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:50:31,883][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:50:31,883][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:31,883][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:50:31,884][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:50:31,884][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:31,885][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:31,885][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:31,885][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:31,885][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:35,998][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85990
[2024-02-26 23:50:35,998][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85990
2024-02-26 23:50:37,419 ignite.distributed.launcher.Parallel INFO: End of run
new_size=17 done.
2024-02-26 23:50:41,479 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:50:41,479 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:50:41,479 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x145ee13f23e0>' in 2 processes
2024-02-26 23:50:49,551 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:50:49,951 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14924b42c740>}
[2024-02-26 23:50:50,062][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:50:50,062][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:50:50,062][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:50,062][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:50:50,063][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:50:50,063][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:50,063][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:50,070][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:50:50,071][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:50:50,071][PyLogger][INFO]: World size: 2
[2024-02-26 23:50:54,174][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85480
[2024-02-26 23:50:54,174][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85480
2024-02-26 23:50:55,681 ignite.distributed.launcher.Parallel INFO: End of run
new_size=18 done.
2024-02-26 23:50:59,357 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:50:59,357 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:50:59,357 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x148ad97b23e0>' in 2 processes
2024-02-26 23:51:07,301 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:51:07,709 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b30395a930>}
[2024-02-26 23:51:07,828][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:51:07,828][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:51:07,828][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:07,828][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:51:07,829][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:51:07,829][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:07,829][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:07,829][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:07,830][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:07,830][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:11,789][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85630
[2024-02-26 23:51:11,789][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85630
2024-02-26 23:51:12,863 ignite.distributed.launcher.Parallel INFO: End of run
new_size=19 done.
2024-02-26 23:51:16,476 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:51:16,476 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:51:16,476 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1550967923e0>' in 2 processes
2024-02-26 23:51:23,189 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:51:23,597 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x15080f5fc440>}
[2024-02-26 23:51:23,711][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:51:23,711][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:51:23,711][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:23,711][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:51:23,712][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:51:23,712][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:23,712][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:23,714][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:23,715][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:23,715][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:27,859][PyLogger][INFO]: Rank[0]: val_accuracy: 0.85380
[2024-02-26 23:51:27,859][PyLogger][INFO]: Rank[1]: val_accuracy: 0.85380
2024-02-26 23:51:29,309 ignite.distributed.launcher.Parallel INFO: End of run
new_size=20 done.
2024-02-26 23:51:32,979 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:51:32,980 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:51:32,980 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1494726e63e0>' in 2 processes
2024-02-26 23:51:40,741 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:51:41,145 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14c534e40140>}
[2024-02-26 23:51:41,259][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:41,259][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:41,259][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:41,268][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:51:41,269][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:51:41,269][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:41,269][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:51:41,270][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:51:41,270][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:41,270][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:45,472][PyLogger][INFO]: Rank[1]: val_accuracy: 0.84230
[2024-02-26 23:51:45,472][PyLogger][INFO]: Rank[0]: val_accuracy: 0.84230
2024-02-26 23:51:46,550 ignite.distributed.launcher.Parallel INFO: End of run
new_size=21 done.
2024-02-26 23:51:50,552 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:51:50,552 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:51:50,552 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1492184423e0>' in 2 processes
2024-02-26 23:51:57,920 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:51:58,326 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f46fdc86e0>}
[2024-02-26 23:51:58,438][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:58,438][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:58,438][PyLogger][INFO]: World size: 2
[2024-02-26 23:51:58,439][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:51:58,439][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:51:58,440][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:51:58,440][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:51:58,440][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:51:58,441][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:51:58,441][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:02,628][PyLogger][INFO]: Rank[1]: val_accuracy: 0.83250
[2024-02-26 23:52:02,628][PyLogger][INFO]: Rank[0]: val_accuracy: 0.83250
2024-02-26 23:52:04,086 ignite.distributed.launcher.Parallel INFO: End of run
new_size=22 done.
2024-02-26 23:52:07,704 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:52:07,704 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:52:07,704 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x151b6b22e3e0>' in 2 processes
2024-02-26 23:52:15,503 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:52:15,900 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154b15feb3e0>}
[2024-02-26 23:52:16,012][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:16,013][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:16,013][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:16,017][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:52:16,017][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:52:16,017][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:16,017][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:52:16,018][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:52:16,018][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:16,018][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:20,302][PyLogger][INFO]: Rank[1]: val_accuracy: 0.82530
[2024-02-26 23:52:20,302][PyLogger][INFO]: Rank[0]: val_accuracy: 0.82530
2024-02-26 23:52:21,361 ignite.distributed.launcher.Parallel INFO: End of run
new_size=23 done.
2024-02-26 23:52:25,023 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:52:25,023 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:52:25,023 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14935f8a63e0>' in 2 processes
2024-02-26 23:52:32,935 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:52:33,336 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b362434830>}
[2024-02-26 23:52:33,457][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:33,457][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:33,457][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:33,462][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:52:33,462][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:52:33,462][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:33,462][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:52:33,463][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:52:33,463][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:33,463][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:37,813][PyLogger][INFO]: Rank[1]: val_accuracy: 0.81490
[2024-02-26 23:52:37,814][PyLogger][INFO]: Rank[0]: val_accuracy: 0.81490
2024-02-26 23:52:39,313 ignite.distributed.launcher.Parallel INFO: End of run
new_size=24 done.
2024-02-26 23:52:42,861 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:52:42,861 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:52:42,861 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x15378b38e3e0>' in 2 processes
2024-02-26 23:52:50,853 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:52:51,250 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14f4295a4440>}
[2024-02-26 23:52:51,366][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:51,366][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:51,366][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:51,368][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:52:51,368][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:52:51,368][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:52:51,368][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:52:51,369][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:52:51,369][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:52:51,369][PyLogger][INFO]: World size: 2
[2024-02-26 23:52:55,828][PyLogger][INFO]: Rank[0]: val_accuracy: 0.79860
[2024-02-26 23:52:55,828][PyLogger][INFO]: Rank[1]: val_accuracy: 0.79860
2024-02-26 23:52:57,363 ignite.distributed.launcher.Parallel INFO: End of run
new_size=25 done.
2024-02-26 23:53:01,442 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:53:01,442 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:53:01,442 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1539ca81e3e0>' in 2 processes
2024-02-26 23:53:08,425 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:53:08,840 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14bfc7dfc0e0>}
[2024-02-26 23:53:08,954][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:08,954][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:08,954][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:08,958][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:53:08,958][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:53:08,959][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:08,959][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:53:08,960][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:53:08,960][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:08,960][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:13,512][PyLogger][INFO]: Rank[1]: val_accuracy: 0.78040
[2024-02-26 23:53:13,512][PyLogger][INFO]: Rank[0]: val_accuracy: 0.78040
2024-02-26 23:53:15,041 ignite.distributed.launcher.Parallel INFO: End of run
new_size=26 done.
2024-02-26 23:53:18,769 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:53:18,769 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:53:18,769 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14ccedda23e0>' in 2 processes
2024-02-26 23:53:25,686 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:53:26,099 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x153e16c5f260>}
[2024-02-26 23:53:26,212][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:53:26,212][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:53:26,212][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:26,212][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:53:26,214][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:53:26,214][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:26,214][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:26,218][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:26,218][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:26,218][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:30,834][PyLogger][INFO]: Rank[0]: val_accuracy: 0.76100
[2024-02-26 23:53:30,834][PyLogger][INFO]: Rank[1]: val_accuracy: 0.76100
2024-02-26 23:53:32,304 ignite.distributed.launcher.Parallel INFO: End of run
new_size=27 done.
2024-02-26 23:53:35,920 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:53:35,920 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:53:35,920 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x146c4a36e3e0>' in 2 processes
2024-02-26 23:53:42,803 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:53:43,353 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x1517674cc830>}
[2024-02-26 23:53:43,453][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:43,453][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:43,453][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:43,478][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:53:43,478][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:53:43,478][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:53:43,478][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:53:43,479][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:53:43,479][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:53:43,479][PyLogger][INFO]: World size: 2
[2024-02-26 23:53:48,178][PyLogger][INFO]: Rank[1]: val_accuracy: 0.74950
[2024-02-26 23:53:48,178][PyLogger][INFO]: Rank[0]: val_accuracy: 0.74950
2024-02-26 23:53:49,673 ignite.distributed.launcher.Parallel INFO: End of run
new_size=28 done.
2024-02-26 23:53:53,275 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:53:53,275 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:53:53,276 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14eb005123e0>' in 2 processes
2024-02-26 23:54:00,607 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:54:01,002 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x155005900d70>}
[2024-02-26 23:54:01,118][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:54:01,119][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:54:01,119][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:01,119][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:54:01,120][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:54:01,120][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:01,120][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:01,121][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:01,121][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:01,121][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:05,988][PyLogger][INFO]: Rank[0]: val_accuracy: 0.73010
[2024-02-26 23:54:05,988][PyLogger][INFO]: Rank[1]: val_accuracy: 0.73010
2024-02-26 23:54:07,472 ignite.distributed.launcher.Parallel INFO: End of run
new_size=29 done.
2024-02-26 23:54:11,415 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:54:11,415 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:54:11,416 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x145e51bd63e0>' in 2 processes
2024-02-26 23:54:18,338 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:54:18,815 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154296e48920>}
[2024-02-26 23:54:18,928][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:54:18,928][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:54:18,928][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:18,928][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:54:18,929][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:54:18,929][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:18,929][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:18,932][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:18,932][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:18,932][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:23,846][PyLogger][INFO]: Rank[0]: val_accuracy: 0.71190
[2024-02-26 23:54:23,846][PyLogger][INFO]: Rank[1]: val_accuracy: 0.71190
2024-02-26 23:54:25,326 ignite.distributed.launcher.Parallel INFO: End of run
new_size=30 done.
2024-02-26 23:54:29,153 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:54:29,153 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:54:29,153 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14704664e3e0>' in 2 processes
2024-02-26 23:54:37,208 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:54:37,625 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x149b63dc4200>}
[2024-02-26 23:54:37,742][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:54:37,742][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:54:37,742][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:37,742][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:54:37,743][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:54:37,743][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:37,743][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:37,744][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:37,744][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:37,744][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:42,884][PyLogger][INFO]: Rank[1]: val_accuracy: 0.68950
[2024-02-26 23:54:42,884][PyLogger][INFO]: Rank[0]: val_accuracy: 0.68950
2024-02-26 23:54:44,415 ignite.distributed.launcher.Parallel INFO: End of run
new_size=31 done.
2024-02-26 23:54:48,175 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:54:48,175 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:54:48,175 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1455fdac63e0>' in 2 processes
2024-02-26 23:54:56,332 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:54:56,761 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14d104b95ac0>}
[2024-02-26 23:54:56,874][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:54:56,874][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:54:56,874][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:56,874][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:54:56,875][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:54:56,876][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:56,876][PyLogger][INFO]: World size: 2
[2024-02-26 23:54:56,876][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:54:56,876][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:54:56,876][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:02,040][PyLogger][INFO]: Rank[1]: val_accuracy: 0.68750
[2024-02-26 23:55:02,040][PyLogger][INFO]: Rank[0]: val_accuracy: 0.68750
2024-02-26 23:55:03,582 ignite.distributed.launcher.Parallel INFO: End of run
new_size=32 done.
2024-02-26 23:55:07,126 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:55:07,126 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:55:07,126 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1511b89023e0>' in 2 processes
2024-02-26 23:55:14,338 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:55:14,750 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14fc38db6960>}
[2024-02-26 23:55:14,873][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:14,873][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:14,873][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:14,882][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:55:14,882][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:55:14,882][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:14,882][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:55:14,883][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:55:14,883][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:14,883][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:20,808][PyLogger][INFO]: Rank[1]: val_accuracy: 0.65920
[2024-02-26 23:55:20,808][PyLogger][INFO]: Rank[0]: val_accuracy: 0.65920
2024-02-26 23:55:22,363 ignite.distributed.launcher.Parallel INFO: End of run
new_size=33 done.
2024-02-26 23:55:26,354 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:55:26,354 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:55:26,354 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x1553b37ea3e0>' in 2 processes
2024-02-26 23:55:33,498 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:55:33,909 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x14b1ea6c0320>}
[2024-02-26 23:55:34,024][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:55:34,024][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:55:34,024][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:34,024][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:55:34,025][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:34,025][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:34,025][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:34,025][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:55:34,025][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:34,025][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:39,836][PyLogger][INFO]: Rank[0]: val_accuracy: 0.61130
[2024-02-26 23:55:39,836][PyLogger][INFO]: Rank[1]: val_accuracy: 0.61130
2024-02-26 23:55:41,389 ignite.distributed.launcher.Parallel INFO: End of run
new_size=34 done.
2024-02-26 23:55:45,363 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:55:45,363 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:55:45,363 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x14c442c963e0>' in 2 processes
2024-02-26 23:55:52,362 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:55:52,793 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x148e6d0002c0>}
[2024-02-26 23:55:52,908][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:52,908][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:52,908][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:52,917][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:55:52,918][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:55:52,918][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:55:52,918][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:55:52,919][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:55:52,919][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:55:52,919][PyLogger][INFO]: World size: 2
[2024-02-26 23:55:58,912][PyLogger][INFO]: Rank[1]: val_accuracy: 0.58600
[2024-02-26 23:55:58,912][PyLogger][INFO]: Rank[0]: val_accuracy: 0.58600
2024-02-26 23:56:00,033 ignite.distributed.launcher.Parallel INFO: End of run
new_size=35 done.
2024-02-26 23:56:03,540 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'nccl'
2024-02-26 23:56:03,540 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: 
	nproc_per_node: 2
	nnodes: 1
	node_rank: 0
2024-02-26 23:56:03,540 ignite.distributed.launcher.Parallel INFO: Spawn function '<function evaluation at 0x150c45cc63e0>' in 2 processes
2024-02-26 23:56:10,946 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0
2024-02-26 23:56:11,348 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': 
	{'batch_size': 512, 'num_workers': 0, 'pin_memory': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x154a58880200>}
[2024-02-26 23:56:11,462][PyLogger][INFO]: GPU device[1]: Tesla P100-SXM2-16GB
[2024-02-26 23:56:11,463][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:56:11,463][PyLogger][INFO]: World size: 2
[2024-02-26 23:56:11,465][PyLogger][INFO]: PyTorch version: 2.2.0
[2024-02-26 23:56:11,465][PyLogger][INFO]: Ignite version: 0.4.13
[2024-02-26 23:56:11,465][PyLogger][INFO]: GPU device[0]: Tesla P100-SXM2-16GB
[2024-02-26 23:56:11,465][PyLogger][INFO]: CUDA version: 12.1
[2024-02-26 23:56:11,466][PyLogger][INFO]: CUDNN version: 8902
[2024-02-26 23:56:11,466][PyLogger][INFO]: Distributed backend: nccl
[2024-02-26 23:56:11,466][PyLogger][INFO]: World size: 2
[2024-02-26 23:56:17,385][PyLogger][INFO]: Rank[0]: val_accuracy: 0.55730
[2024-02-26 23:56:17,385][PyLogger][INFO]: Rank[1]: val_accuracy: 0.55730
2024-02-26 23:56:18,908 ignite.distributed.launcher.Parallel INFO: End of run
new_size=36 done.
